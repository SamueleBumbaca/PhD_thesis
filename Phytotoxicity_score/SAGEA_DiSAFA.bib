@misc{accrediaEA402Rev03,
  title = {{{EA-4}}/02 Rev.03 - {{Evaluation}} of the {{Uncertainty}} of {{Measurement}} in Calibration},
  author = {{accredia}},
  journal = {Accredia},
  urldate = {2023-01-12},
  langid = {american},
  file = {/home/samuelebumbaca/Zotero/storage/SC83YICB/ea-4-02-rev-03-evaluation-of-the-uncertainty-of-measurement-in-calibration.html}
}

@misc{adzemovicRobotmurlockVariationalAutoEncoder2024,
  title = {Robotmurlock/{{VariationalAutoEncoder}}},
  author = {Ad{\v z}emovi{\'c}, Momir},
  year = {2024},
  month = nov,
  urldate = {2025-01-05},
  abstract = {Implementation of the Auto-Encoding Variational Bayes paper in Pytorch with detailed explanation.},
  keywords = {deep-learning,variational-autoencoder,variational-inference}
}

@misc{AgisoftMetashape2102023,
  title = {Agisoft {{Metashape}} 2.1.0},
  year = {2023},
  month = oct,
  annotation = {Published: Agisoft Metashape Software}
}

@misc{AgiSoftPhotoScanProfessional,
  title = {{{AgiSoft PhotoScan Professional}} ({{Version}} 1.2.6) ({{Software}}). (2016*). {{Retrieved}} from {{http://www.agisoft.com/downloads/installer/}}}
}

@article{agrestiAnalysisOrdinalCategorical,
  title = {Analysis of {{Ordinal Categorical Data}}},
  author = {Agresti, Alan},
  urldate = {2023-12-21},
  isbn = {9780470594001},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/T6SEVIVR/9780470594001.html}
}

@book{agrestiAnalysisOrdinalCategorical2010,
  title = {Analysis of Ordinal Categorical Data},
  author = {Agresti, Alan},
  year = {2010},
  volume = {656},
  publisher = {John Wiley \& Sons}
}

@book{agrestiFoundationsStatisticsData2021,
  title = {Foundations of {{Statistics}} for {{Data Scientists}}: {{With R}} and {{Python}}},
  shorttitle = {Foundations of {{Statistics}} for {{Data Scientists}}},
  author = {Agresti, Alan and Kateri, Maria},
  year = {2021},
  month = nov,
  edition = {1st edition},
  publisher = {{Chapman and Hall/CRC}},
  address = {Boca Raton},
  abstract = {Foundations of Statistics for Data Scientists: With R and Python is designed as a textbook for a one- or two-term introduction to mathematical statistics for students training to become data scientists. It is an in-depth presentation of the topics in statistical science with which any data scientist should be familiar, including probability distributions, descriptive and inferential statistical methods, and linear modeling. The book assumes knowledge of basic calculus, so the presentation can focus on "why it works" as well as "how to do it." Compared to traditional "mathematical statistics" textbooks, however, the book has less emphasis on probability theory and more emphasis on using software to implement statistical methods and to conduct simulations to illustrate key concepts. All statistical analyses in the book use R software, with an appendix showing the same analyses with Python.Key Features:Shows the elements of statistical science that are important for students who plan to become data scientists.Includes Bayesian and regularized fitting of models (e.g., showing an example using the lasso), classification and clustering, and implementing methods with modern software (R and Python).Contains nearly 500 exercises.The book also introduces modern topics that do not normally appear in mathematical statistics texts but are highly relevant for data scientists, such as Bayesian inference, generalized linear models for non-normal responses (e.g., logistic regression and Poisson loglinear models), and regularized model fitting. The nearly 500 exercises are grouped into "Data Analysis and Applications" and "Methods and Concepts." Appendices introduce R and Python and contain solutions for odd-numbered exercises. The book's website (http://stat4ds.rwth-aachen.de/) has expanded R, Python, and Matlab appendices and all data sets from the examples and exercises.},
  isbn = {978-0-367-74845-6},
  langid = {english}
}

@misc{alanovStyleDomainEfficientLightweight2023,
  title = {{{StyleDomain}}: {{Efficient}} and {{Lightweight Parameterizations}} of {{StyleGAN}} for {{One-shot}} and {{Few-shot Domain Adaptation}}},
  shorttitle = {{{StyleDomain}}},
  author = {Alanov, Aibek and Titov, Vadim and Nakhodnov, Maksim and Vetrov, Dmitry},
  year = {2023},
  month = sep,
  number = {arXiv:2212.10229},
  eprint = {2212.10229},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-07-23},
  abstract = {Domain adaptation of GANs is a problem of fine-tuning GAN models pretrained on a large dataset (e.g. StyleGAN) to a specific domain with few samples (e.g. painting faces, sketches, etc.). While there are many methods that tackle this problem in different ways, there are still many important questions that remain unanswered. In this paper, we provide a systematic and in-depth analysis of the domain adaptation problem of GANs, focusing on the StyleGAN model. We perform a detailed exploration of the most important parts of StyleGAN that are responsible for adapting the generator to a new domain depending on the similarity between the source and target domains. As a result of this study, we propose new efficient and lightweight parameterizations of StyleGAN for domain adaptation. Particularly, we show that there exist directions in StyleSpace (StyleDomain directions) that are sufficient for adapting to similar domains. For dissimilar domains, we propose Affine+ and AffineLight+ parameterizations that allows us to outperform existing baselines in few-shot adaptation while having significantly less training parameters. Finally, we examine StyleDomain directions and discover their many surprising properties that we apply for domain mixing and cross-domain image morphing. Source code can be found at https://github.com/AIRI-Institute/StyleDomain.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning}
}

@article{alcalaWorldTradeOrganization2020,
  title = {The {{World Trade Organization Agreement}} on the {{Application}} of {{Sanitary}} and {{Phytosanitary Measures}} and Veterinary Control Procedures.},
  author = {Alcala, R. and Vitikkala, H. and Ferlet, G.},
  year = {2020},
  month = jan,
  journal = {El Acuerdo sobre la Aplicaci{\'o}n de Medidas Sanitarias y Fitosanitarias de la Organizaci{\'o}n Mundial del Comercio y los procedimientos de control veterinario.},
  volume = {39},
  number = {1},
  pages = {253--261},
  publisher = {Organisation Mondiale de la Sante Animale},
  issn = {02531933}
}

@inproceedings{alenya3DModellingLeaves2011,
  title = {{{3D}} Modelling of Leaves from Color and {{ToF}} Data for Robotized Plant Measuring},
  booktitle = {2011 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Alenya, G. and Dellen, B. and Torras, C.},
  year = {2011},
  month = may,
  pages = {3408--3414},
  publisher = {IEEE},
  address = {Shanghai, China},
  doi = {10.1109/ICRA.2011.5980092},
  urldate = {2023-01-13},
  isbn = {978-1-61284-386-5}
}

@article{aliPredictionDryDirectseeded2014,
  title = {Prediction of Dry Direct-Seeded Rice Yields Using Chlorophyll Meter, Leaf Color Chart and {{GreenSeeker}} Optical Sensor in Northwestern {{India}}},
  author = {Ali, A.M. and Thind, H.S. and Sharma, S. and {Varinderpal-Singh}},
  year = {2014},
  month = may,
  journal = {Field Crops Research},
  volume = {161},
  pages = {11--15},
  issn = {03784290},
  doi = {10.1016/j.fcr.2014.03.001},
  urldate = {2022-09-19},
  langid = {english}
}

@article{aliUseImageAnalysis2013,
  title = {Use of {{Image Analysis}} to {{Assess Color Response}} on {{Plants Caused}} by {{Herbicide Application}}},
  author = {Ali, Asif and Streibig, Jens C. and Duus, Joachim and Andreasen, Christian},
  year = {2013},
  journal = {Weed Technology},
  volume = {27},
  number = {3},
  eprint = {43702644},
  eprinttype = {jstor},
  pages = {604--611},
  publisher = {[Cambridge University Press, Weed Science Society of America]},
  issn = {0890-037X},
  urldate = {2023-03-24},
  abstract = {In herbicide-selectivity experiments, response can be measured by visual inspection, stand counts, plant mortality, and biomass. Some response types are relative to nontreated control. We developed a nondestructive method by analyzing digital color images to quantify color changes in leaves caused by herbicides. The range of color components of green and nongreen parts of the plants and soil in Hue, Saturation, and Brightness (HSB) color space were used for segmentation. The canopy color changes of barley, winter wheat, red fescue, and brome fescue caused by doses of a glyphosate and diflufenican mixture, cycloxydim, diquat dibromide, and fluazifop-p-butyl were described with a log-logistic dose---response model, and the relationship between visual inspection and image analysis was calculated at the effective doses that cause 50\% and 90\% response (ED{$_{50}$} and ED{$_{90}$}, respectively). The ranges of HSB components for the green and nongreen parts of the plants and soil were different. The relative potencies were not significantly different from one, indicating that visual and image analysis estimations were about the same. The comparison results suggest that image analysis can be used to assess color changes of plants in response to some herbicides and may have the potential to provide an objective measurement of symptoms. En experimentos de selectividad de herbicidas, la respuesta puede ser medida mediante inspecci{\'o}n visual, conteo de plantas establecidas, mortalidad de plantas y biomasa. Algunos tipos de respuesta son relativos al testigo no-tratado. Nosotros desarrollamos un m{\'e}todo no-destructivo que analiza im{\'a}genes digitales a color para cuantificar cambios en el color de las hojas causados por herbicidas. El rango de los componentes de color de partes verdes y no-verdes de las plantas y el suelo en el {\'a}mbito de tono, saturaci{\'o}n y brillo (HSB) de color fue usado para la segmentaci{\'o}n. Los cambios en el color del dosel de cebada, trigo de invierno, Festuca rubra y Vulpia bromoides causados por dosis de una mezcla de glyphosate y diflufenican, cycloxydim, diquat dibromide, y fluazifop-p-butyl fueron descritos con un modelo log-log{\'i}stico de respuesta a dosis, y la relaci{\'o}n entre la inspecci{\'o}n visual y el an{\'a}lisis de imagen fue calculada a dosis efectivas que causaron una respuesta del 50\% y 90\% (ED{$_{50}$} y ED{$_{90}$}, respectivamente). Lo{\c s} rangos de los componentes de HSB para las partes verdes y no-verdes de las plantas y el suelo fueron diferentes. Las potencias relativas no fueron significativamente diferentes de uno, indicando que las estimaciones del an{\'a}lisis visual y del de imagen fueron casi las mismas. Los resultados de la comparaci{\'o}n sugieren que el an{\'a}lisis de imagen puede ser usado para evaluar los cambios de color de las plantas en respuesta a algunos herbicidas y podr{\'i}a tener potencial para brindar una medida objetiva de los s{\'i}ntomas.}
}

@article{aliUseImageAnalysis2013a,
  title = {Use of {{Image Analysis}} to {{Assess Color Response}} on {{Plants Caused}} by {{Herbicide Application}}},
  author = {Ali, Asif and Streibig, Jens C. and Duus, Joachim and Andreasen, Christian},
  year = {2013},
  month = sep,
  journal = {Weed Technology},
  volume = {27},
  number = {3},
  pages = {604--611},
  publisher = {Cambridge University Press},
  issn = {0890-037X, 1550-2740},
  doi = {10.1614/WT-D-12-00136.1},
  urldate = {2023-03-24},
  abstract = {In herbicide-selectivity experiments, response can be measured by visual inspection, stand counts, plant mortality, and biomass. Some response types are relative to nontreated control. We developed a nondestructive method by analyzing digital color images to quantify color changes in leaves caused by herbicides. The range of color components of green and nongreen parts of the plants and soil in Hue, Saturation, and Brightness (HSB) color space were used for segmentation. The canopy color changes of barley, winter wheat, red fescue, and brome fescue caused by doses of a glyphosate and diflufenican mixture, cycloxydim, diquat dibromide, and fluazifop-p-butyl were described with a log-logistic dose--response model, and the relationship between visual inspection and image analysis was calculated at the effective doses that cause 50\% and 90\% response (ED50 and ED90, respectively). The ranges of HSB components for the green and nongreen parts of the plants and soil were different. The relative potencies were not significantly different from one, indicating that visual and image analysis estimations were about the same. The comparison results suggest that image analysis can be used to assess color changes of plants in response to some herbicides and may have the potential to provide an objective measurement of symptoms., En experimentos de selectividad de herbicidas, la respuesta puede ser medida mediante inspecci{\'o}n visual, conteo de plantas establecidas, mortalidad de plantas y biomasa. Algunos tipos de respuesta son relativos al testigo no-tratado. Nosotros desarrollamos un m{\'e}todo no-destructivo que analiza im{\'a}genes digitales a color para cuantificar cambios en el color de las hojas causados por herbicidas. El rango de los componentes de color de partes verdes y no-verdes de las plantas y el suelo en el {\'a}mbito de tono, saturaci{\'o}n y brillo (HSB) de color fue usado para la segmentaci{\'o}n. Los cambios en el color del dosel de cebada, trigo de invierno, Festuca rubra y Vulpia bromoides causados por dosis de una mezcla de glyphosate y diflufenican, cycloxydim, diquat dibromide, y fluazifop-p-butyl fueron descritos con un modelo log-log{\'i}stico de respuesta a dosis, y la relaci{\'o}n entre la inspecci{\'o}n visual y el an{\'a}lisis de imagen fue calculada a dosis efectivas que causaron una respuesta del 50\% y 90\% (ED50 y ED90, respectivamente). Los rangos de los componentes de HSB para las partes verdes y no-verdes de las plantas y el suelo fueron diferentes. Las potencias relativas no fueron significativamente diferentes de uno, indicando que las estimaciones del an{\'a}lisis visual y del de imagen fueron casi las mismas. Los resultados de la comparaci{\'o}n sugieren que el an{\'a}lisis de imagen puede ser usado para evaluar los cambios de color de las plantas en respuesta a algunos herbicidas y podr{\'i}a tener potencial para brindar una medida objetiva de los s{\'i}ntomas.},
  langid = {english},
  keywords = {barley,brome fescue,Cycloxydim,diflufenican,diquat dibromide,Festuca rubra L.,fluazifop-p-butyl,glyphosate,Herbicide efficacy,Hordeum vulgare L.,logarithmic sprayer,red fescue,Triticum aestivum L.,visual inspection,Vulpia bromoides (L.) S.F. Gray,weeds management,wheat}
}

@article{aliUseImageAnalysis2013b,
  title = {Use of {{Image Analysis}} to {{Assess Color Response}} on {{Plants Caused}} by {{Herbicide Application}}},
  author = {Ali, Asif and Streibig, Jens C. and Duus, Joachim and Andreasen, Christian},
  year = {2013},
  journal = {Weed Technology},
  volume = {27},
  number = {3},
  eprint = {43702644},
  eprinttype = {jstor},
  pages = {604--611},
  publisher = {[Cambridge University Press, Weed Science Society of America]},
  issn = {0890-037X},
  urldate = {2023-03-24},
  abstract = {In herbicide-selectivity experiments, response can be measured by visual inspection, stand counts, plant mortality, and biomass. Some response types are relative to nontreated control. We developed a nondestructive method by analyzing digital color images to quantify color changes in leaves caused by herbicides. The range of color components of green and nongreen parts of the plants and soil in Hue, Saturation, and Brightness (HSB) color space were used for segmentation. The canopy color changes of barley, winter wheat, red fescue, and brome fescue caused by doses of a glyphosate and diflufenican mixture, cycloxydim, diquat dibromide, and fluazifop-p-butyl were described with a log-logistic dose---response model, and the relationship between visual inspection and image analysis was calculated at the effective doses that cause 50\% and 90\% response (ED{$_{50}$} and ED{$_{90}$}, respectively). The ranges of HSB components for the green and nongreen parts of the plants and soil were different. The relative potencies were not significantly different from one, indicating that visual and image analysis estimations were about the same. The comparison results suggest that image analysis can be used to assess color changes of plants in response to some herbicides and may have the potential to provide an objective measurement of symptoms. En experimentos de selectividad de herbicidas, la respuesta puede ser medida mediante inspecci{\'o}n visual, conteo de plantas establecidas, mortalidad de plantas y biomasa. Algunos tipos de respuesta son relativos al testigo no-tratado. Nosotros desarrollamos un m{\'e}todo no-destructivo que analiza im{\'a}genes digitales a color para cuantificar cambios en el color de las hojas causados por herbicidas. El rango de los componentes de color de partes verdes y no-verdes de las plantas y el suelo en el {\'a}mbito de tono, saturaci{\'o}n y brillo (HSB) de color fue usado para la segmentaci{\'o}n. Los cambios en el color del dosel de cebada, trigo de invierno, Festuca rubra y Vulpia bromoides causados por dosis de una mezcla de glyphosate y diflufenican, cycloxydim, diquat dibromide, y fluazifop-p-butyl fueron descritos con un modelo log-log{\'i}stico de respuesta a dosis, y la relaci{\'o}n entre la inspecci{\'o}n visual y el an{\'a}lisis de imagen fue calculada a dosis efectivas que causaron una respuesta del 50\% y 90\% (ED{$_{50}$} y ED{$_{90}$}, respectivamente). Lo{\c s} rangos de los componentes de HSB para las partes verdes y no-verdes de las plantas y el suelo fueron diferentes. Las potencias relativas no fueron significativamente diferentes de uno, indicando que las estimaciones del an{\'a}lisis visual y del de imagen fueron casi las mismas. Los resultados de la comparaci{\'o}n sugieren que el an{\'a}lisis de imagen puede ser usado para evaluar los cambios de color de las plantas en respuesta a algunos herbicidas y podr{\'i}a tener potencial para brindar una medida objetiva de los s{\'i}ntomas.}
}

@article{almasriImpactPrimaryInfection2017,
  title = {Impact of Primary Infection Site of {{Fusarium}} Species on Head Blight Development in Wheat Ears Evaluated by {{IR-thermography}}},
  author = {Al Masri, A. and Hau, B. and Dehne, H.-W. and Mahlein, A.-K. and Oerke, E.-C.},
  year = {2017},
  month = apr,
  journal = {European Journal of Plant Pathology},
  volume = {147},
  number = {4},
  pages = {855--868},
  issn = {1573-8469},
  doi = {10.1007/s10658-016-1051-2},
  urldate = {2023-01-13},
  abstract = {The effect of the primary infection site by Fusarium graminearum and F. culmorum within wheat ears on Fusarium head blight (FHB) was investigated under controlled conditions. FHB development was assessed visually and thermographically following inoculation by: (i) spraying ears, or injecting inoculum into spikelets on (ii) tip, (iii) centre and (iv) base of the ears, separately. Fusarium infection significantly increased the temperature span within ears 6~days post inoculation (dpi), especially infections starting at the ear tip. The temperature difference between air and ear was negatively correlated to FHB severity and enabled disease detection even 29 dpi. F. culmorum caused significant higher disease severity neither reflected in the frequency of infected kernels nor in thousand kernel weight (TKW). Spray inoculations had the strongest effect on TKW, whereas tip inoculations had no effect. Centre and base inoculations had intermediate effects on TKW, although FHB levels did not differ with the same trend among inoculation scenarios. The overall low correlations among FHB severity, infected kernels and TKW are explained by the pathogen spread within ears -- downwards more than upwards -- and the effect on yield formation which is lower for infections of the upper parts of ears. An exponential model showed high goodness of fit for gradients of infected kernels within ears (R2~{$\geq~$}70) except tip infection with F. culmorum. This study confirmed that FHB is a function of the primary infection site within ears. Thermography was useful to differentiate among infection scenarios and may be applied in breeding for FHB resistance.},
  langid = {english},
  keywords = {Fusarium culmorum,Fusarium graminearum,Fusarium head blight,Thermography,Wheat}
}

@misc{AmericanJournalBotany,
  title = {American {{Journal}} of {{Botany}}},
  urldate = {2023-01-13},
  howpublished = {https://bsapubs.onlinelibrary.wiley.com/doi/full/10.2307/2657019}
}

@misc{AnalysisOrdinalCategorical,
  title = {Analysis of {{Ordinal Categorical Data}} {\textbar} {{Wiley Series}} in {{Probability}} and {{Statistics}}},
  urldate = {2023-12-21},
  howpublished = {https://onlinelibrary.wiley.com/doi/book/10.1002/9780470594001},
  file = {/home/samuelebumbaca/Zotero/storage/TXLPXXRZ/9780470594001.html}
}

@article{aneAgricultureFourthIndustrial2019,
  title = {Agriculture in the {{Fourth Industrial Revolution}}},
  author = {Ane, Tanjea and Yasmin, Suraiya},
  year = {2019},
  month = dec,
  journal = {Annals of Bangladesh Agriculture},
  volume = {23},
  doi = {10.3329/aba.v23i2.50060},
  abstract = {Agriculture and industry are tied up and both are complementary to each other. The fourth industrial revolution is an advanced digital technology, it focuses an opportunity that could change the environment in the way human think and work. The farms and factories must implement smart technology to move very fast and it should be an innovative applications to embrace the fourth industrial revolution robustly for Bangladesh. The fourth industrial revolution concept combines artificial intelligence and big data that have achieved significant attention and popularity in precision farming like in monitoring, diagnosing insect pests, measuring soil moisture, diagnosing harvest time and monitoring crop health status and reducing complicated monitoring by human. Industry that extend precision agriculture using artificial intelligence with robotic technology in fourth industrial revolution and its application is embedding into smart observation that retrieve real-time information from field level data with minor human interference. The fourth industrial revolution builds a smart farming technology which brings advanced and sustainable changes for both production and agroprocessing. The fourth industrial revolution extends farms production and also increase their value. This paper reviewed the past effects of industrial revolution, discussed expanded benefit into smart farming and predicted impacts of fourth industrial revolution in Bangladesh agriculture.}
}

@misc{Anomaly_detection_with_embeddingsipynbColab,
  title = {Anomaly\_detection\_with\_embeddings.Ipynb - {{Colab}}},
  urldate = {2025-01-05},
  howpublished = {https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/Anomaly\_detection\_with\_embeddings.ipynb}
}

@article{ashourlooEvaluatingEffectDifferent2014,
  title = {Evaluating the {{Effect}} of {{Different Wheat Rust Disease Symptoms}} on {{Vegetation Indices Using Hyperspectral Measurements}}},
  author = {Ashourloo, Davoud and Mobasheri, Mohammad Reza and Huete, Alfredo},
  year = {2014},
  month = jun,
  journal = {Remote Sensing},
  volume = {6},
  number = {6},
  pages = {5107--5123},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2072-4292},
  doi = {10.3390/rs6065107},
  urldate = {2023-01-13},
  abstract = {Spectral Vegetation Indices (SVIs) have been widely used to indirectly detect plant diseases. The aim of this research is to evaluate the effect of different disease symptoms on SVIs and introduce suitable SVIs to detect rust disease. Wheat leaf rust is one of the prevalent diseases and has different symptoms including yellow, orange, dark brown, and dry areas. The reflectance spectrum data for healthy and infected leaves were collected using a spectroradiometer in the 450 to 1000 nm range. The ratio of the  disease-affected area to the total leaf area and the proportion of each disease symptoms were obtained using RGB digital images. As the disease severity increases, so does the scattering of all SVI values. The indices were categorized into three groups based on their accuracies in disease detection. A few SVIs showed an accuracy of more than 60\% in classification. In the first group, NBNDVI, NDVI, PRI, GI, and RVSI showed the highest amount of classification accuracy. The second and third groups showed classification accuracies of about 20\% and 40\% respectively. Results show that few indices have the ability to indirectly detect plant disease.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {hyperspectral data,vegetation index,wheat rust disease}
}

@misc{AssessingLeafPigment,
  title = {Assessing Leaf Pigment Content and Activity with a Reflectometer {\textbar} {{The New Phytologist}} {\textbar} {{Cambridge Core}}},
  urldate = {2023-01-13},
  howpublished = {https://www.cambridge.org/core/journals/new-phytologist/article/abs/assessing-leaf-pigment-content-and-activity-with-a-reflectometer/070BA29E75C935E961BABA4E1BA135D5}
}

@book{atkinsonCloseRangePhotogrammetry1996,
  title = {Close Range Photogrammetry and Machine Vision},
  editor = {Atkinson, Keith B.},
  year = {1996},
  edition = {Reprinted},
  publisher = {Whittles},
  address = {Caithness},
  isbn = {978-1-870325-73-8},
  langid = {english}
}

@article{auSkeletonExtractionMesh2008,
  title = {Skeleton Extraction by Mesh Contraction},
  author = {Au, Oscar Kin-Chung and Tai, Chiew-Lan and Chu, Hung-Kuo and {Cohen-Or}, Daniel and Lee, Tong-Yee},
  year = {2008},
  month = aug,
  journal = {ACM Transactions on Graphics},
  volume = {27},
  number = {3},
  pages = {1--10},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/1360612.1360643},
  urldate = {2024-06-10},
  abstract = {Extraction of curve-skeletons is a fundamental problem with many applications in computer graphics and visualization. In this paper, we present a simple and robust skeleton extraction method based on mesh contraction. The method works directly on the mesh domain, without pre-sampling the mesh model into a volumetric representation. The method first contracts the mesh geometry into zero-volume skeletal shape by applying implicit Laplacian smoothing with global positional constraints. The contraction does not alter the mesh connectivity and retains the key features of the original mesh. The contracted mesh is then converted into a 1D curve-skeleton through a connectivity surgery process to remove all the collapsed faces while preserving the shape of the contracted mesh and the original topology. The centeredness of the skeleton is refined by exploiting the induced skeleton-mesh mapping. In addition to producing a curve skeleton, the method generates other valuable information about the object's geometry, in particular, the skeleton-vertex correspondence and the local thickness, which are useful for various applications. We demonstrate its effectiveness in mesh segmentation and skinning animation.},
  langid = {english}
}

@article{bakerMechanisticModelsMachine2018,
  title = {Mechanistic Models versus Machine Learning, a Fight Worth Fighting for the Biological Community?},
  author = {Baker, Ruth E. and Pe{\~n}a, Jose-Maria and Jayamohan, Jayaratnam and J{\'e}rusalem, Antoine},
  year = {2018},
  month = may,
  journal = {Biology Letters},
  volume = {14},
  number = {5},
  pages = {20170660},
  publisher = {Royal Society},
  doi = {10.1098/rsbl.2017.0660},
  urldate = {2023-03-24},
  abstract = {Ninety per cent of the world's data have been generated in the last 5 years (Machine learning: the power and promise of computers that learn by example. Report no. DES4702. Issued April 2017. Royal Society). A small fraction of these data is collected with the aim of validating specific hypotheses. These studies are led by the development of mechanistic models focused on the causality of input--output relationships. However, the vast majority is aimed at supporting statistical or correlation studies that bypass the need for causality and focus exclusively on prediction. Along these lines, there has been a vast increase in the use of machine learning models, in particular in the biomedical and clinical sciences, to try and keep pace with the rate of data generation. Recent successes now beg the question of whether mechanistic models are still relevant in this area. Said otherwise, why should we try to understand the mechanisms of disease progression when we can use machine learning tools to directly predict disease outcome?},
  keywords = {machine learning,mechanistic modelling,quantitative biology}
}

@article{baoParallelStructureMotion2021,
  title = {Parallel {{Structure}} from {{Motion}} for {{Sparse Point Cloud Generation}} in {{Large-Scale Scenes}}},
  author = {Bao, Yongtang and Lin, Pengfei and Li, Yao and Qi, Yue and Wang, Zhihui and Du, Wenxiang and Fan, Qing},
  year = {2021},
  month = jun,
  journal = {Sensors},
  volume = {21},
  number = {11},
  pages = {3939},
  issn = {1424-8220},
  doi = {10.3390/s21113939},
  urldate = {2021-12-19},
  abstract = {Scene reconstruction uses images or videos as input to reconstruct a 3D model of a real scene and has important applications in smart cities, surveying and mapping, military, and other fields. Structure from motion (SFM) is a key step in scene reconstruction, which recovers sparse point clouds from image sequences. However, large-scale scenes cannot be reconstructed using a single compute node. Image matching and geometric filtering take up a lot of time in the traditional SFM problem. In this paper, we propose a novel divide-and-conquer framework to solve the distributed SFM problem. First, we use the global navigation satellite system (GNSS) information from images to calculate the GNSS neighborhood. The number of images matched is greatly reduced by matching each image to only valid GNSS neighbors. This way, a robust matching relationship can be obtained. Second, the calculated matching relationship is used as the initial camera graph, which is divided into multiple subgraphs by the clustering algorithm. The local SFM is executed on several computing nodes to register the local cameras. Finally, all of the local camera poses are integrated and optimized to complete the global camera registration. Experiments show that our system can accurately and efficiently solve the structure from motion problem in large-scale scenes.},
  langid = {english}
}

@article{barbedoDeepLearningApplied2022,
  title = {Deep Learning Applied to Plant Pathology: The Problem of Data Representativeness},
  shorttitle = {Deep Learning Applied to Plant Pathology},
  author = {Barbedo, Jayme G. A.},
  year = {2022},
  month = feb,
  journal = {Tropical Plant Pathology},
  volume = {47},
  number = {1},
  pages = {85--94},
  issn = {1983-2052},
  doi = {10.1007/s40858-021-00459-9},
  urldate = {2023-09-12},
  abstract = {The rise of deep learning techniques has profoundly impacted both research and applications of pattern and object recognition in digital images. In plant pathology, the number of scientific articles on the use of deep learning for disease classification using images has grown steadily for at least a decade and targeted most important agricultural crops. Results have been encouraging, with accuracies of many prediction models usually approaching 100\%. It is now widely accepted that, enough data being available, deep learning models can solve most of the image classification problems. However, determining what ``enough'' means in each context is far from trivial because this involves not only the number of samples used for training, but also the quality, in particular the representativeness of the dataset. More important than having a large sample size is to guarantee that all the variability associated to a given classification problem is represented in the dataset. Achieving this goal is particularly challenging for plant disease images because the agricultural environment is non-structured and highly dynamic, containing numerous variables that introduce variability to the problem. To make matters even more difficult, image annotation is time consuming and prone to inconsistencies due to its subjectivity. As a result, all studies in the literature employ datasets that represent only a fraction of the whole range of the variability, and many of these do not even acknowledge the limitations of the experimental conditions. Experiments with limited scope are valuable in the early stages of emerging research topics, but the application of deep learning to plant pathology has matured to the point where new studies need to contribute something more substantial. Unfortunately, many of the recent publications have been redundant, differing from previous research only by the adoption of slightly different experimental setups and improved model architectures. To move forward, new studies in this field need to address the data gap problem more effectively. This article delves deep into some technical and practical issues to achieve this goal and to increase the usefulness of the future studies. Although this article is dedicated primarily to proximal images, many of the remarks also hold for images captured using unmanned aerial vehicles.},
  langid = {english},
  keywords = {Disease recognition,Image analysis,Image datasets,Plant disease}
}

@article{barbedoFactorsInfluencingUse2018,
  title = {Factors Influencing the Use of Deep Learning for Plant Disease Recognition},
  author = {Barbedo, Jayme G. A.},
  year = {2018},
  month = aug,
  journal = {Biosystems Engineering},
  volume = {172},
  pages = {84--91},
  issn = {1537-5110},
  doi = {10.1016/j.biosystemseng.2018.05.013},
  urldate = {2023-12-17},
  abstract = {Deep learning is quickly becoming one of the most important tools for image classification. This technology is now beginning to be applied to the tasks of plant disease classification and recognition. The positive results that are being obtained using this approach hide some issues that are seldom taken into account in the respective experiments. This article presents an investigation into the main factors that affect the design and effectiveness of deep neural nets applied to plant pathology. An in-depth analysis of the subject, in which advantages and shortcomings are highlighted, should lead to more realistic conclusions on the subject. The arguments used throughout the text are built upon both studies found in the literature and experiments carried out using an image database carefully built to reflect and reproduce many of the conditions expected to be found in practice. This database, which contains almost 50,000 images, is being made freely available for academic purposes.},
  keywords = {Deep neural nets,Disease classification,Image database,Image processing,Transfer learning},
  file = {/home/samuelebumbaca/Zotero/storage/CDQ32AQS/S1537511018303027.html}
}

@article{barbedoNovelAlgorithmSemiautomatic2016,
  title = {A Novel Algorithm for Semi-Automatic Segmentation of Plant Leaf Disease Symptoms Using Digital Image Processing},
  author = {Barbedo, J. G. A.},
  year = {2016},
  month = aug,
  journal = {Tropical Plant Pathology},
  volume = {41},
  number = {4},
  pages = {210--224},
  issn = {1983-2052},
  doi = {10.1007/s40858-016-0090-8},
  urldate = {2023-09-11},
  abstract = {A new computer algorithm is proposed to differentiate signs and symptoms of plant disease from asymptomatic tissues in plant leaves. The simple algorithm manipulates the histograms of the H (from HSV color space) and a (from the L*a*b* color space) color channels. All steps in the algorithmic process are automatic, with the exception of the final step in which the user decides which channel (H or a) provides the better differentiation. An in-depth analysis of the problem of disease symptom differentiation is also presented, in which issues such as lesion delimitation, illumination, leaf venation interference, leaf ruggedness, among others, are thoroughly discussed. The proposed algorithm was tested under a wide variety of conditions, which included 19 plant species, 82 diseases, and images gathered under controlled and uncontrolled environmental conditions. The algorithm proved useful for a wide variety of plant diseases and conditions, although some situations may require alternative solutions.},
  langid = {english},
  keywords = {Color histograms,Color space transformations,Disease diagnosis,Leaf symptoms}
}

@article{barnhartUseHighresolutionUnmanned2021,
  title = {Use of High-Resolution Unmanned Aerial Systems Imagery and Machine Learning to Evaluate Grain Sorghum Tolerance to Mesotrione},
  author = {Barnhart, Isaac and Chaudhari, Sushila and Pandian, Balaji A. and Vara Prasad, P. V. and Ciampitti, Ignacio A. and Jugulam, Mithila},
  year = {2021},
  month = mar,
  journal = {Journal of Applied Remote Sensing},
  volume = {15},
  number = {01},
  issn = {1931-3195},
  doi = {10.1117/1.JRS.15.014516},
  urldate = {2022-09-20}
}

@article{basyouniUseNondestructiveSensors2016,
  title = {Use of {{Nondestructive Sensors}} to {{Assess Nitrogen Status}} in {{Potted Dianthus}} ({{Dianthus}} Chinensis {{L}}.) {{Production}}},
  author = {Basyouni, Rania and Dunn, Bruce and Goad, Carla},
  year = {2016},
  month = jul,
  journal = {Canadian Journal of Plant Science},
  pages = {CJPS-2016-0059},
  issn = {0008-4220, 1918-1833},
  doi = {10.1139/CJPS-2016-0059},
  urldate = {2022-09-19},
  langid = {english}
}

@article{basyouniUseNondestructiveSensors2016a,
  title = {Use of {{Nondestructive Sensors}} to {{Assess Nitrogen Status}} in {{Potted Dianthus}} ({{Dianthus}} Chinensis {{L}}.) {{Production}}},
  author = {Basyouni, Rania and Dunn, Bruce and Goad, Carla},
  year = {2016},
  month = jul,
  journal = {Canadian Journal of Plant Science},
  pages = {CJPS-2016-0059},
  issn = {0008-4220, 1918-1833},
  doi = {10.1139/CJPS-2016-0059},
  urldate = {2022-09-19},
  langid = {english}
}

@article{behmannReviewAdvancedMachine2015,
  title = {A Review of Advanced Machine Learning Methods for the Detection of Biotic Stress in Precision Crop Protection},
  author = {Behmann, Jan and Mahlein, Anne-Katrin and Rumpf, Till and R{\"o}mer, Christoph and Pl{\"u}mer, Lutz},
  year = {2015},
  month = jun,
  journal = {Precision Agriculture},
  volume = {16},
  number = {3},
  pages = {239--260},
  issn = {1573-1618},
  doi = {10.1007/s11119-014-9372-7},
  urldate = {2023-01-13},
  abstract = {Effective crop protection requires early and accurate detection of biotic stress. In recent years, remarkable results have been achieved in the early detection of weeds, plant diseases and insect pests in crops. These achievements are related both to the development of non-invasive, high resolution optical sensors and data analysis methods that are able to cope with the resolution, size and complexity of the signals from these sensors. Several methods of machine learning have been utilized for precision agriculture such as support vector machines and neural networks for classification (supervised learning); k-means and self-organizing maps for clustering (unsupervised learning). These methods are able to calculate both linear and non-linear models, require few statistical assumptions and adapt flexibly to a wide range of data characteristics. Successful applications include the early detection of plant diseases based on spectral features and weed detection based on shape descriptors with supervised or unsupervised learning methods. This review gives a short introduction into machine learning, analyses its potential for precision crop protection and provides an overview of instructive examples from different fields of precision agriculture.},
  langid = {english},
  keywords = {Data analysis,Machine learning,Optical sensors,Plant diseases,Stress detection,Weed detection}
}

@article{berdugoSensorsImagingTechniques2013,
  title = {Sensors and Imaging Techniques for the Assessment of the Delay of Wheat Senescence Induced by Fungicides},
  author = {Berdugo, Carlos Andres and Mahlein, Anne-Katrin and Steiner, Ulrike and Dehne, Heinz-Wilhelm and Oerke, Erich-Christian and Berdugo, Carlos Andres and Mahlein, Anne-Katrin and Steiner, Ulrike and Dehne, Heinz-Wilhelm and Oerke, Erich-Christian},
  year = {2013},
  month = may,
  journal = {Functional Plant Biology},
  volume = {40},
  number = {7},
  pages = {677--689},
  publisher = {CSIRO PUBLISHING},
  issn = {1445-4416, 1445-4416},
  doi = {10.1071/FP12351},
  urldate = {2023-01-13},
  abstract = {Near-range and remote sensing techniques are excellent alternatives to destructive methods for measuring beneficial effects of fungicides on plant physiology. Different noninvasive sensors and imaging techniques have been used and compared to measure the effects of three fungicidal compounds (bixafen, fluoxastrobin and prothioconazole) on wheat (Triticum aestivum L.) physiology under disease-free conditions in the greenhouse. Depending on the fungicidal treatment, changes in green leaf area and yield parameters were observed. Chlorophyll fluorescence of leaves was useful for measuring differences in the effective quantum yield of PSII. Reflectance measurements of wheat leaves were highly sensitive to changes in plant vitality. The spectral vegetation indices were useful for determining the differences among treatments in terms of leaf senescence, pigments and water content. The analysis of ear and leaf surface temperature was reliable for detecting effects of fungicides on plant senescence. Using nondestructive sensors, it was possible to assess a delay in senescence of wheat due to fungicide application. Furthermore, it was deduced that sensors and imaging methods are useful tools to estimate the effects of fungicides on wheat physiology. Physiological parameters measured by the sensors were actually more sensitive than yield parameters to assess the effect caused by fungicide application on wheat physiology.},
  langid = {english}
}

@article{bergstrasserHyperARTNoninvasiveQuantification2015,
  title = {{{HyperART}}: Non-Invasive Quantification of Leaf Traits Using Hyperspectral Absorption-Reflectance-Transmittance Imaging},
  shorttitle = {{{HyperART}}},
  author = {Bergstr{\"a}sser, Sergej and Fanourakis, Dimitrios and Schmittgen, Simone and {Cendrero-Mateo}, Maria Pilar and Jansen, Marcus and Scharr, Hanno and Rascher, Uwe},
  year = {2015},
  month = jan,
  journal = {Plant Methods},
  volume = {11},
  number = {1},
  pages = {1},
  issn = {1746-4811},
  doi = {10.1186/s13007-015-0043-0},
  urldate = {2023-01-13},
  abstract = {Combined assessment of leaf reflectance and transmittance is currently limited to spot (point) measurements. This study introduces a tailor-made hyperspectral absorption-reflectance-transmittance imaging (HyperART) system, yielding a non-invasive determination of both reflectance and transmittance of the whole leaf. We addressed its applicability for analysing plant traits, i.e. assessing Cercospora beticola disease severity or leaf chlorophyll content. To test the accuracy of the obtained data, these were compared with reflectance and transmittance measurements of selected leaves acquired by the point spectroradiometer ASD FieldSpec, equipped with the FluoWat device.},
  langid = {english},
  keywords = {Absorption,Cercospora beticola,Chlorophyll content,FieldSpec,FluoWat,Hyperspectral imaging,Imaging spectroscopy,Non-invasive phenotyping,Reflectance,Transmittance}
}

@article{bethmannSEMIGLOBALMATCHINGOBJECT2015,
  title = {{{SEMI-GLOBAL MATCHING IN OBJECT SPACE}}},
  author = {Bethmann, F. and Luhmann, T.},
  year = {2015},
  month = mar,
  journal = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  volume = {XL-3/W2},
  pages = {23--30},
  issn = {2194-9034},
  doi = {10.5194/isprsarchives-XL-3-W2-23-2015},
  urldate = {2022-11-24},
  abstract = {Semi-Global Matching (SGM) is a widespread algorithm for image matching which is used for very different applications, ranging from real-time applications (e.g. for generating 3D data for driver assistance systems) to aerial image matching. Originally developed for stereo-image matching, several extensions have been proposed to use more than two images within the matching process (multibaseline matching, multi-view stereo). These extensions still perform the image matching in (rectified) stereo images and combine the pairwise results afterwards to create the final solution. This paper proposes an alternative approach which is suitable for the introduction of an arbitrary number of images into the matching process and utilizes image matching by using non-rectified images. The new method differs from the original SGM method mainly in two aspects: Firstly, the cost calculation is formulated in object space within a dense voxel raster by using the grey (or colour) values of all images instead of pairwise cost calculation in image space. Secondly, the semi-global (path-wise) minimization process is transferred into object space as well, so that the result of semiglobal optimization leads to index maps (instead of disparity maps) which directly indicate the 3D positions of the best matches. Altogether, this yields to an essential simplification of the matching process compared to multi-view stereo (MVS) approaches. After a description of the new method, results achieved from two different datasets (close-range and aerial) are presented and discussed.},
  langid = {english}
}

@article{bingjianRobustPointSet2011,
  title = {Robust {{Point Set Registration Using Gaussian Mixture Models}}},
  author = {{Bing Jian} and Vemuri, B C},
  year = {2011},
  month = aug,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {33},
  number = {8},
  pages = {1633--1645},
  issn = {0162-8828},
  doi = {10.1109/TPAMI.2010.223},
  urldate = {2021-12-19}
}

@article{biskupStereoImagingSystem2007,
  title = {A Stereo Imaging System for Measuring Structural Parameters of Plant Canopies},
  author = {Biskup, Bernhard and Scharr, Hanno and Schurr, Ulrich and Rascher, Uwe},
  year = {2007},
  journal = {Plant, Cell \& Environment},
  volume = {30},
  number = {10},
  pages = {1299--1308},
  issn = {1365-3040},
  doi = {10.1111/j.1365-3040.2007.01702.x},
  urldate = {2023-01-13},
  abstract = {Plants constantly adapt their leaf orientation in response to fluctuations in the environment, to maintain radiation use efficiency in the face of varying intensity and incidence direction of sunlight. Various methods exist for measuring structural canopy parameters such as leaf angle distribution. However, direct methods tend to be labour-intensive, while indirect methods usually give statistical information on stand level rather than on individual leaves. We present an area-based, binocular stereo system composed of commercially available components that allows three-dimensional reconstruction of small- to medium-sized canopies on the level of single leaves under field conditions. Spatial orientation of single leaves is computed with automated processes using modern, well-established stereo matching and segmentation techniques, which were adapted for the properties of plant canopies, providing high spatial and temporal resolution (angle measurements with an accuracy of approx. {\textpm}5{$^\circ$} and a maximum sampling rate of three frames per second). The applicability of our approach is demonstrated in three case studies: (1) the dihedral leaflet angle of an individual soybean was tracked to monitor nocturnal and daytime leaf movement showing different frequencies and amplitudes; (2) drought stress was diagnosed in soybean by quantifying changes in the zenith leaflet angle distribution; and (3) the diurnal course of the zenith leaf angle distribution of a closed soybean canopy was measured.},
  langid = {english},
  keywords = {3D reconstruction,canopy,leaf movement,screening,stereo imaging,systems biology}
}

@article{blackburnHyperspectralRemoteSensing2007,
  title = {Hyperspectral Remote Sensing of Plant Pigments},
  author = {Blackburn, George Alan},
  year = {2007},
  month = mar,
  journal = {Journal of Experimental Botany},
  volume = {58},
  number = {4},
  pages = {855--867},
  issn = {0022-0957},
  doi = {10.1093/jxb/erl123},
  urldate = {2023-01-13},
  abstract = {The dynamics of pigment concentrations are diagnostic of a range of plant physiological properties and processes. This paper appraises the developing technologies and analytical methods for quantifying pigments non-destructively and repeatedly across a range of spatial scales using hyperspectral remote sensing. Progress in deriving predictive relationships between various characteristics and transforms of hyperspectral reflectance data are evaluated and the roles of leaf and canopy radiative transfer models are reviewed. Requirements are identified for more extensive intercomparisons of different approaches and for further work on the strategies for interpreting canopy scale data. The paper examines the prospects for extending research to the wider range of pigments in addition to chlorophyll, testing emerging methods of hyperspectral analysis and exploring the fusion of hyperspectral and LIDAR remote sensing. In spite of these opportunities for further development and the refinement of techniques, current evidence of an expanding range of applications in the ecophysiological, environmental, agricultural, and forestry sciences highlights the growing value of hyperspectral remote sensing of plant pigments.}
}

@article{bockDiseaseSeverityEstimates2015,
  title = {Disease {{Severity Estimates}}---{{Effects}} of {{Rater Accuracy}} and {{Assessment Methods}} for {{Comparing Treatments}}},
  author = {Bock, C. H. and El Jarroudi, M. and Kouadio, L. A. and Mackels, C. and Chiang, K.-S. and Delfosse, P.},
  year = {2015},
  month = aug,
  journal = {Plant Disease},
  volume = {99},
  number = {8},
  pages = {1104--1112},
  issn = {0191-2917, 1943-7692},
  doi = {10.1094/PDIS-09-14-0925-RE},
  urldate = {2023-09-19},
  abstract = {Assessment of disease severity is required for several purposes in plant pathology; most often, the estimates are made visually. It is established that visual estimates can be inaccurate and unreliable. The ramifications of biased or imprecise estimates by raters have not been fully explored using empirical data, partly because of the logistical difficulties involved in different raters assessing the same leaves for which actual disease has been measured in a replicated experiment with multiple treatments. In this study, nearest percent estimates (NPEs) of Septoria leaf blotch (SLB) on leaves of winter wheat from nontreated and fungicide-treated plots were assessed in both 2006 and 2007 by four raters and compared with assumed actual values measured using image analysis. Lin's concordance correlation (LCC, {$\rho$}               c               ) was used to assess agreement between the two approaches. NPEs were converted to Horsfall-Barratt (HB) midpoints and were compared with actual values. The estimates of SLB severity from fungicide-treated and nontreated plots were analyzed using generalized linear mixed modeling to ascertain effects of rater using both the NPE and HB values. Rater 1 showed good accuracy ({$\rho$}               c               = 0.986 to 0.999), while raters 3 and 4 were less accurate ({$\rho$}               c               = 0.205 to 0.936). Conversion to the HB scale had little effect on bias but reduced numerically both precision and accuracy for most raters on most assessment dates (precision, r = -0.001 to -0.132; and accuracy, {$\rho$}               c               = -0.003 to -0.468). Interrater reliability was also reduced slightly by conversion of estimates to HB midpoint values. Estimates of mean SLB severity were significantly different between image analysis and raters 2, 3, and 4, and there were frequently significant differences among raters (F = 151 to 1,260, P = 0.001 to P {$<$} 0.0001). Only on 26 June 2007 did conversion to the HB scale change the means separation ranking of rater estimates. Nonetheless, image analysis and all raters were able to differentiate control and treated-plot treatments (F = 116 to 1,952, P = 0.002 to P {$<$} 0.0001, depending on date and rater). Conversion of NPEs to the HB scale tended to reduce F values slightly (2006: NPEs, F = 116 to 276, P = 0.002 to 0.0005; and, for the HB-converted values, F = 101 to 270, P = 0.002 to 0.0005; 2007: NPEs, F = 164 to 1,952, P = 0.001 to P {$<$} 0.0001; and, for HB-converted values, F = 126 to 1,633, P = 0.002 to P {$<$} 0.0001). The results reaffirm the need for accurate and reliable disease assessment to minimize over- or underestimates compared with actual disease, and the data we present support the view that, where multiple raters are deployed, they should be assigned in a manner to reduce any potential effect of rater differences on the analysis.},
  langid = {english}
}

@article{bockPlantDiseaseSeverity2010,
  title = {Plant {{Disease Severity Estimated Visually}}, by {{Digital Photography}} and {{Image Analysis}}, and by {{Hyperspectral Imaging}}},
  author = {Bock, C. H. and Poole, G. H. and Parker, P. E. and Gottwald, T. R.},
  year = {2010},
  month = mar,
  journal = {Critical Reviews in Plant Sciences},
  volume = {29},
  number = {2},
  pages = {59--107},
  publisher = {Taylor \& Francis},
  issn = {0735-2689},
  doi = {10.1080/07352681003617285},
  urldate = {2023-01-13},
  abstract = {Reliable, precise and accurate estimates of disease severity are important for predicting yield loss, monitoring and forecasting epidemics, for assessing crop germplasm for disease resistance, and for understanding fundamental biological processes including co-evolution. Disease assessments that are inaccurate and/or imprecise might lead to faulty conclusions being drawn from the data, which in turn can lead to incorrect actions being taken in disease management decisions. Plant disease can be quantified in several different ways. This review considers plant disease severity assessment at the scale of individual plant parts or plants, and describes our current understanding of the sources and causes of assessment error, a better understanding of which is required before improvements can be targeted. The review also considers how these can be identified using various statistical tools. Indeed, great strides have been made in the last thirty years in identifying the sources of assessment error inherent to visual rating, and this review highlights ways that assessment errors can be reduced---particularly by training raters or using assessment aids. Lesion number in relation to area infected is known to influence accuracy and precision of visual estimates---the greater the number of lesions for a given area infected results in more overestimation. Furthermore, there is a widespread tendency to overestimate disease severity at low severities ({$<$}10\%). Both interrater and intrarater reliability can be variable, particularly if training or rating aids are not used. During the last eighty years acceptable accuracy and precision of visual disease assessments have often been achieved using disease scales, particularly because of the time they allegedly save, and the ease with which they can be learned, but recent work suggests there can be some disadvantages to their use. This review considers new technologies that offer opportunity to assess disease with greater objectivity (reliability, precision, and accuracy). One of these, visible light photography and digital image analysis has been increasingly used over the last thirty years, as software has become more sophisticated and user-friendly. Indeed, some studies have produced very accurate estimates of disease using image analysis. In contrast, hyperspectral imagery is relatively recent and has not been widely applied in plant pathology. Nonetheless, it offers interesting and potentially discerning opportunities to assess disease. As plant disease assessment becomes better understood, it is against the backdrop of concepts of reliability, precision and accuracy (and agreement) in plant pathology and measurement science. This review briefly describes these concepts in relation to plant disease assessment. Various advantages and disadvantages of the different approaches to disease assessment are described. For each assessment method some future research priorities are identified that would be of value in better understanding the theory of disease assessment, as it applies to improving and fully realizing the potential of image analysis and hyperspectral imagery.},
  keywords = {error,hyperspectral imagery,image analysis,plant disease assessment,remote sensing,variance}
}

@article{bockPlantDiseaseSeverity2022,
  title = {Plant Disease Severity Estimated Visually: A Century of Research, Best Practices, and Opportunities for Improving Methods and Practices to Maximize Accuracy},
  shorttitle = {Plant Disease Severity Estimated Visually},
  author = {Bock, Clive H. and Chiang, Kuo-Szu and Del Ponte, Emerson M.},
  year = {2022},
  month = feb,
  journal = {Tropical Plant Pathology},
  volume = {47},
  number = {1},
  pages = {25--42},
  issn = {1983-2052},
  doi = {10.1007/s40858-021-00439-z},
  urldate = {2023-01-13},
  abstract = {Plant disease quantification, mainly the intensity of disease symptoms on individual units (severity), is the basis for a plethora of research and applied purposes in plant pathology and related disciplines. These include evaluating treatment effect, monitoring epidemics, understanding yield loss, and phenotyping for host resistance. Although sensor technology has been available to measure disease severity using the visible spectrum or other spectral range imaging, it is visual sensing and perception that still dominates, especially in field research. Awareness of the importance of accuracy of visual estimates of severity began in 1892, when Cobb developed a set of diagrams as an aid to guide estimates of rust severity in wheat. Since that time, various approaches, some of them based on principles of psychophysics, have provided a foundation to understand sources of error during the estimation process as well as to develop different disease scales and disease-specific illustrations indicating the diseased area on specimens, similar to that developed by Cobb, and known as standard area diagrams (SADs). Several rater-related (experience, inherent ability, training) and technology-related (instruction, scales, and SADs) characteristics have been shown to affect accuracy. This review provides a historical perspective of visual severity assessment, accounting for concepts, tools, changing paradigms, and methods to maximize accuracy of estimates. A list of best-operating practices in plant disease quantification and future research on the topic is presented based on the current knowledge.},
  langid = {english}
}

@article{bockVisualEstimatesFully2020,
  title = {From Visual Estimates to Fully Automated Sensor-Based Measurements of Plant Disease Severity: Status and Challenges for Improving Accuracy},
  shorttitle = {From Visual Estimates to Fully Automated Sensor-Based Measurements of Plant Disease Severity},
  author = {Bock, Clive H. and Barbedo, Jayme G. A. and Del Ponte, Emerson M. and Bohnenkamp, David and Mahlein, Anne-Katrin},
  year = {2020},
  month = apr,
  journal = {Phytopathology Research},
  volume = {2},
  number = {1},
  pages = {9},
  issn = {2524-4167},
  doi = {10.1186/s42483-020-00049-8},
  urldate = {2023-09-07},
  abstract = {The severity of plant diseases, traditionally the proportion of the plant tissue exhibiting symptoms, is a key quantitative variable to know for many diseases and is prone to error. Good quality disease severity data should be accurate (close to the true value). Earliest quantification of disease severity was by visual estimates. Sensor-based image analysis including visible spectrum and hyperspectral and multispectral sensors are established technologies that promise to substitute, or complement visual ratings. Indeed, these technologies have measured disease severity accurately under controlled conditions but are yet to demonstrate their full potential for accurate measurement under field conditions. Sensor technology is advancing rapidly, and artificial intelligence may help overcome issues for automating severity measurement under hyper-variable field conditions. The adoption of appropriate scales, training, instruction and aids (standard area diagrams) has contributed to improved accuracy of visual estimates. The apogee of accuracy for visual estimation is likely being approached, and any remaining increases in accuracy are likely to be small. Due to automation and rapidity, sensor-based measurement offers potential advantages compared with visual estimates, but the latter will remain important for years to come. Mobile, automated sensor-based systems will become increasingly common in controlled conditions and, eventually, in the field for measuring plant disease severity for the purpose of research and decision making.},
  keywords = {Accuracy,Artificial intelligence,Assessment,Deep learning,Digital technologies,Disease severity,Machine learning,Mobile device,Phenotyping,Precision,Precision agriculture,Sensor},
  file = {/home/samuelebumbaca/Zotero/storage/Z7IXYKLV/s42483-020-00049-8.html}
}

@article{bogueRobotsPoisedRevolutionise2016,
  title = {Robots Poised to Revolutionise Agriculture},
  author = {Bogue, Robert},
  year = {2016},
  month = jan,
  journal = {Industrial Robot: An International Journal},
  volume = {43},
  number = {5},
  pages = {450--456},
  publisher = {Emerald Group Publishing Limited},
  issn = {0143-991X},
  doi = {10.1108/IR-05-2016-0142},
  urldate = {2023-01-13},
  abstract = {Purpose This paper aims to provide details of a number of recent and significant agricultural robot research and development activities. Design/methodology/approach Following an introduction, this first provides a brief overview of agricultural robot research. It then discusses a number of specific activities involving robots for precision weed control and fertiliser application. A selection of harvesting robots and allied technological developments is then considered and is followed by concluding comments. Findings Agricultural robots are the topic of an extensive research and development effort. Several autonomous robots aimed at precision weed control and fertiliser application have reached the pre-production stage. Equally, harvesting robots are at an advanced stage of development. Both classes exploit state-of-the-art machine vision and image processing technologies which are the topic of a major research effort. These developments will contribute to the forecasted rapid growth in the agricultural robot markets during the next decade. Originality/value Robots are expected to play a significant role in meeting the ever increasing demand for food, and this paper provides details of some recent agricultural robot research and development activities.},
  keywords = {Agriculture,Agrochemicals,Food production,Harvesting,Robots}
}

@article{bolanosFeasibilityEarlyYield2023,
  title = {Feasibility of {{Early Yield Prediction}} per {{Coffee Tree Based}} on {{Multispectral Aerial Imagery}}: {{Case}} of {{Arabica Coffee Crops}} in {{Cauca-Colombia}}},
  shorttitle = {Feasibility of {{Early Yield Prediction}} per {{Coffee Tree Based}} on {{Multispectral Aerial Imagery}}},
  author = {Bola{\~n}os, Julian and Corrales, Juan Carlos and Campo, Liseth Viviana},
  year = {2023},
  month = jan,
  journal = {Remote Sensing},
  volume = {15},
  number = {1},
  pages = {282},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2072-4292},
  doi = {10.3390/rs15010282},
  urldate = {2023-03-29},
  abstract = {Crop yield is an important factor for evaluating production processes and determining the profitability of growing coffee. Frequently, the total number of coffee beans per area unit is estimated manually by physically counting the coffee cherries, the branches, or the flowers. However, estimating yield requires an investment in time and work, so it is not usual for small producers. This paper studies a non-intrusive and attainable alternative to predicting coffee crop yield through multispectral aerial images. The proposal is designed for small low-tech producers monitored by capturing aerial photos with a MapIR camera on an unmanned aerial vehicle. This research shows how to predict yields in the early stages of the coffee tree productive cycle, such as at flowering by using aerial imagery. Physical and spectral descriptors were evaluated as predictors for yield prediction models. The results showed correlations between the selected predictors and 370 yield samples of a Colombian Arabica coffee crop. The coffee tree volume, the Normalized Difference Vegetation Index (NDVI), and the Coffee Ripeness Index (CRI) showed the highest values with 71\%, 55\%, and 63\%, respectively. Further, these predictors were used as the inputs for regression models to analyze their precision in predicting coffee crop yield. The validation stage concluded that Linear Regression and Stochastic Descending Gradient Regression were better models with determination coefficient values of 56\% and 55\%, respectively, which are promising for predicting yield.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {coffee,crop yield,image segmentation,MapIR,multispectral,predictor,UAV}
}

@article{borgognomondinoMultitemporalImageCoregistration2015,
  title = {Multi-Temporal Image Co-Registration Improvement for a Better Representation and Quantification of Risky Situations: The {{Belvedere Glacier}} Case Study},
  shorttitle = {Multi-Temporal Image Co-Registration Improvement for a Better Representation and Quantification of Risky Situations},
  author = {Borgogno Mondino, Enrico},
  year = {2015},
  month = jul,
  journal = {Geomatics, Natural Hazards and Risk},
  volume = {6},
  number = {5-7},
  pages = {362--378},
  publisher = {Taylor \& Francis},
  issn = {1947-5705},
  doi = {10.1080/19475705.2014.927804},
  urldate = {2023-01-25},
  abstract = {Scientific applications dealing with natural hazards make wide use of digital geographical data and change detection techniques. If the attention is focused on changes affecting surfaces' geometry, multi-temporal aerial photogrammetry can represent an effective tool. In this case, the degree of spatial coherence between measurements at different times is an important issue to deal with. Reliability and accuracy of measured differences strictly depend on the strategy used during image processing. In this paper, a simultaneous multi-temporal aerial image bundle adjustment approach (MTBA) is compared against two more traditional strategies for aerial stereo-pair adjustment to map surface changes of the Belvedere Glacier (Italian north-western Alps) in the period 2001--2003. Two aerial stereo pairs (of 2001 and 2003) were used to generate the correspondent digital surface models. These were then compared to map glacier shape differences and calculate ablation and accumulation volumes. Results demonstrate that the proposed MTBA approach improves and maximizes accuracy and reliability of measured differences also when available reference data are low quality ones. Final uncertainty for both direct (surface height differences) and derived (volume changes) measurements were quantified and mapped.}
}

@article{borgognomondinoPreliminaryConsiderationsCosts2017,
  title = {Preliminary Considerations about Costs and Potential Market of Remote Sensing from {{UAV}} in the {{Italian}} Viticulture Context},
  author = {Borgogno Mondino, E. and Gajetti, M.},
  year = {2017},
  month = jan,
  journal = {European Journal of Remote Sensing},
  volume = {50},
  number = {1},
  pages = {310--319},
  publisher = {Taylor \& Francis},
  issn = {null},
  doi = {10.1080/22797254.2017.1328269},
  urldate = {2023-03-25},
  abstract = {UAVs have already demonstrated to be effective in many fields. Nevertheless, at the moment, it is not still clear the type and the value of benefits they can provide for remote sensing purposes in agriculture. In particular, in the Italian context, this technique has still to demonstrate that derivable information can improve ordinary crop management. Furthermore, it is not still clear if costs are consistent with the ones of the agricultural sector and if any actual benefit can be really obtained. Some basic questions have to be answered: (a) are costs consistent with sector incomes? and (b) which is the related economic/environmental value? In this work reference values for UAV costs and productivity are proposed. A cost simulating model, based on both technical and economic considerations, and parameterized in respect of the size of the imaged area is proposed. Different UAV company paradigms are considered demonstrating that sustainable costs can be obtained only by making remote sensing skills internal to company. A brief discussion is also given, concerning (a) UAV potential market in the Italian viticulture context and (b) expected minimal composition that a company, basing its business on this type of service, should have.},
  keywords = {Precision viticulture,UAV,UAV cost analysis,UAV potential market,UAV productivity}
}

@article{bosConceptsTerminologyPlant1995,
  title = {Concepts and {{Terminology}} on {{Plant}}/{{Pest Relationships}}: {{Toward Consensus}} in {{Plant Pathology}} and {{Crop Protection}}},
  shorttitle = {Concepts and {{Terminology}} on {{Plant}}/{{Pest Relationships}}},
  author = {Bos, L and Parlevliet, J E},
  year = {1995},
  journal = {Annual Review of Phytopathology},
  volume = {33},
  number = {1},
  pages = {69--102},
  doi = {10.1146/annurev.py.33.090195.000441},
  urldate = {2023-01-13},
  abstract = {In plant pathology, terminological confusion still reigns despite national attempts at standardization. Terminological agreements reached within the crop protection community in The Netherlands are elaborated here and presented as an endeavor toward international consensus. Much of the on-going terminological disconcert derives from differences in outlook between academically oriented biologists (including biologically trained pathologists) and pathologists working in and for agricultural institutions where disease and harm have anthropocentric connotations. The name crop protection science more realistically covers and marks the field dealt with by most plant pathologists, and adoption of the FAO-defined term pest to encompass all biotic factors that are harmful to plants and their products is advocated. The effect of pests on plants and the interrelationships between pests and plants in dependence upon the environment, topical in resistance breeding, are especially dealt with. A diagrammatic model is used to better describe these relationships and to define the terms that denote the phenomena and mechanisms involved.},
  pmid = {18288897}
}

@article{bravoEarlyDiseaseDetection2003,
  title = {Early {{Disease Detection}} in {{Wheat Fields}} Using {{Spectral Reflectance}}},
  author = {Bravo, C{\'e}dric and Moshou, Dimitrios and West, Jonathan and McCartney, Alastair and Ramon, Herman},
  year = {2003},
  month = feb,
  journal = {Biosystems Engineering},
  volume = {84},
  number = {2},
  pages = {137--145},
  issn = {1537-5110},
  doi = {10.1016/S1537-5110(02)00269-6},
  urldate = {2023-01-13},
  abstract = {The difference in spectral reflectance between healthy and diseased wheat plants infected with Puccinia striiformis (yellow rust) was investigated. In-field spectral images were taken with a spectrograph mounted at spray boom height. A normalisation method based on reflectance and illumination adjustments was applied. To consider the entire canopy reflection, a spatially moving average was introduced. A classification model based on quadratic discrimination was built on a selected group of wavebands obtained by stepwise variable selection. Through this method, confusion rates dropped from 12 to 4\% error classification, based on four different wavebands. These results are very encouraging for the development of a cost-effective optical device for recognising diseases, such as yellow rust, in the field in early spring.},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/VYDZQ8SH/S1537511002002696.html}
}

@article{bruggerImpactCompatibleIncompatible2018,
  title = {Impact of Compatible and Incompatible Barley---{{Blumeria}} Graminis f.Sp. Hordei Interactions on Chlorophyll Fluorescence Parameters},
  author = {Brugger, Anna and Kuska, Matheus Thomas and Mahlein, Anne-Katrin},
  year = {2018},
  month = apr,
  journal = {Journal of Plant Diseases and Protection},
  volume = {125},
  number = {2},
  pages = {177--186},
  issn = {1861-3837},
  doi = {10.1007/s41348-017-0129-1},
  urldate = {2023-01-13},
  abstract = {Interactions between different barley genotypes and the fungal pathogen Blumeria graminis f.sp. hordei (Bgh) have a specific impact on the crop physiology. Within the context of plant resistance phenotyping, it is relevant to investigate early host--pathogen interactions to avoid the crop infestation. Analyzing different parameters of the photosynthesis apparatus gives in-depth information of the plant's health status and can be used for a spatial and temporal assessment of interaction types during plant--pathogen infestation. In the present study, experiments were performed with a near-isogenic line of barley cv. Ingrid WT (susceptible), mlo3 (papilla-based resistance) as well as a near-isogenic line of cv. Pallas, containing the Mla1 (hypersensitive response-based resistance) gene. After inoculation with Bgh isolate K1, the leaves were measured daily using chlorophyll fluorescence imaging. Inoculated, susceptible wild-type leaves showed a reduced effective quantum yield of the photosystem II ({$\Phi$}PSII) already 1 day after inoculation. In accordance with the quantum yield reduction, the non-photochemical quenching (NPQ) increased, indicating thermal dissipation of excess energy. The changes of {$\Phi$}PSII and NPQ represent modifications of the leaf metabolism to aid the fungal nutrition uptake, which is influenced by Bgh. By analyzing these parameters, it was also possible to indicate resistance reactions of mlo3 and Mla1 barley genotypes against Bgh. During papilla formation in mlo3 leaves, {$\Phi$}PSII revealed the lowest values. In contrast, inoculated Mla1 leaves showed the lowest NPQ. The present study proofs that chlorophyll fluorescence imaging is a valuable tool for investigating early plant--pathogen interaction noninvasively. Furthermore, this phytopathology study uses chlorophyll fluorescence imaging, chlorophyll extraction and microscopic observations to characterize the interaction response of different genotypes to an Bgh infection.},
  langid = {english},
  keywords = {Blumeria graminis f.sp. hordei,Chlorophyll fluorescence imaging,Hordeum vulgare,Host-pathogen interaction,Phenotyping}
}

@article{bumbacaSupportingScreeningNew2024,
  title = {Supporting {{Screening}} of {{New Plant Protection Products}} through a {{Multispectral Photogrammetric Approach Integrated}} with {{AI}}},
  author = {Bumbaca, Samuele and {Borgogno-Mondino}, Enrico},
  year = {2024},
  month = feb,
  journal = {Agronomy},
  volume = {14},
  number = {2},
  pages = {306},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2073-4395},
  doi = {10.3390/agronomy14020306},
  urldate = {2024-02-08},
  abstract = {This work was aimed at developing a prototype system based on multispectral digital photogrammetry to support tests required by international regulations for new Plant Protection Products (PPPs). In particular, the goal was to provide a system addressing the challenges of a new PPP evaluation with a higher degree of objectivity with respect to the current one, which relies on expert evaluations. The system uses Digital Photogrammetry, which is applied to multispectral acquisitions and Artificial Intelligence (AI). The goal of this paper is also to simplify the present screening process, moving it towards more objective and quantitative scores about phytotoxicity. The implementation of an opportunely trained AI model for phytotoxicity prediction aims to convert ordinary human visual observations, which are presently provided with a discrete scale (forbidding a variance analysis), into a continuous variable. The technical design addresses the need for a reduced dataset for training the AI model and relating discrete observations, as usually performed, to some proxy variables derived from the photogrammetric multispectral 3D model. To achieve this task, an appropriate photogrammetric multispectral system was designed. The system operates in multi-nadiral-view mode over a bench within a greenhouse exploiting an active system for lighting providing uniform and diffuse illumination. The whole system is intended to reduce the environmental variability of acquisitions tending to a standard situation. The methodology combines advanced image processing, image radiometric calibration, and machine learning techniques to predict the General Phytotoxicity percentage index (PHYGEN), a crucial measure of phytotoxicity. Results show that the system can generate reliable estimates of PHYGEN, compliant with existing accuracy standards (even from previous PPPs symptom severity models), using limited training datasets. The proposed solution addressing this challenge is the adoption of the Logistic Function with LASSO model regularization that has been shown to overcome the limitations of a small sample size (typical of new PPP trials). Additionally, it provides the estimate of a numerical continuous index (a percentage), which makes it possible to tackle the objectivity problem related to human visual evaluation that is presently based on an ordinal discrete scale. In our opinion, the proposed prototype system could have significant potential in improving the screening process for new PPPs. In fact, it works specifically for new PPPs screening and, despite this, it has an accuracy consistent with the one ordinarily accepted for human visual approaches. Additionally, it provides a higher degree of objectivity and repeatability.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {computer vision,diagnostic,digitalization,machine learning,plant protection product}
}

@article{burkartAngularDependencyHyperspectral2015,
  title = {Angular {{Dependency}} of {{Hyperspectral Measurements}} over {{Wheat Characterized}} by a {{Novel UAV Based Goniometer}}},
  author = {Burkart, Andreas and Aasen, Helge and Alonso, Luis and Menz, Gunter and Bareth, Georg and Rascher, Uwe},
  year = {2015},
  month = jan,
  journal = {Remote Sensing},
  volume = {7},
  number = {1},
  pages = {725--746},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2072-4292},
  doi = {10.3390/rs70100725},
  urldate = {2023-01-13},
  abstract = {In this study we present a hyperspectral flying goniometer system, based on a rotary-wing unmanned aerial vehicle (UAV) equipped with a spectrometer mounted on an active gimbal. We show that this approach may be used to collect multiangular hyperspectral data over vegetated environments. The pointing and positioning accuracy are assessed using structure from motion and vary from {$\sigma$} = 1{$^\circ$} to 8{$^\circ$} in pointing and {$\sigma$} = 0.7 to 0.8 m in positioning. We use a wheat dataset to investigate the influence of angular effects on the NDVI, TCARI and REIP vegetation indices. Angular effects caused significant variations on the indices: NDVI = 0.83--0.95; TCARI = 0.04--0.116; REIP = 729--735 nm. Our analysis highlights the necessity to consider angular effects in optical sensors when observing vegetation. We compare the measurements of the UAV goniometer to the angular modules of the SCOPE radiative transfer model. Model and measurements are in high accordance  (r2 = 0.88) in the infrared region at angles close to nadir; in contrast the comparison show discrepancies at low tilt angles (r2 = 0.25). This study demonstrates that the UAV goniometer is a promising approach for the fast and flexible assessment of angular effects.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {bidirectional reflectance distribution function (BRDF),goniometer,hyperspectral,unmanned aerial vehicle (UAV),vegetation,vegetation indices}
}

@article{caiReviewSemisupervisedClustering2023,
  title = {A Review on Semi-Supervised Clustering},
  author = {Cai, Jianghui and Hao, Jing and Yang, Haifeng and Zhao, Xujun and Yang, Yuqing},
  year = {2023},
  month = jun,
  journal = {Information Sciences},
  volume = {632},
  pages = {164--200},
  issn = {0020-0255},
  doi = {10.1016/j.ins.2023.02.088},
  urldate = {2025-01-13},
  abstract = {Semi-supervised clustering (SSC), a technique integrating semi-supervised learning and clustering analysis, incorporates the given prior information (e.g., class labels and pairwise constraints) into clustering to guide the clustering process and improve the performance. In recent years, a large number of valuable works have emerged, focusing on theoretical research and application in different fields. In this paper, a detailed review of SSC is provided from a new perspective. Firstly, all SSC studies are organized as partition-based SSC, hierarchical-based SSC, density-based SSC, graph-based SSC, neural network-based SSC, Nonnegative Matrix Factorization-based SSC and random subspace technique-based SSC. Thus, the semi-supervised researches can be in-depth discussed in each clustering idea. Secondly, the general overviews are detailed in each category respectively, including the performance, the suitable scenarios and the way to add supervising information. Thirdly, the recent successful applications of SSC are summarized according to different backgrounds such as medical, biological, business, journalism, financial and so on. Based on this, some application caveats and development trends of SSC are particularly given in the end. This comprehensive review and analysis of SSC can provide an overall outline, the scope of research topics, and a relative complete analysis of existing SSC methods for researchers.},
  keywords = {Constraints K-means,Constraints spectral clustering,NMF-based semi-supervised clustering,Random subspace-based semi-supervised clustering,Semi-supervised clustering,Semi-supervised fuzzy clustering},
  file = {/home/samuelebumbaca/Zotero/storage/2K44ETN5/S0020025523002840.html}
}

@book{caludeRainbowComputerScience2011,
  title = {Rainbow of {{Computer Science}}},
  editor = {Calude, Cristian S. and Rozenberg, Grzegorz and Salomaa, Arto},
  year = {2011},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {6570},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-19391-0},
  urldate = {2022-11-24},
  isbn = {978-3-642-19390-3 978-3-642-19391-0},
  langid = {english}
}

@misc{CameraCalibrationOpenCV,
  title = {Camera Calibration {{With OpenCV}} --- {{OpenCV}} 3.0.0-Dev Documentation},
  urldate = {2022-09-15},
  howpublished = {https://docs.opencv.org/3.0-beta/doc/tutorials/calib3d/camera\_calibration/camera\_calibration.html},
  file = {/home/samuelebumbaca/Zotero/storage/EIZA4XKP/camera_calibration.html}
}

@misc{cameraMAPIRCameraReflectance,
  title = {{{MAPIR Camera Reflectance Calibration Ground Target Package}} ({{V2}})},
  author = {CAMERA, {\relax MAPIR}},
  journal = {MAPIR CAMERA},
  urldate = {2022-09-15},
  abstract = {This package contains~4~ground targets that each have known reflectance curves. The target material~is composed of a felt-like~material mounted to a plastic substrate. It~can be~captured~from any angle with your~camera thanks to~similar total~and diffuse reflection properties. To use this target, before each flight tak},
  howpublished = {https://www.mapir.camera/products/mapir-camera-reflectance-calibration-ground-target-package-v2},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/64C9ABR3/mapir-camera-reflectance-calibration-ground-target-package-v2.html}
}

@misc{cameraMAPIRCameraReflectancea,
  title = {{{MAPIR Camera Reflectance Calibration Ground Target Package}} ({{V2}})},
  author = {CAMERA, {\relax MAPIR}},
  journal = {MAPIR CAMERA},
  urldate = {2022-09-05},
  abstract = {This package contains~4~ground targets that each have known reflectance curves. The target material~is composed of a felt-like~material mounted to a plastic substrate. It~can be~captured~from any angle with your~camera thanks to~similar total~and diffuse reflection properties. To use this target, before each flight tak},
  howpublished = {https://www.mapir.camera/products/mapir-camera-reflectance-calibration-ground-target-package-v2},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/7IPFRRIV/MAPIR_Camera_Reflectance_Calibration_Ground_Target_Package_Data_V2 (2).xlsx;/home/samuelebumbaca/Zotero/storage/GSJ4JRVQ/mapir-camera-reflectance-calibration-ground-target-package-v2.html}
}

@article{candiagoEvaluatingMultispectralImages2015,
  title = {Evaluating {{Multispectral Images}} and {{Vegetation Indices}} for {{Precision Farming Applications}} from {{UAV Images}}},
  author = {Candiago, Sebastian and Remondino, Fabio and De Giglio, Michaela and Dubbini, Marco and Gattelli, Mario},
  year = {2015},
  month = apr,
  journal = {Remote Sensing},
  volume = {7},
  number = {4},
  pages = {4026--4047},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2072-4292},
  doi = {10.3390/rs70404026},
  urldate = {2023-01-13},
  abstract = {Unmanned Aerial Vehicles (UAV)-based remote sensing offers great possibilities to acquire in a fast and easy way field data for precision agriculture applications. This field of study is rapidly increasing due to the benefits and advantages for farm resources management, particularly for studying crop health. This paper reports some experiences related to the analysis of cultivations (vineyards and tomatoes) with Tetracam multispectral data. The Tetracam camera was mounted on a multi-rotor hexacopter. The multispectral data were processed with a photogrammetric pipeline to create triband orthoimages of the surveyed sites. Those orthoimages were employed to extract some Vegetation Indices (VI) such as the Normalized Difference Vegetation Index (NDVI), the Green Normalized Difference Vegetation Index (GNDVI), and the Soil Adjusted Vegetation Index (SAVI), examining the vegetation vigor for each crop. The paper demonstrates the great potential of high-resolution UAV data and photogrammetric techniques applied in the agriculture framework to collect multispectral images and evaluate different VI, suggesting that these instruments represent a fast, reliable, and  cost-effective resource in crop assessment for precision farming applications.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {agriculture,crops,multispectral,photogrammetry,unmanned aerial vehicles,vegetation,vegetation indices}
}

@article{carellaIntegratedTentativeRemotesensing2022,
  title = {An Integrated, Tentative Remote-Sensing Approach Based on {{NDVI}} Entropy to Model Canine Distemper Virus in Wildlife and to Prompt Science-Based Management Policies},
  author = {Carella, Emanuele and Orusa, Tommaso and Viani, Annalisa and Meloni, Daniela and {Borgogno-Mondino}, Enrico and Orusa, Riccardo},
  year = {2022},
  journal = {Animals},
  volume = {12},
  number = {8},
  pages = {1049}
}

@article{carterLeafOpticalProperties2001,
  title = {Leaf Optical Properties in Higher Plants: Linking Spectral Characteristics to Stress and Chlorophyll Concentration},
  shorttitle = {Leaf Optical Properties in Higher Plants},
  author = {Carter, Gregory A. and Knapp, Alan K.},
  year = {2001},
  journal = {American Journal of Botany},
  volume = {88},
  number = {4},
  pages = {677--684},
  issn = {1537-2197},
  doi = {10.2307/2657068},
  urldate = {2023-12-17},
  abstract = {A number of studies have linked responses in leaf spectral reflectance, transmittance, or absorptance to physiological stress. A variety of stressors including dehydration, flooding, freezing, ozone, herbicides, competition, disease, insects, and deficiencies in ectomycorrhizal development and N fertilization have been imposed on species ranging from grasses to conifers and deciduous trees. In all cases, the maximum difference in reflectance within the 400--850 nm wavelength range between control and stressed states occurred as a reflectance increase at wavelengths near 700 nm. In studies that included transmittance and absorptance as well as reflectance, maximum differences occurred as increases and decreases, respectively, near 700 nm. This common optical response to stress could be simulated closely by varying the chlorophyll concentration of model leaves (fiberglass filter pads) and by the natural variability in leaf chlorophyll concentrations in senescent leaves of five species. The optical response to stress near 700 nm, as well as corresponding changes in reflectance that occur in the green--yellow spectrum, can be explained by the general tendency of stress to reduce leaf chlorophyll concentration.},
  copyright = {{\copyright} 2001 Botanical Society of America},
  langid = {english},
  keywords = {absorptance,chlorophyll,leaf optics,light,reflectance,stress,transmittance},
  file = {/home/samuelebumbaca/Zotero/storage/24S6D35Q/2657068.html}
}

@article{carterLeafOpticalProperties2001a,
  title = {Leaf Optical Properties in Higher Plants: Linking Spectral Characteristics to Stress and Chlorophyll Concentration},
  shorttitle = {Leaf Optical Properties in Higher Plants},
  author = {Carter, Gregory A. and Knapp, Alan K.},
  year = {2001},
  journal = {American Journal of Botany},
  volume = {88},
  number = {4},
  pages = {677--684},
  issn = {1537-2197},
  doi = {10.2307/2657068},
  urldate = {2023-01-13},
  abstract = {A number of studies have linked responses in leaf spectral reflectance, transmittance, or absorptance to physiological stress. A variety of stressors including dehydration, flooding, freezing, ozone, herbicides, competition, disease, insects, and deficiencies in ectomycorrhizal development and N fertilization have been imposed on species ranging from grasses to conifers and deciduous trees. In all cases, the maximum difference in reflectance within the 400--850 nm wavelength range between control and stressed states occurred as a reflectance increase at wavelengths near 700 nm. In studies that included transmittance and absorptance as well as reflectance, maximum differences occurred as increases and decreases, respectively, near 700 nm. This common optical response to stress could be simulated closely by varying the chlorophyll concentration of model leaves (fiberglass filter pads) and by the natural variability in leaf chlorophyll concentrations in senescent leaves of five species. The optical response to stress near 700 nm, as well as corresponding changes in reflectance that occur in the green--yellow spectrum, can be explained by the general tendency of stress to reduce leaf chlorophyll concentration.},
  copyright = {{\copyright} 2001 Botanical Society of America},
  langid = {english},
  keywords = {absorptance,chlorophyll,leaf optics,light,reflectance,stress,transmittance}
}

@article{carterResponsesLeafSpectral1993,
  title = {Responses of {{Leaf Spectral Reflectance}} to {{Plant Stress}}},
  author = {Carter, Gregory A.},
  year = {1993},
  journal = {American Journal of Botany},
  volume = {80},
  number = {3},
  pages = {239--243},
  issn = {1537-2197},
  doi = {10.1002/j.1537-2197.1993.tb13796.x},
  urldate = {2023-03-24},
  abstract = {Leaf spectral reflectances were measured to determine whether leaf reflectance responses to plant stress may differ according to the agent of stress and species. As a result of decreased absorption by pigments, reflectance at visible wavelengths increased consistently in stressed leaves for eight stress agents and among six vascular plant species. Visible reflectance was most sensitive to stress in the 535--640-nm and 685--700-nm wavelength ranges. A sensitivity minimum occurred consistently near 670 nm. Infrared reflectance was comparatively unresponsive to stress, but increased at 1,400--2,500 nm with severe leaf dehydration and the accompanying decreased absorption by water. Thus, visible rather than infrared reflectance was the most reliable indicator of plant stress. Visible reflectance responses to stress were spectrally similar among agents of stress and species.},
  copyright = {{\copyright} 1993 Botanical Society of America},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/2LDWY6TA/j.1537-2197.1993.tb13796.html}
}

@article{castillo-martinezColorIndexBased2020,
  title = {Color Index Based Thresholding Method for Background and Foreground Segmentation of Plant Images},
  author = {{Castillo-Mart{\'i}nez}, Miguel {\'A}. and {Gallegos-Funes}, Francisco J. and {Carvajal-G{\'a}mez}, Blanca E. and {Urriolagoitia-Sosa}, Guillermo and {Rosales-Silva}, Alberto J.},
  year = {2020},
  month = nov,
  journal = {Computers and Electronics in Agriculture},
  volume = {178},
  pages = {105783},
  issn = {0168-1699},
  doi = {10.1016/j.compag.2020.105783},
  urldate = {2022-12-05},
  abstract = {In this paper, the color index based thresholding method for background and foreground segmentation of plant images is presented. The proposed method is implemented with color index approach, for this purpose two color indexes are modified to provide better information about the green color of the plants. Two fixed threshold methods are proposed for the color indexes to discriminate between foreground (green plant) and background (soil). Three versions of the proposed method are presented, these are applied in plant images with controlled conditions and crop images with real environmental conditions. Experimental results demonstrate that the proposed method outperforms other algorithms used as comparative in plant images obtaining a segmentation error of 6.62~{\textpm}~5.85\% and a classification ratio of 1.93~{\textpm}~0.05. Also, the proposed method provides better segmentation results in comparison with other well-known state-of-art algorithms in different crop images. Finally, the proposed method does not require of complex calculus and their implementations are straightforward on any device.},
  langid = {english},
  keywords = {Color index,Green plants,Segmentation,Threshold method},
  file = {/home/samuelebumbaca/Zotero/storage/J8XIGRJ9/S0168169919306398.html}
}

@misc{chadebecDataAugmentationHigh2022,
  title = {Data Augmentation in High Dimensional Low Sample Size Setting Using a Geometry-Based Variational Autoencoder},
  author = {Chadebec, Cl{\'e}ment and {Thibeau-Sutre}, Elina and Burgos, Ninon and Allassonni{\`e}re, St{\'e}phanie},
  year = {2022},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  urldate = {2025-01-05},
  abstract = {Data Augmentation with Variational Autoencoders (TPAMI)},
  copyright = {Apache-2.0}
}

@inproceedings{chadebecDataAugmentationVariational2021,
  title = {Data {{Augmentation}} with {{Variational Autoencoders}} and {{Manifold Sampling}}},
  booktitle = {Deep {{Generative Models}}, and {{Data Augmentation}}, {{Labelling}}, and {{Imperfections}}},
  author = {Chadebec, Cl{\'e}ment and Allassonni{\`e}re, St{\'e}phanie},
  editor = {Engelhardt, Sandy and Oksuz, Ilkay and Zhu, Dajiang and Yuan, Yixuan and Mukhopadhyay, Anirban and Heller, Nicholas and Huang, Sharon Xiaolei and Nguyen, Hien and Sznitman, Raphael and Xue, Yuan},
  year = {2021},
  pages = {184--192},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-88210-5_17},
  abstract = {We propose a new efficient way to sample from a Variational Autoencoder in the challenging low sample size setting (A code is available at https://github.com/clementchadebec/Data\_Augmentation\_with\_VAE-DALI). This method reveals particularly well suited to perform data augmentation in such a low data regime and is validated across various standard and real-life data sets. In particular, this scheme allows to greatly improve classification results on the OASIS database where balanced accuracy jumps from 80.7\% for a classifier trained with the raw data to 88.6\% when trained only with the synthetic data generated by our method. Such results were also observed on 3 standard data sets and with other classifiers.},
  isbn = {978-3-030-88210-5},
  langid = {english},
  keywords = {Data augmentation,Latent space modelling,VAE}
}

@article{chaerleImagingTechniquesEarly2000,
  title = {Imaging Techniques and the Early Detection of Plant Stress},
  author = {Chaerle, Laury and Straeten, Dominique Van Der},
  year = {2000},
  month = nov,
  journal = {Trends in Plant Science},
  volume = {5},
  number = {11},
  pages = {495--501},
  publisher = {Elsevier},
  issn = {1360-1385},
  doi = {10.1016/S1360-1385(00)01781-7},
  urldate = {2023-01-13},
  langid = {english},
  pmid = {11077259}
}

@article{chaudhurySkeletonizationPlantPoint2020,
  title = {Skeletonization of {{Plant Point Cloud Data Using Stochastic Optimization Framework}}},
  author = {Chaudhury, Ayan and Godin, Christophe},
  year = {2020},
  month = jun,
  journal = {Frontiers in Plant Science},
  volume = {11},
  pages = {773},
  issn = {1664-462X},
  doi = {10.3389/fpls.2020.00773},
  urldate = {2021-12-18}
}

@article{chebroluRegistrationSpatiotemporalPoint2021,
  title = {Registration of Spatio-Temporal Point Clouds of Plants for Phenotyping},
  author = {Chebrolu, Nived and Magistri, Federico and L{\"a}be, Thomas and Stachniss, Cyrill},
  editor = {Agudo, Antonio},
  year = {2021},
  month = feb,
  journal = {PLOS ONE},
  volume = {16},
  number = {2},
  pages = {e0247243},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0247243},
  urldate = {2021-12-18},
  abstract = {Plant phenotyping is a central task in crop science and plant breeding. It involves measuring plant traits to describe the anatomy and physiology of plants and is used for deriving traits and evaluating plant performance. Traditional methods for phenotyping are often time-consuming operations involving substantial manual labor. The availability of 3D sensor data of plants obtained from laser scanners or modern depth cameras offers the potential to automate several of these phenotyping tasks. This automation can scale up the phenotyping measurements and evaluations that have to be performed to a larger number of plant samples and at a finer spatial and temporal resolution. In this paper, we investigate the problem of registering 3D point clouds of the plants over time and space. This means that we determine correspondences between point clouds of plants taken at different points in time and register them using a new, non-rigid registration approach. This approach has the potential to form the backbone for phenotyping applications aimed at tracking the traits of plants over time. The registration task involves finding data associations between measurements taken at different times while the plants grow and change their appearance, allowing 3D models taken at different points in time to be compared with each other. Registering plants over time is challenging due to its anisotropic growth, changing topology, and non-rigid motion in between the time of the measurements. Thus, we propose a novel approach that first extracts a compact representation of the plant in the form of a skeleton that encodes both topology and semantic information, and then use this skeletal structure to determine correspondences over time and drive the registration process. Through this approach, we can tackle the data association problem for the time-series point cloud data of plants effectively. We tested our approach on different datasets acquired over time and successfully registered the 3D plant point clouds recorded with a laser scanner. We demonstrate that our method allows for developing systems for automated temporal plant-trait analysis by tracking plant traits at an organ level.},
  langid = {english}
}

@article{cheneUseDepthCamera2012,
  title = {On the Use of Depth Camera for {{3D}} Phenotyping of Entire Plants},
  author = {Ch{\'e}n{\'e}, Yann and Rousseau, David and Lucidarme, Philippe and Bertheloot, Jessica and Caffier, Val{\'e}rie and Morel, Philippe and Belin, {\'E}tienne and {Chapeau-Blondeau}, Fran{\c c}ois},
  year = {2012},
  month = mar,
  journal = {Computers and Electronics in Agriculture},
  volume = {82},
  pages = {122--127},
  issn = {01681699},
  doi = {10.1016/j.compag.2011.12.007},
  urldate = {2023-03-24},
  abstract = {In this article, we assess the potential of depth imaging systems for 3D measurements in the context of plant phenotyping. We propose an original algorithm to segment depth images of plant from a single topview. Various applications of biological interest involving for illustration rosebush, yucca and apple tree are then presented to demonstrate the practical interest of such imaging systems. In addition, the depth camera used here is very low cost and low weight. The present results therefore open interesting perspectives in the direction of high-throughput phenotyping in controlled environment or in field conditions. {\'O} 2012 Elsevier B.V. All rights reserved.},
  langid = {english}
}

@misc{chenGridMaskDataAugmentation2024,
  title = {{{GridMask Data Augmentation}}},
  author = {Chen, Pengguang and Liu, Shu and Zhao, Hengshuang and Wang, Xingquan and Jia, Jiaya},
  year = {2024},
  month = feb,
  number = {arXiv:2001.04086},
  eprint = {2001.04086},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2001.04086},
  urldate = {2025-01-07},
  abstract = {We propose a novel data augmentation method `GridMask' in this paper. It utilizes information removal to achieve state-of-the-art results in a variety of computer vision tasks. We analyze the requirement of information dropping. Then we show limitation of existing information dropping algorithms and propose our structured method, which is simple and yet very effective. It is based on the deletion of regions of the input image. Our extensive experiments show that our method outperforms the latest AutoAugment, which is way more computationally expensive due to the use of reinforcement learning to find the best policies. On the ImageNet dataset for recognition, COCO2017 object detection, and on Cityscapes dataset for semantic segmentation, our method all notably improves performance over baselines. The extensive experiments manifest the effectiveness and generality of the new method.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/samuelebumbaca/Zotero/storage/HR8TXRAZ/2001.html}
}

@article{chiangEffectsRaterBias2016,
  title = {Effects of Rater Bias and Assessment Method on Disease Severity Estimation with Regard to Hypothesis Testing},
  author = {Chiang, K. S. and Bock, C. H. and El Jarroudi, M. and Delfosse, P. and Lee, I. H. and Liu, H. I.},
  year = {2016},
  journal = {Plant Pathology},
  volume = {65},
  number = {4},
  pages = {523--535},
  issn = {1365-3059},
  doi = {10.1111/ppa.12435},
  urldate = {2023-09-12},
  abstract = {The effects of bias (over- and underestimates) in estimates of disease severity on hypothesis testing using different assessment methods was explored. Nearest percentage estimates (NPE), the Horsfall--Barratt (H-B) scale, and two linear category scales (10\% increments, with and without additional grades at low severity) were compared using simulation modelling to assess effects of bias. Type I and type II error rates were used to compare two treatment differences. The power of the H-B scale and the 10\% scale were least for correctly testing a hypothesis compared with the other methods, and the effects of rater bias on type II errors were greater over specific severity ranges. Apart from NPEs, the amended 10\% category scale was most often superior to other methods at all severities tested for reducing the risk of type II errors. It should thus be a preferred method for raters who must use a category scale for disease assessments. Rater bias and assessment method had little effect on type I error rates. The power of the hypothesis test using unbiased estimates was most often greater compared with biased estimates, regardless of assessment method. An unanticipated observation was the greater impact of rater bias compared with assessment method on type II errors. Knowledge of the effects of rater bias and scale type on hypothesis testing can be used to improve accuracy and reliability of disease severity estimates, and can provide a logical framework for improving aids to estimate severity visually, including standard area diagrams and rater training software.},
  copyright = {{\copyright} 2015 British Society for Plant Pathology},
  langid = {english},
  keywords = {phytopathometry,plant disease quantification,rating scales},
  file = {/home/samuelebumbaca/Zotero/storage/M756UVLC/ppa.html}
}

@article{chiangUnderstandingRamificationsQuantitative2022,
  title = {Understanding the Ramifications of Quantitative Ordinal Scales on Accuracy of Estimates of Disease Severity and Data Analysis in Plant Pathology},
  author = {Chiang, Kuo-Szu and Bock, Clive H.},
  year = {2022},
  month = feb,
  journal = {Tropical Plant Pathology},
  volume = {47},
  number = {1},
  pages = {58--73},
  issn = {1983-2052},
  doi = {10.1007/s40858-021-00446-0},
  urldate = {2023-09-12},
  abstract = {The severity of plant diseases, traditionally defined as the proportion of the plant tissue exhibiting symptoms, is a key quantitative variable to know for many diseases but is prone to error. Plant pathologists face many situations in which the measurement by nearest percent estimates (NPEs) of disease severity is time-consuming or impractical. Moreover, rater NPEs of disease severity are notoriously variable. Therefore, NPEs of disease may be of questionable value if severity cannot be determined accurately and reliably. In such situations, researchers have often used a quantitative ordinal scale of measurement---often alleging the time saved, and the ease with which the scale can be learned. Because quantitative ordinal disease scales lack the resolution of the 0 to 100\% scale, they are inherently less accurate. We contend that scale design and structure have ramifications for the resulting analysis of data from the ordinal scale data. To minimize inaccuracy and ensure that there is equivalent statistical power when using quantitative ordinal scale data, design of the scales can be optimized for use in the discipline of plant pathology. In this review, we focus on the nature of quantitative ordinal scales used in plant disease assessment. Subsequently, their application and effects will be discussed. Finally, we will review how to optimize quantitative ordinal scales design to allow sufficient accuracy of estimation while maximizing power for hypothesis testing.},
  langid = {english},
  keywords = {Calculation of the interval range,Nearest percent estimates,Plant disease assessment,Scale design}
}

@article{CHLOROPHYLLMETERSPAD502Plus,
  title = {{{CHLOROPHYLL METER SPAD-502Plus}}},
  pages = {4},
  langid = {english}
}

@article{choiIterativeKClosestPoint2020,
  title = {Iterative {{K-Closest Point Algorithms}} for {{Colored Point Cloud Registration}}},
  author = {Choi, Ouk and Park, Min-Gyu and Hwang, Youngbae},
  year = {2020},
  month = sep,
  journal = {Sensors},
  volume = {20},
  number = {18},
  pages = {5331},
  issn = {1424-8220},
  doi = {10.3390/s20185331},
  urldate = {2021-12-19},
  abstract = {We present two algorithms for aligning two colored point clouds. The two algorithms are designed to minimize a probabilistic cost based on the color-supported soft matching of points in a point cloud to their K-closest points in the other point cloud. The first algorithm, like prior iterative closest point algorithms, refines the pose parameters to minimize the cost. Assuming that the point clouds are obtained from RGB-depth images, our second algorithm regards the measured depth values as variables and minimizes the cost to obtain refined depth values. Experiments with our synthetic dataset show that our pose refinement algorithm gives better results compared to the existing algorithms. Our depth refinement algorithm is shown to achieve more accurate alignments from the outputs of the pose refinement step. Our algorithms are applied to a real-world dataset, providing accurate and visually improved results.},
  langid = {english}
}

@article{chuHyperspectralImagingShallow2022,
  title = {Hyperspectral Imaging with Shallow Convolutional Neural Networks ({{SCNN}}) Predicts the Early Herbicide Stress in Wheat Cultivars},
  author = {Chu, Hangjian and Zhang, Chu and Wang, Mengcen and Gouda, Mostafa and Wei, Xinhua and He, Yong and Liu, Yufei},
  year = {2022},
  month = jan,
  journal = {Journal of Hazardous Materials},
  volume = {421},
  pages = {126706},
  issn = {0304-3894},
  doi = {10.1016/j.jhazmat.2021.126706},
  urldate = {2023-12-17},
  abstract = {The toxicity impacts of herbicides on crop, animals, and human are big problems global wide. The rapid and non-invasive ways for assessing herbicide-responsible effects on crop growth regarding types and levels still remain unexplored. In this study, visible/near infrared hyperspectral imaging (Vis/NIR HSI) coupled with SCNN was used to reveal the different characteristics in the spectral reflectance of 2 varieties of wheat seedling leaves that were subjected to 4 stress levels of 3 herbicide types during 4 stress durations and make early herbicide stress prediction. The first-order derivative results showed the spectral reflectance exhibited obvious differences at 518--531~nm, 637--675~nm and the red-edge. A SCNN model with attention mechanism (SCNN-ATT) was proposed for herbicide type and level classification of different stress durations. Further, a SCNN-based feature selection model (SCNN-FS) was proposed to screen out the characteristic wavelengths. The proposed methods achieved 96\% accuracy of herbicide type classification and around 80\% accuracy of stress level classification for both wheat varieties after 48~h. Overall, this study illustrated the potential of using Vis/NIR HSI to rapidly distinguish different herbicide types and serial levels in wheat at an early stage, which held great value for developing on-line herbicide stress recognizing methods in the field.},
  keywords = {Crops,Deep learning,Herbicide toxicity,Hyperspectral technology,Prediction model},
  file = {/home/samuelebumbaca/Zotero/storage/XJTU4CZJ/S030438942101671X.html}
}

@misc{ClarkeAdvancesGeographic,
  title = {Clarke: {{Advances}} in Geographic Information Systems - {{Google Scholar}}},
  urldate = {2023-01-13},
  howpublished = {https://scholar.google.com/scholar\_lookup?hl=en\&volume=10\&publication\_year=1986\&pages=175-84\&journal=\%00null\%00\&issue=3\%E2\%80\%934\&issn=\%00null\%00\&author=KC+Clarke\&title=Advances+in+geographic+information+systems\&pmid=\%00empty\%00\&doi=\%00empty\%00}
}

@article{curranRemoteSensingFoliar1989,
  title = {Remote Sensing of Foliar Chemistry},
  author = {Curran, Paul J},
  year = {1989},
  month = dec,
  journal = {Remote Sensing of Environment},
  volume = {30},
  number = {3},
  pages = {271--278},
  issn = {0034-4257},
  doi = {10.1016/0034-4257(89)90069-2},
  urldate = {2023-01-13},
  abstract = {Remotely sensed data are being used to estimate foliar chemical content as a result of our need for the information and our increasing ability to understand and measure foliar spectra. This paper reviews how stepwise multiple regression and deconvolution have been used to extract chemical information from foliar spectra, and concludes that both methods are useful, but neither is ideal. It is recommended that the focus of research be modeling in the long term and experimentation in the short term. Long-term research should increase our understanding of the interaction between radiation and foliar chemistry so that the focus of research can move from leaf model to canopy model to field experiment. Short-term research should aim to design experiments in which remotely sensed data are used to generate unambiguous and accurate estimates of foliar chemical content.},
  langid = {english}
}

@article{daleyTopographyPhotosyntheticActivity1989,
  title = {Topography of {{Photosynthetic Activity}} of {{Leaves Obtained}} from {{Video Images}} of {{Chlorophyll Fluorescence}} 1},
  author = {Daley, Paul F. and Raschke, Klaus and Ball, J. Timothy and Berry, Joseph A.},
  year = {1989},
  month = aug,
  journal = {Plant Physiology},
  volume = {90},
  number = {4},
  pages = {1233--1238},
  issn = {0032-0889},
  doi = {10.1104/pp.90.4.1233},
  urldate = {2022-01-13},
  abstract = {The distribution of photosynthetic activity over the area of a leaf and its change with time was determined (at low partial pressure of O2) by recording images of chlorophyll fluorescence during saturating light flashes. Simultaneously, the gas exchange was being measured. Reductions of local fluorescence intensity quantitatively displayed the extent of nonphotochemical quenching; quench coefficients, q ~N, were computed pixel by pixel. Because rates of photosynthetic electron transport are positively correlated with (1 - q ~N), computed images of (1 - q ~N) represented topographies of photosynthetic activity. Following application of abscisic acid to the heterobaric leaves of Xanthium strumarium L., clearly delineated regions varying in nonphotochemical quenching appeared that coincided with areoles formed by minor veins and indicated stomatal closure in groups.}
}

@article{darkoPhotosynthesisArtificialLight2014,
  title = {Photosynthesis under Artificial Light: The Shift in Primary and Secondary Metabolism},
  shorttitle = {Photosynthesis under Artificial Light},
  author = {Darko, Eva and Heydarizadeh, Parisa and Schoefs, Beno{\^i}t and Sabzalian, Mohammad R.},
  year = {2014},
  month = apr,
  journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  volume = {369},
  number = {1640},
  pages = {20130243},
  issn = {0962-8436, 1471-2970},
  doi = {10.1098/rstb.2013.0243},
  urldate = {2021-12-18},
  abstract = {Providing an adequate quantity and quality of food for the escalating human population under changing climatic conditions is currently a great challenge. In outdoor cultures, sunlight provides energy (through photosynthesis) for photosynthetic organisms. They also use light quality to sense and respond to their environment. To increase the production capacity, controlled growing systems using artificial lighting have been taken into consideration. Recent development of light-emitting diode (LED) technologies presents an enormous potential for improving plant growth and making systems more sustainable. This review uses selected examples to show how LED can mimic natural light to ensure the growth and development of photosynthetic organisms, and how changes in intensity and wavelength can manipulate the plant metabolism with the aim to produce functionalized foods.},
  langid = {english}
}

@article{deeryProximalRemoteSensing2014,
  title = {Proximal {{Remote Sensing Buggies}} and {{Potential Applications}} for {{Field-Based Phenotyping}}},
  author = {Deery, David and {Jimenez-Berni}, Jose and Jones, Hamlyn and Sirault, Xavier and Furbank, Robert},
  year = {2014},
  month = sep,
  journal = {Agronomy},
  volume = {4},
  number = {3},
  pages = {349--379},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2073-4395},
  doi = {10.3390/agronomy4030349},
  urldate = {2023-01-13},
  abstract = {The achievements made in genomic technology in recent decades are yet to be matched by fast and accurate crop phenotyping methods. Such crop phenotyping methods are required for crop improvement efforts to meet expected demand for food and fibre in the future. This review evaluates the role of proximal remote sensing buggies for field-based phenotyping with a particular focus on the application of currently available sensor technology for large-scale field phenotyping. To illustrate the potential for the development of high throughput phenotyping techniques, a case study is presented with sample data sets obtained from a ground-based proximal remote sensing buggy mounted with the following sensors: LiDAR, RGB camera, thermal infra-red camera and imaging spectroradiometer. The development of such techniques for routine deployment in commercial-scale breeding and pre-breeding operations will require a multidisciplinary approach to leverage the recent technological advances realised in computer science, image analysis, proximal remote sensing and robotics.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {chlorophyll fluorescence,data processing,field experiments,hyperspectral,image analysis,LiDAR,RGB camera,thermal imaging,time of flight,wheat}
}

@article{deeryProximalRemoteSensing2014a,
  title = {Proximal {{Remote Sensing Buggies}} and {{Potential Applications}} for {{Field-Based Phenotyping}}},
  author = {Deery, David and {Jimenez-Berni}, Jose and Jones, Hamlyn and Sirault, Xavier and Furbank, Robert},
  year = {2014},
  month = sep,
  journal = {Agronomy},
  volume = {4},
  number = {3},
  pages = {349--379},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2073-4395},
  doi = {10.3390/agronomy4030349},
  urldate = {2023-01-13},
  abstract = {The achievements made in genomic technology in recent decades are yet to be matched by fast and accurate crop phenotyping methods. Such crop phenotyping methods are required for crop improvement efforts to meet expected demand for food and fibre in the future. This review evaluates the role of proximal remote sensing buggies for field-based phenotyping with a particular focus on the application of currently available sensor technology for large-scale field phenotyping. To illustrate the potential for the development of high throughput phenotyping techniques, a case study is presented with sample data sets obtained from a ground-based proximal remote sensing buggy mounted with the following sensors: LiDAR, RGB camera, thermal infra-red camera and imaging spectroradiometer. The development of such techniques for routine deployment in commercial-scale breeding and pre-breeding operations will require a multidisciplinary approach to leverage the recent technological advances realised in computer science, image analysis, proximal remote sensing and robotics.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {chlorophyll fluorescence,data processing,field experiments,hyperspectral,image analysis,LiDAR,RGB camera,thermal imaging,time of flight,wheat}
}

@article{deliaTreestructuredMarkovRandom2003,
  title = {A Tree-Structured {{Markov}} Random Field Model for Bayesian Image Segmentation},
  author = {D'Elia, C. and Poggi, G. and Scarpa, G.},
  year = {2003},
  month = oct,
  journal = {IEEE Transactions on Image Processing},
  volume = {12},
  number = {10},
  pages = {1259--1273},
  issn = {1057-7149},
  doi = {10.1109/TIP.2003.817257},
  urldate = {2021-12-19},
  langid = {english}
}

@article{delponteStandardAreaDiagrams2017,
  title = {Standard {{Area Diagrams}} for {{Aiding Severity Estimation}}: {{Scientometrics}}, {{Pathosystems}}, and {{Methodological Trends}} in the {{Last}} 25 {{Years}}},
  shorttitle = {Standard {{Area Diagrams}} for {{Aiding Severity Estimation}}},
  author = {Del Ponte, Emerson M. and Pethybridge, Sarah J. and Bock, Clive H. and Michereff, Sami J. and Machado, Franklin J. and Spolti, Pi{\'e}rri},
  year = {2017},
  month = oct,
  journal = {Phytopathology{\textregistered}},
  volume = {107},
  number = {10},
  pages = {1161--1174},
  publisher = {Scientific Societies},
  issn = {0031-949X},
  doi = {10.1094/PHYTO-02-17-0069-FI},
  urldate = {2023-09-01},
  abstract = {Standard area diagrams (SAD) have long been used as a tool to aid the estimation of plant disease severity, an essential variable in phytopathometry. Formal validation of SAD was not considered prior to the early 1990s, when considerable effort began to be invested developing SAD and assessing their value for improving accuracy of estimates of disease severity in many pathosystems. Peer-reviewed literature post-1990 was identified, selected, and cataloged in bibliographic software for further scrutiny and extraction of scientometric, pathosystem-related, and methodological-related data. In total, 105 studies (127 SAD) were found and authored by 327 researchers from 10 countries, mainly from Brazil. The six most prolific authors published at least seven studies. The scientific impact of a SAD article, based on annual citations after publication year, was affected by disease significance, the journal's impact factor, and methodological innovation. The reviewed SAD encompassed 48 crops and 103 unique diseases across a range of plant organs. Severity was quantified largely by image analysis software such as QUANT, APS-Assess, or a LI-COR leaf area meter. The most typical SAD comprised five to eight black-and-white drawings of leaf diagrams, with severity increasing nonlinearly. However, there was a trend toward using true-color photographs or stylized representations in a range of color combinations and more linear (equally spaced) increments of severity. A two-step SAD validation approach was used in 78 of 105 studies for which linear regression was the preferred method but a trend toward using Lin's correlation concordance analysis and hypothesis tests to detect the effect of SAD on accuracy was apparent. Reliability measures, when obtained, mainly considered variation among rather than within raters. The implications of the findings and knowledge gaps are discussed. A list of best practices for designing and implementing SAD and a website called SADBank for hosting SAD research data are proposed.}
}

@article{demarinisSupportingProPoorReforms2021,
  title = {Supporting {{Pro-Poor Reforms}} of {{Agricultural Systems}} in {{Eastern DRC}} ({{Africa}}) with {{Remotely Sensed Data}}: {{A Possible Contribution}} of {{Spatial Entropy}} to {{Interpret Land Management Practices}}},
  author = {De Marinis, Pietro and De Petris, Samuele and Sarvia, Filippo and Manfron, Giacinto and Momo, Evelyn Joan and Orusa, Tommaso and Corvino, Gianmarco and Sali, Guido and Borgogno, Enrico Mondino},
  year = {2021},
  journal = {Land},
  volume = {10},
  number = {12},
  pages = {1368}
}

@misc{dengAnomalyDetectionReverse2022,
  title = {Anomaly {{Detection}} via {{Reverse Distillation}} from {{One-Class Embedding}}},
  author = {Deng, Hanqiu and Li, Xingyu},
  year = {2022},
  month = mar,
  number = {arXiv:2201.10703},
  eprint = {2201.10703},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2201.10703},
  urldate = {2025-01-05},
  abstract = {Knowledge distillation (KD) achieves promising results on the challenging problem of unsupervised anomaly detection (AD).The representation discrepancy of anomalies in the teacher-student (T-S) model provides essential evidence for AD. However, using similar or identical architectures to build the teacher and student models in previous studies hinders the diversity of anomalous representations. To tackle this problem, we propose a novel T-S model consisting of a teacher encoder and a student decoder and introduce a simple yet effective "reverse distillation" paradigm accordingly. Instead of receiving raw images directly, the student network takes teacher model's one-class embedding as input and targets to restore the teacher's multiscale representations. Inherently, knowledge distillation in this study starts from abstract, high-level presentations to low-level features. In addition, we introduce a trainable one-class bottleneck embedding (OCBE) module in our T-S model. The obtained compact embedding effectively preserves essential information on normal patterns, but abandons anomaly perturbations. Extensive experimentation on AD and one-class novelty detection benchmarks shows that our method surpasses SOTA performance, demonstrating our proposed approach's effectiveness and generalizability.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/samuelebumbaca/Zotero/storage/AU7YRNTV/2201.html}
}

@article{depetrisRPASbasedPhotogrammetrySupport2020,
  title = {{{RPAS-based}} Photogrammetry to Support Tree Stability Assessment: {{Longing}} for Precision Arboriculture},
  shorttitle = {{{RPAS-based}} Photogrammetry to Support Tree Stability Assessment},
  author = {De Petris, Samuele and Sarvia, Filippo and {Borgogno-Mondino}, Enrico},
  year = {2020},
  month = nov,
  journal = {Urban Forestry \& Urban Greening},
  volume = {55},
  pages = {126862},
  issn = {1618-8667},
  doi = {10.1016/j.ufug.2020.126862},
  urldate = {2023-01-25},
  abstract = {Tree stability evaluation is an important issue with great practical implications. In the recent years, tree potential to cause harm has been increasing in consequence of climate change effects, mainly related to windstorms and tree diseases that represent the main tree failure causes. A tree owner has a duty of safety, imposed by civil and penal laws; consequently, he must operate an appropriate tree management to avoid foreseeable injuries or harms. A relevant problem arises when tree monitoring concern wide areas (extensive contexts), like natural park or urban forest; in these situations a variety of management factors have to be taken into account: the spatial size of the monitored areas; the great heterogeneity of trees vegetative conditions; the relevant number of trees; the balance between environmental protection and safe use of the area; the conspicuous cost of controls and technical interventions. With these premises an efficient planning tool is mandatory to manage this complex resource. Geomatics can support these requirements by integrating different techniques like survey, spatialization and modelling of territorial/environmental variables. In this work authors propose a new approach, hereinafter called ``Precision Arboriculture'' (PA), for tree management, fitting extensive contexts requirements. The proposed workflow is mainly based on RPAS photogrammetry technique and is specifically aimed at (i) accurately estimating single tree parameters; (ii) developing a robust algorithm to assess tree stability with the aim of reducing costs by better addressing ground controls through a spatially based management tool. This technology proved to generate estimates of the main dendrometric parameters with accuracies consistent (sometime higher) than the one ordinary required in the arboricultural context. Nevertheless, some ground data are however needed to calibrate models and testing accuracy of estimates. The proposed methodology proved to be able to generate an easy to use tool (Tree Safety Factor map) for better address ground controls aimed at testing tree stability and reducing the correlated hazard. Safety Factor map enhances critical trees addressing mitigation actions like tree removal, pruning, static bracing, limitations of people transit under potential tree fall area. The adoption of a quantitative index permits to better balance costs and benefits in a more objective way, improving economic efficiency of urban forestry and natural park policies. The method is configuring a new approach in arboricultural field involving new technologies, like RPAS photogrammetric survey and skills moving towards a ``Precision Arboriculture'' concept.},
  langid = {english},
  keywords = {CHM,Single tree parameters,Static integrated assessment,Tree stability index},
  file = {/home/samuelebumbaca/Zotero/storage/ZLA4YSD7/S1618866720306798.html}
}

@article{DesignAnalysisEfficacy2012,
  title = {Design and Analysis of Efficacy Evaluation Trials},
  year = {2012},
  month = dec,
  journal = {EPPO Bulletin},
  volume = {42},
  number = {3},
  pages = {367--381},
  issn = {02508052},
  doi = {10.1111/epp.2610},
  urldate = {2023-01-03},
  langid = {english}
}

@article{DesignAnalysisEfficacy2012a,
  title = {Design and Analysis of Efficacy Evaluation Trials},
  year = {2012},
  month = dec,
  journal = {EPPO Bulletin},
  volume = {42},
  number = {3},
  pages = {367--381},
  issn = {02508052},
  doi = {10.1111/epp.2610},
  urldate = {2023-01-03},
  langid = {english}
}

@article{DesignAnalysisEfficacy2012b,
  title = {Design and Analysis of Efficacy Evaluation Trials},
  year = {2012},
  month = dec,
  journal = {EPPO Bulletin},
  volume = {42},
  number = {3},
  pages = {367--381},
  issn = {02508052},
  doi = {10.1111/epp.2610},
  urldate = {2023-05-03},
  langid = {english}
}

@misc{DevelopmentSpectralIndices,
  title = {Development of Spectral Indices for Detecting and Identifying Plant Diseases - {{ScienceDirect}}},
  urldate = {2023-01-13},
  howpublished = {https://www.sciencedirect.com/science/article/abs/pii/S0034425712003793},
  file = {/home/samuelebumbaca/Zotero/storage/CN7U3CQI/S0034425712003793.html}
}

@article{dewolfDiseaseCycleApproach2007,
  title = {Disease {{Cycle Approach}} to {{Plant Disease Prediction}}},
  author = {De Wolf, Erick D. and Isard, Scott A.},
  year = {2007},
  journal = {Annual Review of Phytopathology},
  volume = {45},
  number = {1},
  pages = {203--220},
  doi = {10.1146/annurev.phyto.44.070505.143329},
  urldate = {2023-01-13},
  abstract = {AbstractPlant disease cycles represent pathogen biology as a series of interconnected stages of development including dormancy, reproduction, dispersal, and pathogenesis. The progression through these stages is determined by a continuous sequence of interactions among host, pathogen, and environment. The stages of the disease cycle form the basis of many plant disease prediction models. The relationship of temperature and moisture to disease development and pathogen reproduction serve as the basis for most contemporary plant disease prediction systems. Pathogen dormancy and inoculum dispersal are considered less frequently. We found extensive research efforts evaluating the performance of prediction models as part of operation disease management systems. These efforts appear to be greater than just a few decades ago, and include novel applications of Bayesian decision theory. Advances in information technology have stimulated innovations in model application. This trend must accelerate to provide the disease management strategies needed to maintain global food supplies.},
  pmid = {17408356},
  keywords = {Bayesian decision theory,disease warning,epidemiology,forecasting,modeling,pest management}
}

@book{dexaerdeStatisticalHandbookAgricultural2016,
  title = {A {{Statistical Handbook}} for {{Agricultural Field Trials Specialists}}},
  author = {{d'Exaerde}, G.K.},
  year = {2016},
  publisher = {Gylling Data Management},
  isbn = {978-0-9977002-1-3}
}

@article{dimyatiComparisonSeveralUAVBased2023,
  title = {A {{Comparison}} of {{Several UAV-Based Multispectral Imageries}} in {{Monitoring Rice Paddy}} ({{A Case Study}} in {{Paddy Fields}} in {{Tottori Prefecture}}, {{Japan}})},
  author = {Dimyati, Muhammad and Supriatna, Supriatna and Nagasawa, Ryota and Pamungkas, Fajar Dwi and Pramayuda, Rizki},
  year = {2023},
  month = jan,
  journal = {ISPRS International Journal of Geo-Information},
  volume = {12},
  number = {36},
  pages = {36},
  publisher = {MDPI AG},
  issn = {2220-9964},
  doi = {10.3390/ijgi12020036},
  urldate = {2023-03-29},
  abstract = {DOAJ is a unique and extensive index of diverse open access journals from around the world, driven by a growing community, committed to ensuring quality content is freely available online for everyone.},
  langid = {english}
}

@article{dimyatiComparisonSeveralUAVBased2023a,
  title = {A {{Comparison}} of {{Several UAV-Based Multispectral Imageries}} in {{Monitoring Rice Paddy}} ({{A Case Study}} in {{Paddy Fields}} in {{Tottori Prefecture}}, {{Japan}})},
  author = {Dimyati, Muhammad and Supriatna, Supriatna and Nagasawa, Ryota and Pamungkas, Fajar Dwi and Pramayuda, Rizki},
  year = {2023},
  month = feb,
  journal = {ISPRS International Journal of Geo-Information},
  volume = {12},
  number = {2},
  pages = {36},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2220-9964},
  doi = {10.3390/ijgi12020036},
  urldate = {2023-03-29},
  abstract = {In recent years, unmanned aerial vehicles (UAVs) have been actively applied in the agricultural sector. Several UAVs equipped with multispectral cameras have become available on the consumer market. Multispectral data are informative and practical for evaluating the greenness and growth status of vegetation as well as agricultural crops. The precise monitoring of rice paddy, especially in the Asian region, is crucial for optimizing profitability, sustainability, and protection of agro-ecological services. This paper reports and discusses our findings from experiments conducted to test four different commercially available multispectral cameras (Micesense RedEdge-M, Sentera Single NDVI, Mapir Survey3, and Bizworks Yubaflex), which can be mounted on a UAV in monitoring rice paddy. The survey has conducted in the typical paddy field area located in the alluvial plain in Tottori Prefecture, Japan. Six different vegetation indices (NDVI, BNDVI, GNDVI, VARI, NDRE and MCARI) captured by UAVs were also compared and evaluated monitoring contribution at three different rice cropping phases. The results showed that the spatial distribution of NDVI collected by each camera is almost similar in paddy fields, but the absolute values of NDVI differed significantly from each other. Among them, the Sentera camera showed the most reasonable NDVI values of each growing phase, indicating 0.49 in the early reproductive phase, 0.62 in the late reproductive stage, and 0.38 in the ripening phase. On the other hand, compared to the most commonly used NDVI, VARI which can be calculated from only visible RGB bands, can be used as an easy and effective index for rice paddy monitoring.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {multispectral camera,normalized differences vegetation index,rice paddy monitoring,unmanned aerial vehicle,visible atmospherically resistant index}
}

@article{dingEstimationSPADValue2020,
  title = {Estimation of {{SPAD}} Value in Tomato Leaves by Multispectral Images},
  author = {Ding, Yongjun and Zhang, Jingjing},
  year = {2020},
  month = sep,
  journal = {Journal of Physics: Conference Series},
  volume = {1634},
  number = {1},
  pages = {012128},
  publisher = {IOP Publishing},
  issn = {1742-6596},
  doi = {10.1088/1742-6596/1634/1/012128},
  abstract = {To improve the prediction accuracy of tomato chlorophyll content based on multispectral images, three preprocessing methods that can weaken illumination influence, i.e., self-adaptive gamma correction, multiscale Retinex and reflectance reconstruction, are compared and analyzed, and corresponding estimation models for the tomato Soil-Plant Analysis Development (SPAD) value are established. The correction coefficients are set according to the deviations between the grayscale values of the pixels in the highlighted and shaded areas and the average grayscale values in the area of uniform illumination to realize the self-adaptive gamma correction. The SPAD estimation model is constructed by the corrected image, with input parameters of nir, RVIb,g, RVIg,nir, RVIr,nir, NDVIr,g, and NDVIb,r, and the Rc2 and Rv2 of the model are 0.87 and 0.8, respectively. The original image is convolved with three different Gaussian functions to obtain a multiscale Retinex corrected image, and the SPAD estimation model is constructed. The input parameters are b, RVIr,g, RVIr,nir, RVIg,b, RVIg,nir, RVIb,nir, and NDVIr,g, and the Rc2 and Rv2 of the model are 0.91 and 0.84, respectively. The accuracy of the above two models depends on the selection of the corrected gamma value and the convolution kernel, and improper selections could seriously affect the accuracy of the model. For the SPAD value estimation model based on the reflectance reconstruction, its input parameters are nir, RVIg,nir, RVIr,g, NDVIg,b, NDVIr,nir, and NDVIb,r, and the Rc2 and Rv2 of the model are 0.90 and 0.88, respectively. The preprocessing procedure is simple, and the universality is high, making it suitable for the application of the digital field management of the crop.}
}

@article{dingPredictionSPADValue2015,
  title = {{[Prediction of SPAD value in oilseed rape leaves using hyperspectral imaging technique]}},
  author = {Ding, Xi-bin and Liu, Fei and Zhang, Chu and He, Yong},
  year = {2015},
  month = feb,
  journal = {Guang Pu Xue Yu Guang Pu Fen Xi = Guang Pu},
  volume = {35},
  number = {2},
  pages = {486--491},
  issn = {1000-0593},
  abstract = {In the present work, prediction models of SPAD value (Soil and Plant Analyzer Development, often used as a parameter to indicate chlorophyll content) in oilseed rape leaves were successfully built using hyperspectral imaging technique. The hy perspectral images of 160 oilseed rape leaf samples in the spectral range of 380-1030 nm were acquired. Average spectrum was extracted from the region of interest (ROI) of each sample. We chose spectral data in the spectral range of 500-900 nm for analysis. Using Monte Carlo partial least squares(MC-PLS) algorithm, 13 samples were identified as outliers and eliminated. Based on the spectral information and measured SPAD values of the rest 147 samples, several estimation models have been built based on different parameters using different algorithms for comparison, including: (1) a SPAD value estimation model based on partial least squares(PLS) in the whole wavelength region of 500-900 nm; (2) a SPAD value estimation model based on successive projections algorithmcombined with PLS(SPA-PLS); (3) 4 kind of simple experience SPAD value estimation models in which red edge position was used as an argument; (4) 4 kind of simple experience SPAD value estimation models in which three vegetation indexes R710/R760, (R750-R705)/(R750-R705) and R860/(R550 x R708), which all have been proved to have a good relevance with chlorophyll content, were used as an argument respectively; (5) a SPAD value estimation model based on PLS using the 3 vegetation indexes mentioned above. The results indicate that the optimal prediction performance is achieved by PLS model in the whole wavelength region of 500-900 nm, which has a correlation coefficient(r(p)) of 0.8339 and a root mean squares error of predicted (RMSEP) of 1.52. The SPA-PLS model can provide avery close prediction result while the calibration computation has been significantly reduced and the calibration speed has been accelerated sharply. For simple experience models based on red edge parameters and vegetation indexes, although there is a slight gap between theprediction performance and that of the PLS model in the whole wavelength region of 500-900 nm, they also have their own unique advantages which should be thought highly of: these models are much simpler and thus the calibration computation is reduced significantly, they can perform an important function under circumstances in which increasing modeling speed and reducing calibration computation operand are more important than improving the prediction accuracy, such as the development of portable devices.},
  langid = {chi},
  pmid = {25970918},
  keywords = {Algorithms,Brassica rapa,Chlorophyll,Least-Squares Analysis,Models Theoretical,Plant Leaves,Spectrum Analysis}
}

@article{dongGenerativeConvNetFoundation2024,
  title = {Generative {{ConvNet Foundation Model With Sparse Modeling}} and {{Low-Frequency Reconstruction}} for {{Remote Sensing Image Interpretation}}},
  author = {Dong, Zhe and Gu, Yanfeng and Liu, Tianzhu},
  year = {2024},
  journal = {IEEE Transactions on Geoscience and Remote Sensing},
  volume = {62},
  pages = {1--16},
  issn = {1558-0644},
  doi = {10.1109/TGRS.2023.3348479},
  urldate = {2025-01-05},
  abstract = {Foundation models offer a highly versatile and precise solution for intelligent interpretation of remote sensing images, thus greatly facilitating various remote sensing applications. Nevertheless, conventional remote sensing foundational models based on generative transformers neglect the consideration of multiscale features and frequency information, limiting their potential for dense prediction tasks in remote sensing scenarios. In this article, we make the first attempt to propose a generative convolutional neural network (ConvNet) foundation model tailored for remote sensing scenarios, which comprises two key components: First, a large dataset named GeoSense, containing approximately nine million diverse remote sensing images, is constructed to enhance the robustness and generalization of the foundation model during the pretraining phase. Second, a sparse modeling and low-frequency reconstruction (SMLFR) framework is designed for self-supervised representation learning of the ConvNet foundation model. Specifically, a sparse modeling strategy is proposed in masked image modeling (MIM), which allows ConvNet to process variable-length sequences by treating unmasked patches as voxels and sparsifying the encoder. In addition, a low-frequency reconstruction target is designed to guide the model's attention toward essential ground object features in remote sensing images, while mitigating unnecessary detail interference. To evaluate the general performance of our proposed foundation model, comprehensive experiments have been carried out on five datasets across three downstream tasks. Experimental results demonstrate that our method consistently achieves state-of-the-art performance across all the benchmark datasets and downstream tasks. The code and pretrained models will be available at https://github.com/HIT-SIRS/SMLFR.},
  keywords = {Computational modeling,Convolutional neural network (ConvNet),Data models,foundation model,Image reconstruction,remote sensing,Remote sensing,self-supervised pretraining,Sensors,Task analysis,Transformers},
  file = {/home/samuelebumbaca/Zotero/storage/7AG9RNIX/10378718.html}
}

@article{dudduHighThroughputUAVImageBased2019,
  title = {High-{{Throughput UAV Image-Based Method Is More Precise Than Manual Rating}} of {{Herbicide Tolerance}}},
  author = {Duddu, Hema S. N. and Johnson, Eric N. and Willenborg, Christian J. and Shirtliffe, Steven J.},
  year = {2019},
  month = sep,
  journal = {Plant Phenomics},
  volume = {2019},
  pages = {1--9},
  issn = {2643-6515},
  doi = {10.34133/2019/6036453},
  urldate = {2022-01-28},
  abstract = {The traditional visual rating system is labor-intensive, time-consuming, and prone to human error. Unmanned aerial vehicle (UAV) imagery-based vegetation indices (VI) have potential applications in high-throughput plant phenotyping. The study objective is to determine if UAV imagery provides accurate and consistent estimations of crop injury from herbicide application and its potential as an alternative to visual ratings. The study was conducted at the Kernen Crop Research Farm, University of Saskatchewan in 2016 and 2017. Fababean (                Vicia faba                L.) crop tolerance to nine herbicide tank mixtures was evaluated with 2 rates distributed in a randomized complete block design (RCBD) with 4 blocks. The trial was imaged using a multispectral camera with a ground sample distance (GSD) of 1.2\,cm, one week after the treatment application. Visual ratings of growth reduction and physiological chlorosis were recorded simultaneously with imaging. The optimized soil-adjusted vegetation index (OSAVI) was calculated from the thresholded orthomosaics. The UAV-based vegetation index (OSAVI) produced more precise results compared to visual ratings for both years. The coefficient of variation (CV) of OSAVI was {\textasciitilde}1\% when compared to 18-43\% for the visual ratings. Furthermore, Tukey's honestly significance difference (HSD) test yielded a more precise mean separation for the UAV-based vegetation index than visual ratings. The significant correlations between OSAVI and the visual ratings from the study suggest that undesirable variability associated with visual assessments can be minimized with the UAV-based approach. UAV-based imagery methods had greater precision than the visual-based ratings for crop herbicide damage. These methods have the potential to replace visual ratings and aid in screening crops for herbicide tolerance.},
  langid = {english}
}

@article{dutagaciROSEXAnnotatedData2020,
  title = {{{ROSE-X}}: An Annotated Data Set for Evaluation of {{3D}} Plant Organ Segmentation Methods},
  shorttitle = {{{ROSE-X}}},
  author = {Dutagaci, Helin and Rasti, Pejman and Galopin, Gilles and Rousseau, David},
  year = {2020},
  month = dec,
  journal = {Plant Methods},
  volume = {16},
  number = {1},
  pages = {28},
  issn = {1746-4811},
  doi = {10.1186/s13007-020-00573-w},
  urldate = {2021-12-18},
  abstract = {Abstract                              Background                The production and availability of annotated data sets are indispensable for training and evaluation of automatic phenotyping methods. The need for complete 3D models of real plants with organ-level labeling is even more pronounced due to the advances in 3D vision-based phenotyping techniques and the difficulty of full annotation of the intricate 3D plant structure.                                            Results                We introduce the ROSE-X data set of 11 annotated 3D models of real rosebush plants acquired through X-ray tomography and presented both in volumetric form and as point clouds. The annotation is performed manually to provide ground truth data in the form of organ labels for the voxels corresponding to the plant shoot. This data set is constructed to serve both as training data for supervised learning methods performing organ-level segmentation and as a benchmark to evaluate their performance. The rosebush models in the data set are of high quality and complex architecture with organs frequently touching each other posing a challenge for the current plant organ segmentation methods. We report leaf/stem segmentation results obtained using four baseline methods. The best performance is achieved by the volumetric approach where local features are trained with a random forest classifier, giving Intersection of Union (IoU) values of 97.93\% and 86.23\% for leaf and stem classes, respectively.                                            Conclusion                We provided an annotated 3D data set of 11 rosebush plants for training and evaluation of organ segmentation methods. We also reported leaf/stem segmentation results of baseline methods, which are open to improvement. The data set, together with the baseline results, has the potential of becoming a significant resource for future studies on automatic plant phenotyping.},
  langid = {english}
}

@misc{eppoDigitalTechnologyEfficacy,
  title = {Digital {{Technology}} and {{Efficacy Evaluation}} of {{Plant Protection Products}}},
  author = {EPPO, 2022-06-27/29},
  urldate = {2023-09-07},
  abstract = {EPPO},
  howpublished = {https://www.eppo.int/MEETINGS/2022},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/2AIV2ADN/wk_digital_technology_ppp.html}
}

@misc{eppoDigitalTechnologyEfficacy2022,
  title = {Digital {{Technology}} and {{Efficacy Evaluation}} of {{Plant Protection Products}}},
  shorttitle = {Digital {{Technology}} and {{Efficacy Evaluation}} of {{Plant Protection Products}}},
  author = {EPPO, 2022-06-27/29},
  year = {2022-06-27/0029},
  urldate = {2022-11-07},
  abstract = {The EPPO Workshop on adoption of digital technology for data generation for the efficacy evaluation of plant protection products was organized in collaboration with the Netherlands Food and Consumer Product Safety Authority (NVWA). Thanks are due to our Dutch hosts, in particular Ms Jilesen, for organizing the venue and logistics. Participants greatly appreciated the interesting technical visit to Eurofins experimental station in Elst, where they were welcomed by the Director of Eurofins, Mr Flier. The use of different digital technologies in efficacy trials was demonstrated there thanks to contribution of teams from six different companies. The EPPO Secretariat would like to express their gratitude to the Organizing Committee, Working Group Chairs, and Rapporteurs who helped in structuring this workshop and assisted with finalizing the conclusions. Thanks, are also due to the speakers for their informative presentations and all those attending for their active participation and contribution to the outcomes of the Workshop. The Workshop was organized upon request from EPPO Member Countries which identified the need to critically discuss how the digital technologies used in efficacy trials can be validated and accepted within Good Experimental Practice (GEP) systems and by regulators in the future.   General background At the Workshop the focus was on sharing experience on the use of digital technology in PPP efficacy evaluation, identifying how digital technologies can support existing methods for specific assessment types and discussing knowledge gaps. The participants discussed how digital technologies can be validated, calibrated and verified, as well as what further work or guidance may be needed. The Workshop also focussed on possible work EPPO could do to assist their member countries, including updating of existing, or preparation of new EPPO Standards. The use of digital technologies in the application of plant protection products was outside of the Workshop's scope.   The Workshop provided an excellent opportunity to share experiences on the topic. A total of 72 participants, from 17 EPPO countries were present at the meeting. Presentations Mr Horn (EPPO Director General) welcomed participants and explained the objectives of the Workshop. The opening lectures (click on the links to see the presentations -- PDF) illustrated the current state of developments of digital technologies, their use in practice and potential possibilities for the future. GEP Managers and representatives of GEP units shared their experiences with using digital technologies and on implementing EPPO PP1 Standards while using digital tools. Representatives of plant protection products industry and the digital technology providers presented their experience with the use of digital technology and the potential for use in efficacy trials.     Opening	  Welcome address and objectives of the Workshop	Nico Horn (EPPO) Developments of digital technologies: current state and potential possibilities for the future	  Novel sensing and machine learning techniques for in field disease detection	Gerrit Polder, WUR Plant Research Wageningen (NL) How can we learn from plant breeders? Update on use of digital technologies in plant breeding	Francois Tardieu, INRAE (FR) The integration of digital technologies into biological assessment approaches to enhance data quality and delivery	Rosie Bryson, BASF (DE) GEP managers experience   Experience of Digital Technology in GEP Trials in the UK	Tony Fisher (GB) Digital technologies in GEP Units	Anna Papamichail (GR)   Key studies GEP units - Experiences to share on making use of digital technologies so far and on following EPPO PP1 Standards while using digital tools Cirillo, next generation digital plant pest phenotyping	Peter Korsten, Botany (NL) How can simple RGB pictures be used for counting plant emergence	Martin Gejl, Agrolab (DK) Key studies Plant protection products industry and Digital technology providers Using digital tools to assess R\&D trials - disease recognition at leaf level Ramon Navarra Mestre, BASF (DE) Digital Phenotyping: using sensor-based technologies for measuring crop responses Aline Nink, Bayer CropScience (DE) From images to data: the path of automated techniques for digital trial evaluations	 Valentino Bosco, Corteva (IT) Development of a smartphone/tablet app for cereal stand counts Frank Meier-Runge, Syngenta (DE) Improving traceability, transparency, and precision of assessments for biological dossiers with digital technology Alexis Comar, Hiphen (FR)   Working groups Participants were divided into four Working Groups to discuss the use of digital technologies in efficacy evaluation. Three groups focused on different groups of plant protection products, considering the specificities for efficacy trials of herbicides, fungicides and insecticides, and the fourth group discussed use of digital technologies in the framework of GEP systems. In the final plenary session moderated by Mr Kudsk (DK), the rapporteur of each group summarized the conclusions of their group for all the Workshop participants.     Conclusions and recommendations Based on those outcomes of the Working Groups, the general conclusions and recommendations were elaborated during the plenary session and are summarized as follows. At the moment there is no need to revise EPPO specific Standards concerning digital technologies as the Standards don't specify how the data is obtained. Revision may be needed in the future if digital technologies are used to generate additional parameters. Validation of digital technologies is crucial. A glossary of technical terms is needed, e.g. to clarify the meaning of the terms `calibration', `verification' and `validation'. The raw trial data is the outputs of the assessments, not the images or data files. Calibration, verification and validation is primarily a responsibility of the GEP system. A new Standard or alternatively an addendum to EPPO PP1/181 describing procedures for calibration, verification and validation of digital technologies is urgently needed. Bringing GEP managers together could promote harmonization of the use of digital technologies. Industry may consider sharing a common data set for validation.},
  howpublished = {https://www.eppo.int/MEETINGS/2022\_meetings/https\%3A\%2F\%2Fwww.eppo.int\%2FMEETINGS\%2F2022\_meetings\%2Fwk\_digital\_technology\_ppp},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/3W2FWBCW/wk_digital_technology_ppp.html}
}

@misc{EPPOGlobalDatabase,
  title = {{{EPPO Global Database}}},
  shorttitle = {{{EPPO}} (2022) {{EPPO Global Database}} (Available Online).},
  urldate = {2022-10-28},
  howpublished = {https://gd.eppo.int/},
  file = {/home/samuelebumbaca/Zotero/storage/YJ2SVG9R/gd.eppo.int.html}
}

@article{eppoPP11352014,
  title = {{{PP}} 1/135 (4) {{Phytotoxicity}} Assessment},
  author = {{EPPO}},
  year = {2014},
  journal = {EPPO Bulletin},
  volume = {44},
  number = {3},
  pages = {265--273},
  issn = {1365-2338},
  doi = {10.1111/epp.12134},
  urldate = {2023-09-01},
  abstract = {Specific scope This Standard provides detailed advice on assessment of the phytotoxicity of plant protection products to crops or plant products including propagating material and is intended for use in association with EPPO Standards of series PP 1 (Efficacy evaluation of plant protection products, especially of herbicides and plant growth regulators). Specific approval and amendment First approved in 1987--09. First revision approved in 1997--09. Second revision approved in 2006--09. (Table corrected in 2011--04.) Third revision approved in 2014--09.},
  copyright = {{\copyright} 2014 OEPP/EPPO},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/ZHWNSNHY/epp.html}
}

@article{ESRIShapefileTechnical,
  title = {{{ESRI Shapefile Technical Description}}},
  langid = {english}
}

@article{fangReviewCropCanopy2015,
  title = {{[Review of Crop Canopy Spectral Information Detection Technology and Methods]}},
  author = {Fang, Xiao-rong and Gao, Jun-feng and Xie, Chuan-qi and Zhu, Feng-le and Huang, Ling-xia and He, Yong},
  year = {2015},
  month = jul,
  journal = {Guang Pu Xue Yu Guang Pu Fen Xi = Guang Pu},
  volume = {35},
  number = {7},
  pages = {1949--1955},
  issn = {1000-0593},
  abstract = {Compared with the traditional chemical methods and the subjective visual ways for measuring plant physiology information indicators, the assessments of crop canopy information through spectral radiometer are more simple, rapid and accurate. The applications of different types of spectral radiometer, especially for international general used Cropscan multispectral radiometer, for predicting crop canopy leaf area index under different growth stage, biomass, nitrogen, chlorophyll and yield, and monitoring plant diseases and insect pests were summarized based on crop group information acquisition methods in recent years. The varity of vegetation indices (VIs) were concluded after comparing regression coefficients of related models among different crops. In general, the correlation coefficients of mathematical models were high and it can realize the crop detection of various kinds of physiological information. Besides, the combination of multispectral radiometer and other sensors can provide useful information to evaluate the status of crops growth, which is very important in practice.},
  langid = {chi},
  pmid = {26717758},
  keywords = {Biomass,Chlorophyll,Crops Agricultural,Environmental Monitoring,Models Theoretical,Nitrogen,Plant Diseases,Plant Leaves,Spectrum Analysis}
}

@inproceedings{FASTAPPROXIMATENEAREST2009,
  title = {{{FAST APPROXIMATE NEAREST NEIGHBORS WITH AUTOMATIC ALGORITHM CONFIGURATION}}:},
  shorttitle = {{{FAST APPROXIMATE NEAREST NEIGHBORS WITH AUTOMATIC ALGORITHM CONFIGURATION}}},
  booktitle = {Proceedings of the {{Fourth International Conference}} on {{Computer Vision Theory}} and {{Applications}}},
  year = {2009},
  pages = {331--340},
  publisher = {{SciTePress - Science and and Technology Publications}},
  address = {Lisboa, Portugal},
  doi = {10.5220/0001787803310340},
  urldate = {2022-11-25},
  isbn = {978-989-8111-69-2},
  langid = {english}
}

@article{felzenszwalbEfficientGraphBasedImage2004,
  title = {Efficient {{Graph-Based Image Segmentation}}},
  author = {Felzenszwalb, Pedro F. and Huttenlocher, Daniel P.},
  year = {2004},
  month = sep,
  journal = {International Journal of Computer Vision},
  volume = {59},
  number = {2},
  pages = {167--181},
  issn = {0920-5691},
  doi = {10.1023/B:VISI.0000022288.19776.77},
  urldate = {2022-12-02},
  abstract = {This paper addresses the problem of segmenting an image into regions. We define a predicate for measuring the evidence for a boundary between two regions using a graph-based representation of the image. We then develop an efficient segmentation algorithm based on this predicate, and show that although this algorithm makes greedy decisions it produces segmentations that satisfy global properties. We apply the algorithm to image segmentation using two different kinds of local neighborhoods in constructing the graph, and illustrate the results with both real and synthetic images. The algorithm runs in time nearly linear in the number of graph edges and is also fast in practice. An important characteristic of the method is its ability to preserve detail in low-variability image regions while ignoring detail in high-variability regions.},
  langid = {english}
}

@article{fitzpatrickPredictingErrorRigidbody1998,
  title = {Predicting Error in Rigid-Body Point-Based Registration},
  author = {Fitzpatrick, J.M. and West, J.B. and Maurer, C.R.},
  year = {1998},
  month = oct,
  journal = {IEEE Transactions on Medical Imaging},
  volume = {17},
  number = {5},
  pages = {694--702},
  issn = {02780062},
  doi = {10.1109/42.736021},
  urldate = {2021-12-19}
}

@article{friedmanRegularizationPathsGeneralized2010,
  title = {Regularization {{Paths}} for {{Generalized Linear Models}} via {{Coordinate Descent}}},
  author = {Friedman, Jerome H. and Hastie, Trevor and Tibshirani, Rob},
  year = {2010},
  month = feb,
  journal = {Journal of Statistical Software},
  volume = {33},
  pages = {1--22},
  issn = {1548-7660},
  doi = {10.18637/jss.v033.i01},
  urldate = {2025-03-16},
  abstract = {We develop fast algorithms for estimation of generalized linear models with convex penalties. The models include linear regression, two-class logistic regression, and multi- nomial regression problems while the penalties include {$\ell$}1 (the lasso), {$\ell$}2 (ridge regression) and mixtures of the two (the elastic net). The algorithms use cyclical coordinate descent, computed along a regularization path. The methods can handle large problems and can also deal efficiently with sparse features. In comparative timings we find that the new algorithms are considerably faster than competing methods.},
  copyright = {Copyright (c) 2009 Jerome H. Friedman, Trevor Hastie, Rob Tibshirani},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/WIRL35LD/Friedman et al. - 2010 - Regularization Paths for Generalized Linear Models via Coordinate Descent.pdf}
}

@misc{FrontiersHighThroughput,
  title = {Frontiers {\textbar} {{High Throughput In}} Vivo {{Analysis}} of {{Plant Leaf Chemical Properties Using Hyperspectral Imaging}}},
  urldate = {2023-01-13},
  howpublished = {https://www.frontiersin.org/articles/10.3389/fpls.2017.01348/full},
  file = {/home/samuelebumbaca/Zotero/storage/HHNXT9XA/full.html}
}

@article{fuentesImprovingAccuracyTomato2021,
  title = {Improving {{Accuracy}} of {{Tomato Plant Disease Diagnosis Based}} on {{Deep Learning With Explicit Control}} of {{Hidden Classes}}},
  author = {Fuentes, Alvaro and Yoon, Sook and Lee, Mun Haeng and Park, Dong Sun},
  year = {2021},
  month = dec,
  journal = {Frontiers in Plant Science},
  volume = {12},
  publisher = {Frontiers Media S.A.},
  issn = {1664-462X},
  doi = {10.3389/fpls.2021.682230},
  urldate = {2023-09-01},
  abstract = {Recognizing plant diseases is a major challenge in agriculture, and recent works based on deep learning have shown high efficiency in addressing problems...},
  langid = {english}
}

@inproceedings{gallianiMassivelyParallelMultiview2015,
  title = {Massively {{Parallel Multiview Stereopsis}} by {{Surface Normal Diffusion}}},
  booktitle = {2015 {{IEEE International Conference}} on {{Computer Vision}} ({{ICCV}})},
  author = {Galliani, Silvano and Lasinger, Katrin and Schindler, Konrad},
  year = {2015},
  month = dec,
  pages = {873--881},
  publisher = {IEEE},
  address = {Santiago, Chile},
  doi = {10.1109/ICCV.2015.106},
  urldate = {2022-11-24},
  abstract = {We present a new, massively parallel method for highquality multiview matching. Our work builds on the Patchmatch idea: starting from randomly generated 3D planes in scene space, the best-fitting planes are iteratively propagated and refined to obtain a 3D depth and normal field per view, such that a robust photo-consistency measure over all images is maximized. Our main novelties are on the one hand to formulate Patchmatch in scene space, which makes it possible to aggregate image similarity across multiple views and obtain more accurate depth maps. And on the other hand a modified, diffusion-like propagation scheme that can be massively parallelized and delivers dense multiview correspondence over ten 1.9-Megapixel images in 3 seconds, on a consumer-grade GPU. Our method uses a slanted support window and thus has no fronto-parallel bias; it is completely local and parallel, such that computation time scales linearly with image size, and inversely proportional to the number of parallel threads. Furthermore, it has low memory footprint (four values per pixel, independent of the depth range). It therefore scales exceptionally well and can handle multiple large images at high depth resolution. Experiments on the DTU and Middlebury multiview datasets as well as oblique aerial images show that our method achieves very competitive results with high accuracy and completeness, across a range of different scenarios.},
  isbn = {978-1-4673-8391-2},
  langid = {english}
}

@article{gamonAssessingLeafPigment1999,
  title = {Assessing Leaf Pigment Content and Activity with a Reflectometer},
  author = {Gamon, J. A. and Surfus, J. S.},
  year = {1999},
  month = jul,
  journal = {The New Phytologist},
  volume = {143},
  number = {1},
  pages = {105--117},
  publisher = {Cambridge University Press},
  issn = {1469-8137, 0028-646X},
  doi = {10.1046/j.1469-8137.1999.00424.x},
  urldate = {2023-01-13},
  abstract = {This study explored reflectance indices sampled with a `leaf reflectometer' as measures of pigment content for  leaves of contrasting light history, developmental stage and functional type (herbaceous annual versus  sclerophyllous evergreen). We employed three reflectance indices: a modified normalized difference vegetation  index (NDVI), an index of chlorophyll content; the red/green reflectance ratio (RRED[ratio   ]RGREEN), an index of  anthocyanin content; and the change in photochemical reflectance index upon dark--light conversions ({$\Delta$}PRI), an  index of xanthophyll cycle pigment activity. In Helianthus annuus (sunflower), xanthophyll cycle pigment amounts  were linearly related to growth light environment; leaves in full sun contained approximately twice the amount  of xanthophyll cycle pigments as leaves in deep shade, and at midday a larger proportion of these pigments were  in the photoprotective, de-epoxidized forms relative to shade leaves. Reflectance indices also revealed contrasting  patterns of pigment development in leaves of contrasting structural types (annual versus evergreen). In H. annuus  sun leaves, there was a remarkably rapid increase in amounts of both chlorophyll and xanthophyll cycle pigments  along a leaf developmental sequence. This pattern contrasted with that of Quercus agrifolia (coast live oak, a  sclerophyllous evergreen), which exhibited a gradual development of both chlorophyll and xanthophyll cycle  pigments along with a pronounced peak of anthocyanin pigment content in newly expanding leaves. These  temporal patterns of pigment development in Q. agrifolia leaves suggest that anthocyanins and xanthophyll cycle  pigments serve complementary photoprotective roles during early leaf development. The results illustrate the use  of reflectance indices for distinguishing divergent patterns of pigment activity in leaves of contrasting light history  and functional type.},
  langid = {english},
  keywords = {anthocyanins,chlorophyll,leaf development,leaf pigments,leaf reflectometer,photoprotection,reflectance indices,xanthophyll cycle}
}

@article{gamonNarrowwavebandSpectralIndex1992,
  title = {A Narrow-Waveband Spectral Index That Tracks Diurnal Changes in Photosynthetic Efficiency},
  author = {Gamon, J. A. and Pe{\~n}uelas, J. and Field, C. B.},
  year = {1992},
  month = jul,
  journal = {Remote Sensing of Environment},
  volume = {41},
  number = {1},
  pages = {35--44},
  issn = {0034-4257},
  doi = {10.1016/0034-4257(92)90059-S},
  urldate = {2023-11-09},
  abstract = {We present a new ``physiological reflectance index'' (PRI) isolated from narrow waveband spectral measurements of sunflower canopies. This index correlates with the epoxidation state of the xanthophyll cycle pigments and with the efficiency of photosynthesis in control and nitrogen stress canopies, but not in water stress canopies undergoing midday wilting. It is analogous in formulation to the broadband normalized difference vegetation index (NDVI) and uses reflectance at 531 nm and at a reference wavelength to minimize complications associated with diurnal sun angle changes. In conjunction with other methods, this index may lead to improved remote and ground-based estimates of canopy photosynthetic function.},
  file = {/home/samuelebumbaca/Zotero/storage/5AZQS3D4/003442579290059S.html}
}

@article{garbowMINPACK1SubroutineLibrary1984,
  title = {{{MINPACK-1}}, {{Subroutine Library}} for {{Nonlinear Equation System}}},
  author = {Garbow, Burton S.},
  year = {1984},
  month = apr,
  address = {Nuclear Energy Agency of the OECD (NEA)},
  abstract = {1 - Description of problem or function: MINPACK1 is a package of FORTRAN subprograms for the numerical solution of systems of non- linear equations and nonlinear least-squares problems The individual programs are: Identification/Description: - CHKDER: Check gradients for consistency with functions, - DOGLEG: Determine combination of Gauss-Newton and gradient directions, - DPMPAR: Provide double precision machine parameters, - ENORM: Calculate Euclidean norm of vector, - FDJAC1: Calculate difference approximation to Jacobian (nonlinear equations), - FDJAC2: Calculate difference approximation to Jacobian (least squares), - HYBRD: Solve system of nonlinear equations (approximate Jacobian), - HYBRD1: Easy-to-use driver for HYBRD, - HYBRJ: Solve system of nonlinear equations (analytic Jacobian), - HYBRJ1: Easy-to-use driver for HYBRJ, - LMDER: Solve nonlinear least squares problem (analytic Jacobian), - LMDER1: Easy-to-use driver for LMDER, - LMDIF: Solve nonlinear least squares problem (approximate Jacobian), - LMDIF1: Easy-to-use driver for LMDIF, - LMPAR: Determine Levenberg-Marquardt parameter - LMSTR: Solve nonlinear least squares problem (analytic Jacobian, storage conserving), - LMSTR1: Easy-to-use driver for LMSTR, - QFORM: Accumulate orthogonal matrix from QR factorization QRFAC Compute QR factorization of rectangular matrix, - QRSOLV: Complete solution of least squares problem, - RWUPDT: Update QR factorization after row addition, - R1MPYQ: Apply orthogonal transformations from QR factorization, - R1UPDT: Update QR factorization after rank-1 addition, - SPMPAR: Provide single precision machine parameters 4 Method of solution - MINPACK1 uses the modified Powell hybrid method and the Levenberg-Marquardt algorithm}
}

@article{gatesSpectralPropertiesPlants1965,
  title = {Spectral {{Properties}} of {{Plants}}},
  author = {Gates, David M. and Keegan, Harry J. and Schleter, John C. and Weidner, Victor R.},
  year = {1965},
  month = jan,
  journal = {Applied Optics},
  volume = {4},
  number = {1},
  pages = {11--20},
  publisher = {Optica Publishing Group},
  issn = {2155-3165},
  doi = {10.1364/AO.4.000011},
  urldate = {2023-01-13},
  abstract = {The spectral properties of plant leaves and stems have been obtained for ultraviolet, visible, and infrared frequencies. The spectral reflectance, transmittance, and absorptance for certain plants is given. The mechanism by which radiant energy interacts with a leaf is discussed, including the presence of plant pigments. Examples are given concerning the amount of absorbed solar radiation for clear sky and overcast conditions. The spectral properties of desert plants are compared with those of more mesic plants. The evolution of the spectral properties of plant leaves during the early growing season is given as well as the colorimetric behavior during the autumn.},
  copyright = {{\copyright} 1965 Optical Society of America},
  langid = {english},
  keywords = {Energy transfer,Infrared radiation,Solar energy,Solar radiation,Spectral properties,Visible light}
}

@article{ghahremaniDeepSegmentationPoint2021,
  title = {Deep {{Segmentation}} of {{Point Clouds}} of {{Wheat}}},
  author = {Ghahremani, Morteza and Williams, Kevin and Corke, Fiona M. K. and Tiddeman, Bernard and Liu, Yonghuai and Doonan, John H.},
  year = {2021},
  month = mar,
  journal = {Frontiers in Plant Science},
  volume = {12},
  pages = {608732},
  issn = {1664-462X},
  doi = {10.3389/fpls.2021.608732},
  urldate = {2021-12-18},
  abstract = {The 3D analysis of plants has become increasingly effective in modeling the relative structure of organs and other traits of interest. In this paper, we introduce a novel pattern-based deep neural network, Pattern-Net, for segmentation of point clouds of wheat. This study is the first to segment the point clouds of wheat into defined organs and to analyse their traits directly in 3D space. Point clouds have no regular grid and thus their segmentation is challenging. Pattern-Net creates a dynamic link among neighbors to seek stable patterns from a 3D point set across several levels of abstraction using the K-nearest neighbor algorithm. To this end, different layers are connected to each other to create complex patterns from the simple ones, strengthen dynamic link propagation, alleviate the vanishing-gradient problem, encourage link reuse and substantially reduce the number of parameters. The proposed deep network is capable of analysing and decomposing unstructured complex point clouds into semantically meaningful parts. Experiments on a wheat dataset verify the effectiveness of our approach for segmentation of wheat in 3D space.}
}

@article{ghosalExplainableDeepMachine2018,
  title = {An Explainable Deep Machine Vision Framework for Plant Stress Phenotyping},
  author = {Ghosal, Sambuddha and Blystone, David and Singh, Asheesh K. and Ganapathysubramanian, Baskar and Singh, Arti and Sarkar, Soumik},
  year = {2018},
  month = may,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {115},
  number = {18},
  pages = {4613--4618},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.1716999115},
  urldate = {2023-09-01},
  abstract = {Current approaches for accurate identification, classification, and quantification of biotic and abiotic stresses in crop research and production are predominantly visual and require specialized training. However, such techniques are hindered by subjectivity resulting from inter- and intrarater cognitive variability. This translates to erroneous decisions and a significant waste of resources. Here, we demonstrate a machine learning framework's ability to identify and classify a diverse set of foliar stresses in soybean [Glycine max (L.) Merr.] with remarkable accuracy. We also present an explanation mechanism, using the top-K high-resolution feature maps that isolate the visual symptoms used to make predictions. This unsupervised identification of visual symptoms provides a quantitative measure of stress severity, allowing for identification (type of foliar stress), classification (low, medium, or high stress), and quantification (stress severity) in a single framework without detailed symptom annotation by experts. We reliably identified and classified several biotic (bacterial and fungal diseases) and abiotic (chemical injury and nutrient deficiency) stresses by learning from over 25,000 images. The learned model is robust to input image perturbations, demonstrating viability for high-throughput deployment. We also noticed that the learned model appears to be agnostic to species, seemingly demonstrating an ability of transfer learning. The availability of an explainable model that can consistently, rapidly, and accurately identify and quantify foliar stresses would have significant implications in scientific research, plant breeding, and crop production. The trained model could be deployed in mobile platforms (e.g., unmanned air vehicles and automated ground scouts) for rapid, large-scale scouting or as a mobile application for real-time detection of stress by farmers and researchers.}
}

@article{ghosalExplainableDeepMachine2018a,
  title = {An Explainable Deep Machine Vision Framework for Plant Stress Phenotyping},
  author = {Ghosal, Sambuddha and Blystone, David and Singh, Asheesh K. and Ganapathysubramanian, Baskar and Singh, Arti and Sarkar, Soumik},
  year = {2018},
  month = may,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {115},
  number = {18},
  pages = {4613--4618},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.1716999115},
  urldate = {2023-08-31},
  abstract = {Current approaches for accurate identification, classification, and quantification of biotic and abiotic stresses in crop research and production are predominantly visual and require specialized training. However, such techniques are hindered by subjectivity resulting from inter- and intrarater cognitive variability. This translates to erroneous decisions and a significant waste of resources. Here, we demonstrate a machine learning framework's ability to identify and classify a diverse set of foliar stresses in soybean [Glycine max (L.) Merr.] with remarkable accuracy. We also present an explanation mechanism, using the top-K high-resolution feature maps that isolate the visual symptoms used to make predictions. This unsupervised identification of visual symptoms provides a quantitative measure of stress severity, allowing for identification (type of foliar stress), classification (low, medium, or high stress), and quantification (stress severity) in a single framework without detailed symptom annotation by experts. We reliably identified and classified several biotic (bacterial and fungal diseases) and abiotic (chemical injury and nutrient deficiency) stresses by learning from over 25,000 images. The learned model is robust to input image perturbations, demonstrating viability for high-throughput deployment. We also noticed that the learned model appears to be agnostic to species, seemingly demonstrating an ability of transfer learning. The availability of an explainable model that can consistently, rapidly, and accurately identify and quantify foliar stresses would have significant implications in scientific research, plant breeding, and crop production. The trained model could be deployed in mobile platforms (e.g., unmanned air vehicles and automated ground scouts) for rapid, large-scale scouting or as a mobile application for real-time detection of stress by farmers and researchers.}
}

@book{gibbsThreeDimensionalReconstructionPlant2015,
  title = {Three-{{Dimensional Reconstruction}} of {{Plant Shoots}} from {{Multiple Images}} Using an {{Active Vision System}}},
  author = {Gibbs, Jonathon and Pound, Michael and French, Andrew and Wells, Darren and Pridmore, Tony and Murchie, Erik},
  year = {2015},
  month = oct,
  abstract = {The reconstruction of 3D models of plant shoots is a challenging problem central to the emerging discipline of plant phenomics -- the quantitative measurement of plant structure and function. Current approaches are, however, often limited by the use of static cameras. We propose an automated active phenotyping cell to reconstruct plant shoots from multiple images using a turntable capable of rotating 360 degrees and camera mounted robot arm. To overcome the problem of static camera positions we develop an algorithm capable of analysing the environment and determining viewpoints from which to capture initial images suitable for use by a structure from motion technique.}
}

@article{gitelsonOpticalPropertiesNondestructive2001,
  title = {Optical {{Properties}} and {{Nondestructive Estimation}} of {{Anthocyanin Content}} in {{Plant Leaves}}{\P}},
  author = {Gitelson, Anatoly A. and Merzlyak, Mark N. and Chivkunova, Olga B.},
  year = {2001},
  journal = {Photochemistry and Photobiology},
  volume = {74},
  number = {1},
  pages = {38--45},
  issn = {1751-1097},
  doi = {10.1562/0031-8655(2001)0740038OPANEO2.0.CO2},
  urldate = {2023-03-24},
  abstract = {Absorption and reflectance spectra of maple (Acer platanoides), cotoneaster (Cotoneaster alaunica), dogwood (Cornus alba) and pelargonium (Pelargonium zonale) leaves with a wide range of pigment content and composition were studied in visible and near-infrared spectra in order to reveal specific anthocyanin (Anth) spectral features in leaves. Comparing absorption spectra of Anth-containing and Anth-free leaves with the same chlorophyll (Chl) content, absorption spectra of Anth in leaves were derived. The main spectral feature of Anth absorption in vivo was a peak around 550 nm; the peak magnitude was closely related to Anth content. A quantitative nondestructive technique was developed to subtract Chl contribution to reflectance in this spectral region and retrieve Anth content from reflectance over a wide range of pigment content and composition. Anth reflectance index in the form ARI = (R550)-1- (R700)-1, where (R550)-1 and (R700)-1 are inverse reflectances at 550 and 700 nm, respectively, allowed an accurate estimation of Anth accumulation, even in minute amounts, in intact senescing and stressed leaves.},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/23QTXUT3/0031-8655(2001)0740038OPANEO2.0.html}
}

@article{gitelsonThreebandModelNoninvasive2006,
  title = {Three-Band Model for Noninvasive Estimation of Chlorophyll, Carotenoids, and Anthocyanin Contents in Higher Plant Leaves},
  author = {Gitelson, Anatoly A. and Keydan, Galina P. and Merzlyak, Mark N.},
  year = {2006},
  journal = {Geophysical Research Letters},
  volume = {33},
  number = {11},
  issn = {1944-8007},
  doi = {10.1029/2006GL026457},
  urldate = {2023-01-13},
  abstract = {Leaf pigment content and composition provide important information about plant physiological status. Reflectance measurements offer a rapid, nondestructive technique to estimate pigment content. This paper describes a recently developed three-band conceptual model capable of remotely estimating total of chlorophylls, carotenoids and anthocyanins contents in leaves from many tree and crop species. We tuned the spectral regions used in the model in accord with pigment of interest and the optical characteristics of the leaves studied, and showed that the developed technique allowed accurate estimation of total chlorophylls, carotenoids and anthocyanins, explaining more than 91\%, 70\% and 93\% of pigment variation, respectively. This new technique shows a great potential for noninvasive tracking of the physiological status of vegetation and the impact of environmental changes.},
  langid = {english}
}

@misc{GitHubEriklindernorenPyTorchGAN,
  title = {{{GitHub}} - Eriklindernoren/{{PyTorch-GAN}}: {{PyTorch}} Implementations of {{Generative Adversarial Networks}}.},
  urldate = {2025-01-13},
  howpublished = {https://github.com/eriklindernoren/PyTorch-GAN/tree/master?tab=readme-ov-file\#auxiliary-classifier-gan},
  file = {/home/samuelebumbaca/Zotero/storage/8TQYWCAG/master.html}
}

@article{glasbeyAnalysisHistogramBasedThresholding1993,
  title = {An {{Analysis}} of {{Histogram-Based Thresholding Algorithms}}},
  author = {Glasbey, C. A.},
  year = {1993},
  month = nov,
  journal = {CVGIP: Graphical Models and Image Processing},
  volume = {55},
  number = {6},
  pages = {532--537},
  issn = {1049-9652},
  doi = {10.1006/cgip.1993.1040},
  urldate = {2023-01-25},
  abstract = {Eleven histogram-based global thresholding algorithms are presented in a common notational framework. Relationships among them are identified from 654 mixtures of two Gaussian distributions, plus effects of mixed pixels. The iterated version of Kittler and Illingworth{$\prime$}s minimum error algorithm (Pattern Recognition, 19, 1986, 41-47) is found to be best.},
  langid = {english}
}

@incollection{gomarascaElementsPhotogrammetry2009,
  title = {Elements of {{Photogrammetry}}},
  booktitle = {Basics of {{Geomatics}}},
  author = {Gomarasca, Mario A.},
  editor = {Gomarasca, Mario A.},
  year = {2009},
  pages = {79--121},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-1-4020-9014-1_3},
  urldate = {2022-11-25},
  abstract = {Photogrammetry is a technique that allows the measurement of an object without touching it. Measurement can be performed in two and three dimensions (2D and 3D) exploiting both photograms (analogical images) acquired by traditional photogrammetric cameras and digital imagery. Although photogrammetry was born for architectural survey, it can be considered the first remote sensing technology based on the acquisition of objects' geometric properties from photographic images. Nowadays it is widely used in topographic aerial survey and mapping, and for military purposes.},
  isbn = {978-1-4020-9014-1},
  langid = {english},
  keywords = {Bundle Adjustment,Flight Plan,Ground Control Point,Photo Camera,Stereoscopic Vision}
}

@article{gomarascaSENTINELAPPLICATIONSAGRICULTURE2019,
  title = {{{SENTINEL FOR APPLICATIONS IN AGRICULTURE}}},
  author = {Gomarasca, M. A. and Tornato, A. and Spizzichino, D. and Valentini, E. and Taramelli, A. and Satalino, G. and Vincini, M. and Boschetti, M. and Colombo, R. and Rossi, L. and Borgogno Mondino, E. and Perotti, L. and Alberto, W. and Villa, F.},
  year = {2019},
  month = jul,
  journal = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  volume = {XLII-3/W6},
  pages = {91--98},
  issn = {2194-9034},
  doi = {10.5194/isprs-archives-XLII-3-W6-91-2019},
  urldate = {2022-11-10},
  abstract = {The European Union and the European Space Agency (EU/ESA) have promoted since 1998 (Baveno Manifesto*) the GMES Programme (Global Monitoring for Environment and Security), nowadays called Copernicus (www.copernicus.eu). In the agriculture domain, the use of Copernicus Sentinel imagery and its services are providing several new opportunities. The knowledge of fundamentals of Earth Observation/Geographic Information EO/GI, namely Geomatics, for the development of innovative strategies for professional skills adequacy and capacity building, supporting Copernicus user uptake, becomes mandatory (Gomarasca, 2009). The target is to help bridging gaps between supply and demand of education and training for geospatial sector (www.eo4geo.eu). The innovative and strategical novelties are the complete free access to Sentinel time series imagery and digital image processing software ``Sentinel toolboxes'' such as SNAP (Sentinel Application Platform) for different environments (Windows, Mac, Unix). The paper introduce topics as crop mapping and monitoring, biophysical parameters, phenology and yield estimations, through several concluded or ongoing international projects such as: ERMES -FP7 (http://www.ermes-fp7space.eu/it/homepage/, Busetto et al. 2017) and SATURNO (https://www.progettosaturno.it/, Nutini et al., 2018) devoted to the regional agricultural monitoring. As conclusion, SNAP software for image processing of Sentinel data was demonstrated and tested together with Earth Engine software for specific vertical agriculture applications. The topics reported in this paper have been part of the Summer School `Sentinel for Applications in Agriculture' supported by the Copernicus programme, several scientific associations (AIT, ASITA, EARSeL - European Association of Remote Sensing Laboratories), the European Erasmus+ project EO4GEO, University Departments and Geo-Information Companies.},
  langid = {english}
}

@article{gomesApplicationsComputerVision2012,
  title = {Applications of Computer Vision Techniques in the Agriculture and Food Industry: A Review},
  shorttitle = {Applications of Computer Vision Techniques in the Agriculture and Food Industry},
  author = {Gomes, Juliana and Leta, Fabiana},
  year = {2012},
  month = dec,
  journal = {European Food Research \& Technology},
  volume = {235},
  number = {6},
  pages = {989--1000},
  publisher = {Springer Nature},
  issn = {14382377},
  doi = {10.1007/s00217-012-1844-2},
  urldate = {2022-11-06},
  abstract = {Over the last decades, parallel to technological development, there has been a great increase in the use of visual inspection systems. These systems have been widely implemented, particularly in the stage of inspection of product quality, as a means of replacing manual inspection conducted by humans. Much research has been published proposing the use of such tools in the processes of sorting and classification of food products. This paper presents a review of the main publications in the last ten years with respect to new technologies and to the wide application of systems of visual inspection in the sectors of precision farming and in the food industry.},
  keywords = {AGRICULTURAL industries,Computational vision,COMPUTER vision,Food,Food industry,FOOD industry,Image analysis,INSPECTION & review,Precision farming,PRECISION farming,TECHNOLOGICAL innovations,Visual inspection}
}

@article{gomesCOMPARINGSINGLESENSORCAMERA2021,
  title = {{{COMPARING A SINGLE-SENSOR CAMERA WITH A MULTISENSOR CAMERA FOR MONITORING COFFEE CROP USING UNMANNED AERIAL VEHICLES}}},
  author = {Gomes, Amanda P. A. and de Queiroz, Daniel M. and Valente, Domingos S. M. and Pinto, Francisco de A. de C. and Rosas, Jorge T. F.},
  year = {2021},
  month = feb,
  journal = {Engenharia Agr{\'i}cola},
  volume = {41},
  number = {1},
  pages = {87--97},
  issn = {1809-4430, 0100-6916},
  doi = {10.1590/1809-4430-eng.agric.v41n1p87-97/2021},
  urldate = {2022-09-17},
  abstract = {There exist two options for digital cameras that can capture the near-infrared (NIR) band. Conventional red--green--blue (RGB, visible bands) cameras with a single sensor provide NIR band visibility based on the removal of the internal NIR-blocking filter. Alternatively, multisensor cameras exist that have a specific sensor for each band. The modified RGB cameras are of a lower price. In this context, the objective of this study was to compare the performance of a modified RGB camera with that of a multisensor camera for obtaining the normalized difference vegetation index (NDVI) in an area with coffee cultivations. A multispectral camera with five sensors and another camera with only one sensor were used. The NDVI of the coffee field was also measured using the GreenSeeker handheld NDVI sensor manufactured by Trimble. The images were calibrated radiometrically based on the targets in shades of gray made of napa, and the NDVI was calculated after image calibration. The calibration curves showed a high coefficient of determination. The NDVI value obtained with the calibrated images from the cameras showed a significant correlation with the values obtained by the GreenSeeker NDVI sensor, making it possible to obtain the variability pattern of the vegetation index. However, the NDVI obtained using the multisensor camera was closer to the NDVI obtained by the GreenSeeker NDVI sensor.},
  langid = {english}
}

@article{gomesCOMPARINGSINGLESENSORCAMERA2021a,
  title = {{{COMPARING A SINGLE-SENSOR CAMERA WITH A MULTISENSOR CAMERA FOR MONITORING COFFEE CROP USING UNMANNED AERIAL VEHICLES}}},
  author = {Gomes, Amanda P. A. and de Queiroz, Daniel M. and Valente, Domingos S. M. and Pinto, Francisco de A. de C. and Rosas, Jorge T. F.},
  year = {2021},
  month = mar,
  journal = {Engenharia Agr{\'i}cola},
  volume = {41},
  pages = {87--97},
  publisher = {Associa{\c c}{\~a}o Brasileira de Engenharia Agr{\'i}cola},
  issn = {0100-6916, 1809-4430},
  doi = {10.1590/1809-4430-Eng.Agric.v41n1p87-97/2021},
  urldate = {2023-03-29},
  abstract = {ABSTRACT There exist two options for digital cameras that can capture the near-infrared (NIR) band. Conventional red--green--blue (RGB, visible bands) cameras with a single sensor provide NIR band visibility based on the removal of the internal NIR-blocking filter. Alternatively, multisensor cameras exist that have a specific sensor for each band. The modified RGB cameras are of a lower price. In this context, the objective of this study was to compare the performance of a modified RGB camera with that of a multisensor camera for obtaining the normalized difference vegetation index (NDVI) in an area with coffee cultivations. A multispectral camera with five sensors and another camera with only one sensor were used. The NDVI of the coffee field was also measured using the GreenSeeker handheld NDVI sensor manufactured by Trimble. The images were calibrated radiometrically based on the targets in shades of gray made of napa, and the NDVI was calculated after image calibration. The calibration curves showed a high coefficient of determination. The NDVI value obtained with the calibrated images from the cameras showed a significant correlation with the values obtained by the GreenSeeker NDVI sensor, making it possible to obtain the variability pattern of the vegetation index. However, the NDVI obtained using the multisensor camera was closer to the NDVI obtained by the GreenSeeker NDVI sensor.},
  langid = {english},
  keywords = {modified RGB camera,precision agriculture,radiometric calibration,UAV}
}

@article{gomez-zamanilloDamageAssessmentSoybean2023,
  title = {Damage Assessment of Soybean and Redroot Amaranth Plants in Greenhouse through Biomass Estimation and Deep Learning-Based Symptom Classification},
  author = {{G{\'o}mez-Zamanillo}, Laura and {Bereciartua-P{\'e}rez}, Arantza and Pic{\'o}n, Artzai and Parra, Liliana and Oldenbuerger, Marian and {Navarra-Mestre}, Ram{\'o}n and Klukas, Christian and Eggers, Till and Echazarra, Jone},
  year = {2023},
  month = oct,
  journal = {Smart Agricultural Technology},
  volume = {5},
  pages = {100243},
  issn = {2772-3755},
  doi = {10.1016/j.atech.2023.100243},
  urldate = {2023-08-31},
  abstract = {Greenhouse plant assessment is key part in the process of developing and testing new herbicides as it serves to analyze the response of the species to those different products and doses in a controlled way. With that purpose, trials are carried out in greenhouse where the damage in the treated plants is daily assessed. This assessment of every pot is often performed in comparison with an untreated reference pot, also named as control pot. This assessment is currently done pot by pot through a time-consuming process which consists of visual assessments done by experts in the field. Digital tools to reduce time and to endow the experts with more objective and repetitive methods for establishing the damage in the plants are required. A novel solution based on image processing and deep learning techniques is proposed to estimate the damage in the plants in different growing stages in the greenhouse. Different damage types and in different stages are produced in plants and images of them are acquired to create a dataset. The available annotation is the damage estimation value provided by the experts. The proposed methodology tries to emulate the way the experts estimate the damage over the plants through a two-step procedure. First, the biomass reduction of the assessed plant compared to the corresponding control plant is calculated, and secondly, the possible disease symptoms in the plant are detected. The first part is done using classical image processing techniques and the second part relies on a deep learning based multi-label classification model for symptom classification. The algorithm has been tested over two species: Glycine max (soybean) and Amaranthus retroflexus (redroot amaranth). An R2 of 0.87 and 0.89 respectively is obtained for the damage estimation. The method improves the performance of the current manual process in terms of efficiency and objectivity.},
  keywords = {Convolutional neural network (CNN),Deep learning,Greenhouse,Image processing,Multi-label classification,Plant damage estimation},
  file = {/home/samuelebumbaca/Zotero/storage/6WXQW4U8/S2772375523000734.html}
}

@article{gradyRandomWalksImage2006,
  title = {Random {{Walks}} for {{Image Segmentation}}},
  author = {Grady, L.},
  year = {2006},
  month = nov,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {28},
  number = {11},
  pages = {1768--1783},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2006.233},
  abstract = {A novel method is proposed for performing multilabel, interactive image segmentation. Given a small number of pixels with user-defined (or predefined) labels, one can analytically and quickly determine the probability that a random walker starting at each unlabeled pixel will first reach one of the prelabeled pixels. By assigning each pixel to the label for which the greatest probability is calculated, a high-quality image segmentation may be obtained. Theoretical properties of this algorithm are developed along with the corresponding connections to discrete potential theory and electrical circuits. This algorithm is formulated in discrete space (i.e., on a graph) using combinatorial analogues of standard operators and principles from continuous potential theory, allowing it to be applied in arbitrary dimension on arbitrary graphs},
  keywords = {boundary completion.,Circuits,combinatorial Dirichlet problem,Electric potential,graph cuts,graph theory,Graph theory,harmonic functions,Image segmentation,interactive segmentation,Iterative algorithms,Laplace equation,Laplace equations,Pixel,Probability,random walks,Sparse matrices,Symmetric matrices},
  file = {/home/samuelebumbaca/Zotero/storage/K47FXIFB/1704833.html}
}

@article{gresselTechnicalManualParasitic2002,
  title = {A {{Technical Manual}} for {{Parasitic Weed Research}} and {{Extension}}: {{Edited}} by {{J}}. {{Kroschel}}, {{Kluwer}}, {{Dordrecht}}, 2001, 256 Pp. and 18 Color Plates, {{ISBN-0-7923-6880-0}} ({{Price}}: {{EUR}} 130, {{US}}\$ 113, {{GB}} 79; Hard Cover Only)},
  shorttitle = {A {{Technical Manual}} for {{Parasitic Weed Research}} and {{Extension}}},
  author = {Gressel, Jonathan},
  year = {2002},
  month = feb,
  journal = {Plant Science},
  volume = {162},
  number = {2},
  pages = {325--326},
  issn = {0168-9452},
  doi = {10.1016/S0168-9452(01)00544-1},
  urldate = {2022-11-10},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/S83K7FFE/S0168945201005441.html}
}

@inproceedings{griwodzAliceVisionMeshroomOpensource2021,
  title = {{{AliceVision Meshroom}}: {{An}} Open-Source {{3D}} Reconstruction Pipeline},
  shorttitle = {{{AliceVision Meshroom}}},
  booktitle = {12th {{ACM Multimedia Systems Conference}} ({{MMSys}} 2021)},
  author = {Griwodz, Carsten and Gasparini, Simone and Calvet, Lilian and Gurdjos, Pierre and Castan, Fabien and Maujean, Benoit and Lanthony, Yann and de Lillo, Gregoire},
  year = {2021},
  month = sep,
  pages = {241},
  publisher = {ACM: Association for Computing Machinery},
  doi = {10.1145/3458305.3478443},
  urldate = {2023-03-24},
  abstract = {This paper introduces the Meshroom software and its underlying 3D computer vision framework AliceVision. This solution provides a photogrammetry pipeline to reconstruct 3D scenes from a set of unordered images. It also features other pipelines for fusing multi-bracketing low dynamic range images into high dynamic range, stitching multiple images into a panorama and estimating the motion of a moving camera. Meshroom's nodal architecture allows the user to customize the different pipelines to adjust them to their domain specific needs. The user can interactively add other processing nodes to modify a pipeline, export intermediate data},
  langid = {english}
}

@misc{gronneIntroductionEmbeddingClustering2022,
  title = {Introduction to {{Embedding}}, {{Clustering}}, and {{Similarity}}},
  author = {Gr{\o}nne, Mathias},
  year = {2022},
  month = oct,
  journal = {Medium},
  urldate = {2025-01-05},
  abstract = {Introduction to key elements of ML and Autoencoders: Embedding, Clustering, and Similarity.},
  howpublished = {https://towardsdatascience.com/introduction-to-embedding-clustering-and-similarity-11dd80b00061},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/IAHTL8W4/introduction-to-embedding-clustering-and-similarity-11dd80b00061.html}
}

@article{gumGuideExpressionUncertainty,
  title = {Guide to the Expression of Uncertainty in Measurement - {{Part}} 6: {{Developing}} and Using Measurement Models},
  author = {Gum, Jcgm},
  langid = {english}
}

@article{guoIlluminationInvariantSegmentation2013,
  title = {Illumination Invariant Segmentation of Vegetation for Time Series Wheat Images Based on Decision Tree Model},
  author = {Guo, Wei and Rage, Uday K. and Ninomiya, Seishi},
  year = {2013},
  month = aug,
  journal = {Computers and Electronics in Agriculture},
  volume = {96},
  pages = {58--66},
  issn = {0168-1699},
  doi = {10.1016/j.compag.2013.04.010},
  urldate = {2023-01-13},
  abstract = {Effective and efficient segmentation of vegetation from digital plant images is an actively studied topic in crop phenotyping. Many of the formerly proposed methods showed good performance in the extraction under controlled light conditions but it is still hard to properly extract only vegetation from RGB images taken under natural light condition where the images can contain shadowed and lighted parts with specularly reflected parts of plants. In this paper, we propose a robust method to extract vegetation from the plant images taken under natural light conditions using wheat images. The method is based on a machine learning process, decision tree and image noise reduction filters. We adopted the CART algorithm to create a decision tree in the training process and examined its performance using test images, comparing it with the performances of other methods such as ExG, ExG-ExR and Modified ExG which are widely used recently. The results showed that the accuracy of the vegetation extraction by the proposed method was significantly better than that of the other methods particularly for the images which include strongly shadowed and specularly reflected parts. The proposed method also has an advantage that the same model can be applied to different images without requiring a threshold adjustment for each image.},
  langid = {english},
  keywords = {Machine learning,Natural light condition,Non-thresholding,Specular reflection,Vegetation segmentation}
}

@article{haDeepConvolutionalNeural2017,
  title = {Deep Convolutional Neural Network for Classifying {{Fusarium}} Wilt of Radish from Unmanned Aerial Vehicles},
  author = {Ha, Jin Gwan and Moon, Hyeonjoon and Kwak, Jin Tae and Hassan, Syed Ibrahim and Dang, Minh and Lee, O. New and Park, Han Yong},
  year = {2017},
  month = dec,
  journal = {Journal of Applied Remote Sensing},
  volume = {11},
  number = {4},
  pages = {042621},
  publisher = {SPIE},
  issn = {1931-3195, 1931-3195},
  doi = {10.1117/1.JRS.11.042621},
  urldate = {2023-01-13},
  abstract = {Recently, unmanned aerial vehicles (UAVs) have gained much attention. In particular, there is a growing interest in utilizing UAVs for agricultural applications such as crop monitoring and management. We propose a computerized system that is capable of detecting Fusarium wilt of radish with high accuracy. The system adopts computer vision and machine learning techniques, including deep learning, to process the images captured by UAVs at low altitudes and to identify the infected radish. The whole radish field is first segmented into three distinctive regions (radish, bare ground, and mulching film) via a softmax classifier and K-means clustering. Then, the identified radish regions are further classified into healthy radish and Fusarium wilt of radish using a deep convolutional neural network (CNN). In identifying radish, bare ground, and mulching film from a radish field, we achieved an accuracy of {$\geq$}97.4\%. In detecting Fusarium wilt of radish, the CNN obtained an accuracy of 93.3\%. It also outperformed the standard machine learning algorithm, obtaining 82.9\% accuracy. Therefore, UAVs equipped with computational techniques are promising tools for improving the quality and efficiency of agriculture today.}
}

@article{hajamEffectiveEnsembleConvolutional2023,
  title = {An {{Effective Ensemble Convolutional Learning Model}} with {{Fine-Tuning}} for {{Medicinal Plant Leaf Identification}}},
  author = {Hajam, Mohd Asif and Arif, Tasleem and Khanday, Akib Mohi Ud Din and Neshat, Mehdi},
  year = {2023},
  month = nov,
  journal = {Information},
  volume = {14},
  number = {11},
  pages = {618},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2078-2489},
  doi = {10.3390/info14110618},
  urldate = {2024-01-25},
  abstract = {Accurate and efficient medicinal plant image classification is of utmost importance as these plants produce a wide variety of bioactive compounds that offer therapeutic benefits. With a long history of medicinal plant usage, different parts of plants, such as flowers, leaves, and roots, have been recognized for their medicinal properties and are used for plant identification. However, leaf images are extensively used due to their convenient accessibility and are a major source of information. In recent years, transfer learning and fine-tuning, which use pre-trained deep convolutional networks to extract pertinent features, have emerged as an extremely effective approach for image-identification problems. This study leveraged the power by three-component deep convolutional neural networks, namely VGG16, VGG19, and DenseNet201, to derive features from the input images of the medicinal plant dataset, containing leaf images of 30 classes. The models were compared and ensembled to make four hybrid models to enhance the predictive performance by utilizing the averaging and weighted averaging strategies. Quantitative experiments were carried out to evaluate the models on the Mendeley Medicinal Leaf Dataset. The resultant ensemble of VGG19+DensNet201 with fine-tuning showcased an enhanced capability in identifying medicinal plant images with an improvement of 7.43\% and 5.8\% compared with VGG19 and VGG16. Furthermore, VGG19+DensNet201 can outperform its standalone counterparts by achieving an accuracy of 99.12\% on the test set. A thorough assessment with metrics such as accuracy, recall, precision, and the F1-score firmly established the effectiveness of the ensemble strategy.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {ensemble convolutional learning,fine-tuning,medicinal plant identification,multiclass classification,transfer learning}
}

@article{hamdaneComparisonProximalRemote2022,
  title = {Comparison of {{Proximal Remote Sensing Devices}} of {{Vegetable Crops}} to {{Determine}} the {{Role}} of {{Grafting}} in {{Plant Resistance}} to {{Meloidogyne}} Incognita},
  author = {Hamdane, Yassine and {Gracia-Romero}, Adrian and Buchaillot, Maria Luisa and {Sanchez-Bragado}, Rut and Fullana, Aida Magdalena and Sorribas, Francisco Javier and Araus, Jos{\'e} Luis and Kefauver, Shawn C.},
  year = {2022},
  month = apr,
  journal = {Agronomy},
  volume = {12},
  number = {5},
  pages = {1098},
  issn = {2073-4395},
  doi = {10.3390/agronomy12051098},
  urldate = {2022-09-19},
  abstract = {Proximal remote sensing devices are novel tools that enable the study of plant health status through the measurement of specific characteristics, including the color or spectrum of light reflected or transmitted by the leaves or the canopy. The aim of this study is to compare the RGB and multispectral data collected during five years (2016--2020) of four fruiting vegetables (melon, tomato, eggplant, and peppers) with trial treatments of non-grafted and grafted onto resistant rootstocks cultivated in a Meloidogyne incognita (a root-knot nematode) infested soil in a greenhouse. The proximal remote sensing of plant health status data collected was divided into three levels. Firstly, leaf level pigments were measured using two different handheld sensors (SPAD and Dualex). Secondly, canopy vigor and biomass were assessed using vegetation indices derived from RGB images and the Normalized Difference Vegetation Index (NDVI) measured with a portable spectroradiometer (Greenseeker). Third, we assessed plant level water stress, as a consequence of the root damage by nematodes, using stomatal conductance measured with a porometer and indirectly using plant temperature with an infrared thermometer, and also the stable carbon isotope composition of leaf dry matter.. It was found that the interaction between treatments and crops (ANOVA) was statistically different for only four of seventeen parameters: flavonoid (p {$<$} 0.05), NBI (p {$<$} 0.05), NDVI (p {$<$} 0.05) and the RGB CSI (Crop Senescence Index) (p {$<$} 0.05). Concerning the effect of treatments across all crops, differences existed only in two parameters, which were flavonoid (p {$<$} 0.05) and CSI (p {$<$} 0.001). Grafted plants contained fewer flavonoids (x{\textasciimacron} = 1.37) and showed lower CSI (x{\textasciimacron} = 11.65) than non-grafted plants (x{\textasciimacron} = 1.98 and x{\textasciimacron} = 17.28, respectively, p {$<$} 0.05 and p {$<$} 0.05) when combining all five years and four crops. We conclude that the grafted plants were less stressed and more protected against nematode attack. Leaf flavonoids content and the CSI index were robust indicators of root-knot nematode impacts across multiple crop types.},
  langid = {english}
}

@article{hansenMultispectralRadiometrySource1992,
  title = {Multispectral Radiometry {{A}} Source of Additional Data in Field Fungicide Trials},
  author = {Hansen, {\relax JG} and J{\o}rgensen, {\relax LN} and Simonsen, J},
  year = {1992},
  journal = {Statens Planteavlsfors{\o}g},
  pages = {39}
}

@book{hartleyMultipleViewGeometry2004,
  title = {Multiple {{View Geometry}} in {{Computer Vision}}},
  author = {Hartley, Richard and Zisserman, Andrew},
  year = {2004},
  edition = {2},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9780511811685},
  urldate = {2023-03-23},
  abstract = {A basic problem in computer vision is to understand the structure of a real world scene given several images of it. Techniques for solving this problem are taken from projective geometry and photogrammetry. Here, the authors cover the geometric principles and their algebraic representation in terms of camera projection matrices, the fundamental matrix and the trifocal tensor. The theory and methods of computation of these entities are discussed with real examples, as is their use in the reconstruction of scenes from multiple images. The new edition features an extended introduction covering the key ideas in the book (which itself has been updated with additional examples and appendices) and significant new results which have appeared since the first edition. Comprehensive background material is provided, so readers familiar with linear algebra and basic numerical methods can understand the projective geometry and estimation algorithms presented, and implement the algorithms directly from the book.},
  isbn = {978-0-521-54051-3},
  file = {/home/samuelebumbaca/Zotero/storage/FVTPY22J/0B6F289C78B2B23F596CAA76D3D43F7A.html}
}

@misc{HarvestMasterJuniper,
  title = {Harvest {{Master}} by {{Juniper Systems}}},
  urldate = {2022-09-19},
  howpublished = {https://www.harvestmaster.com/},
  file = {/home/samuelebumbaca/Zotero/storage/N77UMA5J/www.harvestmaster.com.html}
}

@article{hasanbelliuInformationTheoreticShape2014,
  title = {Information {{Theoretic Shape Matching}}},
  author = {Hasanbelliu, Erion and Giraldo, Luis Sanchez and Principe, Jose C.},
  year = {2014},
  month = dec,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {36},
  number = {12},
  pages = {2436--2451},
  issn = {0162-8828, 2160-9292},
  doi = {10.1109/TPAMI.2014.2324585},
  urldate = {2021-12-19}
}

@book{hastieElementsStatisticalLearning2009,
  title = {The {{Elements}} of {{Statistical Learning}}},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year = {2009},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {Springer},
  address = {New York, NY},
  doi = {10.1007/978-0-387-84858-7},
  urldate = {2025-03-16},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-0-387-84857-0 978-0-387-84858-7},
  keywords = {Averaging,Boosting,classification,clustering,data mining,machine learning,Projection pursuit,Random Forest,supervised learning,Support Vector Machine,unsupervised learning}
}

@inproceedings{heExemplarbasedCRFMultiinstance2014,
  title = {An {{Exemplar-based CRF}} for {{Multi-instance Object Segmentation}}},
  booktitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {He, Xuming and Gould, Stephen},
  year = {2014},
  pages = {296--303},
  urldate = {2023-01-13}
}

@article{hillnhutterRemoteSensingDetect2011,
  title = {Remote Sensing to Detect Plant Stress Induced by {{Heterodera}} Schachtii and {{Rhizoctonia}} Solani in Sugar Beet Fields},
  author = {Hillnh{\"u}tter, C. and Mahlein, A. -K. and Sikora, R. A. and Oerke, E. -C.},
  year = {2011},
  month = apr,
  journal = {Field Crops Research},
  volume = {122},
  number = {1},
  pages = {70--77},
  issn = {0378-4290},
  doi = {10.1016/j.fcr.2011.02.007},
  urldate = {2023-01-13},
  abstract = {The characteristically clustered occurrence and low level of mobility of Heterodera schachtii and Rhizoctonia solani in the soil and the induction of stress symptoms in the sugar beet canopy make them ideal targets for site-specific arrangements with precision agriculture tools. A field site infested with H. schachtii and R. solani was investigated in 2009 with near-range and aerial hyperspectral sensors during the growing season. At 31 sample points ground truth data for incidence and severity of the two organisms were collected and geo-referenced. Spectral vegetation indices computed from reflectance measurements obtained from two flight campaigns (AISA, 17th of June; HyMap, 28th of August) and the near-range spectroradiometers were significantly correlated (P{$<$}0.01) with symptoms caused by the nematode or Rhizoctonia crown and root rot. A supervised classification with Spectral Angle Mapper of leaf symptoms induced by the organisms resulted in a classification accuracy of 72 and 64\% for the AISA and HyMap data, respectively. The results demonstrated that remote sensing in combination with geographic information system technologies can be used effectively for the detection and mapping of symptoms caused by beet cyst nematode and Rhizoctonia crown and root rot.},
  langid = {english},
  keywords = {Hyperspectral,Nematode,Soil-borne pathogens,Supervised classification,Vegetation indices}
}

@inproceedings{hirschmullerAccurateEfficientStereo2005,
  title = {Accurate and Efficient Stereo Processing by Semi-Global Matching and Mutual Information},
  booktitle = {2005 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}}'05)},
  author = {Hirschmuller, H.},
  year = {2005},
  month = jun,
  volume = {2},
  pages = {807-814 vol. 2},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2005.56},
  abstract = {This paper considers the objectives of accurate stereo matching, especially at object boundaries, robustness against recording or illumination changes and efficiency of the calculation. These objectives lead to the proposed semi-global matching method that performs pixelwise matching based on mutual information and the approximation of a global smoothness constraint. Occlusions are detected and disparities determined with sub-pixel accuracy. Additionally, an extension for multi-baseline stereo images is presented. There are two novel contributions. Firstly, a hierarchical calculation of mutual information based matching is shown, which is almost as fast as intensity based matching. Secondly, an approximation of a global cost calculation is proposed that can be performed in a time that is linear to the number of pixels and disparities. The implementation requires just 1 second on typical images.},
  keywords = {Belief propagation,Costs,Geometry,Image reconstruction,Lighting,Mutual information,Pixel,Reflection,Robustness,Stereo vision},
  file = {/home/samuelebumbaca/Zotero/storage/9CIE4QMZ/1467526.html}
}

@article{hirschmullerStereoProcessingSemiglobal2008,
  title = {Stereo {{Processing}} by {{Semiglobal Matching}} and {{Mutual Information}}},
  author = {Hirschmuller, H.},
  year = {2008},
  month = feb,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {30},
  number = {2},
  pages = {328--341},
  issn = {0162-8828},
  doi = {10.1109/TPAMI.2007.1166},
  urldate = {2022-11-24},
  abstract = {This paper describes the Semi-Global Matching (SGM) stereo method. It uses a pixelwise, Mutual Information based matching cost for compensating radiometric differences of input images. Pixelwise matching is supported by a smoothness constraint that is usually expressed as a global cost function. SGM performs a fast approximation by pathwise optimizations from all directions. The discussion also addresses occlusion detection, subpixel refinement and multi-baseline matching. Additionally, postprocessing steps for removing outliers, recovering from specific problems of structured environments and the interpolation of gaps are presented. Finally, strategies for processing almost arbitrarily large images and fusion of disparity images using orthographic projection are proposed.},
  langid = {english}
}

@article{hughesOpenAccessRepository,
  title = {An Open Access Repository of Images on Plant Health to Enable the Development of Mobile Disease Diagnostics},
  author = {Hughes, David P and Salath{\'e}, Marcel},
  abstract = {Human society needs to increase food production by an estimated 70\% by 2050 to feed an expected population size that is predicted to be over 9 billion people. Currently, infectious diseases reduce the potential yield by an average of 40\% with many farmers in the developing world experiencing yield losses as high as 100\%. The widespread distribution of smartphones among crop growers around the world with an expected 5 billion smartphones by 2020 offers the potential of turning the smartphone into a valuable tool for diverse communities growing food. One potential application is the development of mobile disease diagnostics through machine learning and crowdsourcing. Here we announce the release of over 50,000 expertly curated images on healthy and infected leaves of crops plants through the existing online platform PlantVillage. We describe both the data and the platform. These data are the beginning of an on-going, crowdsourcing effort to enable computer vision approaches to help solve the problem of yield losses in crop plants due to infectious diseases.},
  langid = {english}
}

@article{huizingaPCAbasedGroupwiseImage2016,
  title = {{{PCA-based}} Groupwise Image Registration for Quantitative {{MRI}}},
  author = {Huizinga, W. and Poot, D.H.J. and Guyader, J.-M. and Klaassen, R. and Coolen, B.F. and {van Kranenburg}, M. and {van Geuns}, R.J.M. and Uitterdijk, A. and Polfliet, M. and Vandemeulebroucke, J. and Leemans, A. and Niessen, W.J. and Klein, S.},
  year = {2016},
  month = apr,
  journal = {Medical Image Analysis},
  volume = {29},
  pages = {65--78},
  issn = {13618415},
  doi = {10.1016/j.media.2015.12.004},
  urldate = {2021-12-19},
  langid = {english}
}

@misc{HyperspectralRemoteSensing,
  title = {Hyperspectral Remote Sensing of Plant Pigments {\textbar} {{Journal}} of {{Experimental Botany}} {\textbar} {{Oxford Academic}}},
  urldate = {2023-01-13},
  howpublished = {https://academic.oup.com/jxb/article/58/4/855/424429}
}

@misc{HyperspectralRemoteSensinga,
  title = {Hyperspectral Remote Sensing of Plant Pigments {\textbar} {{Journal}} of {{Experimental Botany}} {\textbar} {{Oxford Academic}}},
  urldate = {2023-01-13},
  howpublished = {https://academic.oup.com/jxb/article/58/4/855/424429}
}

@misc{INISRepositorySearch,
  title = {{{INIS Repository Search}} - {{Citation}}},
  urldate = {2023-03-10},
  howpublished = {https://inis.iaea.org/search/citationdownload.aspx},
  file = {/home/samuelebumbaca/Zotero/storage/I37FITUG/citationdownload.html}
}

@article{InterpretationStructureMotion1979,
  title = {The Interpretation of Structure from Motion},
  year = {1979},
  month = jan,
  journal = {Proceedings of the Royal Society of London. Series B. Biological Sciences},
  volume = {203},
  number = {1153},
  pages = {405--426},
  issn = {0080-4649, 2053-9193},
  doi = {10.1098/rspb.1979.0006},
  urldate = {2022-01-31},
  abstract = {The interpretation of structure from motion is examined from a computional point of view. The question addressed is how the three dimen\-sional structure and motion of objects can be inferred from the two dimensional transformations of their projected images when no three dimensional information is conveyed by the individual projections. The following scheme is proposed: (i) divide the image into groups of four elements each; (ii) test each group for a rigid interpretation; (iii) combine the results obtained in (ii). It is shown that this scheme will correctly decompose scenes containing arbitrary rigid objects in motion, recovering their three dimensional structure and motion. The analysis is based primarily on the 'structure from motion' theorem which states that the structure of four non-coplanar points is recoverable from three orthographic projections. The interpretation scheme is extended to cover perspective projections, and its psychological relevance is discussed.},
  langid = {english}
}

@article{jacquemoudPROSPECTModelLeaf1990,
  title = {{{PROSPECT}}: {{A}} Model of Leaf Optical Properties Spectra},
  shorttitle = {{{PROSPECT}}},
  author = {Jacquemoud, S. and Baret, F.},
  year = {1990},
  month = nov,
  journal = {Remote Sensing of Environment},
  volume = {34},
  number = {2},
  pages = {75--91},
  issn = {0034-4257},
  doi = {10.1016/0034-4257(90)90100-Z},
  urldate = {2023-01-13},
  abstract = {PROSPECT is a radiative transfer model based of Allen's generalized ``plate model'' that represents the optical properties of plant leaves from 400 nm to 2500 nm. Scattering is described by a spectral refractive index (n) and a parameter characterizing the leaf mesophyll structure (N). Absorption is modeled using pigment concentration (Ca+b), water content (Cw), and the corresponding specific spectral absorption coefficients (Ka+b and Kw). The parameters n, Ka+b, and Kw have been fitted using experimental data corresponding to a wide range of plant types and status. PROSPECT has been tested successfully on independent data sets. Its inversion allows one to reconstruct, with reasonable accuracy, leaf reflectance, and transmittance features in the 400--2500 nm range by adjusting the three input variables N, Ca+b, and Cw.},
  langid = {english}
}

@article{jamesAssessmentPlantDiseases1974,
  title = {Assessment of {{Plant Diseases}} and {{Losses}}},
  author = {James, W C},
  year = {1974},
  journal = {Annual Review of Phytopathology},
  volume = {12},
  number = {1},
  pages = {27--48},
  doi = {10.1146/annurev.py.12.090174.000331},
  urldate = {2023-01-13}
}

@book{jamesIntroductionStatisticalLearning2023,
  title = {An {{Introduction}} to {{Statistical Learning}}: With {{Applications}} in {{Python}}},
  shorttitle = {An {{Introduction}} to {{Statistical Learning}}},
  author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert and Taylor, Jonathan},
  year = {2023},
  series = {Springer {{Texts}} in {{Statistics}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-38747-0},
  urldate = {2025-03-16},
  copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
  isbn = {978-3-031-38746-3 978-3-031-38747-0},
  langid = {english},
  keywords = {data mining,inference,Python,Python software,statistical learning,supervised learning,unsupervsied learning}
}

@article{jayEstimatingLeafChlorophyll2017,
  title = {Estimating Leaf Chlorophyll Content in Sugar Beet Canopies Using Millimeter- to Centimeter-Scale Reflectance Imagery},
  author = {Jay, Sylvain and Gorretta, Nathalie and Morel, Julien and Maupas, Fabienne and Bendoula, Ryad and Rabatel, Gilles and Dutartre, Dan and Comar, Alexis and Baret, Fr{\'e}d{\'e}ric},
  year = {2017},
  month = sep,
  journal = {Remote Sensing of Environment},
  volume = {198},
  pages = {173--186},
  issn = {0034-4257},
  doi = {10.1016/j.rse.2017.06.008},
  urldate = {2023-01-13},
  abstract = {Accurate estimation of leaf chlorophyll content (Cab) from remote sensing is of tremendous significance to monitor the physiological status of vegetation or to estimate primary production. Many vegetation indices (VIs) have been developed to retrieve Cab at the canopy level from meter- to decameter-scale reflectance observations. However, most of these VIs may be affected by the possible confounding influence of canopy structure. The objective of this study is to develop methods for Cab estimation using millimeter to centimeter spatial resolution reflectance imagery acquired at the field level. Hyperspectral images were acquired over sugar beet canopies from a ground-based platform in the 400--1000nm range, concurrently to Cab, green fraction (GF), green area index (GAI) ground measurements. The original image spatial resolution was successively degraded from 1mm to 35cm, resulting in eleven sets of hyperspectral images. Vegetation and soil pixels were discriminated, and for each spatial resolution, measured Cab values were related to various VIs computed over four sets of reflectance spectra extracted from the images (soil and vegetation pixels, only vegetation pixels, 50\% darkest and brightest vegetation pixels). The selected VIs included some classical VIs from the literature as well as optimal combinations of spectral bands, including simple ratio (SR), modified normalized difference (mND) and structure insensitive pigment index (SIPI). In the case of mND and SIPI, the use of a blue reference band instead of the classical near-infrared one was also investigated. For the eleven spatial resolutions, the four pixel selections and the five VI formats, similar band combinations are obtained when optimizing VI performances: the main bands of interest are generally located in the blue, red, red-edge and near-infrared domains. Overall, mNDblue[728,850] defined as (R440-R728)/(R440+R850) and computed over the brightest green pixels obtains the best correlations with Cab for spatial resolutions finer than 8.8cm with a root mean square error of prediction better than 2.6{$\mu$}g/cm2. Conversely, mNDblue[728,850] poorly correlates with variations in GF and GAI, thus reducing the risk of deriving non-causal relationships with Cab that would actually be due to the covariance between Cab and these canopy structure variables. As mNDblue[728,850] can be calculated from most current multispectral sensors, it is therefore a promising VI to retrieve Cab from millimeter- to centimeter-scale reflectance imagery.},
  langid = {english},
  keywords = {Leaf chlorophyll content,Millimeter to centimeter spatial resolutions,mND,Reflectance imagery,Vegetation index}
}

@article{jayPhysicallybasedModelRetrieving2016,
  title = {A Physically-Based Model for Retrieving Foliar Biochemistry and Leaf Orientation Using Close-Range Imaging Spectroscopy},
  author = {Jay, Sylvain and Bendoula, Ryad and Hadoux, Xavier and F{\'e}ret, Jean-Baptiste and Gorretta, Nathalie},
  year = {2016},
  month = may,
  journal = {Remote Sensing of Environment},
  volume = {177},
  pages = {220--236},
  issn = {0034-4257},
  doi = {10.1016/j.rse.2016.02.029},
  urldate = {2023-01-13},
  abstract = {Radiative transfer models have long been used to characterize the foliar content at the leaf and canopy levels. However, they still do not apply well to close-range imaging spectroscopy, especially because directional effects are usually not taken into account. For this purpose, we introduce a physical approach to describe and simulate the variation in leaf reflectance observed at this scale. Two parameters are thus introduced to represent (1) specular reflection at the leaf surface and (2) local leaf orientation. The model, called COSINE (ClOse-range Spectral ImagiNg of lEaves), can be coupled with a directional--hemispherical reflectance model of leaf optical properties to relate the measured reflectance to the foliar content. In this study, we show that, when combining COSINE with the PROSPECT model, the overall PROCOSINE model allows for a robust submillimeter retrieval of foliar content based on numerical inversion and pseudo-bidirectional reflectance factor hyperspectral measurements. The relevance of the added parameters is first shown through a sensitivity analysis performed in the visible and near-infrared (VNIR) and shortwave infrared (SWIR) ranges. PROCOSINE is then validated based on VNIR and SWIR hyperspectral images of various leaf species exhibiting different surface properties. Introducing these two parameters within the inversion allows us to obtain accurate maps of PROSPECT parameters, e.g., the chlorophyll content in the VNIR range, and the equivalent water thickness and leaf mass per area in the SWIR range. Through the estimation of light incident angle, the PROCOSINE inversion also provides information on leaf orientation, which is a critical parameter in vegetation remote sensing.},
  langid = {english},
  keywords = {Close-range,COSINE,Hyperspectral,Imaging spectroscopy,Leaf optical properties,Pigment retrieval,PROCOSINE,PROSPECT,Radiative transfer,Vegetation}
}

@article{jayPhysicallybasedModelRetrieving2016a,
  title = {A Physically-Based Model for Retrieving Foliar Biochemistry and Leaf Orientation Using Close-Range Imaging Spectroscopy},
  author = {Jay, Sylvain and Bendoula, Ryad and Hadoux, Xavier and F{\'e}ret, Jean-Baptiste and Gorretta, Nathalie},
  year = {2016},
  month = may,
  journal = {Remote Sensing of Environment},
  volume = {177},
  pages = {220--236},
  issn = {0034-4257},
  doi = {10.1016/j.rse.2016.02.029},
  urldate = {2023-01-13},
  abstract = {Radiative transfer models have long been used to characterize the foliar content at the leaf and canopy levels. However, they still do not apply well to close-range imaging spectroscopy, especially because directional effects are usually not taken into account. For this purpose, we introduce a physical approach to describe and simulate the variation in leaf reflectance observed at this scale. Two parameters are thus introduced to represent (1) specular reflection at the leaf surface and (2) local leaf orientation. The model, called COSINE (ClOse-range Spectral ImagiNg of lEaves), can be coupled with a directional--hemispherical reflectance model of leaf optical properties to relate the measured reflectance to the foliar content. In this study, we show that, when combining COSINE with the PROSPECT model, the overall PROCOSINE model allows for a robust submillimeter retrieval of foliar content based on numerical inversion and pseudo-bidirectional reflectance factor hyperspectral measurements. The relevance of the added parameters is first shown through a sensitivity analysis performed in the visible and near-infrared (VNIR) and shortwave infrared (SWIR) ranges. PROCOSINE is then validated based on VNIR and SWIR hyperspectral images of various leaf species exhibiting different surface properties. Introducing these two parameters within the inversion allows us to obtain accurate maps of PROSPECT parameters, e.g., the chlorophyll content in the VNIR range, and the equivalent water thickness and leaf mass per area in the SWIR range. Through the estimation of light incident angle, the PROCOSINE inversion also provides information on leaf orientation, which is a critical parameter in vegetation remote sensing.},
  langid = {english},
  keywords = {Close-range,COSINE,Hyperspectral,Imaging spectroscopy,Leaf optical properties,Pigment retrieval,PROCOSINE,PROSPECT,Radiative transfer,Vegetation},
  file = {/home/samuelebumbaca/Zotero/storage/U4PV5VIP/S0034425716300566.html}
}

@article{jiangResearchAccuracyStability2015,
  title = {{[Research on Accuracy and Stability of Inversing Vegetation Chlorophyll Content by Spectral Index Method]}},
  author = {Jiang, Hai-ling and Yang, Hang and Chen, Xiao-ping and Wang, Shu-dong and Li, Xue-ke and Liu, Kai and Cen, Yi},
  year = {2015},
  month = apr,
  journal = {Guang Pu Xue Yu Guang Pu Fen Xi = Guang Pu},
  volume = {35},
  number = {4},
  pages = {975--981},
  issn = {1000-0593},
  abstract = {Spectral index method was widely applied to the inversion of crop chlorophyll content. In the present study, PSR3500 spectrometer and SPAD-502 chlorophyll fluorometer were used to acquire the spectrum and relative chlorophyll content (SPAD value) of winter wheat leaves on May 2nd 2013 when it was at the jointing stage of winter wheat. Then the measured spectra were resampled to simulate TM multispectral data and Hyperion hyperspectral data respectively, using the Gaussian spectral response function. We chose four typical spectral indices including normalized difference vegetation index (NDVD, triangle vegetation index (TVI), the ratio of modified transformed chlorophyll absorption ratio index (MCARI) to optimized soil adjusted vegetation index (OSAVI) (MCARI/OSAVI) and vegetation index based on universal pattern decomposition (VIUPD), which were constructed with the feature bands sensitive to the vegetation chlorophyll. After calculating these spectral indices based on the resampling TM and Hyperion data, the regression equation between spectral indices and chlorophyll content was established. For TM, the result indicates that VIUPD has the best correlation with chlorophyll (R2 = 0.819 7) followed by NDVI (R2 = 0.791 8), while MCARI/OSAVI and TVI also show a good correlation with R2 higher than 0.5. For the simulated Hyperion data, VIUPD again ranks first with R2 = 0.817 1, followed by MCARI/OSAVI (R2 = 0.658 6), while NDVI and TVI show very low values with R2 less than 0.2. It was demonstrated that VIUPD has the best accuracy and stability to estimate chlorophyll of winter wheat whether using simulated TM data or Hyperion data, which reaffirms that VIUPD is comparatively sensor independent. The chlorophyll estimation accuracy and stability of MCARI/OSAVI also works well, partly because OSAVI could reduce the influence of backgrounds. Two broadband spectral indices NDVI and TVI are weak for the chlorophyll estimation of simulated Hyperion data mainly because of their dependence on few bands and the strong influence of atmosphere, solar altitude, viewing angle of sensor, background and so on. In conclusion, the stability and consistency of chlorophyll estimation is equally important to the estimation accuracy by spectral index method. VIUPD introduced in the study has the best performance to estimate winter wheat chlorophyll, which illustrates its potential ability in the area of estimating vegetation biochemical parameters.},
  langid = {jpn},
  pmid = {26197586},
  keywords = {Chlorophyll,Plant Leaves,Soil,Spectrum Analysis,Triticum}
}

@article{jiangResearchAccuracyStability2015a,
  title = {{[Research on Accuracy and Stability of Inversing Vegetation Chlorophyll Content by Spectral Index Method]}},
  author = {Jiang, Hai-ling and Yang, Hang and Chen, Xiao-ping and Wang, Shu-dong and Li, Xue-ke and Liu, Kai and Cen, Yi},
  year = {2015},
  month = apr,
  journal = {Guang Pu Xue Yu Guang Pu Fen Xi = Guang Pu},
  volume = {35},
  number = {4},
  pages = {975--981},
  issn = {1000-0593},
  abstract = {Spectral index method was widely applied to the inversion of crop chlorophyll content. In the present study, PSR3500 spectrometer and SPAD-502 chlorophyll fluorometer were used to acquire the spectrum and relative chlorophyll content (SPAD value) of winter wheat leaves on May 2nd 2013 when it was at the jointing stage of winter wheat. Then the measured spectra were resampled to simulate TM multispectral data and Hyperion hyperspectral data respectively, using the Gaussian spectral response function. We chose four typical spectral indices including normalized difference vegetation index (NDVD, triangle vegetation index (TVI), the ratio of modified transformed chlorophyll absorption ratio index (MCARI) to optimized soil adjusted vegetation index (OSAVI) (MCARI/OSAVI) and vegetation index based on universal pattern decomposition (VIUPD), which were constructed with the feature bands sensitive to the vegetation chlorophyll. After calculating these spectral indices based on the resampling TM and Hyperion data, the regression equation between spectral indices and chlorophyll content was established. For TM, the result indicates that VIUPD has the best correlation with chlorophyll (R2 = 0.819 7) followed by NDVI (R2 = 0.791 8), while MCARI/OSAVI and TVI also show a good correlation with R2 higher than 0.5. For the simulated Hyperion data, VIUPD again ranks first with R2 = 0.817 1, followed by MCARI/OSAVI (R2 = 0.658 6), while NDVI and TVI show very low values with R2 less than 0.2. It was demonstrated that VIUPD has the best accuracy and stability to estimate chlorophyll of winter wheat whether using simulated TM data or Hyperion data, which reaffirms that VIUPD is comparatively sensor independent. The chlorophyll estimation accuracy and stability of MCARI/OSAVI also works well, partly because OSAVI could reduce the influence of backgrounds. Two broadband spectral indices NDVI and TVI are weak for the chlorophyll estimation of simulated Hyperion data mainly because of their dependence on few bands and the strong influence of atmosphere, solar altitude, viewing angle of sensor, background and so on. In conclusion, the stability and consistency of chlorophyll estimation is equally important to the estimation accuracy by spectral index method. VIUPD introduced in the study has the best performance to estimate winter wheat chlorophyll, which illustrates its potential ability in the area of estimating vegetation biochemical parameters.},
  langid = {jpn},
  pmid = {26197586},
  keywords = {Chlorophyll,Plant Leaves,Soil,Spectrum Analysis,Triticum}
}

@article{jinCornPlantSensing2009,
  title = {Corn Plant Sensing Using Real-Time Stereo Vision},
  author = {Jin, Jian and Tang, Lie},
  year = {2009},
  journal = {Journal of Field Robotics},
  volume = {26},
  number = {6-7},
  pages = {591--608},
  issn = {1556-4967},
  doi = {10.1002/rob.20293},
  urldate = {2023-01-13},
  abstract = {Though some two-dimensional (2D) machine vision--based systems for early-growth-stage corn plant sensing exist, some of their shortcomings are difficult to overcome. The greatest challenge comes from separating individual corn plants with overlapped plant canopies. With 2D machine vision, variation in outdoor lighting conditions and weeds in the background also pose difficulties in corn plant identification. Adding the depth dimension has the potential to improve the performance of such a sensing system. A new corn plant sensing system using a real-time stereo vision system was investigated in this research. Top-view depth images of corn plant canopy were acquired. By processing the depth images, the algorithm effectively updated the plant skeleton structures and finally recognized individual corn plants and detected their center positions. The stereo vision system was tested over corn plants of V2--V3 growth stages in both laboratory and field conditions. Experimental results showed that the stereo vision system was capable of detecting both separated and overlapped corn plants. During the field test, 96.7\% of the corn plants were correctly detected, and plant center positions were estimated with maximum distance errors of 5 and 1 cm for 74.6\% and 62.3\% of detections, respectively. {\copyright} 2009 Wiley Periodicals, Inc.},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/8PT7KKFF/rob.html}
}

@article{juGLCCGeneralFramework2023,
  title = {{{GLCC}}: {{A General Framework}} for {{Graph-Level Clustering}}},
  shorttitle = {{{GLCC}}},
  author = {Ju, Wei and Gu, Yiyang and Chen, Binqi and Sun, Gongbo and Qin, Yifang and Liu, Xingyuming and Luo, Xiao and Zhang, Ming},
  year = {2023},
  month = jun,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {37},
  number = {4},
  pages = {4391--4399},
  issn = {2374-3468},
  doi = {10.1609/aaai.v37i4.25559},
  urldate = {2025-01-13},
  abstract = {This paper studies the problem of graph-level clustering, which is a novel yet challenging task. This problem is critical in a variety of real-world applications such as protein clustering and genome analysis in bioinformatics. Recent years have witnessed the success of deep clustering coupled with graph neural networks (GNNs). However, existing methods focus on clustering among nodes given a single graph, while exploring clustering on multiple graphs is still under-explored. In this paper, we propose a general graph-level clustering framework named Graph-Level Contrastive Clustering (GLCC) given multiple graphs. Specifically, GLCC first constructs an adaptive affinity graph to explore instance- and cluster-level contrastive learning (CL). Instance-level CL leverages graph Laplacian based contrastive loss to learn clustering-friendly representations while cluster-level CL captures discriminative cluster representations incorporating neighbor information of each sample. Moreover, we utilize neighbor-aware pseudo-labels to reward the optimization of representation learning. The two steps can be alternatively trained to collaborate and benefit each other. Experiments on a range of well-known datasets demonstrate the superiority of our proposed GLCC over competitive baselines.},
  copyright = {Copyright (c) 2023 Association for the Advancement of Artificial Intelligence},
  langid = {english},
  keywords = {ML: Clustering}
}

@book{kaehlerLearningOpenCV32016,
  title = {Learning {{OpenCV}} 3: {{Computer Vision}} in {{C}}++ with the {{OpenCV Library}}},
  shorttitle = {Learning {{OpenCV}} 3},
  author = {Kaehler, Adrian and Bradski, Gary},
  year = {2016},
  month = dec,
  publisher = {"O'Reilly Media, Inc."},
  abstract = {Get started in the rapidly expanding field of computer vision with this practical guide. Written by Adrian Kaehler and Gary Bradski, creator of the open source OpenCV library, this book provides a thorough introduction for developers, academics, roboticists, and hobbyists. You'll learn what it takes to build applications that enable computers to "see" and make decisions based on that data.With over 500 functions that span many areas in vision, OpenCV is used for commercial applications such as security, medical imaging, pattern and face recognition, robotics, and factory product inspection. This book gives you a firm grounding in computer vision and OpenCV for building simple or sophisticated vision applications. Hands-on exercises in each chapter help you apply what you've learned.This volume covers the entire library, in its modern C++ implementation, including machine learning tools for computer vision.Learn OpenCV data types, array types, and array operationsCapture and store still and video images with HighGUITransform images to stretch, shrink, warp, remap, and repairExplore pattern recognition, including face detectionTrack objects and motion through the visual fieldReconstruct 3D images from stereo visionDiscover basic and advanced machine learning techniques in OpenCV},
  googlebooks = {LPm3DQAAQBAJ},
  isbn = {978-1-4919-3796-9},
  langid = {english},
  keywords = {Computers / Artificial Intelligence / Computer Vision & Pattern Recognition,Computers / Languages / C,Technology & Engineering / Robotics}
}

@article{kalyoncuGeometricLeafClassification2015,
  title = {Geometric Leaf Classification},
  author = {Kalyoncu, Cem and Toygar, {\"O}nsen},
  year = {2015},
  month = apr,
  journal = {Computer Vision and Image Understanding},
  volume = {133},
  pages = {102--109},
  issn = {1077-3142},
  doi = {10.1016/j.cviu.2014.11.001},
  urldate = {2023-01-13},
  abstract = {In this paper, we propose a novel method including segmentation, a combination of new and well-known feature extraction and classification methods to classify plant leaves. The aim of the proposed features is to distinguish leaf margins, which cannot be distinguished using commonly used geometric features. Additionally, Linear Discriminant Classifier is used for classification, therefore using features that are noisy for some leaf types does not reduce the performance of the system. The proposed system outperforms the well-known geometric methods that are used for leaf classification.},
  langid = {english},
  keywords = {Geometric features,Leaf classification,Linear Discriminant Classifier,Multi-scale distance matrix}
}

@inproceedings{katafuchiImagebasedPlantDisease2021,
  title = {Image-Based {{Plant Disease Diagnosis}} with {{Unsupervised Anomaly Detection}} Based on {{Reconstructability}} of {{Colors}}:},
  shorttitle = {Image-Based {{Plant Disease Diagnosis}} with {{Unsupervised Anomaly Detection}} Based on {{Reconstructability}} of {{Colors}}},
  booktitle = {Proceedings of the {{International Conference}} on {{Image Processing}} and {{Vision Engineering}}},
  author = {Katafuchi, Ryoya and Tokunaga, Terumasa},
  year = {2021},
  pages = {112--120},
  publisher = {{SCITEPRESS - Science and Technology Publications}},
  address = {Online Streaming, --- Select a Country ---},
  doi = {10.5220/0010463201120120},
  urldate = {2024-07-23},
  abstract = {This paper proposes an unsupervised anomaly detection technique for image-based plant disease diagnosis. The construction of large and publicly available datasets containing labeled images of healthy and diseased crop plants led to growing interest in computer vision techniques for automatic plant disease diagnosis. Although supervised image classifiers based on deep learning can be a powerful tool for plant disease diagnosis, they require a huge amount of labeled data. The data mining technique of anomaly detection includes unsupervised approaches that do not require rare samples for training classifiers. We propose an unsupervised anomaly detection technique for image-based plant disease diagnosis that is based on the reconstructability of colors; a deep encoder-decoder network trained to reconstruct the colors of healthy plant images should fail to reconstruct colors of symptomatic regions. Our proposed method includes a new image-based framework for plant disease detection that utilizes a conditional adversarial network called pix2pix and a new anomaly score based on CIEDE2000 color difference. Experiments with PlantVillage dataset demonstrated the superiority of our proposed method compared to an existing anomaly detector at identifying diseased crop images in terms of accuracy, interpretability and computational efficiency.},
  isbn = {978-989-758-511-1},
  langid = {english}
}

@article{kaurImageFusionTechniques2021,
  title = {Image {{Fusion Techniques}}: {{A Survey}}},
  shorttitle = {Image {{Fusion Techniques}}},
  author = {Kaur, Harpreet and Koundal, Deepika and Kadyan, Virender},
  year = {2021},
  month = dec,
  journal = {Archives of Computational Methods in Engineering},
  volume = {28},
  number = {7},
  pages = {4425--4447},
  issn = {1134-3060, 1886-1784},
  doi = {10.1007/s11831-021-09540-7},
  urldate = {2021-12-19},
  langid = {english}
}

@article{kawataStatisticallyHarmonizedAlignmentClassification2007,
  title = {A {{Statistically Harmonized Alignment-Classification}} in {{Image Space Enables Accurate}} and {{Robust Alignment}} of {{Noisy Images}} in {{Single Particle Analysis}}},
  author = {Kawata, M. and Sato, C.},
  year = {2007},
  month = jun,
  journal = {Journal of Electron Microscopy},
  volume = {56},
  number = {3},
  pages = {83--92},
  issn = {0022-0744, 1477-9986},
  doi = {10.1093/jmicro/dfm010},
  urldate = {2021-12-19},
  langid = {english}
}

@article{kerrImmediateIrrigationImproves2019,
  title = {Immediate {{Irrigation Improves Turfgrass Safety}} to {{Postemergence Herbicides}}},
  author = {Kerr, Robert Andrew and McCarty, Lambert B. and Brown, Philip J. and Harris, James and McElroy, J. Scott},
  year = {2019},
  month = feb,
  journal = {HortScience},
  volume = {54},
  number = {2},
  pages = {353--356},
  issn = {0018-5345, 2327-9834},
  doi = {10.21273/HORTSCI13571-18},
  urldate = {2022-09-20},
  abstract = {Summer annual grassy weeds such as goosegrass (               Eleusine indica               L. Gaertn.) continue to be problematic to control selectively with postemergence (POST) herbicides within turfgrass stands. In recent years, reduced performance by certain herbicides (e.g., foramsulfuron), cancellation of goosegrass-specific herbicides (e.g., diclofop-methyl), and cancellation and/or severe use reductions of other herbicides [e.g., monosodium methanearsonate (MSMA)] have limited the options for satisfactory control and maintenance of an acceptable ({$\leq$}30\% visual turfgrass injury) turfgrass quality. Currently available herbicides (e.g., topramezone and metribuzin) with goosegrass activity typically injure warm-season turfgrass species. The objectives of this research were to evaluate both `Tifway 419' bermudagrass [               Cynodon dactylon               (L.) Pers. {\texttimes}               Cynodon transvaalensis               Burtt-Davy] injury after treatment with POST herbicides, and to determine whether irrigating immediately after application reduces turfgrass injury. Treatments were control ({\textpm} irrigation); topramezone (Pylex 2.8C; {\textpm} irrigation); carfentrazone + 2,4-D + dicamba + 2-(2-methyl-4-chlorophenoxy) propionic acid (MCPP) (Speedzone 2.2L; {\textpm} irrigation); carfentrazone + 2,4-D + dicamba + MCPP in combination with topramezone ({\textpm} irrigation); metribuzin (Sencor 75DF; {\textpm} irrigation); mesotrione (Tenacity 4L; {\textpm} irrigation); simazine 4L ({\textpm}irrigation); and mesotrione + simazine ({\textpm} irrigation). Irrigated treatments were applied immediately with a hand hose precalibrated to apply 0.6 cm or 0.25 inch ({$\approx$}6.3 L). Visual turfgrass injury for combined herbicide treatments for the irrigated plots was 6\% 4 days after treatment (DAT), 12\% 1 week after treatment (WAT), 17\% 2 WAT, and 6\% 4 WAT, whereas nonirrigated plots had turfgrass injury of 14\% at 4 DAT, 31\% 1 WAT, 35\% 2 WAT, and 12\% 4 WAT. Irrigated pots had normalized differences vegetative indices (NDVI) ratings of 0.769 at 4 DAT, 0.644 at 1 WAT, 0.612 at 2 WAT, and 0.621 at 4 WAT, whereas nonirrigated plots had the lowest (least green) turfgrass NDVI ratings of 0.734 at 4 DAT, 0.599 at 1 WAT, 0.528 at 2 WAT, and 0.596 at 4 WAT. These experiments suggest turfgrass injury could be alleviated by immediately incorporating herbicides through irrigation.}
}

@incollection{kerstingFeedingWorldBig2016,
  title = {Feeding the {{World}} with {{Big Data}}: {{Uncovering Spectral Characteristics}} and {{Dynamics}} of {{Stressed Plants}}},
  shorttitle = {Feeding the {{World}} with {{Big Data}}},
  booktitle = {Computational {{Sustainability}}},
  author = {Kersting, Kristian and Bauckhage, Christian and Wahabzada, Mirwaes and Mahlein, Anne-Kathrin and Steiner, Ulrike and Oerke, Erich-Christian and R{\"o}mer, Christoph and Pl{\"u}mer, Lutz},
  editor = {L{\"a}ssig, J{\"o}rg and Kersting, Kristian and Morik, Katharina},
  year = {2016},
  series = {Studies in {{Computational Intelligence}}},
  pages = {99--120},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-31858-5_6},
  urldate = {2023-01-13},
  abstract = {Modern communication, sensing, and actuator technologies as well as methods from signal processing, pattern recognition, and data mining are increasingly applied in agriculture, ultimately helping to meet the challenge of ``How to feed a hungry world?'' Developments such as increased mobility, wireless networks, new environmental sensors, robots, and the computational cloud put the vision of a sustainable agriculture for anybody, anytime, and anywhere within reach. Unfortunately, data-driven agriculture also presents unique computational problems in scale and interpretability: (1) Data is gathered often at massive scale, and (2) researchers and experts of complementary skills have to cooperate in order to develop models and tools for data intensive discovery that yield easy-to-interpret insights for users that are not necessarily trained computer scientists. On the problem of mining hyperspectral images to uncover spectral characteristic and dynamics of drought stressed plants, we showcase that both challenges can be met and that big data mining can---and should---play a key role for feeding the world, while enriching and transforming data mining.},
  isbn = {978-3-319-31858-5},
  langid = {english},
  keywords = {Drought Level,Drought Stress,Drought Stress Level,Euclidean Embedding,Precision Farming}
}

@article{kienbaumDeepCobPreciseHighthroughput2021,
  title = {{{DeepCob}}: Precise and High-Throughput Analysis of Maize Cob Geometry Using Deep Learning with an Application in Genebank Phenomics},
  shorttitle = {{{DeepCob}}},
  author = {Kienbaum, Lydia and Correa Abondano, Miguel and Blas, Raul and Schmid, Karl},
  year = {2021},
  month = dec,
  journal = {Plant Methods},
  volume = {17},
  number = {1},
  pages = {91},
  issn = {1746-4811},
  doi = {10.1186/s13007-021-00787-6},
  urldate = {2021-12-18},
  abstract = {Abstract                              Background                Maize cobs are an important component of crop yield that exhibit a high diversity in size, shape and color in native landraces and modern varieties. Various phenotyping approaches were developed to measure maize cob parameters in a high throughput fashion. More recently, deep learning methods like convolutional neural networks (CNNs) became available and were shown to be highly useful for high-throughput plant phenotyping. We aimed at comparing classical image segmentation with deep learning methods for maize cob image segmentation and phenotyping using a large image dataset of native maize landrace diversity from Peru.                                            Results                                  Comparison of three image analysis methods showed that a Mask R-CNN trained on a diverse set of maize cob images was highly superior to classical image analysis using the Felzenszwalb-Huttenlocher algorithm and a Window-based CNN due to its robustness to image quality and object segmentation accuracy (                                                            \$\$r=0.99\$\$                                                                        r                          =                          0.99                                                                                                      ). We integrated Mask R-CNN into a high-throughput pipeline to segment both maize cobs and rulers in images and perform an automated quantitative analysis of eight phenotypic traits, including diameter, length, ellipticity, asymmetry, aspect ratio and average values of red, green and blue color channels for cob color. Statistical analysis identified key training parameters for efficient iterative model updating. We also show that a small number of 10--20 images is sufficient to update the initial Mask R-CNN model to process new types of cob images. To demonstrate an application of the pipeline we analyzed phenotypic variation in 19,867 maize cobs extracted from 3449 images of 2484 accessions from the maize genebank of Peru to identify phenotypically homogeneous and heterogeneous genebank accessions using multivariate clustering.                                                            Conclusions                Single Mask R-CNN model and associated analysis pipeline are widely applicable tools for maize cob phenotyping in contexts like genebank phenomics or plant breeding.},
  langid = {english}
}

@article{kierdorfLeavesEstimationOccluded2022,
  title = {Behind the {{Leaves}}: {{Estimation}} of {{Occluded Grapevine Berries With Conditional Generative Adversarial Networks}}},
  shorttitle = {Behind the {{Leaves}}},
  author = {Kierdorf, Jana and Weber, Immanuel and Kicherer, Anna and Zabawa, Laura and Drees, Lukas and Roscher, Ribana},
  year = {2022},
  month = mar,
  journal = {Frontiers in Artificial Intelligence},
  volume = {5},
  publisher = {Frontiers},
  issn = {2624-8212},
  doi = {10.3389/frai.2022.830026},
  urldate = {2025-01-06},
  abstract = {{$<$}p{$>$}The need for accurate yield estimates for viticulture is becoming more important due to increasing competition in the wine market worldwide. One of the most promising methods to estimate the harvest is berry counting, as it can be approached non-destructively, and its process can be automated. In this article, we present a method that addresses the challenge of occluded berries with leaves to obtain a more accurate estimate of the number of berries that will enable a better estimate of the harvest. We use generative adversarial networks, a deep learning-based approach that generates a highly probable scenario behind the leaves exploiting learned patterns from images with non-occluded berries. Our experiments show that the estimate of the number of berries after applying our method is closer to the manually counted reference. In contrast to applying a factor to the berry count, our approach better adapts to local conditions by directly involving the appearance of the visible berries. Furthermore, we show that our approach can identify which areas in the image should be changed by adding new berries without explicitly requiring information about hidden areas.{$<$}/p{$>$}},
  langid = {english},
  keywords = {deep learning,Domain transfer,Generative Adversarial Networks,grape generation,machine   learning,yield counting}
}

@article{kimHierarchicalAlignmentBreast2012,
  title = {Hierarchical Alignment of Breast {{DCE}}-{{MR}} Images by Groupwise Registration and Robust Feature Matching},
  author = {Kim, Minjeong and Wu, Guorong and Shen, Dinggang},
  year = {2012},
  month = jan,
  journal = {Medical Physics},
  volume = {39},
  number = {1},
  pages = {353--366},
  issn = {0094-2405, 2473-4209},
  doi = {10.1118/1.3665705},
  urldate = {2021-12-19},
  langid = {english}
}

@article{kirchgessnerETHFieldPhenotyping2016,
  title = {The {{ETH}} Field Phenotyping Platform {{FIP}}: A Cable-Suspended Multi-Sensor System},
  shorttitle = {The {{ETH}} Field Phenotyping Platform {{FIP}}},
  author = {Kirchgessner, Norbert and Liebisch, Frank and Yu, Kang and Pfeifer, Johannes and Friedli, Michael and Hund, Andreas and Walter, Achim and Kirchgessner, Norbert and Liebisch, Frank and Yu, Kang and Pfeifer, Johannes and Friedli, Michael and Hund, Andreas and Walter, Achim},
  year = {2016},
  month = oct,
  journal = {Functional Plant Biology},
  volume = {44},
  number = {1},
  pages = {154--168},
  publisher = {CSIRO PUBLISHING},
  issn = {1445-4416, 1445-4416},
  doi = {10.1071/FP16165},
  urldate = {2023-01-13},
  abstract = {Crop phenotyping is a major bottleneck in current plant research. Field-based high-throughput phenotyping platforms are an important prerequisite to advance crop breeding. We developed a cable-suspended field phenotyping platform covering an area of {\textasciitilde}1 ha. The system operates from 2 to 5 m above the canopy, enabling a high image resolution. It can carry payloads of up to 12 kg and can be operated under adverse weather conditions. This ensures regular measurements throughout the growing period even during cold, windy and moist conditions. Multiple sensors capture the reflectance spectrum, temperature, height or architecture of the canopy. Monitoring from early development to maturity at high temporal resolution allows the determination of dynamic traits and their correlation to environmental conditions throughout the entire season. We demonstrate the capabilities of the system with respect to monitoring canopy cover, canopy height and traits related to thermal and multi-spectral imaging by selected examples from winter wheat, maize and soybean. The system is discussed in the context of other, recently established field phenotyping approaches; such as ground-operating or aerial vehicles, which impose traffic on the field or require a higher distance to the canopy.},
  langid = {english}
}

@article{kotwalAgriculturalPlantDiseases2023,
  title = {Agricultural Plant Diseases Identification: {{From}} Traditional Approach to Deep Learning},
  shorttitle = {Agricultural Plant Diseases Identification},
  author = {Kotwal, Jameer and Kashyap, Dr. Ramgopal and Pathan, Dr. Shafi},
  year = {2023},
  month = jan,
  journal = {Materials Today: Proceedings},
  series = {3rd {{International Congress}} on {{Mechanical}} and {{Systems Engineering}} ({{CAMSE}} 2022)},
  volume = {80},
  pages = {344--356},
  issn = {2214-7853},
  doi = {10.1016/j.matpr.2023.02.370},
  urldate = {2023-09-01},
  abstract = {Plant disease computerization in agriculture areas an important for every country, as the population rate increases the demand for food supply also increases. Today, the significant adaption of modern techniques and tools increases the accuracy of detection the plant disease. Identifying plant diseases in an early stage can reduce their spread. Early identifying is a beginning stage to fight against disease spreading. For plenty of years, researchers have researched how to tackle the common disease effects amongst humans, animals, and plants. However, there are still many gaps are remaining to identify and explore. In recent years, there have been many researchers using Deep Learning (DL) and Transfer Learning (TL) technologies to detect agricultural diseases based on Machine Learning (ML) algorithms that were developed with the development of Artificial Intelligence (AI) technology. Many, DL architectures are carried out together with numerous diverse visualization strategies to perceive and label the features of plant diseases. Our take a look at additionally makes a specialty of how ML strategies had been moved from conventional ML to DL and additionally numerous overall performance metrics (F1-score, sensitivity, accuracy, etc) are used for the assessment of the architecture/strategies. Some challenges are figure out while identifying the plant disease detection.},
  keywords = {Convolution neural network (CNN),Deep learning,Plant diseases},
  file = {/home/samuelebumbaca/Zotero/storage/JWWRV32M/S2214785323009343.html}
}

@book{krausPhotogrammetryGeometryImages2011,
  title = {Photogrammetry: {{Geometry}} from {{Images}} and {{Laser Scans}}},
  shorttitle = {Photogrammetry},
  author = {Kraus, Karl},
  year = {2011},
  month = oct,
  journal = {Photogrammetry},
  publisher = {De Gruyter},
  doi = {10.1515/9783110892871},
  urldate = {2023-01-25},
  abstract = {This textbook deals with the basics and methods of photogrammetry and laser scanning which are used to determine the form and location of objects, with measurements provided by sensors placed in air planes as well as on terrestrial platforms. Many examples and exercises with solutions are included. Photogrammetry, Laserscanning.},
  isbn = {978-3-11-089287-1},
  langid = {english},
  keywords = {Cartography,Geodesy,Geology,Geophysics}
}

@article{kurugolluColorImageSegmentation2001,
  title = {Color Image Segmentation Using Histogram Multithresholding and Fusion},
  author = {Kurugollu, F and Sankur, B and Harmanci, A. E},
  year = {2001},
  month = nov,
  journal = {Image and Vision Computing},
  volume = {19},
  number = {13},
  pages = {915--928},
  issn = {0262-8856},
  doi = {10.1016/S0262-8856(01)00052-X},
  urldate = {2023-01-13},
  abstract = {A novel method for multiband image segmentation has been proposed. The method is based on segmentation of subsets of bands using multithresholding followed by the fusion of the resulting segmentation ``channels''. For color images the band subsets are chosen as the RB, RG and BG pairs, whose two-dimensional histograms are processed via a peak-picking algorithm to effect multithresholding. The segmentation maps are first fused by running a label concordance algorithm and then smoothed by a spatial--chromatic majority filter. It is shown that for multiband images, multithresholding subsets of bands followed by a fusion stage results in improved performance and running time.},
  langid = {english},
  keywords = {Fusion,Image segmentation,Multithresholding}
}

@article{lamprinouGroupwiseImageAlignment2020,
  title = {Groupwise {{Image Alignment}} via {{Self Quotient Images}}},
  author = {Lamprinou, Nefeli and Nikolikos, Nikolaos and Psarakis, Emmanouil Z.},
  year = {2020},
  month = apr,
  journal = {Sensors},
  volume = {20},
  number = {8},
  pages = {2325},
  issn = {1424-8220},
  doi = {10.3390/s20082325},
  urldate = {2021-12-19},
  abstract = {Compared with pairwise registration, the groupwise one is capable of handling a large-scale population of images simultaneously in an unbiased way. In this work we improve upon the state-of-the-art pixel-level, Least-Squares (LS)-based groupwise image registration methods. Specifically, the registration technique is properly adapted by the use of Self Quotient Images (SQI) in order to become capable for solving the groupwise registration of photometrically distorted, partially occluded as well as unimodal and multimodal images. Moreover, the proposed groupwise technique is linear to the cardinality of the image set and thus it can be used for the successful solution of the problem on large image sets with low complexity. From the application of the proposed technique on a series of experiments for the groupwise registration of photometrically and geometrically distorted, partially occluded faces as well as unimodal and multimodal magnetic resonance image sets and its comparison with the Lucas--Kanade Entropy (LKE) algorithm, the obtained results look very promising, in terms of alignment quality, using as figures of merit the mean Peak Signal to Noise Ratio ( m P S N R ) and mean Structural Similarity ( m S S I M ), and computational cost.},
  langid = {english}
}

@book{latiniLessicoNuvoleParole2021,
  title = {Lessico e Nuvole: Le Parole Del Cambiamento Climatico},
  author = {Latini, Gianni and Bagliani, Marco and Orusa, Tommaso},
  year = {2021},
  publisher = {Youcanprint}
}

@article{lauComparingLinkingMachine2022,
  title = {Comparing and Linking Machine Learning and Semi-Mechanistic Models for the Predictability of Endemic Measles Dynamics},
  author = {Lau, Max S. Y. and Becker, Alex and Madden, Wyatt and Waller, Lance A. and Metcalf, C. Jessica E. and Grenfell, Bryan T.},
  year = {2022},
  month = sep,
  journal = {PLOS Computational Biology},
  volume = {18},
  number = {9},
  pages = {e1010251},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1010251},
  urldate = {2023-03-24},
  abstract = {Measles is one the best-documented and most-mechanistically-studied non-linear infectious disease dynamical systems. However, systematic investigation into the comparative performance of traditional mechanistic models and machine learning approaches in forecasting the transmission dynamics of this pathogen are still rare. Here, we compare one of the most widely used semi-mechanistic models for measles (TSIR) with a commonly used machine learning approach (LASSO), comparing performance and limits in predicting short to long term outbreak trajectories and seasonality for both regular and less regular measles outbreaks in England and Wales (E\&W) and the United States. First, our results indicate that the proposed LASSO model can efficiently use data from multiple major cities and achieve similar short-to-medium term forecasting performance to semi-mechanistic models for E\&W epidemics. Second, interestingly, the LASSO model also captures annual to biennial bifurcation of measles epidemics in E\&W caused by susceptible response to the late 1940s baby boom. LASSO may also outperform TSIR for predicting less-regular dynamics such as those observed in major cities in US between 1932--45. Although both approaches capture short-term forecasts, accuracy suffers for both methods as we attempt longer-term predictions in highly irregular, post-vaccination outbreaks in E\&W. Finally, we illustrate that the LASSO model can both qualitatively and quantitatively reconstruct mechanistic assumptions, notably susceptible dynamics, in the TSIR model. Our results characterize the limits of predictability of infectious disease dynamics for strongly immunizing pathogens with both mechanistic and machine learning models, and identify connections between these two approaches.},
  langid = {english},
  keywords = {Cities,Disease dynamics,Dynamical systems,Epidemiology,Forecasting,Machine learning,Measles,Vaccination and immunization}
}

@article{lazarTaizZeigerPlant2003,
  title = {Taiz, {{L}}. and {{Zeiger}}, {{E}}. {{Plant}} Physiology. 3rd Edn.},
  author = {Lazar, T.},
  year = {2003},
  month = may,
  journal = {Annals of Botany},
  volume = {91},
  number = {6},
  pages = {750--751},
  issn = {03057364, 10958290},
  doi = {10.1093/aob/mcg079},
  urldate = {2023-01-10},
  langid = {english}
}

@article{lemaireUniversalBroadLeaf2004,
  title = {Towards Universal Broad Leaf Chlorophyll Indices Using {{PROSPECT}} Simulated Database and Hyperspectral Reflectance Measurements},
  author = {{le Maire}, G. and Fran{\c c}ois, C. and Dufr{\^e}ne, E.},
  year = {2004},
  month = jan,
  journal = {Remote Sensing of Environment},
  volume = {89},
  number = {1},
  pages = {1--28},
  issn = {0034-4257},
  doi = {10.1016/j.rse.2003.09.004},
  urldate = {2023-01-13},
  abstract = {Fifty-three leaves were randomly sampled on different deciduous tree species, representing a wide range of chlorophyll contents, tree ages, and leaf structural features. Their reflectance was measured between 400 and 800 nm with a 1-nm step, and their chlorophyll content determined by extraction. A larger simulated database (11,583 spectra) was built using the PROSPECT model, in order to test, calibrate, and obtain universal indices, i.e., indices applicable to a wide range of species and leaf structure. To our knowledge, almost all leaf chlorophyll indices published in the literature since 1973 have been tested on both databases. Fourteen canonical types of indices (published ones and new ones) were identified, and their wavelengths calibrated on the simulated database as well as on the experimental database to determine the best wavelengths and, hence, the best performances in chlorophyll estimation for each index types. These indices go from simple reflectance ratios to more sophisticated indices using reflectance first derivatives (using the Savitzky and Golay method). We also tested other nondestructive methods to obtain total chlorophyll concentration: SPAD (Minolta Camera, Osaka, Japan) and neural networks. The validity of the actual PROSPECT model is challenged by our results: Important discordances are found when the indices are calculated with PROSPECT compared to experimental data, especially for some indices and wavelengths. The discordance is even greater when the indices are determined with PROSPECT and applied on the experimental database. A new calibration of PROSPECT is therefore necessary for any study aiming at using simulated spectra to determine or to calibrate indices. The ``peak jump'' and the multiple-peak feature observed on the first derivative of the reflectances (e.g., in the Red-Edge Inflection Point [REIP] index) has been investigated. It was shown that chlorophyll absorption alone can explain this feature. The peak jump disqualifies the REIP to be a valuable chlorophyll index. A simple modified difference ratio gave the best results among all published indices (cross-validated RMSE=2.1 {$\mu$}g/cm2 on the experimental database). After calibration on the experimental database, modified Simple Ratio (mSR) and modified Normalized Difference (mND) indices gave the best performances (RMSECV=1.8 {$\mu$}g/cm2 on the experimental database). The new Double Difference (DD) index, although not the best on the experimental database (RMSECV=2.9 {$\mu$}g/cm2), has the best results on the larger simulated database (RMSE=3.7 {$\mu$}g/cm2) and is expected to give good results on larger experimental databases. The best reflectance-based indices give better performances than the current commercial nondestructive device SPAD (RMSECV=4.5 {$\mu$}g/cm2). In this leaf-level study, the best indices are very near from each other, so that complex methods are useless: REIP-like, neural networks, and derivative-based indices are not necessary and give worst results than simpler properly chosen indices. These conclusions will certainly be different for a canopy-level study, where the derivative-based indices may perform significantly better than the other ones.},
  langid = {english},
  keywords = {Hyperspectral reflectance measurements,PROSPECT,Universal broad leaf chlorophyll indices}
}

@article{lemesTriangularGreennessIndex2022,
  title = {Triangular {{Greenness Index}} to {{Evaluate}} the {{Effects}} of {{Dicamba}} in {{Soybean}}},
  author = {Lemes, Ernane Miranda and Coelho, L{\'i}sias and de Andrade, Samuel Lacerda and Oliveira, Aline dos Santos and Marques, Matheus Gregorio and do Nascimento, Felipe Mauro Assis and da Cunha, Jo{\~a}o Paulo Arantes Rodrigues},
  year = {2022},
  month = sep,
  journal = {AgriEngineering},
  volume = {4},
  number = {3},
  pages = {758--769},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2624-7402},
  doi = {10.3390/agriengineering4030049},
  urldate = {2023-03-24},
  abstract = {Significant losses in agricultural production are due to abiotic stresses, such as herbicide phytotoxicity. Dicamba (diglycolamine salt) is a herbicide used for post-emergent control of broadleaf weeds. It has a possibility to vapor-spread into neighboring fields causing damage to other crops. However, not every stress can be easily identified. Therefore, remote sensing has the potential as a new tool in early injury detection. This study evaluated the effects of simulated dicamba drift on the occurrence of phytotoxicity in soybeans (Glycine max). Soybean was assessed in seven dicamba doses (0, 0.056, 0.56, 5.6, 11.2, 28, 112 g ha-1) for changes in plant injury (scale of notes), spectral aspects (triangular greenness index (TGI), and shoot dry mass. The plants were photographed using a digital camera positioned at 1.2 m above the planting media level. The results indicate a positive effect of low dicamba doses (0.56 and 0.056 g a.e. ha-1) on TGI canopy distinction and shoot dry mass. Soybean TGI canopy distinction and the injury scale estimated at 45 days after sowing, and the soybean shoot dry mass observed at 99 days after sowing, presented significant and moderate Pearson's r coefficient of correlations (r = -0.609 and 0.625), indicating TGI as a valid and practical spectral index for plant dicamba-injured evaluations.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {herbicide phytotoxicity,image analysis,plant analysis,soybean,weed management}
}

@article{li3DImagingGreenhouse2017,
  title = {{{3D Imaging}} of {{Greenhouse Plants}} with an {{Inexpensive Binocular Stereo Vision System}}},
  author = {Li, Dawei and Xu, Lihong and Tang, Xue-song and Sun, Shaoyuan and Cai, Xin and Zhang, Peng},
  year = {2017},
  month = may,
  journal = {Remote Sensing},
  volume = {9},
  number = {5},
  pages = {508},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2072-4292},
  doi = {10.3390/rs9050508},
  urldate = {2022-09-25},
  abstract = {Nowadays, 3D imaging of plants not only contributes to monitoring and managing plant growth, but is also becoming an essential part of high-throughput plant phenotyping. In this paper, an inexpensive (less than 70 USD) and portable platform with binocular stereo vision is established, which can be controlled by a laptop. In the stereo matching step, an efficient cost calculating measure---AD-Census---is integrated with the adaptive support-weight (ASW) approach to improve the ASW's performance on real plant images. In the quantitative assessment, our stereo algorithm reaches an average error rate of 6.63\% on the Middlebury datasets, which is lower than the error rates of the original ASW approach and several other popular algorithms. The imaging experiments using the proposed stereo system are carried out in three different environments including an indoor lab, an open field with grass, and a multi-span glass greenhouse. Six types of greenhouse plants are used in experiments; half of them are ornamentals and the others are greenhouse crops. The imaging accuracy of the proposed method at different baseline settings is investigated, and the results show that the optimal length of the baseline (distance between the two cameras of the stereo system) is around 80 mm for reaching a good trade-off between the depth accuracy and the mismatch rate for a plant that is placed within 1 m of the cameras. Error analysis from both theoretical and experimental sides show that for an object that is approximately 800 mm away from the stereo platform, the measured depth error of a single point is no higher than 5 mm, which is tolerable considering the dimensions of greenhouse plants. By applying disparity refinement, the proposed methodology generates dense and accurate point clouds of crops in different environments including an indoor lab, an outdoor field, and a greenhouse. Our approach also shows invariance against changing illumination in a real greenhouse, as well as the capability of recovering 3D surfaces of highlighted leaf regions. The method not only works on a binocular stereo system, but is also potentially applicable to a SFM-MVS (structure-from-motion and multiple-view stereo) system or any multi-view imaging system that uses stereo matching.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {3D imaging,greenhouse plants,point cloud,remote sensing,stereo matching},
  file = {/home/samuelebumbaca/Zotero/storage/FV2Q2Q6R/htm.html}
}

@article{liaoAssessmentChlorophyllContent2014,
  title = {{[Assessment of chlorophyll content using a new vegetation index based on multi-angular hyperspectral image data]}},
  author = {Liao, Qin-hong and Zhang, Dong-yan and Wang, Ji-hua and Yang, Gui-jun and Yang, Hao and Coburn, Craig and Wong, Zhijie and Wang, Da-cheng},
  year = {2014},
  month = jun,
  journal = {Guang Pu Xue Yu Guang Pu Fen Xi = Guang Pu},
  volume = {34},
  number = {6},
  pages = {1599--1604},
  issn = {1000-0593},
  abstract = {The fast estimation of chlorophyll content is significant for understanding the crops growth, monitoring the disease and insect, and assessing the yield of crops. This study gets the hyperspectral imagery data by using a self-developed multi-angular acquisition system during the different maize growth period, the reflectance of maize canopy was extracted accurately from the hyperspectral images under different view angles in the principal plane. The hot-dark-spot index (HDS) of red waveband was calculated through the analysis of simulated values by ACRM model and measured values, then this index was used to modify the vegetation index (TCARI), thus a new vegetation index (HD-TCARI) based on the multi-angular observation was proposed. Finally, the multi-angular hyperspectral imagery data was used to validate the vegetation indexes. The result showed that HD-TCARI could effectively reduce the LAI effects on the assessment of chlorophyll content. When the chlorophyll content was greater than 30 {$\mu$}g x cm(-2), the correlation (R2) between HD-TCARI and LAI was only 26.88\%-28.72\%. In addition, the HD-TCARI could resist the saturation of vegetation index during the assessment of high chlorophyll content. When the LAI varled from 1 to 6, the linear relation between HD-TCARI and chlorophyll content could be improved by 9\% compared with TCARI. The ground validation of HD-TCARI by multi-angular hyperspectral image showed that the linear relation between HD-TCARI and chlorophyll content (R2 = 66.74\%) was better than the TCARI (R2 = 39.92\%), which indicated that HD-TCARI has good potentials for estimating the chlorophyll content.},
  langid = {chi},
  pmid = {25358171},
  keywords = {Chlorophyll,Crops Agricultural,Models Theoretical,Plant Leaves,Spectrum Analysis,Zea mays}
}

@article{liaoFastAlgorithmMultilevel,
  title = {A {{Fast Algorithm}} for {{Multilevel Thresholding}}},
  author = {Liao, Ping-Sung and Chen, Tse-Sheng and Chung, Pau-Choo},
  pages = {15},
  langid = {english}
}

@article{liebischRemoteAerialPhenotyping2015,
  title = {Remote, Aerial Phenotyping of Maize Traits with a Mobile Multi-Sensor Approach},
  author = {Liebisch, Frank and Kirchgessner, Norbert and Schneider, David and Walter, Achim and Hund, Andreas},
  year = {2015},
  month = feb,
  journal = {Plant Methods},
  volume = {11},
  number = {1},
  pages = {9},
  issn = {1746-4811},
  doi = {10.1186/s13007-015-0048-8},
  urldate = {2023-01-13},
  abstract = {Field-based high throughput phenotyping is a bottleneck for crop breeding research. We present a novel method for repeated remote phenotyping of maize genotypes using the Zeppelin NT aircraft as an experimental sensor platform. The system has the advantage of a low altitude and cruising speed compared to many drones or airplanes, thus enhancing image resolution while reducing blurring effects. Additionally there was no restriction in sensor weight. Using the platform, red, green and blue colour space (RGB), normalized difference vegetation index (NDVI) and thermal images were acquired throughout the growing season and compared with traits measured on the ground. Ground control points were used to co-register the images and to overlay them with a plot map.},
  keywords = {Aerial phenotyping,Image analysis,NDVI,Near infrared imaging,Remote sensing,Thermal imaging,Zea mays}
}

@article{liHighthroughputPhenotypingAnalysis2021,
  title = {High-Throughput Phenotyping Analysis of Maize at the Seedling Stage Using End-to-End Segmentation Network},
  author = {Li, Yinglun and Wen, Weiliang and Guo, Xinyu and Yu, Zetao and Gu, Shenghao and Yan, Haipeng and Zhao, Chunjiang},
  editor = {Bianconi, Francesco},
  year = {2021},
  month = jan,
  journal = {PLOS ONE},
  volume = {16},
  number = {1},
  pages = {e0241528},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0241528},
  urldate = {2021-12-18},
  abstract = {Image processing technologies are available for high-throughput acquisition and analysis of phenotypes for crop populations, which is of great significance for crop growth monitoring, evaluation of seedling condition, and cultivation management. However, existing methods rely on empirical segmentation thresholds, thus can have insufficient accuracy of extracted phenotypes. Taking maize as an example crop, we propose a phenotype extraction approach from top-view images at the seedling stage. An end-to-end segmentation network, named PlantU-net, which uses a small amount of training data, was explored to realize automatic segmentation of top-view images of a maize population at the seedling stage. Morphological and color related phenotypes were automatic extracted, including maize shoot coverage, circumscribed radius, aspect ratio, and plant azimuth plane angle. The results show that the approach can segment the shoots at the seedling stage from top-view images, obtained either from the UAV or tractor-based high-throughput phenotyping platform. The average segmentation accuracy, recall rate, and F1 score are 0.96, 0.98, and 0.97, respectively. The extracted phenotypes, including maize shoot coverage, circumscribed radius, aspect ratio, and plant azimuth plane angle, are highly correlated with manual measurements (R                2                = 0.96--0.99). This approach requires less training data and thus has better expansibility. It provides practical means for high-throughput phenotyping analysis of early growth stage crop populations.},
  langid = {english}
}

@article{liHighThroughputPlantPhenotyping2021,
  title = {High-{{Throughput Plant Phenotyping Platform}} ({{HT3P}}) as a {{Novel Tool}} for {{Estimating Agronomic Traits From}} the {{Lab}} to the {{Field}}},
  author = {Li, Daoliang and Quan, Chaoqun and Song, Zhaoyang and Li, Xiang and Yu, Guanghui and Li, Cheng and Muhammad, Akhter},
  year = {2021},
  month = jan,
  journal = {Frontiers in Bioengineering and Biotechnology},
  volume = {8},
  pages = {623705},
  issn = {2296-4185},
  doi = {10.3389/fbioe.2020.623705},
  urldate = {2021-12-18},
  abstract = {Food scarcity, population growth, and global climate change have propelled crop yield growth driven by high-throughput phenotyping into the era of big data. However, access to large-scale phenotypic data has now become a critical barrier that phenomics urgently must overcome. Fortunately, the high-throughput plant phenotyping platform (HT3P), employing advanced sensors and data collection systems, can take full advantage of non-destructive and high-throughput methods to monitor, quantify, and evaluate specific phenotypes for large-scale agricultural experiments, and it can effectively perform phenotypic tasks that traditional phenotyping could not do. In this way, HT3Ps are novel and powerful tools, for which various commercial, customized, and even self-developed ones have been recently introduced in rising numbers. Here, we review these HT3Ps in nearly 7 years from greenhouses and growth chambers to the field, and from ground-based proximal phenotyping to aerial large-scale remote sensing. Platform configurations, novelties, operating modes, current developments, as well the strengths and weaknesses of diverse types of HT3Ps are thoroughly and clearly described. Then, miscellaneous combinations of HT3Ps for comparative validation and comprehensive analysis are systematically present, for the first time. Finally, we consider current phenotypic challenges and provide fresh perspectives on future development trends of HT3Ps. This review aims to provide ideas, thoughts, and insights for the optimal selection, exploitation, and utilization of HT3Ps, and thereby pave the way to break through current phenotyping bottlenecks in botany.}
}

@article{liIterativeAlgorithmMinimum1998,
  title = {An Iterative Algorithm for Minimum Cross Entropy Thresholding},
  author = {Li, C. H. and Tam, P. K. S.},
  year = {1998},
  month = jun,
  journal = {Pattern Recognition Letters},
  volume = {19},
  number = {8},
  pages = {771--776},
  issn = {0167-8655},
  doi = {10.1016/S0167-8655(98)00057-9},
  urldate = {2023-01-25},
  abstract = {A fast iterative method is derived for minimum cross entropy thresholding using a one-point iteration scheme. Simulations performed using synthetic generated histograms and a real image show the speed advantage and the accuracy of the iterated version.},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/5TTGIRDU/S0167865598000579.html}
}

@article{liIterativeAlgorithmMinimum1998a,
  title = {An Iterative Algorithm for Minimum Cross Entropy Thresholding},
  author = {Li, C. H. and Tam, P. K. S.},
  year = {1998},
  month = jun,
  journal = {Pattern Recognition Letters},
  volume = {19},
  number = {8},
  pages = {771--776},
  issn = {0167-8655},
  doi = {10.1016/S0167-8655(98)00057-9},
  urldate = {2023-01-25},
  abstract = {A fast iterative method is derived for minimum cross entropy thresholding using a one-point iteration scheme. Simulations performed using synthetic generated histograms and a real image show the speed advantage and the accuracy of the iterated version.},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/FFQ9K7VT/S0167865598000579.html}
}

@article{lillesaeterSpectralReflectancePartly1982,
  title = {Spectral Reflectance of Partly Transmitting Leaves: {{Laboratory}} Measurements and Mathematical Modeling},
  shorttitle = {Spectral Reflectance of Partly Transmitting Leaves},
  author = {Lillesaeter, O.},
  year = {1982},
  month = jul,
  journal = {Remote Sensing of Environment},
  volume = {12},
  number = {3},
  pages = {247--254},
  issn = {0034-4257},
  doi = {10.1016/0034-4257(82)90057-8},
  urldate = {2023-01-13},
  abstract = {Previous work related to remote sensing of natural sceneries has shown that the near infrared signature of a plant canopy is a combined function of leaf optical properties, canopy geometry, and soil reflectance. This paper deals with the problems involved in spectrophotometric measurements of leaves that are partly transmitting and partly reflecting, and thus influenced by the sample background provided by the measuring instrument. A mathematical model requiring only single-leaf spectral reflectance data as input is developed for prediction of multiple-leaf reflectance. The validity of the model appears to be adequate for any number of stacked leaves, when leaf-to-leaf variations caused by differences in water content and pigmentation are considered.},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/S52NEKA4/0034425782900578.html}
}

@article{liMinimumCrossEntropy1993,
  title = {Minimum Cross Entropy Thresholding},
  author = {Li, C. H. and Lee, C. K.},
  year = {1993},
  month = apr,
  journal = {Pattern Recognition},
  volume = {26},
  number = {4},
  pages = {617--625},
  issn = {0031-3203},
  doi = {10.1016/0031-3203(93)90115-D},
  urldate = {2023-01-25},
  abstract = {The threshold selection problem is solved by minimizing the cross entropy between the image and its segmented version. The cross entropy is formulated in a pixel-to-pixel basis between the two images and a computationally attractive algorithm employing the histogram is developed. Without making a priori assumptions about the population distribution, this method provides an unbiased estimate of a binarized version of the image in an information theoretic sense.},
  langid = {english},
  keywords = {Image segmentation,Maximum entropy method,Minimum cross entropy,Thresholding},
  file = {/home/samuelebumbaca/Zotero/storage/6DRXH6VX/003132039390115D.html}
}

@misc{linder-norenEriklindernorenPyTorchGAN2025,
  title = {Eriklindernoren/{{PyTorch-GAN}}},
  author = {{Linder-Nor{\'e}n}, Erik},
  year = {2025},
  month = jan,
  urldate = {2025-01-05},
  abstract = {PyTorch implementations of Generative Adversarial Networks.},
  copyright = {MIT}
}

@article{liRobustPointSet2020,
  title = {Robust {{Point Set Registration Using Signature Quadratic Form Distance}}},
  author = {Li, Liang and Yang, Ming and Wang, Chunxiang and Wang, Bing},
  year = {2020},
  month = may,
  journal = {IEEE Transactions on Cybernetics},
  volume = {50},
  number = {5},
  pages = {2097--2109},
  issn = {2168-2267, 2168-2275},
  doi = {10.1109/TCYB.2018.2845745},
  urldate = {2021-12-19}
}

@article{liuIndustry40Agriculture2021,
  title = {From {{Industry}} 4.0 to {{Agriculture}} 4.0: {{Current Status}}, {{Enabling Technologies}}, and {{Research Challenges}}},
  shorttitle = {From {{Industry}} 4.0 to {{Agriculture}} 4.0},
  author = {Liu, Ye and Ma, Xiaoyuan and Shu, Lei and Hancke, Gerhard Petrus and {Abu-Mahfouz}, Adnan M.},
  year = {2021},
  month = jun,
  journal = {IEEE Transactions on Industrial Informatics},
  volume = {17},
  number = {6},
  pages = {4322--4334},
  issn = {1941-0050},
  doi = {10.1109/TII.2020.3003910},
  abstract = {The three previous industrial revolutions profoundly transformed agriculture industry from indigenous farming to mechanized farming and recent precision agriculture. Industrial farming paradigm greatly improves productivity, but a number of challenges have gradually emerged, which have exacerbated in recent years. Industry 4.0 is expected to reshape the agriculture industry once again and promote the fourth agricultural revolution. In this article, first, we review the current status of industrial agriculture along with lessons learned from industrialized agricultural production patterns, industrialized agricultural production processes, and the industrialized agri-food supply chain. Furthermore, five emerging technologies, namely the Internet of Things, robotics, artificial intelligence, big data analytics, and blockchain, toward Agriculture 4.0 are discussed. Specifically, we focus on the key applications of these emerging technologies in the agricultural sector and corresponding research challenges. This article aims to open up new research opportunities for readers, particularly industrial practitioners.},
  keywords = {Agriculture,Agriculture 4.0,Animals,industrial agriculture,Industry 4.0,precision agriculture,Productivity,Soil,Supply chains},
  file = {/home/samuelebumbaca/Zotero/storage/A5LDPB3H/9122412.html}
}

@article{longClassificationWheatDiseases2023,
  title = {Classification of Wheat Diseases Using Deep Learning Networks with Field and Glasshouse Images},
  author = {Long, Megan and Hartley, Matthew and Morris, Richard J. and Brown, James K. M.},
  year = {2023},
  journal = {Plant Pathology},
  volume = {72},
  number = {3},
  pages = {536--547},
  issn = {1365-3059},
  doi = {10.1111/ppa.13684},
  urldate = {2023-09-01},
  abstract = {Crop diseases can cause major yield losses, so the ability to detect and identify them in their early stages is important for disease control. Deep learning methods have shown promise in classifying multiple diseases; however, many studies do not use datasets that represent real field conditions, necessitating either further image processing or reducing their applicability. In this paper, we present a dataset of wheat images taken in real growth situations, including both field and glasshouse conditions, with five categories: healthy plants and four foliar diseases, yellow rust, brown rust, powdery mildew and Septoria leaf blotch. This dataset was used to train a deep learning model. The resulting model, named CerealConv, reached a 97.05\% classification accuracy. When tested against trained pathologists on a subset of images from the larger dataset, the model delivered an accuracy score 2\% higher than the best-performing pathologist. Image masks were used to show that the model was using the correct information to drive its classifications. These results show that deep learning networks are a viable tool for disease detection and classification in the field, and disease quantification is a logical next step.},
  langid = {english},
  keywords = {brown rust,convolutional neural network (CNN),deep learning,septoria,wheat,yellow rust},
  file = {/home/samuelebumbaca/Zotero/storage/INZPQAM6/ppa.html}
}

@article{lottesEffectiveVisionbasedClassification2017,
  title = {Effective {{Vision-based Classification}} for {{Separating Sugar Beets}} and {{Weeds}} for {{Precision Farming}}},
  author = {Lottes, Philipp and H{\"o}rferlin, Markus and Sander, Slawomir and Stachniss, Cyrill},
  year = {2017},
  journal = {Journal of Field Robotics},
  volume = {34},
  number = {6},
  pages = {1160--1178},
  issn = {1556-4967},
  doi = {10.1002/rob.21675},
  urldate = {2023-01-13},
  abstract = {The use of robots in precision farming has the potential to reduce the reliance on herbicides and pesticides through selectively spraying individual plants or through manual weed removal. A prerequisite for that is the ability of the robot to separate and identify the value crops and the weeds in the field. Based on the output of the robot's perception system, it can trigger the actuators for spraying or removal. In this paper, we address the problem of detecting sugar beet plants as well as weeds using a camera installed on a mobile field robot. We propose a system that performs vegetation detection, local as well as object-based feature extraction, random forest classification, and smoothing through a Markov random field to obtain an accurate estimate of crops and weeds. We implemented and thoroughly evaluated our system using a real farm robot in different sugar beet fields, and we illustrate that our approach allows for accurately identifying weeds in a field.},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/QZSNJMFY/rob.html}
}

@article{loweDistinctiveImageFeatures2004,
  title = {Distinctive {{Image Features}} from {{Scale-Invariant Keypoints}}},
  author = {Lowe, David G.},
  year = {2004},
  month = nov,
  journal = {International Journal of Computer Vision},
  volume = {60},
  number = {2},
  pages = {91--110},
  issn = {0920-5691},
  doi = {10.1023/B:VISI.0000029664.99615.94},
  urldate = {2022-11-24},
  abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
  langid = {english}
}

@article{loweHyperspectralImageAnalysis2017,
  title = {Hyperspectral Image Analysis Techniques for the Detection and Classification of the Early Onset of Plant Disease and Stress},
  author = {Lowe, Amy and Harrison, Nicola and French, Andrew P.},
  year = {2017},
  month = oct,
  journal = {Plant Methods},
  volume = {13},
  number = {1},
  pages = {80},
  issn = {1746-4811},
  doi = {10.1186/s13007-017-0233-z},
  urldate = {2023-01-13},
  abstract = {This review explores how imaging techniques are being developed with a focus on deployment for crop monitoring methods. Imaging applications are discussed in relation to both field and glasshouse-based plants, and techniques are sectioned into `healthy and diseased plant classification' with an emphasis on classification accuracy, early detection of stress, and disease severity. A central focus of the review is the use of hyperspectral imaging and how this is being utilised to find additional information about plant health, and the ability to predict onset of disease. A summary of techniques used to detect biotic and abiotic stress in plants is presented, including the level of accuracy associated with each method.},
  langid = {english},
  keywords = {Early detection of stress,Hyperspectral image analysis,Hyperspectral imaging,Image analysis techniques,Plant disease and stress,Vegetation Indices}
}

@inproceedings{loweObjectRecognitionLocal1999,
  title = {Object Recognition from Local Scale-Invariant Features},
  booktitle = {Proceedings of the {{Seventh IEEE International Conference}} on {{Computer Vision}}},
  author = {Lowe, D.G.},
  year = {1999},
  pages = {1150-1157 vol.2},
  publisher = {IEEE},
  address = {Kerkyra, Greece},
  doi = {10.1109/ICCV.1999.790410},
  urldate = {2024-01-23},
  abstract = {An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest-neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low-residual least-squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially-occluded images with a computation time of under 2 seconds.},
  isbn = {978-0-7695-0164-2},
  langid = {english}
}

@article{luRoboticPlatformCorn2017,
  title = {A {{Robotic Platform}} for {{Corn Seedling Morphological Traits Characterization}}},
  author = {Lu, Hang and Tang, Lie and Whitham, Steven A. and Mei, Yu},
  year = {2017},
  month = sep,
  journal = {Sensors},
  volume = {17},
  number = {9},
  pages = {2082},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1424-8220},
  doi = {10.3390/s17092082},
  urldate = {2025-01-05},
  abstract = {Crop breeding plays an important role in modern agriculture, improving plant performance, and increasing yield. Identifying the genes that are responsible for beneficial traits greatly facilitates plant breeding efforts for increasing crop production. However, associating genes and their functions with agronomic traits requires researchers to observe, measure, record, and analyze phenotypes of large numbers of plants, a repetitive and error-prone job if performed manually. An automated seedling phenotyping system aimed at replacing manual measurement, reducing sampling time, and increasing the allowable work time is thus highly valuable. Toward this goal, we developed an automated corn seedling phenotyping platform based on a time-of-flight of light (ToF) camera and an industrial robot arm. A ToF camera is mounted on the end effector of the robot arm. The arm positions the ToF camera at different viewpoints for acquiring 3D point cloud data. A camera-to-arm transformation matrix was calculated using a hand-eye calibration procedure and applied to transfer different viewpoints into an arm-based coordinate frame. Point cloud data filters were developed to remove the noise in the background and in the merged seedling point clouds. A 3D-to-2D projection and an x-axis pixel density distribution method were used to segment the stem and leaves. Finally, separated leaves were fitted with 3D curves for morphological traits characterization. This platform was tested on a sample of 60 corn plants at their early growth stages with between two to five leaves. The error ratios of the stem height and leave length measurements are 13.7\% and 13.1\%, respectively, demonstrating the feasibility of this robotic system for automated corn seedling phenotyping.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {3D reconstruction,corn breeding,plant phenotyping,point cloud,robot arm,ToF camera}
}

@article{maeda-gutierrezComparisonConvolutionalNeural2020,
  title = {Comparison of {{Convolutional Neural Network Architectures}} for {{Classification}} of {{Tomato Plant Diseases}}},
  author = {{Maeda-Guti{\'e}rrez}, Valeria and {Galv{\'a}n-Tejada}, Carlos E. and {Zanella-Calzada}, Laura A. and {Celaya-Padilla}, Jos{\'e} M. and {Galv{\'a}n-Tejada}, Jorge I. and {Gamboa-Rosales}, Hamurabi and {Luna-Garc{\'i}a}, Huizilopoztli and {Magallanes-Quintanar}, Rafael and Guerrero M{\'e}ndez, Carlos A. and {Olvera-Olvera}, Carlos A.},
  year = {2020},
  month = jan,
  journal = {Applied Sciences},
  volume = {10},
  number = {4},
  pages = {1245},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-3417},
  doi = {10.3390/app10041245},
  urldate = {2023-11-27},
  abstract = {Tomato plants are highly affected by diverse diseases. A timely and accurate diagnosis plays an important role to prevent the quality of crops. Recently, deep learning (DL), specifically convolutional neural networks (CNNs), have achieved extraordinary results in many applications, including the classification of plant diseases. This work focused on fine-tuning based on the comparison of the state-of-the-art architectures: AlexNet, GoogleNet, Inception V3, Residual Network (ResNet) 18, and ResNet 50. An evaluation of the comparison was finally performed. The dataset used for the experiments is contained by nine different classes of tomato diseases and a healthy class from PlantVillage. The models were evaluated through a multiclass statistical analysis based on accuracy, precision, sensitivity, specificity, F-Score, area under the curve (AUC), and receiving operating characteristic (ROC) curve. The results present significant values obtained by the GoogleNet technique, with 99.72\% of AUC and 99.12\% of sensitivity. It is possible to conclude that this significantly success rate makes the GoogleNet model a useful tool for farmers in helping to identify and protect tomatoes from the diseases mentioned.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {classification,convolutional neural networks,deep learning,tomato plant diseases}
}

@article{mahleinDevelopmentSpectralIndices2013,
  title = {Development of Spectral Indices for Detecting and Identifying Plant Diseases},
  author = {Mahlein, A. -K. and Rumpf, T. and Welke, P. and Dehne, H. -W. and Pl{\"u}mer, L. and Steiner, U. and Oerke, E. -C.},
  year = {2013},
  month = jan,
  journal = {Remote Sensing of Environment},
  volume = {128},
  pages = {21--30},
  issn = {0034-4257},
  doi = {10.1016/j.rse.2012.09.019},
  urldate = {2023-01-13},
  abstract = {Spectral vegetation indices (SVIs) have been shown to be useful for an indirect detection of plant diseases. However, these indices have not been evaluated to detect or to differentiate between plant diseases on crop plants. The aim of this study was to develop specific spectral disease indices (SDIs) for the detection of diseases in crops. Sugar beet plants and the three leaf diseases Cercospora leaf spot, sugar beet rust and powdery mildew were used as model system. Hyperspectral signatures of healthy and diseased sugar beet leaves were assessed with a non-imaging spectroradiometer at different developing stages and disease severities of pathogens. Significant and most relevant wavelengths and two band normalized differences from 450 to 950nm, describing the impact of a disease on sugar beet leaves were extracted from the data-set using the RELIEF-F algorithm. To develop hyperspectral indices for the detection of sugar beet diseases the best weighted combination of a single wavelength and a normalized wavelength difference was exhaustively searched testing all possible combinations. The optimized disease indices were tested for their ability to detect and to classify healthy and diseased sugar beet leaves. With a high accuracy and sensitivity healthy sugar beet leaves and leaves, infected with Cercospora leaf spot, sugar beet rust and powdery mildew were classified (balanced classification accuracy: 89\%, 92\%, 87\%, 85\%, respectively). Spectral disease indices were also successfully applied on hyperspectral imaging data and on non-imaging data from a sugar beet field. Specific disease indices will improve disease detection, identification and monitoring in precision agriculture applications.},
  langid = {english},
  keywords = {Band selection,Hyperspectral reflectance,leaf spot,Plant diseases,Powdery mildew,Precision crop protection,Spectral disease indices,Sugar beet,Sugar beet rust}
}

@article{mahleinDevelopmentSpectralIndices2013a,
  title = {Development of Spectral Indices for Detecting and Identifying Plant Diseases},
  author = {Mahlein, A. -K. and Rumpf, T. and Welke, P. and Dehne, H. -W. and Pl{\"u}mer, L. and Steiner, U. and Oerke, E. -C.},
  year = {2013},
  month = jan,
  journal = {Remote Sensing of Environment},
  volume = {128},
  pages = {21--30},
  issn = {0034-4257},
  doi = {10.1016/j.rse.2012.09.019},
  urldate = {2023-01-13},
  abstract = {Spectral vegetation indices (SVIs) have been shown to be useful for an indirect detection of plant diseases. However, these indices have not been evaluated to detect or to differentiate between plant diseases on crop plants. The aim of this study was to develop specific spectral disease indices (SDIs) for the detection of diseases in crops. Sugar beet plants and the three leaf diseases Cercospora leaf spot, sugar beet rust and powdery mildew were used as model system. Hyperspectral signatures of healthy and diseased sugar beet leaves were assessed with a non-imaging spectroradiometer at different developing stages and disease severities of pathogens. Significant and most relevant wavelengths and two band normalized differences from 450 to 950nm, describing the impact of a disease on sugar beet leaves were extracted from the data-set using the RELIEF-F algorithm. To develop hyperspectral indices for the detection of sugar beet diseases the best weighted combination of a single wavelength and a normalized wavelength difference was exhaustively searched testing all possible combinations. The optimized disease indices were tested for their ability to detect and to classify healthy and diseased sugar beet leaves. With a high accuracy and sensitivity healthy sugar beet leaves and leaves, infected with Cercospora leaf spot, sugar beet rust and powdery mildew were classified (balanced classification accuracy: 89\%, 92\%, 87\%, 85\%, respectively). Spectral disease indices were also successfully applied on hyperspectral imaging data and on non-imaging data from a sugar beet field. Specific disease indices will improve disease detection, identification and monitoring in precision agriculture applications.},
  langid = {english},
  keywords = {Band selection,Hyperspectral reflectance,leaf spot,Plant diseases,Powdery mildew,Precision crop protection,Spectral disease indices,Sugar beet,Sugar beet rust}
}

@article{mahleinHyperspectralSensorsImaging2018,
  title = {Hyperspectral {{Sensors}} and {{Imaging Technologies}} in {{Phytopathology}}: {{State}} of the {{Art}}},
  shorttitle = {Hyperspectral {{Sensors}} and {{Imaging Technologies}} in {{Phytopathology}}},
  author = {Mahlein, A.-K. and Kuska, M.T. and Behmann, J. and Polder, G. and Walter, A.},
  year = {2018},
  journal = {Annual Review of Phytopathology},
  volume = {56},
  number = {1},
  pages = {535--558},
  doi = {10.1146/annurev-phyto-080417-050100},
  urldate = {2023-01-13},
  abstract = {Plant disease detection represents a tremendous challenge for research and practical applications. Visual assessment by human raters is time-consuming, expensive, and error prone. Disease rating and plant protection need new and innovative techniques to address forthcoming challenges and trends in agricultural production that require more precision than ever before. Within this context, hyperspectral sensors and imaging techniques---intrinsically tied to efficient data analysis approaches---have shown an enormous potential to provide new insights into plant-pathogen interactions and for the detection of plant diseases. This article provides an overview of hyperspectral sensors and imaging technologies for assessing compatible and incompatible plant-pathogen interactions. Within the progress of digital technologies, the vision, which is increasingly discussed in the society and industry, includes smart and intuitive solutions for assessing plant features in plant phenotyping or for making decisions on plant protection measures in the context of precision agriculture.},
  pmid = {30149790},
  keywords = {digital technologies,machine learning,noninvasive,phenotyping,plant disease detection,precision agriculture}
}

@article{mahleinPlantDiseaseDetection2016,
  title = {Plant {{Disease Detection}} by {{Imaging Sensors}} -- {{Parallels}} and {{Specific Demands}} for {{Precision Agriculture}} and {{Plant Phenotyping}}},
  author = {Mahlein, Anne-Katrin},
  year = {2016},
  month = feb,
  journal = {Plant Disease},
  volume = {100},
  number = {2},
  pages = {241--251},
  publisher = {Scientific Societies},
  issn = {0191-2917},
  doi = {10.1094/PDIS-03-15-0340-FE},
  urldate = {2023-01-13},
  abstract = {Early and accurate detection and diagnosis of plant diseases are key factors in plant production and the reduction of both qualitative and quantitative losses in crop yield. Optical techniques, such as RGB imaging, multi- and hyperspectral sensors, thermography, or chlorophyll fluorescence, have proven their potential in automated, objective, and reproducible detection systems for the identification and quantification of plant diseases at early time points in epidemics. Recently, 3D scanning has also been added as an optical analysis that supplies additional information on crop plant vitality. Different platforms from proximal to remote sensing are available for multiscale monitoring of single crop organs or entire fields. Accurate and reliable detection of diseases is facilitated by highly sophisticated and innovative methods of data analysis that lead to new insights derived from sensor data for complex plant-pathogen systems. Nondestructive, sensor-based methods support and expand upon visual and/or molecular approaches to plant disease assessment. The most relevant areas of application of sensor-based analyses are precision agriculture and plant phenotyping.}
}

@misc{MAIAS2Sentinel,
  title = {{{MAIA S2 Versus Sentinel}} 2: {{Spectral Issues}} and {{Their Effects}} in the {{Precision Farming Context}}},
  shorttitle = {{{MAIA S2 Versus Sentinel}} 2},
  journal = {springerprofessional.de},
  urldate = {2023-03-24},
  abstract = {Precision agriculture involves the integration of new technologies including Geographic Information Systems (GIS), Global Navigation Satellites Systems (GNSS) and Remote Sensing (RS) platforms and sensors to allow farmers to maximize the {\dots}},
  howpublished = {https://www.springerprofessional.de/en/maia-s2-versus-sentinel-2-spectral-issues-and-their-effects-in-t/19653452},
  langid = {english}
}

@misc{MAPIR_Survey3_Camera_Datasheet_Englishpdf,
  title = {{{MAPIR}}\_{{Survey3}}\_{{Camera}}\_{{Datasheet}}\_{{English}}.Pdf},
  journal = {Google Docs},
  urldate = {2022-09-20},
  howpublished = {www.mapir.camera},
  file = {/home/samuelebumbaca/Zotero/storage/R6T3R7NZ/view.html}
}

@inproceedings{martinDatabaseHumanSegmented2001,
  title = {A Database of Human Segmented Natural Images and Its Application to Evaluating Segmentation Algorithms and Measuring Ecological Statistics},
  booktitle = {Proceedings {{Eighth IEEE International Conference}} on {{Computer Vision}}. {{ICCV}} 2001},
  author = {Martin, D. and Fowlkes, C. and Tal, D. and Malik, J.},
  year = {2001},
  month = jul,
  volume = {2},
  pages = {416-423 vol.2},
  doi = {10.1109/ICCV.2001.937655},
  abstract = {This paper presents a database containing 'ground truth' segmentations produced by humans for images of a wide variety of natural scenes. We define an error measure which quantifies the consistency between segmentations of differing granularities and find that different human segmentations of the same image are highly consistent. Use of this dataset is demonstrated in two applications: (1) evaluating the performance of segmentation algorithms and (2) measuring probability distributions associated with Gestalt grouping factors as well as statistics of image region properties.},
  keywords = {Application software,Computer errors,Electric variables measurement,Humans,Image databases,Image recognition,Image segmentation,Layout,Statistics,Testing},
  file = {/home/samuelebumbaca/Zotero/storage/HZYTETC7/937655.html}
}

@article{martinLearningDetectNatural2004,
  title = {Learning to Detect Natural Image Boundaries Using Local Brightness, Color, and Texture Cues},
  author = {Martin, D.R. and Fowlkes, C.C. and Malik, J.},
  year = {2004},
  month = may,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {26},
  number = {5},
  pages = {530--549},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2004.1273918},
  abstract = {The goal of this work is to accurately detect and localize boundaries in natural scenes using local image measurements. We formulate features that respond to characteristic changes in brightness, color, and texture associated with natural boundaries. In order to combine the information from these features in an optimal way, we train a classifier using human labeled images as ground truth. The output of this classifier provides the posterior probability of a boundary at each image location and orientation. We present precision-recall curves showing that the resulting detector significantly outperforms existing approaches. Our two main results are 1) that cue combination can be performed adequately with a simple linear model and 2) that a proper, explicit treatment of texture is required to detect boundaries in natural images.},
  keywords = {Brightness,Data mining,Detectors,Feature extraction,Humans,Image edge detection,Image segmentation,Layout,Pixel,Supervised learning}
}

@inproceedings{maSkeletonExtraction3D2003,
  title = {Skeleton Extraction of {{3D}} Objects with Radial Basis Functions},
  booktitle = {2003 {{Shape Modeling International}}.},
  author = {Ma, Wan-Chun and Wu, Fu-Che and Ouhyoung, Ming},
  year = {2003},
  pages = {207--215},
  publisher = {IEEE},
  urldate = {2024-06-10}
}

@article{mcdonaldHumanVsMachine2022,
  title = {Human vs. {{Machine}}, the {{Eyes Have It}}. {{Assessment}} of {{Stemphylium Leaf Blight}} on {{Onion Using Aerial Photographs}} from an {{NIR Camera}}},
  author = {McDonald, Mary Ruth and Tayviah, Cyril Selasi and Gossen, Bruce D.},
  year = {2022},
  journal = {Remote Sensing},
  volume = {14},
  number = {2},
  issn = {2072-4292},
  doi = {10.3390/rs14020293},
  abstract = {Aerial surveillance could be a useful tool for early detection and quantification of plant diseases, however, there are often confounding effects of other types of plant stress. Stemphylium leaf blight (SLB), caused by the fungus Stemphylium vesicarium, is a damaging foliar disease of onion. Studies were conducted to determine if near-infrared photographic images could be used to accurately assess SLB severity in onion research trials in the Holland Marsh in Ontario, Canada. The site was selected for its uniform soil and level topography. Aerial photographs were taken in 2015 and 2016 using an Xnite-Canon SX230NDVI with a near-infrared filter, mounted on a modified Cine Star\&mdash;8 MK Heavy Lift RTF octocopter UAV. Images were taken at 15\&ndash;20 m above the ground, providing an average of 0.5 cm/pixel and a field of view of 15 \&times; 20 m. Photography and ground assessments of disease were carried out on the same day. NDVI (normalized difference vegetation index), green NDVI, chlorophyll index and plant senescence reflective index (PSRI) were calculated from the images. There were differences in SLB incidence and severity in the field plots and differences in the vegetative indices among the treatments, but there were no correlations between disease assessments and any of the indices.}
}

@inproceedings{meiBuildingAccurateStereo2011,
  title = {On Building an Accurate Stereo Matching System on Graphics Hardware},
  booktitle = {2011 {{IEEE International Conference}} on {{Computer Vision Workshops}} ({{ICCV Workshops}})},
  author = {Mei, Xing and Sun, Xun and Zhou, Mingcai and Jiao, Shaohui and Wang, Haitao and Zhang, Xiaopeng},
  year = {2011},
  month = nov,
  pages = {467--474},
  doi = {10.1109/ICCVW.2011.6130280},
  abstract = {This paper presents a GPU-based stereo matching system with good performance in both accuracy and speed. The matching cost volume is initialized with an AD-Census measure, aggregated in dynamic cross-based regions, and updated in a scanline optimization framework to produce the disparity results. Various errors in the disparity results are effectively handled in a multi-step refinement process. Each stage of the system is designed with parallelism considerations such that the computations can be accelerated with CUDA implementations. Experimental results demonstrate the accuracy and the efficiency of the system: currently it is the top performer in the Middlebury benchmark, and the results are achieved on GPU within 0.1 seconds. We also provide extra examples on stereo video sequences and discuss the limitations of the system.},
  keywords = {Accuracy,Graphics processing unit,Image color analysis,Image edge detection,Interpolation,Reliability,Stereo vision},
  file = {/home/samuelebumbaca/Zotero/storage/6LK2BTPX/6130280.html}
}

@inproceedings{merrellRealTimeVisibilityBasedFusion2007,
  title = {Real-{{Time Visibility-Based Fusion}} of {{Depth Maps}}},
  booktitle = {2007 {{IEEE}} 11th {{International Conference}} on {{Computer Vision}}},
  author = {Merrell, Paul and Akbarzadeh, Amir and Wang, Liang and Mordohai, Philippos and Frahm, Jan-Michael and Yang, Ruigang and Nister, David and Pollefeys, Marc},
  year = {2007},
  pages = {1--8},
  publisher = {IEEE},
  address = {Rio de Janeiro, Brazil},
  doi = {10.1109/ICCV.2007.4408984},
  urldate = {2022-11-24},
  abstract = {We present a viewpoint-based approach for the quick fusion of multiple stereo depth maps. Our method selects depth estimates for each pixel that minimize violations of visibility constraints and thus remove errors and inconsistencies from the depth maps to produce a consistent surface. We advocate a two-stage process in which the first stage generates potentially noisy, overlapping depth maps from a set of calibrated images and the second stage fuses these depth maps to obtain an integrated surface with higher accuracy, suppressed noise, and reduced redundancy. We show that by dividing the processing into two stages we are able to achieve a very high throughput because we are able to use a computationally cheap stereo algorithm and because this architecture is amenable to hardwareaccelerated (GPU) implementations. A rigorous formulation based on the notion of stability of a depth estimate is presented first. It aims to determine the validity of a depth estimate by rendering multiple depth maps into the reference view as well as rendering the reference depth map into the other views in order to detect occlusions and freespace violations. We also present an approximate alternative formulation that selects and validates only one hypothesis based on confidence. Both formulations enable us to perform video-based reconstruction at up to 25 frames per second. We show results on the Multi-View Stereo Evaluation benchmark datasets and several outdoors video sequences. Extensive quantitative analysis is performed using an accurately surveyed model of a real building as ground truth.},
  isbn = {978-1-4244-1630-1},
  langid = {english}
}

@article{merzlyakLightAbsorptionAnthocyanins2008,
  title = {Light Absorption by Anthocyanins in Juvenile, Stressed, and Senescing Leaves},
  author = {Merzlyak, Mark N. and Chivkunova, Olga B. and Solovchenko, Alexei E. and Naqvi, K. Razi},
  year = {2008},
  month = oct,
  journal = {Journal of Experimental Botany},
  volume = {59},
  number = {14},
  pages = {3903--3911},
  issn = {0022-0957},
  doi = {10.1093/jxb/ern230},
  urldate = {2023-01-13},
  abstract = {The optical properties of leaves from five species, Norway maple (Acer platanoides L.), cotoneaster (Cotoneaster alaunica Golite), hazel (Corylus avellana L.), Siberian dogwood (Cornus alba L.), and Virginia creeper (Parthenocissus quinquefolia (L.) Planch.), differing in pigment composition and at different stages of ontogenesis, were studied. Anthocyanin absorption maxima in vivo, as estimated with spectrophotometry of intact anthocyanic versus acyanic leaves and microspectrophotometry of vacuoles in the leaf cross-sections, were found between 537 nm and 542 nm, showing a red shift of 5--20 nm compared with the corresponding maxima in acidic water--methanol extracts. In non-senescent leaves, strong anthocyanin absorption was found between 500 nm and 600 nm (with a 70--80 nm apparent bandwidth). By and large, absorption by anthocyanin in leaves followed a modified form of the Lambert--Beer law, showing a linear trend up to a content of nearly 50 nmol cm-2, and permitting thereby a non-invasive determination of anthocyanin content. The apparent specific absorption coefficients of anthocyanins at 550 nm showed no substantial dependence on the species. Anthocyanin contribution to total light absorption at 550 nm was followed in maple leaves in the course of autumn senescence. Photoprotection by vacuolar anthocyanins is discussed with special regard to their distribution within a leaf; radiation screening by anthocyanins predominantly localized in the epidermal cells in A. platanoides and C. avellana leaves was also evaluated.}
}

@article{mewesSpectralRequirementsAirborne2011,
  title = {Spectral Requirements on Airborne Hyperspectral Remote Sensing Data for Wheat Disease Detection},
  author = {Mewes, Thorsten and Franke, Jonas and Menz, Gunter},
  year = {2011},
  month = dec,
  journal = {Precision Agriculture},
  volume = {12},
  number = {6},
  pages = {795--812},
  issn = {1573-1618},
  doi = {10.1007/s11119-011-9222-9},
  urldate = {2023-01-13},
  abstract = {Remote sensing approaches are of increasing importance for agricultural applications, particularly for the support of selective agricultural measures that increase the productivity of crop stands. In contrast to multi-spectral image data, hyperspectral data has been shown to be highly suitable for the detection of crop growth anomalies, since they allow a detailed examination of stress-dependent changes in certain spectral ranges. However, the entire spectrum covered by hyperspectral data is probably not needed for discrimination between healthy and stressed plants. To define an optimal sensor-based system or a data product designed for crop stress detection, it is necessary to know which spectral wavelengths are significantly affected by stress factors and which spectral resolution is needed. In this study, a single airborne hyperspectral HyMap dataset was analyzed for its potential to detect plant stress symptoms in wheat stands induced by a pathogen infection. The Bhattacharyya distance (BD) with a forward feature search strategy was used to select relevant bands for the differentiation between healthy and fungal infected stands. Two classification algorithms, i.e. spectral angle mapper (SAM) and support vector machines (SVM) were used to classify the data covering an experimental field. Thus, the original dataset as well as datasets reduced to several band combinations as selected by the feature selection approach were classified. To analyze the influence of the spectral resolution on the detection accuracy, the original dataset was additionally stepwise spectrally resampled and a feature selection was carried out on each step. It is demonstrated that just a few phenomenon-specific spectral features are sufficient to detect wheat stands infected with powdery mildew. With original spectral resolution of HyMap, the highest classification accuracy could be obtained by using only 13 spectral bands with a Kappa coefficient of 0.59 in comparison to Kappa 0.57 using all spectral bands of the HyMap sensor. The results demonstrate that even a few hyperspectral bands as well as bands with lower spectral resolution still allow an adequate detection of fungal infections in wheat. By focusing on a few relevant bands, the detection accuracy could be enhanced and thus more reliable information could be extracted which may be helpful in agricultural practice.},
  langid = {english},
  keywords = {Bhattacharyya distance,Crop stress,Data reduction,Feature selection,Hyperspectral data,Spectral angle mapper,Spectral resolution,Support vector machines}
}

@article{mezarisStillImageObjective,
  title = {Still {{Image Objective Segmentation Evaluation}} Using {{Ground Truth}}},
  author = {Mezaris, V and Kompatsiaris, I and Strintzis, M G},
  abstract = {In this paper, an objective segmentation evaluation metric suitable for the evaluation of still image segmentation results is proposed. The proposed metric is based on the spatial accuracy approach, originally proposed for the evaluation of foreground/backgroung segmentation masks generated from video sequences. This approach is extended to still image segmentation evaluation, where both the estimated segmentation masks and the ground truth mask typically contain multiple regions. The proposed method takes into account, using a single metric, not only the accuracy of the boundary localization of the created segments but also the under-segmentation and over-segmentation effects, which can hinder the performance of any segmentation algorithm and decrease the usability of the segmentation results in content-based applications. Several experiments have shown the potential of this approach.},
  langid = {english}
}

@article{miaoLabel3DMaizeToolkit3D2021,
  title = {{{Label3DMaize}}: Toolkit for {{3D}} Point Cloud Data Annotation of Maize Shoots},
  shorttitle = {{{Label3DMaize}}},
  author = {Miao, Teng and Wen, Weiliang and Li, Yinglun and Wu, Sheng and Zhu, Chao and Guo, Xinyu},
  year = {2021},
  month = may,
  journal = {GigaScience},
  volume = {10},
  number = {5},
  pages = {giab031},
  issn = {2047-217X},
  doi = {10.1093/gigascience/giab031},
  urldate = {2021-12-18},
  abstract = {Abstract                              Background                The 3D point cloud is the most direct and effective data form for studying plant structure and morphology. In point cloud studies, the point cloud segmentation of individual plants to organs directly determines the accuracy of organ-level phenotype estimation and the reliability of the 3D plant reconstruction. However, highly accurate, automatic, and robust point cloud segmentation approaches for plants are unavailable. Thus, the high-throughput segmentation of many shoots is challenging. Although deep learning can feasibly solve this issue, software tools for 3D point cloud annotation to construct the training dataset are lacking.                                            Results                We propose a top-to-down point cloud segmentation algorithm using optimal transportation distance for maize shoots. We apply our point cloud annotation toolkit for maize shoots, Label3DMaize, to achieve semi-automatic point cloud segmentation and annotation of maize shoots at different growth stages, through a series of operations, including stem segmentation, coarse segmentation, fine segmentation, and sample-based segmentation. The toolkit takes {$\sim$}4--10 minutes to segment a maize shoot and consumes 10--20\% of the total time if only coarse segmentation is required. Fine segmentation is more detailed than coarse segmentation, especially at the organ connection regions. The accuracy of coarse segmentation can reach 97.2\% that of fine segmentation.                                            Conclusion                Label3DMaize integrates point cloud segmentation algorithms and manual interactive operations, realizing semi-automatic point cloud segmentation of maize shoots at different growth stages. The toolkit provides a practical data annotation tool for further online segmentation research based on deep learning and is expected to promote automatic point cloud processing of various plants.},
  langid = {english}
}

@article{millerPlantDiseaseDiagnostic2009,
  title = {Plant {{Disease Diagnostic Capabilities}} and {{Networks}}},
  author = {Miller, Sally A. and Beed, Fen D. and Harmon, Carrie Lapaire},
  year = {2009},
  month = sep,
  journal = {Annual Review of Phytopathology},
  volume = {47},
  number = {1},
  pages = {15--38},
  issn = {0066-4286, 1545-2107},
  doi = {10.1146/annurev-phyto-080508-081743},
  urldate = {2023-01-13},
  abstract = {Emerging, re-emerging and endemic plant pathogens continue to challege our ability to safeguard plant health worldwide. Further, globalization, climate change, increased human mobility, and pathogen and vector evolution have combined to increase the spread of invasive plant pathogens. Early and accurate diagnoses and pathogen surveillance on local, regional, and global scales are necessary to predict outbreaks and allow time for development and application of mitigation strategies. Plant disease diagnostic networks have developed worldwide to address the problems of efficient and effective disease diagnosis and pathogen detection, engendering cooperation of institutions and experts within countries and across national borders. Networking maximizes impact in the face of shrinking government investments in agriculture and diminishing human resource capacity in diagnostics and applied pathology. New technologies promise to improve the speed and accuracy of disease diagnostics and pathogen detection. Widespread adoption of standard operating procedures and diagnostic laboratory accreditation serve to build trust and confidence among institutions. Case studies of national, regional, and international diagnostic networks are presented.},
  langid = {english}
}

@article{minerviniImagebasedPlantPhenotyping2014,
  title = {Image-Based Plant Phenotyping with Incremental Learning and Active Contours},
  author = {Minervini, Massimo and Abdelsamea, Mohammed M. and Tsaftaris, Sotirios A.},
  year = {2014},
  month = sep,
  journal = {Ecological Informatics},
  series = {Special {{Issue}} on {{Multimedia}} in {{Ecology}} and {{Environment}}},
  volume = {23},
  pages = {35--48},
  issn = {1574-9541},
  doi = {10.1016/j.ecoinf.2013.07.004},
  urldate = {2023-01-13},
  abstract = {Plant phenotyping investigates how a plant's genome, interacting with the environment, affects the observable traits of a plant (phenome). It is becoming increasingly important in our quest towards efficient and sustainable agriculture. While sequencing the genome is becoming increasingly efficient, acquiring phenotype information has remained largely of low throughput. Current solutions for automated image-based plant phenotyping, rely either on semi-automated or manual analysis of the imaging data, or on expensive and proprietary software which accompanies costly hardware infrastructure. While some attempts have been made to create software applications that enable the analysis of such images in an automated fashion, most solutions are tailored to particular acquisition scenarios and restrictions on experimental design. In this paper we propose and test, a method for the segmentation and the automated analysis of time-lapse plant images from phenotyping experiments in a general laboratory setting, that can adapt to scene variability. The method involves minimal user interaction, necessary to establish the statistical experiments that may follow. At every time instance (i.e., a digital photograph), it segments the plants in images that contain many specimens of the same species. For accurate plant segmentation we propose a vector valued level set formulation that incorporates features of color intensity, local texture, and prior knowledge. Prior knowledge is incorporated using a plant appearance model implemented with Gaussian mixture models, which utilizes incrementally information from previously segmented instances. The proposed approach is tested on Arabidopsis plant images acquired with a static camera capturing many subjects at the same time. Our validation with ground truth segmentations and comparisons with state-of-the-art methods in the literature shows that the proposed method is able to handle images with complicated and changing background in an automated fashion. An accuracy of 96.7\% (dice similarity coefficient) was observed, which was higher than other methods used for comparison. While here it was tested on a single plant species, the fact that we do not employ shape driven models and we do not rely on fully supervised classification (trained on a large dataset) increases the ease of deployment of the proposed solution for the study of different plant species in a variety of laboratory settings. Our solution will be accompanied by an easy to use graphical user interface and, to facilitate adoption, we will make the software available to the scientific community.},
  langid = {english},
  keywords = {Active contour model,Agriculture,Gaussian mixture model,Machine learning,Phenotyping,Plant segmentation}
}

@article{minkSensorbasedEvaluationMaize2020,
  title = {Sensor-Based Evaluation of Maize ({{Zea}} Mays) and Weed Response to Post-Emergence Herbicide Applications of {{Isoxaflutole}} and {{Cyprosulfamide}} Applied as Crop Seed Treatment or Herbicide Mixing Partner},
  author = {Mink, Robin and Linn, Alexander Ingo and Santel, Hans-Joachim and Gerhards, Roland},
  year = {2020},
  journal = {Pest Management Science},
  volume = {76},
  number = {5},
  pages = {1856--1865},
  issn = {1526-4998},
  doi = {10.1002/ps.5715},
  urldate = {2023-03-24},
  abstract = {BACKGROUND Some maize post-emergence herbicides obtain their crop/weed selectivity only through the use of chemical crop safeners. Safeners improve the tolerance of maize to herbicidal active ingredients. In order to investigate the crop response to safener (cyprosulfamide) spray application and seed treatment, greenhouse and field trials were conducted on three maize development stages (2-, 4-, and 6-leaf stage). Visual estimations on crop vitality were compared to ground-based and airborne hyperspectral and multispectral sensors. RESULTS The reduction of cyprosulfamide by 88\% when applied as seed treatment did not significantly reduce maize biomass yields at the field. The crop deterioration in both trials was stronger in the cyprosulfamide seed treatments compared to the spray applications but was found to be transient in the field trial. The hyperspectral sensor and multispectral camera data correlated with R2 = 0.84 (CropSpec Vegetation Index) and R2 = 0.64 (Green Normalized Difference Vegetation Index). CONCLUSION The sensor-based collection of crop responses to treatments enables early, quantifiable and auditor-independent assessments. In particular, the airborne multispectral imagery assessment of field experiments provides more detailed and comprehensive information than visually collected data. {\copyright} 2019 The Authors. Pest Management Science published by John Wiley \& Sons Ltd on behalf of Society of Chemical Industry.},
  langid = {english},
  keywords = {crop stress measurement,remote sensing,sensor fusion,spectral indices,spectrometer,UAV multispectral imagery,weed management},
  file = {/home/samuelebumbaca/Zotero/storage/AIZ44UKB/ps.html}
}

@article{mirandaDetectionAnomalousGrapevine2022,
  title = {Detection of {{Anomalous Grapevine Berries Using Variational Autoencoders}}},
  author = {Miranda, Miro and Zabawa, Laura and Kicherer, Anna and Strothmann, Laurenz and Rascher, Uwe and Roscher, Ribana},
  year = {2022},
  month = jun,
  journal = {Frontiers in Plant Science},
  volume = {13},
  pages = {729097},
  issn = {1664-462X},
  doi = {10.3389/fpls.2022.729097},
  urldate = {2025-01-05},
  abstract = {Grapevine is one of the economically most important quality crops. The monitoring of the plant performance during the growth period is, therefore, important to ensure a high quality end-product. This includes the observation, detection, and respective reduction of unhealthy berries (physically damaged, or diseased). At harvest, it is not necessary to know the exact cause of the damage, but rather if the damage is apparent or not. Since a manual screening and selection before harvest is time-consuming and expensive, we propose an automatic, image-based machine learning approach, which can lead observers directly to anomalous areas without the need to monitor every plant manually. Specifically, we train a fully convolutional variational autoencoder with a feature perceptual loss on images with healthy berries only and consider image areas with deviations from this model as damaged berries. We use heatmaps which visualize the results of the trained neural network and, therefore, support the decision making for farmers. We compare our method against a convolutional autoencoder that was successfully applied to a similar task and show that our approach outperforms it.},
  pmcid = {PMC9198582},
  pmid = {35720600}
}

@article{mirikSatelliteRemoteSensing2011,
  title = {Satellite {{Remote Sensing}} of {{Wheat Infected}} by {{Wheat}} Streak Mosaic Virus},
  author = {Mirik, M. and Jones, D. C. and Price, J. A. and Workneh, F. and Ansley, R. J. and Rush, C. M.},
  year = {2011},
  month = jan,
  journal = {Plant Disease},
  volume = {95},
  number = {1},
  pages = {4--12},
  publisher = {Scientific Societies},
  issn = {0191-2917},
  doi = {10.1094/PDIS-04-10-0256},
  urldate = {2023-01-13},
  abstract = {The prevalence of wheat streak mosaic, caused by Wheat streak mosaic virus, was assessed using Landsat 5 Thematic Mapper (TM) images in two counties of the Texas Panhandle during the 2005--2006 and 2007--2008 crop years. In both crop years, wheat streak mosaic was widely distributed in the counties studied. Healthy and diseased wheat were separated on the images using the maximum likelihood classifier. The overall classification accuracies were between 89.47 and 99.07\% for disease detection when compared to ``ground truth'' field observations. Omission errors (i.e., pixels incorrectly excluded from a particular class and assigned to other classes) varied between 0 and 12.50\%. Commission errors (i.e., pixels incorrectly assigned to a particular class that actually belong to other classes) ranged from 0 to 23.81\%. There were substantial differences between planted wheat acreage reported by the United States Department of Agriculture-National Agricultural Statistics Service (USDA-NASS) and that detected by image analyses. However, harvested wheat acreage reported by USDA-NASS and that detected by image classifications were closely matched. These results indicate that the TM image can be used to accurately detect and quantify incidence of wheat streak mosaic over large areas. This method appears to be one of the best currently available for identification and mapping disease incidence over large and remote areas by offering a repeatable, inexpensive, and synoptic strategy during the course of a growing season.}
}

@misc{MiSTreeMistree13,
  title = {{{MiSTree}} --- Mistree 1.3 Documentation},
  urldate = {2024-06-10},
  howpublished = {https://mistree.readthedocs.io/en/latest/\#installation},
  file = {/home/samuelebumbaca/Zotero/storage/DMRXPKCJ/latest.html}
}

@article{moulonPositionnementRobustePrecis,
  title = {{Positionnement robuste et pr{\'e}cis de r{\'e}seaux d'images}},
  author = {Moulon, Pierre},
  pages = {193},
  langid = {french}
}

@phdthesis{moulonPositionnementRobustePrecis2014,
  title = {Positionnement Robuste et Pr{\'e}cis de R{\'e}seaux d'images},
  author = {Moulon, Pierre},
  year = {2014},
  school = {Universit{\'e} Paris-Est}
}

@article{moulonPositionnementRobustePrecisa,
  title = {{Positionnement robuste et pr{\'e}cis de r{\'e}seaux d'images}},
  author = {Moulon, Pierre},
  pages = {193},
  langid = {french}
}

@misc{mukherjeeClusterGANLatentSpace2019,
  title = {{{ClusterGAN}} : {{Latent Space Clustering}} in {{Generative Adversarial Networks}}},
  shorttitle = {{{ClusterGAN}}},
  author = {Mukherjee, Sudipto and Asnani, Himanshu and Lin, Eugene and Kannan, Sreeram},
  year = {2019},
  month = jan,
  number = {arXiv:1809.03627},
  eprint = {1809.03627},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1809.03627},
  urldate = {2025-01-13},
  abstract = {Generative Adversarial networks (GANs) have obtained remarkable success in many unsupervised learning tasks and unarguably, clustering is an important unsupervised learning problem. While one can potentially exploit the latent-space back-projection in GANs to cluster, we demonstrate that the cluster structure is not retained in the GAN latent space. In this paper, we propose ClusterGAN as a new mechanism for clustering using GANs. By sampling latent variables from a mixture of one-hot encoded variables and continuous latent variables, coupled with an inverse network (which projects the data to the latent space) trained jointly with a clustering specific loss, we are able to achieve clustering in the latent space. Our results show a remarkable phenomenon that GANs can preserve latent space interpolation across categories, even though the discriminator is never exposed to such vectors. We compare our results with various clustering baselines and demonstrate superior performance on both synthetic and real datasets.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/samuelebumbaca/Zotero/storage/ITR7W5L6/1809.html}
}

@misc{mukherjeeClusterGANLatentSpace2019a,
  title = {{{ClusterGAN}} : {{Latent Space Clustering}} in {{Generative Adversarial Networks}}},
  shorttitle = {{{ClusterGAN}}},
  author = {Mukherjee, Sudipto and Asnani, Himanshu and Lin, Eugene and Kannan, Sreeram},
  year = {2019},
  month = jan,
  number = {arXiv:1809.03627},
  eprint = {1809.03627},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1809.03627},
  urldate = {2025-01-13},
  abstract = {Generative Adversarial networks (GANs) have obtained remarkable success in many unsupervised learning tasks and unarguably, clustering is an important unsupervised learning problem. While one can potentially exploit the latent-space back-projection in GANs to cluster, we demonstrate that the cluster structure is not retained in the GAN latent space. In this paper, we propose ClusterGAN as a new mechanism for clustering using GANs. By sampling latent variables from a mixture of one-hot encoded variables and continuous latent variables, coupled with an inverse network (which projects the data to the latent space) trained jointly with a clustering specific loss, we are able to achieve clustering in the latent space. Our results show a remarkable phenomenon that GANs can preserve latent space interpolation across categories, even though the discriminator is never exposed to such vectors. We compare our results with various clustering baselines and demonstrate superior performance on both synthetic and real datasets.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/samuelebumbaca/Zotero/storage/JZ4FBCK6/1809.html}
}

@article{myronenkoPointSetRegistration2010,
  title = {Point {{Set Registration}}: {{Coherent Point Drift}}},
  shorttitle = {Point {{Set Registration}}},
  author = {Myronenko, Andriy and {Xubo Song}},
  year = {2010},
  month = dec,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {32},
  number = {12},
  pages = {2262--2275},
  issn = {0162-8828},
  doi = {10.1109/TPAMI.2010.46},
  urldate = {2021-12-19}
}

@misc{nagarAutomatedSeedQuality2021,
  title = {Automated {{Seed Quality Testing System}} Using {{GAN}} \& {{Active Learning}}},
  author = {Nagar, Sandeep and Pani, Prateek and Nair, Raj and Varma, Girish},
  year = {2021},
  month = oct,
  number = {arXiv:2110.00777},
  eprint = {2110.00777},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2110.00777},
  urldate = {2025-01-05},
  abstract = {Quality assessment of agricultural produce is a crucial step in minimizing food stock wastage. However, this is currently done manually and often requires expert supervision, especially in smaller seeds like corn. We propose a novel computer vision-based system for automating this process. We build a novel seed image acquisition setup, which captures both the top and bottom views. Dataset collection for this problem has challenges of data annotation costs/time and class imbalance. We address these challenges by i.) using a Conditional Generative Adversarial Network (CGAN) to generate real-looking images for the classes with lesser images and ii.) annotate a large dataset with minimal expert human intervention by using a Batch Active Learning (BAL) based annotation tool. We benchmark different image classification models on the dataset obtained. We are able to get accuracies of up to 91.6\% for testing the physical purity of seed samples.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Hardware Architecture},
  file = {/home/samuelebumbaca/Zotero/storage/4XT7JNAC/2110.html}
}

@article{nawazRobustDeepLearning2022,
  title = {A Robust Deep Learning Approach for Tomato Plant Leaf Disease Localization and Classification},
  author = {Nawaz, Marriam and Nazir, Tahira and Javed, Ali and Masood, Momina and Rashid, Junaid and Kim, Jungeun and Hussain, Amir},
  year = {2022},
  month = nov,
  journal = {Scientific Reports},
  volume = {12},
  number = {1},
  pages = {18568},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-022-21498-5},
  urldate = {2023-09-01},
  abstract = {Tomato plants' disease detection and classification at the earliest stage can save the farmers from expensive crop sprays and can assist in increasing the food quantity. Although, extensive work has been presented by the researcher for the tomato plant disease classification, however, the timely localization and identification of various tomato leaf diseases is a complex job as a consequence of the huge similarity among the healthy and affected portion of plant leaves. Furthermore, the low contrast information between the background and foreground of the suspected sample has further complicated the plant leaf disease detection process. To deal with the aforementioned challenges, we have presented a robust deep learning (DL)-based approach namely ResNet-34-based Faster-RCNN for tomato plant leaf disease classification. The proposed method includes three basic steps. Firstly, we generate the annotations of the suspected images to specify the region of interest (RoI). In the next step, we have introduced ResNet-34 along with Convolutional Block Attention Module (CBAM) as a feature extractor module of Faster-RCNN to extract the deep key points. Finally, the calculated features are utilized for the Faster-RCNN model training to locate and categorize the numerous tomato plant leaf anomalies. We tested the presented work on an accessible standard database, the PlantVillage Kaggle dataset. More specifically, we have obtained the mAP and accuracy values of 0.981, and 99.97\% respectively along with the test time of 0.23~s. Both qualitative and quantitative results confirm that the presented solution is robust to the detection of plant leaf disease and can replace the manual systems. Moreover, the proposed method shows a low-cost solution to tomato leaf disease classification which is robust to several image transformations like the variations in the size, color, and orientation of the leaf diseased portion. Furthermore, the framework can locate the affected plant leaves under the occurrence of blurring, noise, chrominance, and brightness variations. We have confirmed through the reported results that our approach is robust to several tomato leaf diseases classification under the varying image capturing conditions. In the future, we plan to extend our approach to apply it to other parts of plants as well.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Diseases,Mathematics and computing,Plant sciences}
}

@article{neillUseCropSensing2011,
  title = {Use of Crop Sensing Technology in Crop Protection Research},
  author = {Neill, {\relax DE} and Follas, {\relax GB}},
  year = {2011},
  journal = {New Zealand Plant Protection},
  volume = {64},
  pages = {287--287}
}

@inproceedings{nguyenPlantPhenotypingUsing2016,
  title = {Plant Phenotyping Using Multi-View Stereo Vision with Structured Lights},
  booktitle = {Autonomous {{Air}} and {{Ground Sensing Systems}} for {{Agricultural Optimization}} and {{Phenotyping}}},
  author = {Nguyen, Thuy Tuong and Slaughter, David C. and Maloof, Julin N. and Sinha, Neelima},
  year = {2016},
  month = may,
  volume = {9866},
  pages = {22--30},
  publisher = {SPIE},
  doi = {10.1117/12.2229513},
  urldate = {2022-11-10},
  abstract = {A multi-view stereo vision system for true 3D reconstruction, modeling and phenotyping of plants was created that successfully resolves many of the shortcomings of traditional camera-based 3D plant phenotyping systems. This novel system incorporates several features including: computer algorithms, including camera calibration, excessive-green based plant segmentation, semi-global stereo block matching, disparity bilateral filtering, 3D point cloud processing, and 3D feature extraction, and hardware consisting of a hemispherical superstructure designed to hold five stereo pairs of cameras and a custom designed structured light pattern illumination system. This system is nondestructive and can extract 3D features of whole plants modeled from multiple pairs of stereo images taken at different view angles. The study characterizes the systems phenotyping performance for 3D plant features: plant height, total leaf area, and total leaf shading area. For plants having specified leaf spacing and size, the algorithms used in our system yielded satisfactory experimental results and demonstrated the ability to study plant development where the same plants were repeatedly imaged and phenotyped over the time.},
  file = {/home/samuelebumbaca/Zotero/storage/T8MJB229/12.2229513.html}
}

@article{nieuwenhuisSpatiallyVaryingColor2013,
  title = {Spatially {{Varying Color Distributions}} for {{Interactive Multilabel Segmentation}}},
  author = {Nieuwenhuis, Claudia and Cremers, Daniel},
  year = {2013},
  month = may,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {35},
  number = {5},
  pages = {1234--1247},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2012.183},
  abstract = {We propose a method for interactive multilabel segmentation which explicitly takes into account the spatial variation of color distributions. To this end, we estimate a joint distribution over color and spatial location using a generalized Parzen density estimator applied to each user scribble. In this way, we obtain a likelihood for observing certain color values at a spatial coordinate. This likelihood is then incorporated in a Bayesian MAP estimation approach to multiregion segmentation which in turn is optimized using recently developed convex relaxation techniques. These guarantee global optimality for the two-region case (foreground/background) and solutions of bounded optimality for the multiregion case. We show results on the GrabCut benchmark, the recently published Graz benchmark, and on the Berkeley segmentation database which exceed previous approaches such as GrabCut [32], the Random Walker [15], Santner's approach [35], TV-Seg [39], and interactive graph cuts [4] in accuracy. Our results demonstrate that taking into account the spatial variation of color models leads to drastic improvements for interactive image segmentation.},
  keywords = {Bayesian methods,color distribution,convex optimization,Image color analysis,Image segmentation,Joints,Kernel,Motion segmentation,Probability distribution,spatially varying}
}

@article{nikithLeafDiseaseDetection2023,
  title = {Leaf {{Disease Detection}} and {{Classification}}},
  author = {Nikith, B. V. and Keerthan, N. K. S. and Praneeth, M. S. and Amrita, Dr. T},
  year = {2023},
  month = jan,
  journal = {Procedia Computer Science},
  series = {International {{Conference}} on {{Machine Learning}} and {{Data Engineering}}},
  volume = {218},
  pages = {291--300},
  issn = {1877-0509},
  doi = {10.1016/j.procs.2023.01.011},
  urldate = {2023-12-17},
  abstract = {The notion of smart farming is gaining traction in the agricultural industry these days, and it makes use of sensors and a variety of machine learning based technologies. According to recent surveys, 56 percent of the agricultural industry is facing significant losses because of diseases developing on plant leaves. It's critical to keep track of the disease's spread and enhance agricultural yields. To prevent the disease from spreading, we must first recognize it on time and prevent it. As a result, we may solve this problem by putting in place some algorithms for detecting sickness on leaves. This paper presents a comparative analysis between support vector machines (SVM) model, K-Nearest Neighbor (KNN) model and convolution neural network (CNN) model. The three different models are presented and examined in this research, and they can detect eight different leaf diseases. The CNN model has achieved an accuracy of 96 percent when trained with the images of soyabean leaf disease dataset, outperforms the KNN and SVM models, which have accuracy of 64 percent and 76 percent, respectively},
  keywords = {CNN,HOG,kernels,KNN,SVM},
  file = {/home/samuelebumbaca/Zotero/storage/SD95BKG2/S187705092300011X.html}
}

@article{nikouBayesianFrameworkImage2010,
  title = {A {{Bayesian Framework}} for {{Image Segmentation With Spatially Varying Mixtures}}},
  author = {Nikou, Christophoros and Likas, Aristidis C and Galatsanos, Nikolaos P},
  year = {2010},
  month = sep,
  journal = {IEEE Transactions on Image Processing},
  volume = {19},
  number = {9},
  pages = {2278--2289},
  issn = {1057-7149, 1941-0042},
  doi = {10.1109/TIP.2010.2047903},
  urldate = {2021-12-19}
}

@inproceedings{nisterScalableRecognitionVocabulary2006,
  title = {Scalable {{Recognition}} with a {{Vocabulary Tree}}},
  booktitle = {2006 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}}'06)},
  author = {Nister, D. and Stewenius, H.},
  year = {2006},
  month = jun,
  volume = {2},
  pages = {2161--2168},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2006.264},
  abstract = {A recognition scheme that scales efficiently to a large number of objects is presented. The efficiency and quality is exhibited in a live demonstration that recognizes CD-covers from a database of 40000 images of popular music CD's. The scheme builds upon popular techniques of indexing descriptors extracted from local regions, and is robust to background clutter and occlusion. The local region descriptors are hierarchically quantized in a vocabulary tree. The vocabulary tree allows a larger and more discriminatory vocabulary to be used efficiently, which we show experimentally leads to a dramatic improvement in retrieval quality. The most significant property of the scheme is that the tree directly defines the quantization. The quantization and the indexing are therefore fully integrated, essentially being one and the same. The recognition quality is evaluated through retrieval on a database with ground truth, showing the power of the vocabulary tree approach, going as high as 1 million images.},
  keywords = {Computer vision,Frequency,Image databases,Image recognition,Indexing,Quantization,Robustness,Spatial databases,Visualization,Vocabulary},
  file = {/home/samuelebumbaca/Zotero/storage/CI87PER9/1641018.html}
}

@article{novakRectificationDigitalImagery1992,
  title = {Rectification of {{Digital Imagery}}},
  author = {Novak, Kurt},
  year = {1992},
  journal = {PHOTOGRAMMETRIC ENGINEERING},
  pages = {6},
  abstract = {Different methods can be applied to generate digital orthophotos. Three commonly used approaches are analyzed and compared in this paper. They can be applied to rectify both digitized aerial photographs and satellite scenes. These methods are polynomial, projective, and differential rectifications. The first two are defined by analytical transformations between image and orthophoto without considering the geometry and orientation of the camera. They are approximate solutions. The last one models the physical reality of the imaging process by means of the collinearity equations and corrects for relief displacements. For eliminating distortions of the camera system, additional parameters were included. This proves to be necessary when images are directly taken by video cameras. All three methods were implemented on a workstation and were tested with digitized aerial photographs and video images. By overlaying GIS data over the digital orthophoto, the quality of the rectification is checked. To determine the planimetric accuracy of the results, the coordinates of targets were measured in a digital orthophoto and compared to known map coordinates.},
  langid = {english}
}

@article{nutterDiseaseAssessmentConcepts2006,
  title = {Disease {{Assessment Concepts}} and the {{Advancements Made}} in {{Improving}} the {{Accuracy}} and {{Precision}} of {{Plant Disease Data}}},
  author = {Nutter, Forrest W. and Esker, Paul D. and Netto, Rosalee A. Coelho},
  year = {2006},
  month = may,
  journal = {European Journal of Plant Pathology},
  volume = {115},
  number = {1},
  pages = {95--103},
  issn = {1573-8469},
  doi = {10.1007/s10658-005-1230-z},
  urldate = {2023-01-13},
  abstract = {New concepts in phytopathometry continue to emerge, such as the evolution of the concept of pathogen intensity versus the well-established concept of disease intensity. The concept of pathogen severity, defined as the quantitative measurement of the amount of pathogen per sampling unit has also emerged in response to the now commonplace development of quantitative molecular detection tools. Although the concept of disease severity, i.e., the amount of disease per sampling unit, is a well-established concept, the accuracy and precision of visual estimates of disease severity is often questioned. This article will review disease assessment concepts, as well as the methods and assessment aides currently available to improve the accuracy and precision of visually-based disease severity data. The accuracy and precision of visual disease severity assessments can be improved by quantitatively measuring and comparing the accuracy and precision of rates and/or assessment methods using linear regression, by using computer-based disease assessment training programmes, and by developing and using diagrammatic keys (standard area diagrams).},
  langid = {english},
  keywords = {phytopathometry}
}

@article{nutterImprovingAccuracyPrecision1995,
  title = {Improving the Accuracy and Precision of Disease Assessments: Selection of Methods and Use of Computer-Aided Training Programs},
  shorttitle = {Improving the Accuracy and Precision of Disease Assessments},
  author = {Nutter, Forrest W. and Schultz, Patricia M.},
  year = {1995},
  month = jun,
  journal = {Canadian Journal of Plant Pathology},
  volume = {17},
  number = {2},
  pages = {174--184},
  publisher = {Taylor \& Francis},
  issn = {0706-0661},
  doi = {10.1080/07060669509500709},
  urldate = {2023-01-13}
}

@article{obertiSelectiveSprayingGrapevines2016,
  title = {Selective Spraying of Grapevines for Disease Control Using a Modular Agricultural Robot},
  author = {Oberti, Roberto and Marchi, Massimo and Tirelli, Paolo and Calcante, Aldo and Iriti, Marcello and Tona, Emanuele and Ho{\v c}evar, Marko and Baur, Joerg and Pfaff, Julian and Sch{\"u}tz, Christoph and Ulbrich, Heinz},
  year = {2016},
  month = jun,
  journal = {Biosystems Engineering},
  series = {Special {{Issue}}: {{Advances}} in {{Robotic Agriculture}} for {{Crops}}},
  volume = {146},
  pages = {203--215},
  issn = {1537-5110},
  doi = {10.1016/j.biosystemseng.2015.12.004},
  urldate = {2023-01-13},
  abstract = {Due to their recognised role in causing environmental pressures, the need to reduce production costs and public concerns over the healthfulness of fresh products and food, reducing pesticide use in agriculture is a major objective. In current farming practice, pesticides are typically applied uniformly across fields, despite many pests and diseases exhibiting uneven spatial distributions and evolving around discrete foci. This is the fundamental rationale for implementing the selective targeting of pesticide applications such that pesticides are deposited only where and when they are needed and at the correct dose. This approach is explored using the example of powdery mildew on grape vines controlled by means of a modular agricultural robot developed within the EU-project CROPS. The CROPS manipulator was configured to six degrees of freedom and equipped with a new precision-spraying end-effector with an integrated disease-sensing system based on R-G-NIR multispectral imaging. The robotic system was tested on four different replicates of grapevine canopy plots (5~m in length~{\texttimes}~1.8~m in height) prepared in a greenhouse setup by aligning potted plants exhibiting different levels of disease. The results indicate that the robot was able to automatically detect and spray from 85\% to 100\% of the diseased area within the canopy and to reduce the pesticide use from 65\% to 85\% when compared to a conventional homogeneous spraying of the canopy. This work, to the best of our knowledge, is the first using a totally automatic selective system for spraying of diseases in specialty crops.},
  langid = {english},
  keywords = {Agricultural robot,Automation,Crop protection,Disease sensing,Precision spraying}
}

@article{oerkeHyperspectralPhenotypingReaction2016,
  title = {Hyperspectral Phenotyping of the Reaction of Grapevine Genotypes to {{{\emph{Plasmopara}}}}{\emph{ Viticola}}},
  author = {Oerke, Erich-Christian and Herzog, Katja and Toepfer, Reinhard},
  year = {2016},
  month = oct,
  journal = {Journal of Experimental Botany},
  volume = {67},
  number = {18},
  pages = {5529--5543},
  issn = {0022-0957, 1460-2431},
  doi = {10.1093/jxb/erw318},
  urldate = {2021-12-22},
  langid = {english}
}

@article{omasaImageAnalysisChlorophyll1987,
  title = {Image {{Analysis}} of {{Chlorophyll Fluorescence Transients}} for {{Diagnosing}} the {{Photosynthetic System}} of {{Attached Leaves}}},
  author = {Omasa, Kenji and Shimazaki, Ken-Ichiro and Aiga, Ichiro and Larcher, Walter and Onoe, Morio},
  year = {1987},
  month = jul,
  journal = {Plant Physiology},
  volume = {84},
  number = {3},
  pages = {748--752},
  issn = {0032-0889},
  doi = {10.1104/pp.84.3.748},
  abstract = {A new image instrumentation system for quantitative analysis of the rapid change in intensity of chlorophyll fluorescence during dark-light transition (CFI, chlorophyll fluorescence induction), which is a sensitive indicator of the various reactions of photosynthesis, was developed and its performance was evaluated. This system made it possible to resolve CFI at any small leaf area (about 1 square millimeter) of a whole leaf when the plant was illuminated by blue-green light at more than 50 micromoles photons per square meter per second. In order to test the usefulness of this system, we applied it to analyze the effect of SO2 on photosynthetic apparatus in attached sunflower leaves. Dynamic CFI imaging over the whole single leaf, where there was no visible injury, indicated not only the local changes in photosynthetic activity but also the site of inhibition in photosynthetic electron transport system in chloroplasts. The new instrumentation system will be useful for the analytical diagnosis of various stress-actions on plants in situ.}
}

@misc{OpenCVCameraCalibration,
  title = {{{OpenCV}}: {{Camera Calibration}}},
  urldate = {2023-03-25},
  howpublished = {https://docs.opencv.org/4.x/dc/dbb/tutorial\_py\_calibration.html},
  file = {/home/samuelebumbaca/Zotero/storage/AKUA67N8/tutorial_py_calibration.html}
}

@misc{OpenCVDocumentationIndex,
  title = {{{OpenCV}} Documentation Index},
  urldate = {2023-03-24},
  howpublished = {https://docs.opencv.org/},
  file = {/home/samuelebumbaca/Zotero/storage/ZQWW6K7W/docs.opencv.org.html}
}

@article{orusaExploringShorttermClimate2021,
  title = {Exploring {{Short-term}} Climate Change Effects on Rangelands and Broad-Leaved Forests by Free Satellite Data in {{Aosta Valley}} ({{Northwest Italy}})},
  author = {Orusa, Tommaso and Borgogno Mondino, Enrico},
  year = {2021},
  journal = {Climate},
  volume = {9},
  number = {3},
  pages = {47}
}

@article{orusaGeomaticsEOData2020,
  title = {Geomatics and {{EO}} Data to Support Wildlife Diseases Assessment at Landscape Level: {{A}} Pilot Experience to Map Infectious Keratoconjunctivitis in Chamois and Phenological Trends in {{Aosta Valley}} ({{NW Italy}})},
  author = {Orusa, Tommaso and Orusa, Riccardo and Viani, Annalisa and Carella, Emanuele and Borgogno Mondino, Enrico},
  year = {2020},
  journal = {Remote Sensing},
  volume = {12},
  number = {21},
  pages = {3542}
}

@article{orusaGoogleEarthEngine2023,
  title = {A {{Google Earth Engine Algorithm}} to {{Map Phenological Metrics}} in {{Mountain Areas Worldwide}} with {{Landsat Collection}} and {{Sentinel-2}}},
  author = {Orusa, Tommaso and Viani, Annalisa and Cammareri, Duke and Borgogno Mondino, Enrico},
  year = {2023},
  journal = {Geomatics},
  volume = {3},
  number = {1},
  pages = {221--238}
}

@inproceedings{orusaLandsat8Thermal2019,
  title = {Landsat 8 Thermal Data to Support Urban Management and Planning in the Climate Change Era: {{A}} Case Study in {{Torino}} Area, {{NW Italy}}},
  booktitle = {Remote {{Sensing Technologies}} and {{Applications}} in {{Urban Environments IV}}},
  author = {Orusa, {\relax TOMMASO} and Mondino, E Borgogno},
  year = {2019},
  volume = {11157},
  pages = {133--149},
  publisher = {SPIE}
}

@article{orusaPossibleLandCover2022,
  title = {A {{Possible Land Cover EAGLE Approach}} to {{Overcome Remote Sensing Limitations}} in the {{Alps Based}} on {{Sentinel-1}} and {{Sentinel-2}}: {{The Case}} of {{Aosta Valley}} ({{NW Italy}})},
  author = {Orusa, Tommaso and Cammareri, Duke and Borgogno Mondino, Enrico},
  year = {2022},
  journal = {Remote Sensing},
  volume = {15},
  number = {1},
  pages = {178}
}

@article{orusaRiskAssessmentRising2023,
  title = {Risk {{Assessment}} of {{Rising Temperatures Using Landsat}} 4--9 {{LST Time Series}} and {{Meta}}{\textregistered} {{Population Dataset}}: {{An Application}} in {{Aosta Valley}}, {{NW Italy}}},
  author = {Orusa, Tommaso and Viani, Annalisa and Moyo, Boineelo and Cammareri, Duke and {Borgogno-Mondino}, Enrico},
  year = {2023},
  journal = {Remote Sensing},
  volume = {15},
  number = {9},
  pages = {2348},
  publisher = {Multidisciplinary Digital Publishing Institute}
}

@article{orusaRiskAssessmentRising2023a,
  title = {Risk {{Assessment}} of {{Rising Temperatures Using Landsat}} 4--9 {{LST Time Series}} and {{Meta}}{\textregistered} {{Population Dataset}}: {{An Application}} in {{Aosta Valley}}, {{NW Italy}}},
  author = {Orusa, Tommaso and Viani, Annalisa and Moyo, Boineelo and Cammareri, Duke and {Borgogno-Mondino}, Enrico},
  year = {2023},
  journal = {Remote Sensing},
  volume = {15},
  number = {9},
  pages = {2348},
  publisher = {Multidisciplinary Digital Publishing Institute}
}

@article{orusaRiskAssessmentRising2023b,
  title = {Risk {{Assessment}} of {{Rising Temperatures Using Landsat}} 4--9 {{LST Time Series}} and {{Meta}}{\textregistered} {{Population Dataset}}: {{An Application}} in {{Aosta Valley}}, {{NW Italy}}},
  author = {Orusa, Tommaso and Viani, Annalisa and Moyo, Boineelo and Cammareri, Duke and {Borgogno-Mondino}, Enrico},
  year = {2023},
  journal = {Remote Sensing},
  volume = {15},
  number = {9},
  pages = {2348},
  publisher = {Multidisciplinary Digital Publishing Institute}
}

@article{orusaRiskAssessmentRising2023c,
  title = {Risk {{Assessment}} of {{Rising Temperatures Using Landsat}} 4--9 {{LST Time Series}} and {{Meta}}{\textregistered} {{Population Dataset}}: {{An Application}} in {{Aosta Valley}}, {{NW Italy}}},
  author = {Orusa, Tommaso and Viani, Annalisa and Moyo, Boineelo and Cammareri, Duke and {Borgogno-Mondino}, Enrico},
  year = {2023},
  journal = {Remote Sensing},
  volume = {15},
  number = {9},
  pages = {2348},
  publisher = {Multidisciplinary Digital Publishing Institute}
}

@article{orusaScalableEarthObservation2022,
  title = {A {{Scalable Earth Observation Service}} to {{Map Land Cover}} in {{Geomorphological Complex Areas}} beyond the {{Dynamic World}}: {{An Application}} in {{Aosta Valley}} ({{NW Italy}})},
  author = {Orusa, Tommaso and Cammareri, Duke and Borgogno Mondino, Enrico},
  year = {2022},
  journal = {Applied Sciences},
  volume = {13},
  number = {1},
  pages = {390}
}

@article{oteroAnatomySIFTMethod2014,
  title = {Anatomy of the {{SIFT Method}}},
  author = {Otero, Ives Rey and Delbracio, Mauricio},
  year = {2014},
  month = dec,
  journal = {Image Processing On Line},
  volume = {4},
  pages = {370--396},
  issn = {2105-1232},
  doi = {10.5201/ipol.2014.82},
  urldate = {2022-11-24},
  abstract = {This article presents a detailed description and implementation of the Scale Invariant Feature Transform (SIFT), a popular image matching algorithm. This work contributes to a detailed dissection of SIFT's complex chain of transformations and to a careful presentation of each of its design parameters. A companion online demonstration allows the reader to use SIFT and individually set each parameter to analyze its impact on the algorithm results.},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/2ATQY5YG/82.html}
}

@article{otsuThresholdSelectionMethod1979,
  title = {A {{Threshold Selection Method}} from {{Gray-Level Histograms}}},
  author = {Otsu, Nobuyuki},
  year = {1979},
  month = jan,
  journal = {IEEE Transactions on Systems, Man, and Cybernetics},
  volume = {9},
  number = {1},
  pages = {62--66},
  issn = {0018-9472, 2168-2909},
  doi = {10.1109/TSMC.1979.4310076},
  urldate = {2023-12-21}
}

@article{owenEvaluationApplicationTimings2013,
  title = {{Evaluation of Application Timings of Warrant Herbicide for Soybean Phytotoxicity}},
  author = {Owen, Michael D. and Franzenburg, Damian D. and Grossnickle, Dean M. and Lux, James F.},
  year = {2013},
  month = jan,
  journal = {Iowa State University Research and Demonstration Farms Progress Reports},
  volume = {2012},
  number = {1},
  publisher = {Iowa State University Digital Press},
  urldate = {2023-12-17},
  abstract = {{$<$}p{$>$}Warrant herbicide is an encapsulated formulation of acetochlor herbicide and labeled for postemergence use in soybean. This study was designed to evaluate crop safety from various Warrant treatments and application timings including early preplant, preemergence, and postemergence. Early preplant and preemergence applications of Warrant are currently not labeled for use in soybean.{$<$}/p{$>$}},
  langid = {None}
}

@inproceedings{panichevUnetBasedConvolutional2019,
  title = {U-Net Based Convolutional Neural Network for Skeleton Extraction},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition Workshops}}},
  author = {Panichev, Oleg and Voloshyna, Alona},
  year = {2019},
  pages = {0--0},
  urldate = {2024-06-10}
}

@inproceedings{pape3DHistogramBasedSegmentation2015,
  title = {3-{{D Histogram-Based Segmentation}} and {{Leaf Detection}} for {{Rosette Plants}}},
  booktitle = {Computer {{Vision}} - {{ECCV}} 2014 {{Workshops}}},
  author = {Pape, Jean-Michel and Klukas, Christian},
  editor = {Agapito, Lourdes and Bronstein, Michael M. and Rother, Carsten},
  year = {2015},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {61--74},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-16220-1_5},
  abstract = {Recognition and segmentation of plant organs like leaves is one of the major challenges in digital plant phenotyping. Here we present a 3-D histogram-based segmentation and recognition approach for top view images of rosette plants such as Arabidopsis thaliana and tobacco. Furthermore a euclidean-distance-map-based method for the detection of leaves and the corresponding plant leaf segmentation method were developed. An approach for the detection of optimal leaf split points for the separation of overlapping leaf segments was created. We tested and tuned our algorithms for the Leaf Segmentation Challenge (LSC). The results demonstrate that our method is robust and handles demanding imaging situations and different species with high accuracy.},
  isbn = {978-3-319-16220-1},
  langid = {english},
  keywords = {3-D Histogram thresholding,Euclidean distance map,Graph analysis,Leaf counting,Leaf segmentation}
}

@article{paulusMeasuringCrops3D2019,
  title = {Measuring Crops in {{3D}}: Using Geometry for Plant Phenotyping},
  shorttitle = {Measuring Crops in {{3D}}},
  author = {Paulus, Stefan},
  year = {2019},
  month = dec,
  journal = {Plant Methods},
  volume = {15},
  number = {1},
  pages = {103},
  issn = {1746-4811},
  doi = {10.1186/s13007-019-0490-0},
  urldate = {2021-12-18},
  langid = {english}
}

@article{pengRobustCPDAlgorithm2016,
  title = {Robust {{CPD Algorithm}} for {{Non-Rigid Point Set Registration Based}} on {{Structure Information}}},
  author = {Peng, Lei and Li, Guangyao and Xiao, Mang and Xie, Li},
  editor = {Yap, Pew-Thian},
  year = {2016},
  month = feb,
  journal = {PLOS ONE},
  volume = {11},
  number = {2},
  pages = {e0148483},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0148483},
  urldate = {2021-12-19},
  langid = {english}
}

@article{perez-harguindeguyNewHandbookStandardised2013,
  title = {New Handbook for Standardised Measurement of Plant Functional Traits Worldwide},
  author = {{P{\'e}rez-Harguindeguy}, N. and D{\'i}az, S. and Garnier, E. and Lavorel, S. and Poorter, H. and Jaureguiberry, P. and {Bret-Harte}, M. S. and Cornwell, W. K. and Craine, J. M. and Gurvich, D. E. and Urcelay, C. and Veneklaas, E. J. and Reich, P. B. and Poorter, L. and Wright, I. J. and Ray, P. and Enrico, L. and Pausas, J. G. and de Vos, A. C. and Buchmann, N. and Funes, G. and Qu{\'e}tier, F. and Hodgson, J. G. and Thompson, K. and Morgan, H. D. and ter Steege, H. and van der Heijden, M. G. A. and Sack, L. and Blonder, B. and Poschlod, P. and Vaieretti, M. V. and Conti, G. and Staver, A. C. and Aquino, S. and Cornelissen, J. H. C. and {P{\'e}rez-Harguindeguy}, N. and D{\'i}az, S. and Garnier, E. and Lavorel, S. and Poorter, H. and Jaureguiberry, P. and {Bret-Harte}, M. S. and Cornwell, W. K. and Craine, J. M. and Gurvich, D. E. and Urcelay, C. and Veneklaas, E. J. and Reich, P. B. and Poorter, L. and Wright, I. J. and Ray, P. and Enrico, L. and Pausas, J. G. and de Vos, A. C. and Buchmann, N. and Funes, G. and Qu{\'e}tier, F. and Hodgson, J. G. and Thompson, K. and Morgan, H. D. and ter Steege, H. and van der Heijden, M. G. A. and Sack, L. and Blonder, B. and Poschlod, P. and Vaieretti, M. V. and Conti, G. and Staver, A. C. and Aquino, S. and Cornelissen, J. H. C.},
  year = {2013},
  month = apr,
  journal = {Australian Journal of Botany},
  volume = {61},
  number = {3},
  pages = {167--234},
  issn = {1444-9862, 1444-9862},
  doi = {10.1071/BT12225},
  urldate = {2022-01-28},
  abstract = {Plant functional traits are the features (morphological, physiological, phenological) that represent ecological strategies and determine how plants respond to environmental factors, affect other trophic levels and influence ecosystem properties. Variation in plant functional traits, and trait syndromes, has proven useful for tackling many important ecological questions at a range of scales, giving rise to a demand for standardised ways to measure ecologically meaningful plant traits. This line of research has been among the most fruitful avenues for understanding ecological and evolutionary patterns and processes. It also has the potential both to build a predictive set of local, regional and global relationships between plants and environment and to quantify a wide range of natural and human-driven processes, including changes in biodiversity, the impacts of species invasions, alterations in biogeochemical processes and vegetation--atmosphere interactions. The importance of these topics dictates the urgent need for more and better data, and increases the value of standardised protocols for quantifying trait variation of different species, in particular for traits with power to predict plant- and ecosystem-level processes, and for traits that can be measured relatively easily. Updated and expanded from the widely used previous version, this handbook retains the focus on clearly presented, widely applicable, step-by-step recipes, with a minimum of text on theory, and not only includes updated methods for the traits previously covered, but also introduces many new protocols for further traits. This new handbook has a better balance between whole-plant traits, leaf traits, root and stem traits and regenerative traits, and puts particular emphasis on traits important for predicting species' effects on key ecosystem properties. We hope this new handbook becomes a standard companion in local and global efforts to learn about the responses and impacts of different plant species with respect to environmental changes in the present, past and future.},
  langid = {english}
}

@article{pertuzAnalysisFocusMeasure2013,
  title = {Analysis of Focus Measure Operators for Shape-from-Focus},
  author = {Pertuz, Said and Puig, Domenec and Garcia, Miguel Angel},
  year = {2013},
  journal = {Pattern Recognition},
  volume = {46},
  number = {5},
  pages = {1415--1432},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2012.11.011},
  abstract = {Shape-from-focus (SFF) has widely been studied in computer vision as a passive depth recovery and 3D reconstruction method. One of the main stages in SFF is the computation of the focus level for every pixel of an image by means of a focus measure operator. In this work, a methodology to compare the performance of different focus measure operators for shape-from-focus is presented and applied. The selected operators have been chosen from an extensive review of the state-of-the-art. The performance of the different operators has been assessed through experiments carried out under different conditions, such as image noise level, contrast, saturation and window size. Such performance is discussed in terms of the working principles of the analyzed operators.},
  keywords = {Autofocus,Defocus model,Focus measure,Shape from focus}
}

@article{petterInternationalStandardsDiagnosis2008,
  title = {International Standards for the Diagnosis of Regulated Pests},
  author = {Petter, Fran{\c c}oise and Roy, Anne Sophie and Smith, Ian},
  year = {2008},
  month = jul,
  journal = {European Journal of Plant Pathology},
  volume = {121},
  number = {3},
  pages = {331--337},
  issn = {1573-8469},
  doi = {10.1007/s10658-007-9248-z},
  abstract = {For the last 10~years, the European and Mediterranean Plant Protection Organization (EPPO) has run a European Panel on diagnostics, which has developed regional standards on diagnostic protocols. Nearly 80 such standards have now been approved, and are in active use in EPPO countries. In 2003, the Commission for Phytosanitary Measures (CPM) of FAO, in reviewing global needs for International Standards for Phytosanitary Measures (ISPMs), recognized that there is a strong interest in developing diagnostic protocols for all contracting parties to the International Plant Protection Convention (IPPC). Such protocols would support the harmonization of detection and identification procedures worldwide, contribute to greater transparency and comparability in the diagnostics for regulated pests, and assist in the resolution of disputes between trading partners. In addition, such protocols would be very useful in technical assistance programmes. In 2004, the CPM adopted a mechanism for rapid development of ISPMs in specific areas, particularly suitable for diagnostic protocols. A Technical Panel was accordingly established to develop protocols for specific pests and meets on an annual basis. A format for international diagnostic protocols was adopted in 2006 and a list of priority pests was established. In 2003, EPPO initiated a new programme on quality management and accreditation for plant pest laboratories and Standards are now also being developed in this area. In 2006, a survey of existing diagnostic capacities in EPPO member countries was undertaken and a database on diagnostic expertise was created.}
}

@article{PictureThresholdingUsing1978,
  title = {Picture {{Thresholding Using}} an {{Iterative Selection Method}}},
  year = {1978},
  month = aug,
  journal = {IEEE Transactions on Systems, Man, and Cybernetics},
  volume = {8},
  number = {8},
  pages = {630--632},
  issn = {2168-2909},
  doi = {10.1109/TSMC.1978.4310039},
  keywords = {Aircraft,Brightness,Histograms,Image analysis,Image converters,Image segmentation,Iterative methods,Layout,Physics computing,Sampling methods},
  file = {/home/samuelebumbaca/Zotero/storage/NF5EVJWU/stamp.html}
}

@article{pingRetrievalModelSubtle2010,
  title = {{[Retrieval model for subtle variation of contamination stressed maize chlorophyll using hyperspectral data]}},
  author = {Ping, Wang and Liu, Xiang-nanz and Huang, Fang},
  year = {2010},
  month = jan,
  journal = {Guang Pu Xue Yu Guang Pu Fen Xi = Guang Pu},
  volume = {30},
  number = {1},
  pages = {197--201},
  issn = {1000-0593},
  abstract = {Chlorophyll content is an important indicator of photosynthesis activity, stress and nutritional state. In the present paper, the hyperspectral data, foliar chlorophyll content and heavy metal contents in foliar and soil were measured for the maize growing in three natural fields. In most previous research, the contamination stress was controlled artificially in laboratory by adding chromium, zinc or copper pollutant etc. to the soil, and the pollutant concentration added was much higher than that in natural environment. The three sample fields were under different heavy mental contamination level, but all located at the Changchun region, Northeast China, where is called Golden Maize Belts in the world. After continuum removal (400-800 nm), ten spectral indices were computed including max absorption position, normalized reflectance at max absorption position, absorption depth, green peak, normalized reflectance at green peak, red edge, normalized reflectance at red edge, red peak, absorption width, and asymmetry degree. The physics meaning of the above indices and their correlation with maize foliar chlorophyll content were analyzed. It was found that there were close relationships between these indices and foliar chlorophyll content except max absorption position, green edge and asymmetry degree. Besides the asymmetry degree, five indices were selected in the stepwise multiple linear regression for estimating chlorophyll content and its determination coefficient (R2) is 0.7027. Furthermore, in order to measure the weak change information of foliar chlorophyll content under the contamination stress, the BP artificial neural network (ANN-BP) was used. Several ANN-BP models were built and tried with different structure, namely five nodes, seven nodes or ten nodes in input layer, one hidden layer or two hidden layer, and different nodes number in hidden layers. It was found that the highest accuracy of estimates was obtained by the model with two hidden layers, ten nodes in input layer, seven nodes in first hidden layer and 4 nodes in second hidden layer (R2 = 0.9758).},
  langid = {chi},
  pmid = {20302113},
  keywords = {Chlorophyll,Models Theoretical,Neural Networks Computer,Plant Leaves,Spectrum Analysis,Zea mays}
}

@article{pinterRemoteSensingCrop2003,
  title = {Remote {{Sensing}} for {{Crop Management}}},
  author = {Pinter, Paul J., {\relax Jr}. and Hatfield, Jerry L. and Schepers, James S. and Barnes, Edward M. and Moran, M. Susan and Daughtry, Craig S.T. and Upchurch, Dan R.},
  year = {2003},
  month = jun,
  journal = {Photogrammetric Engineering \& Remote Sensing},
  volume = {69},
  number = {6},
  pages = {647--664},
  doi = {10.14358/PERS.69.6.647},
  abstract = {Scientists with the Agricultural Research Service (ARS) and various government agencies and private institutions have provided a great deal of fundamental information relating spectral reflectance and thermal emittance properties of soils and crops to their agronomic and biophysical characteristics. This knowledge has facilitated the development and use of various remote sensing methods for non-destructive monitoring of plant growth and development and for the detection of many environmental stresses which limit plant productivity. Coupled with rapid advances in computing and positionlocating technologies, remote sensing from ground-, air-, and space-based platforms is now capable of providing detailed spatial and temporal information on plant response to their local environment that is needed for site specific agricultural management approaches. This manuscript, which emphasizes contributions by ARS researchers, reviews the biophysical basis of remote sensing; examines approaches that have been developed, refined, and tested for management of water, nutrients, and pests in agricultural crops; and assesses the role of remote sensing in yield prediction. It concludes with a discussion of challenges facing remote sensing in the future.}
}

@misc{PlantDetectionCounting,
  title = {Plant Detection and Counting from High-Resolution {{RGB}} Images Acquired from {{UAVs}}: Comparison between Deep-Learning and Handcrafted Methods with Application to Maize, Sugar Beet, and Sunflower Crops {\textbar} {{bioRxiv}}},
  urldate = {2022-09-25},
  howpublished = {https://www.biorxiv.org/content/10.1101/2021.04.27.441631v1.abstract},
  file = {/home/samuelebumbaca/Zotero/storage/FV55SUWS/2021.04.27.441631v1.html}
}

@misc{PlantDiseaseDetection,
  title = {Plant {{Disease Detection}} by {{Imaging Sensors}} -- {{Parallels}} and {{Specific Demands}} for {{Precision Agriculture}} and {{Plant Phenotyping}} {\textbar} {{Plant Disease}}},
  urldate = {2023-01-13},
  howpublished = {https://apsjournals.apsnet.org/doi/full/10.1094/PDIS-03-15-0340-FE}
}

@article{polakEvaluationMetricImage2009,
  title = {An Evaluation Metric for Image Segmentation of Multiple Objects},
  author = {Polak, Mark and Zhang, Hong and Pi, Minghong},
  year = {2009},
  month = jul,
  journal = {Image and Vision Computing},
  volume = {27},
  number = {8},
  pages = {1223--1227},
  issn = {0262-8856},
  doi = {10.1016/j.imavis.2008.09.008},
  urldate = {2023-01-13},
  abstract = {It is important to be able to evaluate the performance of image segmentation algorithms objectively. In this paper, we define a new error measure which quantifies the performance of an image segmentation algorithm for identifying multiple objects in an image. This error measure is based on object-by-object comparisons of a segmented image and a ground-truth (reference) image. It takes into account the size, shape, and position of each object. Compared to existing error measures, our proposed error measure works at the object level, and is sensitive to both over-segmentation and under-segmentation. Hence, it can serve as a useful tool for comparing image segmentation algorithms and for tuning the parameters of a segmentation algorithm.},
  langid = {english},
  keywords = {Error measure,Evaluation,Image segmentation},
  file = {/home/samuelebumbaca/Zotero/storage/9DJAFTPH/S0262885608001984.html}
}

@article{poorterArtGrowingPlants2012,
  title = {The Art of Growing Plants for Experimental Purposes: A Practical Guide for the Plant Biologist},
  shorttitle = {The Art of Growing Plants for Experimental Purposes},
  author = {Poorter, Hendrik and Fiorani, Fabio and Stitt, Mark and Schurr, Uli and Finck, Alex and Gibon, Yves and Usadel, Bj{\"o}rn and Munns, Rana and Atkin, Owen K. and Tardieu, Fran{\c c}ois and Pons, Thijs L. and Poorter, Hendrik and Fiorani, Fabio and Stitt, Mark and Schurr, Uli and Finck, Alex and Gibon, Yves and Usadel, Bj{\"o}rn and Munns, Rana and Atkin, Owen K. and Tardieu, Fran{\c c}ois and Pons, Thijs L.},
  year = {2012},
  month = jun,
  journal = {Functional Plant Biology},
  volume = {39},
  number = {11},
  pages = {821--838},
  issn = {1445-4416, 1445-4416},
  doi = {10.1071/FP12028},
  urldate = {2022-01-28},
  abstract = {Every year thousands of experiments are conducted using plants grown under more-or-less controlled environmental conditions. The aim of many such experiments is to compare the phenotype of different species or genotypes in a specific environment, or to study plant performance under a range of suboptimal conditions. Our paper aims to bring together the minimum knowledge necessary for a plant biologist to set up such experiments and apply the environmental conditions that are appropriate to answer the questions of interest. We first focus on the basic choices that have to be made with regard to the experimental setup (e.g. where are the plants grown; what rooting medium; what pot size). Second, we present practical considerations concerning the number of plants that have to be analysed considering the variability in plant material and the required precision. Third, we discuss eight of the most important environmental factors for plant growth (light quantity, light quality, CO2, nutrients, air humidity, water, temperature and salinity); what critical issues should be taken into account to ensure proper growth conditions in controlled environments and which specific aspects need attention if plants are challenged with a certain a-biotic stress factor. Finally, we propose a simple checklist that could be used for tracking and reporting experimental conditions.},
  langid = {english}
}

@article{poorterPotSizeMatters2012,
  title = {Pot Size Matters: A Meta-Analysis of the Effects of Rooting Volume on Plant Growth},
  shorttitle = {Pot Size Matters},
  author = {Poorter, Hendrik and B{\"u}hler, Jonas and van Dusschoten, Dagmar and Climent, Jos{\'e} and Postma, Johannes A. and Poorter, Hendrik and B{\"u}hler, Jonas and van Dusschoten, Dagmar and Climent, Jos{\'e} and Postma, Johannes A.},
  year = {2012},
  month = jun,
  journal = {Functional Plant Biology},
  volume = {39},
  number = {11},
  pages = {839--850},
  issn = {1445-4416, 1445-4416},
  doi = {10.1071/FP12049},
  urldate = {2022-01-28},
  abstract = {The majority of experiments in plant biology use plants grown in some kind of container or pot. We conducted a meta-analysis on 65 studies that analysed the effect of pot size on growth and underlying variables. On average, a doubling of the pot size increased biomass production by 43\%. Further analysis of pot size effects on the underlying components of growth suggests that reduced growth in smaller pots is caused mainly by a reduction in photosynthesis per unit leaf area, rather than by changes in leaf morphology or biomass allocation. The appropriate pot size will logically depend on the size of the plants growing in them. Based on various lines of evidence we suggest that an appropriate pot size is one in which the plant biomass does not exceed 1 g L--1. In current research practice {\textasciitilde}65\% of the experiments exceed that threshold. We suggest that researchers need to carefully consider the pot size in their experiments, as small pots may change experimental results and defy the purpose of the experiment.},
  langid = {english}
}

@article{PP11352014,
  title = {{{PP}} 1/135 (4) {{Phytotoxicity}} Assessment},
  year = {2014},
  month = dec,
  journal = {EPPO Bulletin},
  volume = {44},
  number = {3},
  pages = {265--273},
  issn = {02508052},
  doi = {10.1111/epp.12134},
  urldate = {2022-09-06},
  langid = {english}
}

@misc{PP11354Phytotoxicity,
  title = {{{PP1}}/135(4) - {{Phytotoxicity}} Assessment},
  annotation = {https://pp1.eppo.int/standards/PP1-135-4}
}

@article{PP11812022,
  title = {{{PP}} 1/181 (5) {{Conduct}} and Reporting of Efficacy Evaluation Trials, Including Good Experimental Practice},
  year = {2022},
  journal = {EPPO Bulletin},
  volume = {52},
  number = {1},
  pages = {4--16},
  issn = {1365-2338},
  doi = {10.1111/epp.12788},
  urldate = {2022-09-06},
  abstract = {Specific scope This Standard, intended for use in association with EPPO Standards PP 1 Efficacy evaluation of plant protection products, describes the conduct and reporting of efficacy evaluation trials. Specific approval and amendment First approved in 1992--09. First revision approved in 1996--09. Second revision approved in 2003--09. Revision mainly to reflect zonal assessment approved in 2012--09. Revision to reflect parameters for greenhouse and other protective structures in 2021--09.},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/NGFSYVDQ/epp.html}
}

@misc{PP11815Conduct,
  title = {{{PP1}}/181(5) - {{Conduct}} and Reporting of Efficacy Evaluation Trials, Including Good Experimental Practice},
  annotation = {https://pp1.eppo.int/standards/PP1-181-5}
}

@article{PP13192021,
  title = {{{PP}} 1/319 (1) {{General}} Principles for Efficacy Evaluation of Plant Protection Products with a Mode of Action as Plant Defence Inducers},
  year = {2021},
  month = apr,
  journal = {EPPO Bulletin},
  volume = {51},
  number = {1},
  pages = {5--9},
  issn = {0250-8052, 1365-2338},
  doi = {10.1111/epp.12692},
  urldate = {2022-09-06},
  langid = {english}
}

@misc{PrecisionAgricultureFood,
  title = {Precision {{Agriculture}} and {{Food Security}} {\textbar} {{Science}}},
  urldate = {2023-01-13},
  howpublished = {https://www.science.org/doi/abs/10.1126/science.1183899}
}

@misc{PRELIMINARYCONCERNSAGRONOMIC,
  title = {{PRELIMINARY CONCERNS ABOUT AGRONOMIC INTERPRETATION OF NDVI TIME SERIES FROM SENTINEL-2 DATA: PHENOLOGY AND THERMAL EFFICIENCY OF WINTER WHEAT IN PIEMONTE (NW ITALY) - ProQuest}},
  shorttitle = {{PRELIMINARY CONCERNS ABOUT AGRONOMIC INTERPRETATION OF NDVI TIME SERIES FROM SENTINEL-2 DATA}},
  urldate = {2023-03-24},
  abstract = {Explore millions of resources from scholarly journals, books, newspapers, videos and more, on the ProQuest Platform.},
  howpublished = {https://www.proquest.com/openview/38e36faf03bb6acef6bc3a5a6d3cfc0f/1?pq-origsite=gscholar\&cbl=2037674},
  langid = {italian},
  file = {/home/samuelebumbaca/Zotero/storage/7NB4A86U/1.html}
}

@article{prenticeGeneralizationProbitLogit1976,
  title = {A {{Generalization}} of the {{Probit}} and {{Logit Methods}} for {{Dose Response Curves}}},
  author = {Prentice, Ross L.},
  year = {1976},
  journal = {Biometrics},
  volume = {32},
  number = {4},
  eprint = {2529262},
  eprinttype = {jstor},
  pages = {761--768},
  publisher = {[Wiley, International Biometric Society]},
  issn = {0006-341X},
  doi = {10.2307/2529262},
  urldate = {2023-03-24},
  abstract = {The relationship between response probability and dosage in quantal response bioassay is modelled using a four parameter class. In addition to location and scale quantities the model includes two shape parameters that essentially index skewness and heaviness of tails of the dose-response curve. The class of models includes such special cases as the logistic, normal, extreme minimum value, extreme maximum value, double exponential, exponential and reflected exponential distribution functions. Score tests are derived for logistic and normal hypotheses and certain submodels are discussed for which the model fitting is computationally convenient. The data of Bliss [1935] illustrates the potential improvement over usual methods in the estimation of critical dose levels.}
}

@article{qianDevelopmentApplicationCrop2014,
  title = {Development and Application of Crop Monitoring System for Detecting Chlorophyll Content of Tomato Seedlings},
  author = {Qian, Wu and Hong, Sun and Minzan, Li and Wei, Yang},
  year = {2014},
  journal = {International Journal of Agricultural and Biological Engineering},
  volume = {7},
  number = {2},
  pages = {138--145},
  issn = {1934-6352},
  doi = {10.25165/ijabe.v7i2.1220},
  urldate = {2023-02-23},
  abstract = {A crop monitoring system was developed to nondestructively monitor the crop growth status in the field.  With a two channel multispectral camera with one lens, controlling platform, wireless remote control module and control software, the system was able to synchronously acquire visible image (red(R), green(G), blue(B): 400-700 nm) and near-infrared (NIR) image (760-1 000 nm).  The tomato seedlings multi-spectral images collection experiment in the greenhouse was conducted by using the developed system from the seeding stage to fruiting stage.  More than 240 couples of tomato seedlings pictures were acquired with the Soil and Plant Analyzer Development (SPAD) value measured at the same time.  The obtained images were available to process, and some vegetation indexes, such as normalized difference vegetation index (NDVI), ratio vegetation index (RVI) and normalized difference green index (NDGI), were calculated.  Considering the SPAD value and the correlation coefficient between SPAD and other parameters in different fertilization treatments, the multiple linear regressions (MLR) model for tomato seedlings chlorophyll content predication was built based on the average gray value in red, green, blue and NIR, vegetable indexes, NDVI, RVI and NDGI in the 33.3\% (N1), 66.6\% (N2), and 100\% (N3) nutrient levels during seeding stage and blossom and fruit stage.  The R2 of the model is 0.88.  The results revealed that the developed crop monitoring system provided a feasible tool to detect the growth status of tomato.  More filed experiments and multi-spectral image analysis will be investigated to evaluate the crop growth status in the near future. Keywords: multi-spectral image, crop growth status, image acquisition, 2-CCD sensor, precision agriculture DOI: 10.3965/j.ijabe.20140702.017 Citation: Wu Q, Sun H, Li M Z, Yang W.  Development and application of crop monitoring system for detecting chlorophyll content of tomato seedlings.  Int J Agric \& Biol Eng, 2014; 7(2): 138－145.},
  copyright = {Copyright (c)},
  langid = {english},
  keywords = {2-CCD sensor,crop growth status,image acquisition,multi-spectral image,precision agriculture}
}

@inproceedings{quanImagebasedPlantModeling2006,
  title = {Image-Based Plant Modeling},
  booktitle = {{{ACM SIGGRAPH}} 2006 {{Papers}}},
  author = {Quan, Long and Tan, Ping and Zeng, Gang and Yuan, Lu and Wang, Jingdong and Kang, Sing Bing},
  year = {2006},
  month = jul,
  series = {{{SIGGRAPH}} '06},
  pages = {599--604},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1179352.1141929},
  urldate = {2023-01-13},
  abstract = {In this paper, we propose a semi-automatic technique for modeling plants directly from images. Our image-based approach has the distinct advantage that the resulting model inherits the realistic shape and complexity of a real plant. We designed our modeling system to be interactive, automating the process of shape recovery while relying on the user to provide simple hints on segmentation. Segmentation is performed in both image and 3D spaces, allowing the user to easily visualize its effect immediately. Using the segmented image and 3D data, the geometry of each leaf is then automatically recovered from the multiple views by fitting a deformable leaf model. Our system also allows the user to easily reconstruct branches in a similar manner. We show realistic reconstructions of a variety of plants, and demonstrate examples of plant editing.},
  isbn = {978-1-59593-364-5},
  keywords = {image-based modeling,photography,plant modeling,tree modeling}
}

@article{raoSemanticPointCloud2021,
  title = {Semantic {{Point Cloud Segmentation Using Fast Deep Neural Network}} and {{DCRF}}},
  author = {Rao, Yunbo and Zhang, Menghan and Cheng, Zhanglin and Xue, Junmin and Pu, Jiansu and Wang, Zairong},
  year = {2021},
  month = apr,
  journal = {Sensors},
  volume = {21},
  number = {8},
  pages = {2731},
  issn = {1424-8220},
  doi = {10.3390/s21082731},
  urldate = {2021-12-18},
  abstract = {Accurate segmentation of entity categories is the critical step for 3D scene understanding. This paper presents a fast deep neural network model with Dense Conditional Random Field (DCRF) as a post-processing method, which can perform accurate semantic segmentation for 3D point cloud scene. On this basis, a compact but flexible framework is introduced for performing segmentation to the semantics of point clouds concurrently, contribute to more precise segmentation. Moreover, based on semantics labels, a novel DCRF model is elaborated to refine the result of segmentation. Besides, without any sacrifice to accuracy, we apply optimization to the original data of the point cloud, allowing the network to handle fewer data. In the experiment, our proposed method is conducted comprehensively through four evaluation indicators, proving the superiority of our method.},
  langid = {english}
}

@book{rcoreteamLanguageEnvironmentStatistical2017,
  title = {R: {{A Language}} and {{Environment}} for {{Statistical Computing}}},
  author = {{R Core Team}},
  year = {2017},
  publisher = {R Foundation for Statistical Computing},
  address = {Vienna, Austria}
}

@article{RegulationECNo,
  title = {Regulation ({{EC}}) {{No}}~1107/2009 of the {{European Parliament}} and of the {{Council}} of 21~{{October}} 2009 Concerning the Placing of Plant Protection Products on the Market and Repealing {{Council Directives}} 79/117/{{EEC}} and 91/414/{{EEC}}},
  pages = {50},
  langid = {english}
}

@article{renDeepClusteringComprehensive2024,
  title = {Deep {{Clustering}}: {{A Comprehensive Survey}}},
  shorttitle = {Deep {{Clustering}}},
  author = {Ren, Yazhou and Pu, Jingyu and Yang, Zhimeng and Xu, Jie and Li, Guofeng and Pu, Xiaorong and Yu, Philip S. and He, Lifang},
  year = {2024},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  pages = {1--21},
  issn = {2162-2388},
  doi = {10.1109/TNNLS.2024.3403155},
  urldate = {2025-01-13},
  abstract = {Cluster analysis plays an indispensable role in machine learning and data mining. Learning a good data representation is crucial for clustering algorithms. Recently, deep clustering (DC), which can learn clustering-friendly representations using deep neural networks (DNNs), has been broadly applied in a wide range of clustering tasks. Existing surveys for DC mainly focus on the single-view fields and the network architectures, ignoring the complex application scenarios of clustering. To address this issue, in this article, we provide a comprehensive survey for DC in views of data sources. With different data sources, we systematically distinguish the clustering methods in terms of methodology, prior knowledge, and architecture. Concretely, DC methods are introduced according to four categories, i.e., traditional single-view DC, semi-supervised DC, deep multiview clustering (MVC), and deep transfer clustering. Finally, we discuss the open challenges and potential future opportunities in different fields of DC.},
  keywords = {Clustering methods,Deep clustering (DC),Feature extraction,multiview clustering (MVC),Probability distribution,Representation learning,semi-supervised clustering,Surveys,Task analysis,transfer learning,Transfer learning},
  file = {/home/samuelebumbaca/Zotero/storage/GQ5D94H6/10585323.html}
}

@inproceedings{riemenschneiderHoughRegionsJoining2012,
  title = {Hough {{Regions}} for {{Joining Instance Localization}} and {{Segmentation}}},
  booktitle = {Computer {{Vision}} -- {{ECCV}} 2012},
  author = {Riemenschneider, Hayko and Sternig, Sabine and Donoser, Michael and Roth, Peter M. and Bischof, Horst},
  editor = {Fitzgibbon, Andrew and Lazebnik, Svetlana and Perona, Pietro and Sato, Yoichi and Schmid, Cordelia},
  year = {2012},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {258--271},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-33712-3_19},
  abstract = {Object detection and segmentation are two challenging tasks in computer vision, which are usually considered as independent steps. In this paper, we propose a framework which jointly optimizes for both tasks and implicitly provides detection hypotheses and corresponding segmentations. Our novel approach is attachable to any of the available generalized Hough voting methods. We introduce Hough Regions by formulating the problem of Hough space analysis as Bayesian labeling of a random field. This exploits provided classifier responses, object center votes and low-level cues like color consistency, which are combined into a global energy term. We further propose a greedy approach to solve this energy minimization problem providing a pixel-wise assignment to background or to a specific category instance. This way we bypass the parameter sensitive non-maximum suppression that is required in related methods. The experimental evaluation demonstrates that state-of-the-art detection and segmentation results are achieved and that our method is inherently able to handle overlapping instances and an increased range of articulations, aspect ratios and scales.},
  isbn = {978-3-642-33712-3},
  langid = {english},
  keywords = {Category Instance,Conditional Random Field,Object Detection,Object Instance,Seed Region}
}

@article{ritzResearchMethodsWeed2015,
  title = {Research {{Methods}} in {{Weed Science}}: {{Statistics}}},
  shorttitle = {Research {{Methods}} in {{Weed Science}}},
  author = {Ritz, Christian and Kniss, Andrew R. and Streibig, Jens C.},
  year = {2015},
  journal = {Weed Science},
  volume = {63},
  eprint = {26906697},
  eprinttype = {jstor},
  pages = {166--187},
  publisher = {[Cambridge University Press, Weed Science Society of America]},
  issn = {0043-1745},
  urldate = {2023-03-24}
}

@article{rongComputerVisionDetection2017,
  title = {Computer Vision Detection of Surface Defect on Oranges by Means of a Sliding Comparison Window Local Segmentation Algorithm},
  author = {Rong, Dian and Rao, Xiuqin and Ying, Yibin},
  year = {2017},
  month = may,
  journal = {Computers and Electronics in Agriculture},
  volume = {137},
  pages = {59--68},
  issn = {0168-1699},
  doi = {10.1016/j.compag.2017.02.027},
  urldate = {2023-09-01},
  abstract = {Automatic detection of defective oranges by computer vision system is not easy because of the uneven lightness distribution on the surface of oranges. It means that the methods onlydirectly using global segmentation provide unsatisfactory results when orange images present faint defect characters or inhomogeneous surface. The contrast between sound and defective regions can be used to produce more accurate segmentation results, which is more capable of detecting pixels lying around the defect boundary on orange surface based on the local segmentation method. In this paper, we study and propose a sliding comparison window local segmentation algorithm and also presents the detailed image processing procedure including removal of background pixels, image binarization using local segmentation, image subtraction, image morphological modification, removal of stem end pixels for detecting surface defect in an orange gray-level image. This method is an original contribution that allows successful segmentation of various types of surface defects (e.g., insect injury, wind scarring, thrips scarring, scale infestation, canker spot, dehiscent fruit, copper burn, phytotoxicity).The image segmentation algorithm was tested with 1191 samples of oranges. The proposed algorithm was able to correctly detect 97\% of the defective orange. Future work will be focused on whole surface and fast on-line inspection.},
  keywords = {Computer vision,Defect detection,Image local segmentation,Orange surface defect},
  file = {/home/samuelebumbaca/Zotero/storage/Y4J547D7/S0168169916305579.html}
}

@article{roseAccuracyAnalysisMultiView2015,
  title = {Accuracy {{Analysis}} of a {{Multi-View Stereo Approach}} for {{Phenotyping}} of {{Tomato Plants}} at the {{Organ Level}}},
  author = {Rose, Johann and Paulus, Stefan and Kuhlmann, Heiner},
  year = {2015},
  month = apr,
  journal = {Sensors},
  volume = {15},
  number = {5},
  pages = {9651--9665},
  issn = {1424-8220},
  doi = {10.3390/s150509651},
  urldate = {2022-10-21},
  langid = {english}
}

@article{rossiPerformancesEvaluationLowCost2020,
  title = {Performances {{Evaluation}} of a {{Low-Cost Platform}} for {{High-Resolution Plant Phenotyping}}},
  author = {Rossi, Riccardo and Leolini, Claudio and {Costafreda-Aumedes}, Sergi and Leolini, Luisa and Bindi, Marco and Zaldei, Alessandro and Moriondo, Marco},
  year = {2020},
  month = jan,
  journal = {Sensors},
  volume = {20},
  number = {11},
  pages = {3150},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1424-8220},
  doi = {10.3390/s20113150},
  urldate = {2025-03-16},
  abstract = {This study aims to test the performances of a low-cost and automatic phenotyping platform, consisting of a Red-Green-Blue (RGB) commercial camera scanning objects on rotating plates and the reconstruction of main plant phenotypic traits via the structure for motion approach (SfM). The precision of this platform was tested in relation to three-dimensional (3D) models generated from images of potted maize, tomato and olive tree, acquired at a different frequency (steps of 4{$^\circ$}, 8{$^\circ$} and 12{$^\circ$}) and quality (4.88, 6.52 and 9.77 {\textmu}m/pixel). Plant and organs heights, angles and areas were extracted from the 3D models generated for each combination of these factors. Coefficient of determination (R2), relative Root Mean Square Error (rRMSE) and Akaike Information Criterion (AIC) were used as goodness-of-fit indexes to compare the simulated to the observed data. The results indicated that while the best performances in reproducing plant traits were obtained using 90 images at 4.88 {\textmu}m/pixel (R2 = 0.81, rRMSE = 9.49\% and AIC = 35.78), this corresponded to an unviable processing time (from 2.46 h to 28.25 h for herbaceous plants and olive trees, respectively). Conversely, 30 images at 4.88 {\textmu}m/pixel resulted in a good compromise between a reliable reconstruction of considered traits (R2 = 0.72, rRMSE = 11.92\% and AIC = 42.59) and processing time (from 0.50 h to 2.05 h for herbaceous plants and olive trees, respectively). In any case, the results pointed out that this input combination may vary based on the trait under analysis, which can be more or less demanding in terms of input images and time according to the complexity of its shape (R2 = 0.83, rRSME = 10.15\% and AIC = 38.78). These findings highlight the reliability of the developed low-cost platform for plant phenotyping, further indicating the best combination of factors to speed up the acquisition and elaboration process, at the same time minimizing the bias between observed and simulated data.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {3D phenotyping,low-cost platform,plant imaging,structure for motion},
  file = {/home/samuelebumbaca/Zotero/storage/U86W27Z4/Rossi et al. - 2020 - Performances Evaluation of a Low-Cost Platform for High-Resolution Plant Phenotyping.pdf}
}

@inproceedings{rotherGrabCutInteractiveForeground2004,
  title = {"{{GrabCut}}": Interactive Foreground Extraction Using Iterated Graph Cuts},
  shorttitle = {"{{GrabCut}}"},
  booktitle = {{{ACM SIGGRAPH}} 2004 {{Papers}}},
  author = {Rother, Carsten and Kolmogorov, Vladimir and Blake, Andrew},
  year = {2004},
  month = aug,
  series = {{{SIGGRAPH}} '04},
  pages = {309--314},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1186562.1015720},
  urldate = {2022-12-12},
  abstract = {The problem of efficient, interactive foreground/background segmentation in still images is of great practical importance in image editing. Classical image segmentation tools use either texture (colour) information, e.g. Magic Wand, or edge (contrast) information, e.g. Intelligent Scissors. Recently, an approach based on optimization by graph-cut has been developed which successfully combines both types of information. In this paper we extend the graph-cut approach in three respects. First, we have developed a more powerful, iterative version of the optimisation. Secondly, the power of the iterative algorithm is used to simplify substantially the user interaction needed for a given quality of result. Thirdly, a robust algorithm for "border matting" has been developed to estimate simultaneously the alpha-matte around an object boundary and the colours of foreground pixels. We show that for moderately difficult examples the proposed method outperforms competitive tools.},
  isbn = {978-1-4503-7823-9},
  keywords = {Alpha Matting,Foreground extraction,Graph Cuts,Image Editing,Interactive Image Segmentation}
}

@article{rouseMONITORINGVEGETATIONSYSTEMS,
  title = {{{MONITORING VEGETATION SYSTEMS IN THE GREAT PLAINS WITH ERTS}}},
  author = {Rouse, W and Haas, R H},
  pages = {9},
  abstract = {The Great Plains Corridor rangeland project being conducted at Texas A\&M University utilizes natural vegetation systems as phenological indicators of seasonal development and climatic effects upon regional growth conditions. A method has been developed for quantitative measurement of vegetation conditions over broad regions using ERTS-1 MSS data. Radiance values recorded in ERTS-1 spectral bands 5 and 7, corrected for sun angle, are used to compute a band ratio parameter which is shown to be correlated with aboveground green biomass on rangelands.},
  langid = {english}
}

@inproceedings{rouseMonitoringVegetationSystems1974,
  title = {Monitoring Vegetation Systems in the {{Great Plains}} with {{ERTS}}},
  author = {Rouse, J. W. and Haas, R. H. and Schell, J. A. and Deering, D. W.},
  year = {1974},
  month = jan,
  urldate = {2024-02-08},
  abstract = {The Great Plains Corridor rangeland project utilizes natural vegetation systems as phenological indicators of seasonal development and climatic effects upon regional growth conditions. A method has been developed for quantitative measurement of vegetation conditions over broad regions using ERTS-1 MSS data. Radiance values recorded in ERTS-1 spectral bands 5 and 7, corrected for sun angle, are used to compute a band ratio parameter which is shown to be correlated with aboveground green biomass on rangelands.},
  keywords = {Geophysics},
  annotation = {NTRS Author Affiliations: Texas A\&M Univ.\\
NTRS Report/Patent Number: PAPER-A20\\
NTRS Document ID: 19740022614\\
NTRS Research Center: Legacy CDMS (CDMS)},
  file = {/home/samuelebumbaca/Zotero/storage/LHM4GRWT/19740022614.html}
}

@article{samueleMappingSARGeometric2021,
  title = {Mapping {{SAR}} Geometric Distortions and Their Stability along Time: A New Tool in {{Google Earth Engine}} Based on {{Sentinel-1}} Image Time Series},
  author = {Samuele, De Petris and Filippo, Sarvia and Orusa, Tommaso and Enrico, Borgogno-Mondino},
  year = {2021},
  journal = {International Journal of Remote Sensing},
  volume = {42},
  number = {23},
  pages = {9135--9154}
}

@article{sanjay-gopalBayesianPixelClassification1998,
  title = {Bayesian Pixel Classification Using Spatially Variant Finite Mixtures and the Generalized {{EM}} Algorithm},
  author = {{Sanjay-Gopal}, S. and Hebert, T.J.},
  year = {1998},
  month = jul,
  journal = {IEEE Transactions on Image Processing},
  volume = {7},
  number = {7},
  pages = {1014--1028},
  issn = {10577149},
  doi = {10.1109/83.701161},
  urldate = {2021-12-19}
}

@article{sankaranReviewAdvancedTechniques2010,
  title = {A Review of Advanced Techniques for Detecting Plant Diseases},
  author = {Sankaran, Sindhuja and Mishra, Ashish and Ehsani, Reza and Davis, Cristina},
  year = {2010},
  month = jun,
  journal = {Computers and Electronics in Agriculture},
  volume = {72},
  number = {1},
  pages = {1--13},
  issn = {0168-1699},
  doi = {10.1016/j.compag.2010.02.007},
  urldate = {2023-01-13},
  abstract = {Diseases in plants cause major production and economic losses in agricultural industry worldwide. Monitoring of health and detection of diseases in plants and trees is critical for sustainable agriculture. To the best of our knowledge, there is no sensor commercially available for real-time assessment of health conditions in trees. Currently, scouting is most widely used mechanism for monitoring stress in trees, which is an expensive, labor-intensive, and time-consuming process. Molecular techniques such as polymerase chain reaction are used for the identification of plant diseases that require detailed sampling and processing procedure. Early information on crop health and disease detection can facilitate the control of diseases through proper management strategies such as vector control through pesticide applications, fungicide applications, and disease-specific chemical applications; and can improve productivity. The present review recognizes the need for developing a rapid, cost-effective, and reliable health-monitoring sensor that would facilitate advancements in agriculture. It describes the currently used technologies that can be used for developing a ground-based sensor system to assist in monitoring health and diseases in plants under field conditions. These technologies include spectroscopic and imaging-based, and volatile profiling-based plant disease detection methods. The paper compares the benefits and limitations of these potential methods.},
  langid = {english},
  keywords = {GC-MS,Imaging techniques,Plant diseases,Spectroscopy,Volatile profiling}
}

@article{sankaranReviewAdvancedTechniques2010a,
  title = {A Review of Advanced Techniques for Detecting Plant Diseases},
  author = {Sankaran, Sindhuja and Mishra, Ashish and Ehsani, Reza and Davis, Cristina},
  year = {2010},
  month = jun,
  journal = {Computers and Electronics in Agriculture},
  volume = {72},
  number = {1},
  pages = {1--13},
  issn = {0168-1699},
  doi = {10.1016/j.compag.2010.02.007},
  urldate = {2023-01-13},
  abstract = {Diseases in plants cause major production and economic losses in agricultural industry worldwide. Monitoring of health and detection of diseases in plants and trees is critical for sustainable agriculture. To the best of our knowledge, there is no sensor commercially available for real-time assessment of health conditions in trees. Currently, scouting is most widely used mechanism for monitoring stress in trees, which is an expensive, labor-intensive, and time-consuming process. Molecular techniques such as polymerase chain reaction are used for the identification of plant diseases that require detailed sampling and processing procedure. Early information on crop health and disease detection can facilitate the control of diseases through proper management strategies such as vector control through pesticide applications, fungicide applications, and disease-specific chemical applications; and can improve productivity. The present review recognizes the need for developing a rapid, cost-effective, and reliable health-monitoring sensor that would facilitate advancements in agriculture. It describes the currently used technologies that can be used for developing a ground-based sensor system to assist in monitoring health and diseases in plants under field conditions. These technologies include spectroscopic and imaging-based, and volatile profiling-based plant disease detection methods. The paper compares the benefits and limitations of these potential methods.},
  langid = {english},
  keywords = {GC-MS,Imaging techniques,Plant diseases,Spectroscopy,Volatile profiling}
}

@inproceedings{sarviaMAIAS2Sentinel2021,
  title = {{{MAIA S2}} versus Sentinel 2: Spectral Issues and Their Effects in the Precision Farming Context},
  booktitle = {Computational {{Science}} and {{Its Applications}}--{{ICCSA}} 2021: 21st {{International Conference}}, {{Cagliari}}, {{Italy}}, {{September}} 13--16, 2021, {{Proceedings}}, {{Part VII}} 21},
  author = {Sarvia, Filippo and De Petris, Samuele and Orusa, Tommaso and {Borgogno-Mondino}, Enrico},
  year = {2021},
  pages = {63--77},
  publisher = {Springer}
}

@inproceedings{satoTEASARTreestructureExtraction2000,
  title = {{{TEASAR}}: Tree-Structure Extraction Algorithm for Accurate and Robust Skeletons},
  shorttitle = {{{TEASAR}}},
  booktitle = {Proceedings the {{Eighth Pacific Conference}} on {{Computer Graphics}} and {{Applications}}},
  author = {Sato, M. and Bitter, I. and Bender, M.A. and Kaufman, A.E. and Nakajima, M.},
  year = {2000},
  pages = {281--449},
  publisher = {IEEE Comput. Soc},
  address = {Hong Kong, China},
  doi = {10.1109/PCCGA.2000.883951},
  urldate = {2024-06-10},
  abstract = {We introduce the TEASAR algorithm which is a Treestructure Extraction Algorithm delivering Skeletons that are Accurate and Robust. Volumetric skeletons are needed for accurate measurements of length along branching and winding structures. Skeletons are also required in automatic virtual navigation, such as traveling through human organs (e.g., the colon) to control movement and orientation of the virtual caniera. We introduce a concise but general definition of a skeleton, and provide an algorithm thatfinds the skeleton accurately and rapidly. Our solution isfully automatic, whichfrees the userfrom having to engage in data preprocessing. Wepresent the accurate skeletons computed on a number of test datasets. The algorithm is eficient as denionstrated by the running times on a single 194 M H z MIPS RIOOOO CPU which were all belowfive minutes.},
  isbn = {978-0-7695-0868-9},
  langid = {english}
}

@inproceedings{schaeferExamplebasedSkeletonExtraction2007,
  title = {Example-Based Skeleton Extraction},
  booktitle = {Symposium on {{Geometry Processing}}},
  author = {Schaefer, Scott and Yuksel, Can},
  year = {2007},
  volume = {153},
  pages = {162},
  urldate = {2024-06-10}
}

@article{scharrLeafSegmentationPlant2016,
  title = {Leaf Segmentation in Plant Phenotyping: A Collation Study},
  shorttitle = {Leaf Segmentation in Plant Phenotyping},
  author = {Scharr, Hanno and Minervini, Massimo and French, Andrew P. and Klukas, Christian and Kramer, David M. and Liu, Xiaoming and Luengo, Imanol and Pape, Jean Michel and Polder, Gerrit and Vukadinovic, Danijela and Yin, Xi and Tsaftaris, Sotirios A.},
  year = {2016},
  journal = {Machine Vision Applications},
  volume = {27},
  number = {4},
  pages = {585--606},
  publisher = {Springer},
  issn = {0932-8092},
  doi = {10.1007/s00138-015-0737-3},
  urldate = {2023-09-07},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/4Y5H5C34/leaf-segmentation-in-plant-phenotyping-a-collation-study.html}
}

@article{scharsteinTaxonomyEvaluationDense2002,
  title = {A {{Taxonomy}} and {{Evaluation}} of {{Dense Two-Frame Stereo Correspondence Algorithms}}},
  author = {Scharstein, Daniel and Szeliski, Richard},
  year = {2002},
  month = apr,
  journal = {International Journal of Computer Vision},
  volume = {47},
  number = {1},
  pages = {7--42},
  issn = {1573-1405},
  doi = {10.1023/A:1014573219977},
  urldate = {2022-11-24},
  abstract = {Stereo matching is one of the most active research areas in computer vision. While a large number of algorithms for stereo correspondence have been developed, relatively little work has been done on characterizing their performance. In this paper, we present a taxonomy of dense, two-frame stereo methods. Our taxonomy is designed to assess the different components and design decisions made in individual stereo algorithms. Using this taxonomy, we compare existing stereo methods and present experiments evaluating the performance of many different variants. In order to establish a common software platform and a collection of data sets for easy evaluation, we have designed a stand-alone, flexible C++ implementation that enables the evaluation of individual components and that can easily be extended to include new algorithms. We have also produced several new multi-frame stereo data sets with ground truth and are making both the code and data sets available on the Web. Finally, we include a comparative evaluation of a large set of today's best-performing stereo algorithms.},
  langid = {english},
  keywords = {evaluation of performance,stereo correspondence software,stereo matching survey}
}

@article{schiavonEffectsFungicidesCreeping2022,
  title = {Effects of Fungicides on Creeping Bentgrass Health and Rooting Characteristics under Abiotic Stress},
  author = {Schiavon, Marco and Petelewicz, Pawel and Orlinski, Pawel M. and Baird, James H.},
  year = {2022},
  month = jun,
  journal = {International Turfgrass Society Research Journal},
  volume = {14},
  number = {1},
  pages = {893--901},
  issn = {2573-1513, 2573-1513},
  doi = {10.1002/its2.11},
  urldate = {2022-09-20},
  langid = {english}
}

@misc{schleglUnsupervisedAnomalyDetection2017,
  title = {Unsupervised {{Anomaly Detection}} with {{Generative Adversarial Networks}} to {{Guide Marker Discovery}}},
  author = {Schlegl, Thomas and Seeb{\"o}ck, Philipp and Waldstein, Sebastian M. and {Schmidt-Erfurth}, Ursula and Langs, Georg},
  year = {2017},
  month = mar,
  number = {arXiv:1703.05921},
  eprint = {1703.05921},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-07-23},
  abstract = {Obtaining models that capture imaging markers relevant for disease progression and treatment monitoring is challenging. Models are typically based on large amounts of data with annotated examples of known markers aiming at automating detection. High annotation effort and the limitation to a vocabulary of known markers limit the power of such approaches. Here, we perform unsupervised learning to identify anomalies in imaging data as candidates for markers. We propose AnoGAN, a deep convolutional generative adversarial network to learn a manifold of normal anatomical variability, accompanying a novel anomaly scoring scheme based on the mapping from image space to a latent space. Applied to new data, the model labels anomalies, and scores image patches indicating their fit into the learned distribution. Results on optical coherence tomography images of the retina demonstrate that the approach correctly identifies anomalous images, such as images containing retinal fluid or hyperreflective foci.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning}
}

@article{schorDevelopmentRoboticDetection2017,
  title = {Development of a Robotic Detection System for Greenhouse Pepper Plant Diseases},
  author = {Schor, Noa and Berman, Sigal and Dombrovsky, Aviv and Elad, Yigal and Ignat, Timea and Bechar, Avital},
  year = {2017},
  month = jun,
  journal = {Precision Agriculture},
  volume = {18},
  number = {3},
  pages = {394--409},
  issn = {1573-1618},
  doi = {10.1007/s11119-017-9503-z},
  urldate = {2023-01-13},
  abstract = {Automation of disease detection and monitoring can facilitate targeted and timely disease control, which can lead to increased yield, improved crop quality and reduction in the quantity of applied pesticides. Further advantages are reduced production costs, reduced exposure to pesticides for farm workers and inspectors and increased sustainability. Symptoms are unique for each disease and crop, and each plant may suffer from multiple threats. Thus, a dedicated integrated disease-detection system and algorithms are required. The development of such a robotic detection system for two major threats of bell pepper plants: powdery mildew (PM) and Tomato spotted wilt virus (TSWV), is presented. Detection algorithms were developed based on principal component analysis using RGB and multispectral NIR-R-G sensors. High accuracy was obtained for pixel classification as diseased or healthy, for both diseases, using RGB imagery (PM: 95\%, TSWV: 90\%). NIR-R-G multispectral imagery yielded low classification accuracy (PM: 80\%, TSWV: 61\%). Accordingly, the final sensing apparatus was composed of a RGB sensor and a single-laser-beam distance sensor. A relatively fast cycle time (average 26.7~s per plant) operation cycle for detection of the two diseases was developed and tested. The cycle time was mainly influenced by sub-tasks requiring motion of the manipulator. Among these tasks, the most demanding were the determination of the required detection position and orientation. The time for task completion may be reduced by increasing the robotic work volume and by improving the algorithm for determining position and orientation.},
  langid = {english},
  keywords = {Disease detection,Multispectral imagery,Powdery mildew,RGB imagery,Tomato spotted wilt virus}
}

@article{schunckPheno4DSpatiotemporalDataset2021,
  title = {{{Pheno4D}}: {{A}} Spatio-Temporal Dataset of Maize and Tomato Plant Point Clouds for Phenotyping and Advanced Plant Analysis},
  shorttitle = {{{Pheno4D}}},
  author = {Schunck, David and Magistri, Federico and Rosu, Radu Alexandru and Corneli{\ss}en, Andr{\'e} and Chebrolu, Nived and Paulus, Stefan and L{\'e}on, Jens and Behnke, Sven and Stachniss, Cyrill and Kuhlmann, Heiner and Klingbeil, Lasse},
  editor = {Agudo, Antonio},
  year = {2021},
  month = aug,
  journal = {PLOS ONE},
  volume = {16},
  number = {8},
  pages = {e0256340},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0256340},
  urldate = {2021-12-18},
  abstract = {Understanding the growth and development of individual plants is of central importance in modern agriculture, crop breeding, and crop science. To this end, using 3D data for plant analysis has gained attention over the last years. High-resolution point clouds offer the potential to derive a variety of plant traits, such as plant height, biomass, as well as the number and size of relevant plant organs. Periodically scanning the plants even allows for performing spatio-temporal growth analysis. However, highly accurate 3D point clouds from plants recorded at different growth stages are rare, and acquiring this kind of data is costly. Besides, advanced plant analysis methods from machine learning require annotated training data and thus generate intense manual labor before being able to perform an analysis. To address these issues, we present with this dataset paper a multi-temporal dataset featuring high-resolution registered point clouds of maize and tomato plants, which we manually labeled for computer vision tasks, such as for instance segmentation and 3D reconstruction, providing approximately 260 million labeled 3D points. To highlight the usability of the data and to provide baselines for other researchers, we show a variety of applications ranging from point cloud segmentation to non-rigid registration and surface reconstruction. We believe that our dataset will help to develop new algorithms to advance the research for plant phenotyping, 3D reconstruction, non-rigid registration, and deep learning on raw point clouds. The dataset is freely accessible at                https://www.ipb.uni-bonn.de/data/pheno4d/                .},
  langid = {english}
}

@article{schunckPheno4DSpatiotemporalDataset2021a,
  title = {{{Pheno4D}}: {{A}} Spatio-Temporal Dataset of Maize and Tomato Plant Point Clouds for Phenotyping and Advanced Plant Analysis},
  shorttitle = {{{Pheno4D}}},
  author = {Schunck, David and Magistri, Federico and Rosu, Radu Alexandru and Corneli{\ss}en, Andr{\'e} and Chebrolu, Nived and Paulus, Stefan and L{\'e}on, Jens and Behnke, Sven and Stachniss, Cyrill and Kuhlmann, Heiner and Klingbeil, Lasse},
  editor = {Agudo, Antonio},
  year = {2021},
  month = aug,
  journal = {PLOS ONE},
  volume = {16},
  number = {8},
  pages = {e0256340},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0256340},
  urldate = {2021-12-18},
  abstract = {Understanding the growth and development of individual plants is of central importance in modern agriculture, crop breeding, and crop science. To this end, using 3D data for plant analysis has gained attention over the last years. High-resolution point clouds offer the potential to derive a variety of plant traits, such as plant height, biomass, as well as the number and size of relevant plant organs. Periodically scanning the plants even allows for performing spatio-temporal growth analysis. However, highly accurate 3D point clouds from plants recorded at different growth stages are rare, and acquiring this kind of data is costly. Besides, advanced plant analysis methods from machine learning require annotated training data and thus generate intense manual labor before being able to perform an analysis. To address these issues, we present with this dataset paper a multi-temporal dataset featuring high-resolution registered point clouds of maize and tomato plants, which we manually labeled for computer vision tasks, such as for instance segmentation and 3D reconstruction, providing approximately 260 million labeled 3D points. To highlight the usability of the data and to provide baselines for other researchers, we show a variety of applications ranging from point cloud segmentation to non-rigid registration and surface reconstruction. We believe that our dataset will help to develop new algorithms to advance the research for plant phenotyping, 3D reconstruction, non-rigid registration, and deep learning on raw point clouds. The dataset is freely accessible at                https://www.ipb.uni-bonn.de/data/pheno4d/                .},
  langid = {english}
}

@misc{SciELOBrazilCOMPARING,
  title = {{{SciELO}} - {{Brazil}} - {{COMPARING A SINGLE-SENSOR CAMERA WITH A MULTISENSOR CAMERA FOR MONITORING COFFEE CROP USING UNMANNED AERIAL VEHICLES COMPARING A SINGLE-SENSOR CAMERA WITH A MULTISENSOR CAMERA FOR MONITORING COFFEE CROP USING UNMANNED AERIAL VEHICLES}}},
  urldate = {2022-10-14},
  howpublished = {https://www.scielo.br/j/eagri/a/JL7zQzY3mRXdBvxv4YMWLMd/?lang=en},
  file = {/home/samuelebumbaca/Zotero/storage/AUEITVNN/JL7zQzY3mRXdBvxv4YMWLMd.html}
}

@misc{Scipyoptimizecurve_fitSciPyV193,
  title = {Scipy.Optimize.Curve\_fit --- {{SciPy}} v1.9.3 {{Manual}}},
  urldate = {2022-12-06},
  howpublished = {https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve\_fit.html},
  file = {/home/samuelebumbaca/Zotero/storage/9LC3WLBQ/scipy.optimize.curve_fit.html}
}

@article{seefeldtLogLogisticAnalysisHerbicide1995,
  title = {Log-{{Logistic Analysis}} of {{Herbicide Dose-Response Relationships}}},
  author = {Seefeldt, Steven S. and Jensen, Jens Erik and Fuerst, E. Patrick},
  year = {1995},
  journal = {Weed Technology},
  volume = {9},
  number = {2},
  eprint = {3987736},
  eprinttype = {jstor},
  pages = {218--227},
  publisher = {[Cambridge University Press, Weed Science Society of America]},
  issn = {0890-037X},
  urldate = {2023-03-24},
  abstract = {Dose-response studies are an important tool in weed science. The use of such studies has become especially prevalent following the widespread development of herbicide resistant weeds. In the past, analyses of dose-response studies have utilized various types of transformations and equations which can be validated with several statistical techniques. Most dose-response analysis methods 1) do not accurately describe data at the extremes of doses and 2) do not provide a proper statistical test for the difference(s) between two or more dose-response curves. Consequently, results of dose-response studies are analyzed and reported in a great variety of ways, and comparison of results among various researchers is not possible. The objective of this paper is to review the principles involved in dose-response research and explain the log-logistic analysis of herbicide dose-response relationships. In this paper the log-logistic model is illustrated using a nonlinear computer analysis of experimental data. The log-logistic model is an appropriate method for analyzing most dose-response studies. This model has been used widely and successfully in weed science for many years in Europe. The log-logistic model possesses several clear advantages over other analysis methods and the authors suggest that it should be widely adopted as a standard herbicide dose-response analysis method.}
}

@article{seeligAssessmentLeafWater2008,
  title = {The Assessment of Leaf Water Content Using Leaf Reflectance Ratios in the Visible, Near-, and Short-wave-infrared},
  author = {Seelig, H.-D. and Hoehn, A. and Stodieck, L. S. and Klaus, D. M. and Adams III, W. W. and Emery, W. J.},
  year = {2008},
  month = jul,
  journal = {International Journal of Remote Sensing},
  volume = {29},
  number = {13},
  pages = {3701--3713},
  publisher = {Taylor \& Francis},
  issn = {0143-1161},
  doi = {10.1080/01431160701772500},
  urldate = {2023-01-13},
  abstract = {The common features of spectral reflectance from vegetation foliage upon leaf dehydration are decreasing water absorption troughs in the near-infrared (NIR) and short-wave-infrared (SWIR). We studied which leaf water index in the NIR and SWIR is most suitable for the assessment of leaf water content and the detection of leaf dehydration from the laboratory standpoint. We also examined the influence of the thickness of leaves upon leaf water indices. All leaf water content indices examined exhibited basic correlations with the relative water content (RWC) of leaves, while the R 1300/R 1450 leaf water index also demonstrated a high signal strength and low variability (R 2{$>$}0.94). All examined leaf reflectance ratios could also be correlated with leaf thickness. The thickness of leaves, however, was not independent of leaf RWC but appeared to decrease substantially as a result of leaf dehydration.}
}

@article{sezginSurveyImageThresholding2004,
  title = {Survey over Image Thresholding Techniques and Quantitative Performance Evaluation},
  author = {Sezgin, Mehmet and Sankur, B{\"u}lent},
  year = {2004},
  month = jan,
  journal = {Journal of Electronic Imaging},
  volume = {13},
  number = {1},
  pages = {146--165},
  publisher = {SPIE},
  issn = {1017-9909, 1560-229X},
  doi = {10.1117/1.1631315},
  urldate = {2023-01-25},
  abstract = {The \emph{Journal of Electronic Imaging} (JEI), copublished bimonthly with the Society for Imaging Science and Technology, publishes peer-reviewed papers that cover research and applications in all areas of electronic imaging science and technology.}
}

@article{sezginSurveyImageThresholding2004a,
  title = {Survey over Image Thresholding Techniques and Quantitative Performance Evaluation},
  author = {Sezgin, Mehmet and Sankur, B{\"u}lent},
  year = {2004},
  month = jan,
  journal = {Journal of Electronic Imaging},
  volume = {13},
  number = {1},
  pages = {146--165},
  publisher = {SPIE},
  issn = {1017-9909, 1560-229X},
  doi = {10.1117/1.1631315},
  urldate = {2023-01-25},
  abstract = {The \emph{Journal of Electronic Imaging} (JEI), copublished bimonthly with the Society for Imaging Science and Technology, publishes peer-reviewed papers that cover research and applications in all areas of electronic imaging science and technology.}
}

@article{shenDeepskeletonLearningMultitask2017,
  title = {Deepskeleton: {{Learning}} Multi-Task Scale-Associated Deep Side Outputs for Object Skeleton Extraction in Natural Images},
  shorttitle = {Deepskeleton},
  author = {Shen, Wei and Zhao, Kai and Jiang, Yuan and Wang, Yan and Bai, Xiang and Yuille, Alan},
  year = {2017},
  journal = {IEEE Transactions on Image Processing},
  volume = {26},
  number = {11},
  pages = {5298--5311},
  publisher = {IEEE},
  urldate = {2024-06-10}
}

@inproceedings{shenObjectSkeletonExtraction2016,
  title = {Object Skeleton Extraction in Natural Images by Fusing Scale-Associated Deep Side Outputs},
  booktitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Shen, Wei and Zhao, Kai and Jiang, Yuan and Wang, Yan and Zhang, Zhijiang and Bai, Xiang},
  year = {2016},
  pages = {222--230},
  urldate = {2024-06-10}
}

@phdthesis{siImprovingQualityLiDAR2022,
  title = {Improving the {{Quality}} of {{LiDAR Point Cloud Data}} for {{Greenhouse Crop Monitoring}}},
  author = {Si, Gaoshoutong},
  year = {2022},
  urldate = {2022-09-25},
  langid = {english},
  school = {The Ohio State University},
  file = {/home/samuelebumbaca/Zotero/storage/S9AAPBP9/10.html}
}

@article{silvaComparativeAssessmentFeature2013,
  title = {Comparative Assessment of Feature Selection and Classification Techniques for Visual Inspection of Pot Plant Seedlings},
  author = {Silva, L. O. L. A. and Koga, M. L. and Cugnasca, C. E. and Costa, A. H. R.},
  year = {2013},
  month = sep,
  journal = {Computers and Electronics in Agriculture},
  volume = {97},
  pages = {47--55},
  issn = {0168-1699},
  doi = {10.1016/j.compag.2013.07.001},
  urldate = {2023-01-13},
  abstract = {Homogeneity plays an important role in ornamental plant and flower production. As assessing the quality of seedlings is an effective way of predicting plant growth performance, a vision system capable of performing this task is desirable. Yet, the optical sorting of agricultural products must find ways to incorporate knowledge from human experts into the computational solution. Our aim is evaluating feature selection techniques with respect to the performance of vision-based inspection and classification of pot plant seedlings. A large feature set was initially obtained from seedlings images and several subsets were generated with various features selection techniques. The performance of each subset was compared to some of the most popular classifiers in the literature: Naive Bayes, k-Nearest Neighbors, Logistic Regression, C4.5, Random Forest, Multilayer Perceptron as well as Partial Least Squares and Support Vector Machine Discriminant Analysis. The best classifier and subset configuration is presented; our results show that feature selection was indeed advantageous, generating accuracy gains of up to 7.4\%.},
  langid = {english},
  keywords = {Agricultural,Computer vision,Machine learning,Sorting},
  file = {/home/samuelebumbaca/Zotero/storage/KJFKVSCD/S0168169913001518.html}
}

@article{simkoPhenomicApproachesTools2017,
  title = {Phenomic {{Approaches}} and {{Tools}} for {{Phytopathologists}}},
  author = {Simko, Ivan and {Jimenez-Berni}, Jose A. and Sirault, Xavier R. R.},
  year = {2017},
  month = jan,
  journal = {Phytopathology{\textregistered}},
  volume = {107},
  number = {1},
  pages = {6--17},
  publisher = {Scientific Societies},
  issn = {0031-949X},
  doi = {10.1094/PHYTO-02-16-0082-RVW},
  urldate = {2023-01-13},
  abstract = {Plant phenomics approaches aim to measure traits such as growth, performance, and composition of plants using a suite of noninvasive technologies. The goal is to link phenotypic traits to the genetic information for particular genotypes, thus creating the bridge between the phenome and genome. Application of sensing technologies for detecting specific phenotypic reactions occurring during plant-pathogen interaction offers new opportunities for elucidating the physiological mechanisms that link pathogen infection and disease symptoms in the host, and also provides a faster approach in the selection of genetic material that is resistant to specific pathogens or strains. Appropriate phenomics methods and tools may also allow presymptomatic detection of disease-related changes in plants or to identify changes that are not visually apparent. This review focuses on the use of sensor-based phenomics tools in plant pathology such as those related to digital imaging, chlorophyll fluorescence imaging, spectral imaging, and thermal imaging. A brief introduction is provided for less used approaches like magnetic resonance, soft x-ray imaging, ultrasound, and detection of volatile compounds. We hope that this concise review will stimulate further development and use of tools for automatic, nondestructive, and high-throughput phenotyping of plant-pathogen interaction.}
}

@inproceedings{singhInDepthExplorationAnomaly2024,
  title = {An {{In-Depth Exploration}} of {{Anomaly Detection}}, {{Classification}}, and {{Localization}} with {{Deep Learning}}: {{A Comprehensive Overview}}},
  shorttitle = {An {{In-Depth Exploration}} of {{Anomaly Detection}}, {{Classification}}, and {{Localization}} with {{Deep Learning}}},
  booktitle = {Semantic {{Intelligence}}},
  author = {Singh, Kamred Udham and Kumar, Ankit and Kumar, Gaurav and Singh, Teekam and Choudhury, Tanupriya and Kotecha, Ketan},
  editor = {Jain, Sarika and Mihindukulasooriya, Nandana and Janev, Valentina and Shimizu, Cogan Matthew},
  year = {2024},
  pages = {115--125},
  publisher = {Springer Nature},
  address = {Singapore},
  doi = {10.1007/978-981-97-7356-5_10},
  abstract = {The ability to identify trends in the data when one set of data is deviating from another is called Data Mining. The development of anomalies has made it possible to identify and avoid malware, as well as several other unlawful practices. Traditional detection strategies have shown strong results However, as deep learning progresses, important findings have emerged over the past few years. In order to summarize existing and the most cutting-edge fraud and intrusion detection strategies, we address these issues depending on the existence of neural networks, from broad to shallower. This paper provides an analysis of the published techniques for anomaly detection, especially on the contribution of deep learning to detection. Methods were sorted according to the kind of DNN included in this study. These classes helped us to categorize the deep learners by how often they've been using, in data representation and for differentiating between various types of anomalies. In addition, deep neural networks in specific anomaly detection tasks presented incontrovertible proof of their effective implementation.},
  isbn = {978-981-97-7356-5},
  langid = {english}
}

@article{soaresEfficientSegmentationLeaves2013,
  title = {Efficient Segmentation of Leaves in Semi-Controlled Conditions},
  author = {Soares, Jo{\~a}o V. B. and Jacobs, David W.},
  year = {2013},
  month = nov,
  journal = {Machine Vision and Applications},
  volume = {24},
  number = {8},
  pages = {1623--1643},
  issn = {1432-1769},
  doi = {10.1007/s00138-013-0530-0},
  urldate = {2023-01-13},
  abstract = {We present a study on segmentation of leaf images restricted to semi-controlled conditions, in which leaves are photographed against a solid light-colored background. Such images can be used in practice for plant species identification, by analyzing the distinctive shapes of the leaves. We restrict our attention to segmentation in this semi-controlled condition, providing us with a more well-defined problem, which at the same time presents several challenges. The most important of these are: the variety of leaf shapes, inevitable presence of shadows and specularities, and the time constraints required by interactive species identification applications. We evaluate several popular segmentation algorithms on this task. Different datasets of leaf images are used, with manually segmented images serving as ground truth for quantitative comparisons. We observe that many of the methods are not immediately applicable: they are either too slow or would require that important modifications be introduced. We thus present extensions to our previously published segmentation method, which are able to improve its performance. The previous approach was based on pixel clustering in color space. Our extensions introduce a graph cut step and the use of a training set of manual segmentations in order to adjust important parameters of the method. The new method is fast enough for an interactive application, while producing state-of-the-art results.},
  langid = {english},
  keywords = {Electronic field guide,Expectation-Maximization,Graph cut,Image segmentation,Species identification}
}

@misc{SPAD502KONICAMINOLTA,
  title = {{{SPAD-502}} - {{KONICA MINOLTA Europe}}},
  urldate = {2022-09-19},
  howpublished = {https://www5.konicaminolta.eu/it/strumenti-di-misura/prodotti/misura-di-colore/articoli-non-piu-in-produzione/spad-502.html},
  file = {/home/samuelebumbaca/Zotero/storage/CKMFM2QE/spad-502.html}
}

@article{sphrrzybyWDaaytShkhS2019,
  title = {{ارزیابی وضعیت شاخص سبزینگی گوجه و خیار گلخانه{\null}ای با استفاده از حسگرهای غیرمخرب}},
  author = {س‍‍پهر, بهنام and محمدی منور, حسنی},
  year = {2019},
  month = mar,
  journal = {ماشین های کشاورزی},
  volume = {9},
  number = {1},
  doi = {10.22067/jam.v9i1.67383},
  urldate = {2022-09-18},
  langid = {persian}
}

@article{sphrrzybyWDaaytShkhS2019a,
  title = {{ارزیابی وضعیت شاخص سبزینگی گوجه و خیار گلخانه{\null}ای با استفاده از حسگرهای غیرمخرب}},
  author = {س‍‍پهر, بهنام and محمدی منور, حسنی},
  year = {2019},
  month = mar,
  journal = {ماشین های کشاورزی},
  volume = {9},
  number = {1},
  doi = {10.22067/jam.v9i1.67383},
  urldate = {2022-09-18},
  langid = {persian}
}

@article{stevensTheoryScalesMeasurement1946,
  title = {On the {{Theory}} of {{Scales}} of {{Measurement}}},
  author = {Stevens, S. S.},
  year = {1946},
  month = jun,
  journal = {Science},
  volume = {103},
  number = {2684},
  pages = {677--680},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.103.2684.677},
  urldate = {2023-11-13}
}

@article{stornDifferentialEvolutionSimple1997,
  title = {Differential {{Evolution}} -- {{A Simple}} and {{Efficient Heuristic}} for Global {{Optimization}} over {{Continuous Spaces}}},
  author = {Storn, Rainer and Price, Kenneth},
  year = {1997},
  month = dec,
  journal = {Journal of Global Optimization},
  volume = {11},
  number = {4},
  pages = {341--359},
  issn = {1573-2916},
  doi = {10.1023/A:1008202821328},
  urldate = {2025-03-16},
  abstract = {A new heuristic approach for minimizing possiblynonlinear and non-differentiable continuous spacefunctions is presented. By means of an extensivetestbed it is demonstrated that the new methodconverges faster and with more certainty than manyother acclaimed global optimization methods. The newmethod requires few control variables, is robust, easyto use, and lends itself very well to parallelcomputation.},
  langid = {english},
  keywords = {evolution strategy,genetic algorithm,global optimization,nonlinear optimization,Stochastic optimization},
  file = {/home/samuelebumbaca/Zotero/storage/K6XQ5SA9/Storn and Price - 1997 - Differential Evolution – A Simple and Efficient Heuristic for global Optimization over Continuous Sp.pdf}
}

@inproceedings{strechaCombinedDepthOutlier2006,
  title = {Combined {{Depth}} and {{Outlier Estimation}} in {{Multi-View Stereo}}},
  booktitle = {2006 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}}'06)},
  author = {Strecha, C. and Fransens, R. and Van Gool, L.},
  year = {2006},
  month = jun,
  volume = {2},
  pages = {2394--2401},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2006.78},
  abstract = {In this paper, we present a generative model based approach to solve the multi-view stereo problem. The input images are considered to be generated by either one of two processes: (i) an inlier process, which generates the pixels which are visible from the reference camera and which obey the constant brightness assumption, and (ii) an outlier process which generates all other pixels. Depth and visibility are jointly modelled as a hiddenMarkov Random Field, and the spatial correlations of both are explicitly accounted for. Inference is made tractable by an EM-algorithm, which alternates between estimation of visibility and depth, and optimisation of model parameters. We describe and compare two implementations of the E-step of the algorithm, which correspond to the Mean Field and Bethe approximations of the free energy. The approach is validated by experiments on challenging real-world scenes, of which two are contaminated by independently moving objects.},
  keywords = {Brightness,Cameras,Hidden Markov models,Inference algorithms,Kernel,Layout,Noise level,Pixel,Rendering (computer graphics),Stereo vision}
}

@article{streibigSensorbasedAssessmentHerbicide2014,
  title = {Sensor-Based Assessment of Herbicide Effects},
  author = {Streibig, J C and Rasmussen, J and And{\'u}jar, D and Andreasen, C and Berge, T W and Chachalis, D and Dittmann, T and Gerhards, R and Giselsson, T M and Hamouz, P and {Jaeger-Hansen}, C and Jensen, K and J{\o}rgensen, R N and Keller, M and Laursen, M and Midtiby, H S and Nielsen, J and M{\"u}ller, S and Nordmeyer, H and Peteinatos, G and Papadopoulos, A and Svensgaard, J and Weis, M and Christensen, S},
  year = {2014},
  journal = {Weed Research},
  volume = {54},
  number = {3},
  pages = {223--233},
  issn = {1365-3180},
  doi = {10.1111/wre.12079},
  urldate = {2022-11-10},
  abstract = {Non-destructive assessment of herbicide effects may be able to support integrated weed management. To test whether effects of herbicides on canopy variables could be detected by sensors, two crops were used as models and treated with herbicides at BBCH 20 using a logarithmic sprayer. Twelve days after spraying at BBCH 25 and 42 days after sowing, nine sensor systems scanned a spring barley and an oilseed rape field experiment sown at different densities and sprayed with increasing field rates of glyphosate and tribenuron-methyl. The objective was to compare ED50s for crops and weeds derived by the different sensors in relation to crop density and herbicides. Although sensors were not directly developed to detect herbicide symptoms, they all detected changes in canopy colours or height and crop density. Generally ED50s showed the same pattern in response to crop density within herbicide, but there were marked differences between barley and oilseed rape. We suggest that the results of comparing the various sensor outputs could become a stepping stone to future standardisation for the benefit of the research and development of sensors that will detect herbicide effect on crops and weeds, particularly at the most vulnerable stages of development of the canopy.},
  langid = {english},
  keywords = {barley,glyphosate,image analysis,logarithmic sprayer,oilseed rape,tribenuron-methyl},
  file = {/home/samuelebumbaca/Zotero/storage/CBMYDRU6/wre.html}
}

@article{streibigSensorbasedAssessmentHerbicide2014a,
  title = {Sensor-Based Assessment of Herbicide Effects},
  author = {Streibig, J C and Rasmussen, J and And{\'u}jar, D and Andreasen, C and Berge, T W and Chachalis, D and Dittmann, T and Gerhards, R and Giselsson, T M and Hamouz, P and {Jaeger-Hansen}, C and Jensen, K and J{\o}rgensen, R N and Keller, M and Laursen, M and Midtiby, H S and Nielsen, J and M{\"u}ller, S and Nordmeyer, H and Peteinatos, G and Papadopoulos, A and Svensgaard, J and Weis, M and Christensen, S},
  editor = {Kudsk, Per},
  year = {2014},
  month = jun,
  journal = {Weed Research},
  volume = {54},
  number = {3},
  pages = {223--233},
  issn = {00431737},
  doi = {10.1111/wre.12079},
  urldate = {2023-03-24},
  abstract = {Non-destructive assessment of herbicide effects may be able to support integrated weed management. To test whether effects of herbicides on canopy variables could be detected by sensors, two crops were used as models and treated with herbicides at BBCH 20 using a logarithmic sprayer. Twelve days after spraying at BBCH 25 and 42 days after sowing, nine sensor systems scanned a spring barley and an oilseed rape field experiment sown at different densities and sprayed with increasing field rates of glyphosate and tribenuron-methyl. The objective was to compare ED50s for crops and weeds derived by the different sensors in relation to crop density and herbicides. Although sensors were not directly developed to detect herbicide symptoms, they all detected changes in canopy colours or height and crop density. Generally ED50s showed the same pattern in response to crop density within herbicide, but there were marked differences between barley and oilseed rape. We suggest that the results of comparing the various sensor outputs could become a stepping stone to future standardisation for the benefit of the research and development of sensors that will detect herbicide effect on crops and weeds, particularly at the most vulnerable stages of development of the canopy.},
  langid = {english}
}

@misc{StudyPlantDisease,
  title = {The {{Study}} of {{Plant Disease Epidemics}} {\textbar} {{Epidemiology}}},
  urldate = {2023-01-31},
  howpublished = {https://apsjournals.apsnet.org/doi/book/10.1094/9780890545058},
  file = {/home/samuelebumbaca/Zotero/storage/YTZ7XWDB/9780890545058.html}
}

@article{sunDetectionCornChlorophyll2010,
  title = {{[Detection of corn chlorophyll content using canopy spectral reflectance]}},
  author = {Sun, Hong and Li, Min-zan and Zhang, Yan-e and Zhao, Yong and Wang, Hai-hua},
  year = {2010},
  month = sep,
  journal = {Guang Pu Xue Yu Guang Pu Fen Xi = Guang Pu},
  volume = {30},
  number = {9},
  pages = {2488--2492},
  issn = {1000-0593},
  abstract = {The canopy spectral reflectance and chlorophyll content of corn were measured and analyzed under different nitrogen treatments. The correlation between spectral reflectance and chlorophyll content was discussed based on different growth stages and different nitrogen levels. The results showed positive correlations under high and normal nitrogen treatment, while negative correlation under low nitrogen treatment. The relation between reflectance of normal fertilizer region and chlorophyll content was better than others, with r(Normal) {$>$} r(High) {$>$} r(Low). Normal fertilizer was the best condition to detect the corn chlorophyll content using spectral reflectance. Analysis of the relations at different growth stages showed that on the band of 400-1000 nm the absolute value of correlation coefficient increased and reached the maximum at shooting stage, it decreased until anthesis-silking stage, and then rebounded at milking stage. The positive correlations were found at shooting and milking stage, while negative correlations were found at seedling, trumpet and anthesis-silking stage. It was indicated that the sensitive stages to detect the chlorophyll content were shooting and trumpet stage with high absolute value of correlation coefficient above 0.6 around 550 nm. In order to detect the chlorophyll content of corn, 558, 667, 714 and 912 nm were selected to establish the MLR model and PLSR model. The results showed that PLSR was more capable of building chlorophyll content models reflecting correct relations among multi-variables compared with MLR. In the meanwhile, three wavelengths were selected (558, 667 and 714 nm) to build different vegetation indices such as GDVI, GRVI, GNDVI, DVI, RVI and NDVI. The correlation between DVI and chlorophyll con tent was better than others and DVI was used to establish binomial model and exponential model at shooting stage (R2 = 0.80) and trumpet stage (R2 = 0.66) respectively which was higher than PLSR It also provided a feasible method to detect chlorophyll content non-destructively.},
  langid = {chi},
  pmid = {21105424},
  keywords = {Chlorophyll,Fertilizers,Models Theoretical,Nitrogen,Plant Leaves,Spectrum Analysis,Zea mays}
}

@article{sunMeasurementMethodBased2019,
  title = {Measurement {{Method Based}} on {{Multispectral Three-Dimensional Imaging}} for the {{Chlorophyll Contents}} of {{Greenhouse Tomato Plants}}},
  author = {Sun, Guoxiang and Wang, Xiaochan and Sun, Ye and Ding, Yongqian and Lu, Wei},
  year = {2019},
  month = jan,
  journal = {Sensors},
  volume = {19},
  number = {15},
  pages = {3345},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1424-8220},
  doi = {10.3390/s19153345},
  urldate = {2023-02-23},
  abstract = {Nondestructive plant growth measurement is essential for researching plant growth and health. A nondestructive measurement system to retrieve plant information includes the measurement of morphological and physiological information, but most systems use two independent measurement systems for the two types of characteristics. In this study, a highly integrated, multispectral, three-dimensional (3D) nondestructive measurement system for greenhouse tomato plants was designed. The system used a Kinect sensor, an SOC710 hyperspectral imager, an electric rotary table, and other components. A heterogeneous sensing image registration technique based on the Fourier transform was proposed, which was used to register the SOC710 multispectral reflectance in the Kinect depth image coordinate system. Furthermore, a 3D multiview RGB-D image-reconstruction method based on the pose estimation and self-calibration of the Kinect sensor was developed to reconstruct a multispectral 3D point cloud model of the tomato plant. An experiment was conducted to measure plant canopy chlorophyll and the relative chlorophyll content was measured by the soil and plant analyzer development (SPAD) measurement model based on a 3D multispectral point cloud model and a single-view point cloud model and its performance was compared and analyzed. The results revealed that the measurement model established by using the characteristic variables from the multiview point cloud model was superior to the one established using the variables from the single-view point cloud model. Therefore, the multispectral 3D reconstruction approach is able to reconstruct the plant multispectral 3D point cloud model, which optimizes the traditional two-dimensional image-based SPAD measurement method and can obtain a precise and efficient high-throughput measurement of plant chlorophyll.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {chlorophyll,greenhouse tomato,multispectral,plant phenotypes,SPAD,three-dimensional reconstruction}
}

@article{suSkeletonExtractionTree2011,
  title = {Skeleton Extraction for Tree Models},
  author = {Su, Zhixun and Zhao, Yuandi and Zhao, Chunjiang and Guo, Xinyu and Li, Zhiyang},
  year = {2011},
  journal = {Mathematical and Computer Modelling},
  volume = {54},
  number = {3-4},
  pages = {1115--1120},
  publisher = {Elsevier},
  urldate = {2024-06-10},
  file = {/home/samuelebumbaca/Zotero/storage/S3BAJ7J7/S0895717710005340.html}
}

@inproceedings{tagliasacchiCurveSkeletonExtraction2009,
  title = {Curve Skeleton Extraction from Incomplete Point Cloud},
  booktitle = {{{ACM SIGGRAPH}} 2009 Papers},
  author = {Tagliasacchi, Andrea and Zhang, Hao and {Cohen-Or}, Daniel},
  year = {2009},
  month = jul,
  pages = {1--9},
  publisher = {ACM},
  address = {New Orleans Louisiana},
  doi = {10.1145/1576246.1531377},
  urldate = {2024-06-10},
  isbn = {978-1-60558-726-4},
  langid = {english}
}

@book{taizPlantPhysiologyDevelopment2015,
  title = {Plant Physiology and Development},
  author = {Taiz, Lincoln and Zeiger, Eduardo and M??ller, I. M and Murphy, Angus S and Taiz, Lincoln},
  year = {2015},
  isbn = {978-1-60535-353-1},
  langid = {english},
  annotation = {OCLC: 897091434}
}

@article{tamRegistration3DPoint2013,
  title = {Registration of {{3D Point Clouds}} and {{Meshes}}: {{A Survey}} from {{Rigid}} to {{Nonrigid}}},
  shorttitle = {Registration of {{3D Point Clouds}} and {{Meshes}}},
  author = {Tam, G. K. L. and {Zhi-Quan Cheng} and {Yu-Kun Lai} and Langbein, F. C. and {Yonghuai Liu} and Marshall, D. and Martin, R. R. and {Xian-Fang Sun} and Rosin, P. L.},
  year = {2013},
  month = jul,
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {19},
  number = {7},
  pages = {1199--1217},
  issn = {1077-2626},
  doi = {10.1109/TVCG.2012.310},
  urldate = {2021-12-19}
}

@article{tanTomatoLeafDiseases2021,
  title = {Tomato {{Leaf Diseases Classification Based}} on {{Leaf Images}}: {{A Comparison}} between {{Classical Machine Learning}} and {{Deep Learning Methods}}},
  shorttitle = {Tomato {{Leaf Diseases Classification Based}} on {{Leaf Images}}},
  author = {Tan, Lijuan and Lu, Jinzhu and Jiang, Huanyu},
  year = {2021},
  month = sep,
  journal = {AgriEngineering},
  volume = {3},
  number = {3},
  pages = {542--558},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2624-7402},
  doi = {10.3390/agriengineering3030035},
  urldate = {2023-11-27},
  abstract = {Tomato production can be greatly reduced due to various diseases, such as bacterial spot, early blight, and leaf mold. Rapid recognition and timely treatment of diseases can minimize tomato production loss. Nowadays, a large number of researchers (including different institutes, laboratories, and universities) have developed and examined various traditional machine learning (ML) and deep learning (DL) algorithms for plant disease classification. However, through pass survey analysis, we found that there are no studies comparing the classification performance of ML and DL for the tomato disease classification problem. The performance and outcomes of different traditional ML and DL (a subset of ML) methods may vary depending on the datasets used and the tasks to be solved. This study generally aimed to identify the most suitable ML/DL models for the PlantVillage tomato dataset and the tomato disease classification problem. For machine learning algorithm implementation, we used different methods to extract disease features manually. In our study, we extracted a total of 52 texture features using local binary pattern (LBP) and gray level co-occurrence matrix (GLCM) methods and 105 color features using color moment and color histogram methods. Among all the feature extraction methods, the COLOR+GLCM method obtained the best result. By comparing the different methods, we found that the metrics (accuracy, precision, recall, F1 score) of the tested deep learning networks (AlexNet, VGG16, ResNet34, EfficientNet-b0, and MobileNetV2) were all better than those of the measured machine learning algorithms (support vector machine (SVM), k-nearest neighbor (kNN), and random forest (RF)). Furthermore, we found that, for our dataset and classification task, among the tested ML/DL algorithms, the ResNet34 network obtained the best results, with accuracy of 99.7\%, precision of 99.6\%, recall of 99.7\%, and F1 score of 99.7\%.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {deep learning,disease classification,feature extraction,machine learning}
}

@article{taoEstablishmentCropGrowth2016,
  title = {{[Establishment of The Crop Growth and Nitrogen Nutrition State Model Using Spectral Parameters Canopy Cover]}},
  author = {Tao, Zhi-Qiang and Bagum, Shamim Ara and Ma, Wei and Zhou, Bao-yuan and Fu, Jin-dong and Cui, Ri-xian and Sun, Xue-fang and Zhao, Ming},
  year = {2016},
  month = jan,
  journal = {Guang Pu Xue Yu Guang Pu Fen Xi = Guang Pu},
  volume = {36},
  number = {1},
  pages = {231--236},
  issn = {1000-0593},
  abstract = {In order to explore a non-destructive monitoring technique, the use of digital photo pixels canopy cover (CC) diagnosis and prediction on maize growth and its nitrogen nutrition status. This study through maize canopy digital photo images on relationship between color index in the photo and the leaf area index (LAI), shoot dry matter weight (DM), leaf nitrogen content percentage (N\%). The test conducted in the Chinese Academy of Agricultural Science from 2012 to 2013, based on Maize canopy Visual Image Analysis System developed by Visual Basic Version 6.0, analyzed the correlation of CC, color indices, LAI, DM, N\% on maize varieties (Zhongdan909, ZD 909) under three nitrogen levels treatments, furthermore the indicators significantly correlated were fitted with modeling, The results showed that CC had a highly significant correlation with LAI (r = 0.93, p {$<$} 0.01), DM (r = 0. 94, p {$<$} 0.01), N\% (r = 0.82, p {$<$} 0.01). Estimating the model of LAI, DM and N\% by CC were all power function, and the equation respectively were y = 3.281 2x(0.763 9), y = 283.658 1x(0.553 6) and y = 3.064 5x(0.932 9); using independent data from modeling for model validation indicated that R2, RMSE and RE based on 1 : 1 line relationship between measured values and simulated values in the model of CC estimating LAI were 0.996, 0.035 and 1.46\%; R2, RMSE and RE in the model of CC estimating DM were 0.978, 5.408 g and 2.43\%; R2, RMSE and RE in the model of CC estimating N\% were 0.990, 0.054 and 2.62\%. In summary, the model can comparatively accurately estimate the LAI, DM and N\% by CC under different nitrogen levels at maize grain filling stage, indicating that it is feasible to apply digital camera on real-time undamaged rapid monitoring and prediction for maize growth conditions and its nitrogen nutrition status. This research finding is to be verified in the field experiment, and further analyze the applicability throughout the growing period in other maize varieties and different planting density.},
  langid = {chi},
  pmid = {27228773},
  keywords = {Models Theoretical,Nitrogen,Plant Leaves,Spectrum Analysis,Zea mays}
}

@article{tardieuPlantResponseEnvironmental2013,
  title = {Plant Response to Environmental Conditions: Assessing Potential Production, Water Demand, and Negative Effects of Water Deficit},
  shorttitle = {Plant Response to Environmental Conditions},
  author = {Tardieu, Francois},
  year = {2013},
  journal = {Frontiers in Physiology},
  volume = {4},
  issn = {1664-042X},
  urldate = {2022-01-28},
  abstract = {This paper reviews methods for analyzing plant performance and its genetic variability under a range of environmental conditions. Biomass accumulation is linked every day to available light in the photosynthetically active radiation (PAR) domain, multiplied by the proportion of light intercepted by plants and by the radiation use efficiency. Total biomass is cumulated over the duration of the considered phase (e.g., plant cycle or vegetative phase). These durations are essentially constant for a given genotype provided that time is corrected for temperature (thermal time). Several ways of expressing thermal time are reviewed. Two alternative equations are presented, based either on the effect of transpiration, or on yield components. Their comparative interests and drawbacks are discussed. The genetic variability of each term of considered equations affects yield under water deficit, via mechanisms at different scales of plant organization and time. The effect of any physiological mechanism on yield of stressed plants acts via one of these terms, although the link is not always straightforward. Finally, I propose practical ways to compare the productivity of genotypes in field environments, and a ``minimum dataset'' of environmental data and traits that should be recorded for that.}
}

@inproceedings{tardieuWhitePaperPlant2009,
  title = {White Paper on Plant Phenotyping},
  booktitle = {{{EPSO Workshop}}},
  author = {Tardieu, F and Schurr, U},
  year = {2009}
}

@article{tengLeafSegmentationClassification2011,
  title = {Leaf Segmentation, Classification, and Three-Dimensional Recovery from a Few Images with Close Viewpoints},
  author = {Teng, Chin-Hung and Kuo, Yi-Ting and Chen, Yung-Sheng},
  year = {2011},
  month = mar,
  journal = {Optical Engineering},
  volume = {50},
  number = {3},
  pages = {037003},
  publisher = {SPIE},
  issn = {0091-3286, 1560-2303},
  doi = {10.1117/1.3549927},
  urldate = {2023-01-13},
  abstract = {In this paper, we incorporate a set of sophisticated algorithms to implement a leaf segmentation and classification system. This system inherits the advantages of these algorithms while eliminating the difficulties each algorithm faced. Our system can segment leaves from images of live plants with arbitrary image conditions, and classify them against sketched leaf shapes or real leaves. This system can also estimate the three-dimensional (3-D) information of leaves which is not only useful for leaf segmentation but is also beneficial for further 3-D shape recovery. Although our system requires more than one image to reconstruct the 3-D structure of the scene, it has been designed so that only a few images with close viewpoints are sufficient to achieve the task, thus the system is still flexible and easy to use in image acquisition. For leaf classification, we adopt the normalized centroid-contour distance as our classification feature and employ a circular-shift comparing scheme to measure leaf similarity so that the system has the advantage of being invariant to leaf translation, rotation and scaling. We have conducted a series of experiments on many leaf images and the results are encouraging. The leaves can be well segmented and the classification results are also acceptable.}
}

@article{thelenUseOpticalRemote2004,
  title = {Use of {{Optical Remote Sensing}} for {{Detecting Herbicide Injury}} in {{Soybean}}},
  author = {Thelen, Kurt D. and Kravchenko, A. N. and Lee, Chad D.},
  year = {2004},
  journal = {Weed Technology},
  volume = {18},
  number = {2},
  eprint = {3989218},
  eprinttype = {jstor},
  pages = {292--297},
  publisher = {[Cambridge University Press, Weed Science Society of America]},
  issn = {0890-037X},
  urldate = {2023-01-10},
  abstract = {Experiments were conducted from 2000 to 2002 at two locations each year to determine if lactofen and imazethapyr injury to soybean could be detected using digital aerial imagery and ground-based optical remote sensing. Lactofen and imazethapyr were applied at base rates of 105 and 71 g/ha, respectively, and at 0, 2X, and 4X rates. Treated plots were evaluated between 7 and 21 d after treatment for crop injury using a ground-based radiometer and a system using computer analysis of digital aerial imagery. Both the ground-based radiometer and the digital aerial imagery were effective in detecting herbicide injury under most conditions. The digital aerial imagery system was found to be more sensitive in detecting herbicide injury than the ground-based radiometer system. Herbicide or herbicide rate had a significant effect on normalized differential vegetation indices (NDVI) derived from digital aerial imagery in four of four site-years. NDVI values derived from a multispectral ground-based radiometer were significant for herbicide or herbicide rate in four of six site-years. NDVI values from treated plots were subtracted from the NDVI value of the untreated check to generate a {$\Delta$}NDVI. The resulting {$\Delta$}NDVI values from the ground-based radiometer system were significant for herbicide or herbicide rate in six of six site-years. Neither optical remote-sensing system was effective at estimating actual application rates of lactofen and imazethapyr across a broad range of field and weather conditions due to temporal and spatial variability in crop response to the herbicides.}
}

@article{thelenUseOpticalRemote2004a,
  title = {Use of {{Optical Remote Sensing}} for {{Detecting Herbicide Injury}} in {{Soybean}}},
  author = {Thelen, Kurt D. and Kravchenko, A. N. and Lee, Chad D.},
  year = {2004},
  journal = {Weed Technology},
  volume = {18},
  number = {2},
  eprint = {3989218},
  eprinttype = {jstor},
  pages = {292--297},
  publisher = {[Cambridge University Press, Weed Science Society of America]},
  issn = {0890-037X},
  urldate = {2023-01-31},
  abstract = {Experiments were conducted from 2000 to 2002 at two locations each year to determine if lactofen and imazethapyr injury to soybean could be detected using digital aerial imagery and ground-based optical remote sensing. Lactofen and imazethapyr were applied at base rates of 105 and 71 g/ha, respectively, and at 0, 2X, and 4X rates. Treated plots were evaluated between 7 and 21 d after treatment for crop injury using a ground-based radiometer and a system using computer analysis of digital aerial imagery. Both the ground-based radiometer and the digital aerial imagery were effective in detecting herbicide injury under most conditions. The digital aerial imagery system was found to be more sensitive in detecting herbicide injury than the ground-based radiometer system. Herbicide or herbicide rate had a significant effect on normalized differential vegetation indices (NDVI) derived from digital aerial imagery in four of four site-years. NDVI values derived from a multispectral ground-based radiometer were significant for herbicide or herbicide rate in four of six site-years. NDVI values from treated plots were subtracted from the NDVI value of the untreated check to generate a {$\Delta$}NDVI. The resulting {$\Delta$}NDVI values from the ground-based radiometer system were significant for herbicide or herbicide rate in six of six site-years. Neither optical remote-sensing system was effective at estimating actual application rates of lactofen and imazethapyr across a broad range of field and weather conditions due to temporal and spatial variability in crop response to the herbicides.}
}

@article{thomasiRelationshipVegetationIndices2021,
  title = {Relationship of Vegetation Indices with Herbicide Phytotoxicity in Winter Cereals},
  author = {Thomasi, Rosana M. and L{\'u}cio, Alessandro D. and Amado, Telmo J. C. and Pott, Luan P. and Zanon, Alencar and Werle, Isabel S. and Macedo, Mariana and Ulguim, Andr{\'e} R.},
  year = {2021},
  month = nov,
  journal = {Advances in Weed Science},
  volume = {39},
  pages = {02100050},
  issn = {2675-9462},
  doi = {10.51694/AdvWeedSci/2021;39:00017},
  urldate = {2023-01-31},
  abstract = {Background: The evaluation of selective herbicides for weed control in winter cereals is extremely important. Simple methods to evaluate alterations caused by herbicides in the growth and development of winter cereals can be performed with vegetation indices.},
  langid = {english}
}

@article{thomasLeafReflectanceVs1977,
  title = {Leaf {{Reflectance}} vs. {{Leaf Chlorophyll}} and {{Carotenoid Concentrations}} for {{Eight Crops1}}},
  author = {Thomas, J. R. and Gausman, H. W.},
  year = {1977},
  journal = {Agronomy Journal},
  volume = {69},
  number = {5},
  pages = {799--802},
  issn = {1435-0645},
  doi = {10.2134/agronj1977.00021962006900050017x},
  urldate = {2023-03-24},
  abstract = {Leaf reflectance in the 0.40- to 0.75-{$\mu$}m wavelength interval is influenced primarily by the pigments chlorophyll and carotenoid. However, the literature contains very few references to the relation between reflectance from leaves and their carotenoid content. Our objectives in this study were to determine which of three wavelengths in the visible spectral region best related leaf reflectance to total chlorophyll and carotenoid concentrations, and the relative effect of these pigments on reflectance. Hemispherical reflectances of single leaves at each of the 0.45-, 0.55-, and 0.67-{$\mu$}m wavelengths for cantaloupe (Cucumis melo L. cv. reticulatus Naud.), corn (Zea mays L.), cotton (Gossypium hirsutum L.), cucumber (Cucumis sativus L.), head lettuce (Lactuca sativa L. cv. capitata L.), grain sorghum (Sorghum bicolor (L.) Moench), spinach (Spinacia oleracea L.), and tobacco (Nicotiana tabacum L.) were regressed on each crop's leaf total chlorophyll and carotenoid concentrations. The crops were grown in sand culture, and their leaf pigment concentrations were varied by supplying N at rates of 14, 28, 84, 140, and 196 ppm to a basic nutrient solution. Hemispherical reflectance of leaves was inversely related to each crop's leaf chlorophyll and carotenoid concentrations. However, of the three wavelengths tested, the 0.55-{$\mu$}m wavelength seemed superior for individually relating the two pigments to leaf reflectance. The independent effects of carotenoid on hemispherical reflectance were small and generally not statistically significant, whereas the independent effects of chlorophyll while small were generally significant. The combined effects of these variables were highly significant and accounted for 39 to 95\% of the reflectance variability. This study indicated that even though including carotenoid with total chlorophyll measurements improved the correlation of reflectance with pigment concentration, satisfactory results would be obtained by chlorophyll analysis alone.},
  langid = {english},
  keywords = {Absorptance,Carotene,Pigments,Remote sensing,Xanthophyll},
  file = {/home/samuelebumbaca/Zotero/storage/9KBN9C2P/agronj1977.html}
}

@article{thomasObservationPlantPathogen2016,
  title = {Observation of Plant--Pathogen Interaction by Simultaneous Hyperspectral Imaging Reflection and Transmission Measurements},
  author = {Thomas, Stefan and Wahabzada, Mirwaes and Kuska, Matheus Thomas and Rascher, Uwe and Mahlein, Anne-Katrin and Thomas, Stefan and Wahabzada, Mirwaes and Kuska, Matheus Thomas and Rascher, Uwe and Mahlein, Anne-Katrin},
  year = {2016},
  month = oct,
  journal = {Functional Plant Biology},
  volume = {44},
  number = {1},
  pages = {23--34},
  publisher = {CSIRO PUBLISHING},
  issn = {1445-4416, 1445-4416},
  doi = {10.1071/FP16127},
  urldate = {2023-01-13},
  abstract = {Hyperspectral imaging sensors are valuable tools for plant disease detection and plant phenotyping. Reflectance properties are influenced by plant pathogens and resistance responses, but changes of transmission characteristics of plants are less described. In this study we used simultaneously recorded reflectance and transmittance imaging data of resistant and susceptible barley genotypes that were inoculated with Blumeria graminis f. sp. hordei to evaluate the added value of imaging transmission, reflection and absorption for characterisation of disease development. These datasets were statistically analysed using principal component analysis, and compared with visual and molecular disease estimation. Reflection measurement performed significantly better for early detection of powdery mildew infection, colonies could be detected 2 days before symptoms became visible in RGB images. Transmission data could be used to detect powdery mildew 2 days after symptoms becoming visible in reflection based RGB images. Additionally distinct transmission changes occurred at 580--650 nm for pixels containing disease symptoms. It could be shown that the additional information of the transmission data allows for a clearer spatial differentiation and localisation between powdery mildew symptoms and necrotic tissue on the leaf then purely reflectance based data. Thus the information of both measurement approaches are complementary: reflectance based measurements facilitate an early detection, and transmission measurements provide additional information to better understand and quantify the complex spatio-temporal dynamics of plant-pathogen interactions.},
  langid = {english}
}

@article{thomasObservationPlantPathogen2017,
  title = {Observation of Plant--Pathogen Interaction by Simultaneous Hyperspectral Imaging Reflection and Transmission Measurements},
  author = {Thomas, Stefan and Wahabzada, Mirwaes and Kuska, Matheus Thomas and Rascher, Uwe and Mahlein, Anne-Katrin},
  year = {2017},
  journal = {Functional Plant Biology},
  volume = {44},
  number = {1},
  pages = {23},
  issn = {1445-4408},
  doi = {10.1071/FP16127},
  urldate = {2021-12-22},
  abstract = {Hyperspectral imaging sensors are valuable tools for plant disease detection and plant phenotyping. Reflectance properties are influenced by plant pathogens and resistance responses, but changes of transmission characteristics of plants are less described. In this study we used simultaneously recorded reflectance and transmittance imaging data of resistant and susceptible barley genotypes that were inoculated with Blumeria graminis f. sp. hordei to evaluate the added value of imaging transmission, reflection and absorption for characterisation of disease development. These datasets were statistically analysed using principal component analysis, and compared with visual and molecular disease estimation. Reflection measurement performed significantly better for early detection of powdery mildew infection, colonies could be detected 2 days before symptoms became visible in RGB images. Transmission data could be used to detect powdery mildew 2 days after symptoms becoming visible in reflection based RGB images. Additionally distinct transmission changes occurred at 580--650\,nm for pixels containing disease symptoms. It could be shown that the additional information of the transmission data allows for a clearer spatial differentiation and localisation between powdery mildew symptoms and necrotic tissue on the leaf then purely reflectance based data. Thus the information of both measurement approaches are complementary: reflectance based measurements facilitate an early detection, and transmission measurements provide additional information to better understand and quantify the complex spatio-temporal dynamics of plant-pathogen interactions.},
  langid = {english}
}

@article{thomasQuantitativeAssessmentDisease2018,
  title = {Quantitative Assessment of Disease Severity and Rating of Barley Cultivars Based on Hyperspectral Imaging in a Non-Invasive, Automated Phenotyping Platform},
  author = {Thomas, Stefan and Behmann, Jan and Steier, Angelina and Kraska, Thorsten and Muller, Onno and Rascher, Uwe and Mahlein, Anne-Katrin},
  year = {2018},
  month = jun,
  journal = {Plant Methods},
  volume = {14},
  number = {1},
  pages = {45},
  issn = {1746-4811},
  doi = {10.1186/s13007-018-0313-8},
  urldate = {2021-12-22},
  abstract = {Phenotyping is a bottleneck for the development of new plant cultivars. This study introduces a new hyperspectral phenotyping system, which combines the high throughput of canopy scale measurements with the advantages of high spatial resolution and a controlled measurement environment. Furthermore, the measured barley canopies were grown in large containers (called Mini-Plots), which allow plants to develop field-like phenotypes in greenhouse experiments, without being hindered by pot size.},
  keywords = {Disease rating,Greenhouse,High-throughput,Hyperspectral imaging,Phenotyping platform,Simplex Volume Maximization,Support Vector Machine}
}

@article{travisDevelopmentImplementationAdoption1991,
  title = {Development, {{Implementation}}, and {{Adoption}} of {{Expert Systems}} in {{Plant Pathology}}},
  author = {Travis, J W and Latin, R X},
  year = {1991},
  journal = {Annual Review of Phytopathology},
  volume = {29},
  number = {1},
  pages = {343--360},
  doi = {10.1146/annurev.py.29.090191.002015},
  urldate = {2023-01-13}
}

@article{travlosNovelSensorbasedMethod2021,
  title = {Novel Sensor-Based Method (Quick Test) for the in-Season Rapid Evaluation of Herbicide Efficacy under Real Field Conditions in Durum Wheat},
  author = {Travlos, Ilias and Tsekoura, Anastasia and Antonopoulos, Nikolaos and Kanatas, Panagiotis and Gazoulis, Ioannis},
  year = {2021},
  month = mar,
  journal = {Weed Science},
  volume = {69},
  number = {2},
  pages = {147--160},
  issn = {0043-1745, 1550-2759},
  doi = {10.1017/wsc.2021.8},
  urldate = {2022-09-20},
  abstract = {Abstract                            Optimum herbicide use is a key factor affecting the success of any integrated weed management strategy. The main objective of the current study was to implement a method based on spectrometer measurements for the in situ evaluation of herbicide efficacy and the detection of potentially herbicide-resistant weeds. Field trials were conducted in Greece between 2018 and 2020 in several durum wheat fields (               Triticum durum               Desf.). In all trials, the overall effect of herbicide application on the recorded Normalized Difference Vegetation Index (NDVI) values (at 1 and 2 wk after treatment [WAT]) was significant (P {$\leq$} 0.001). For the majority of the surveyed fields, low NDVI values were recorded after 2,4-D application and a mixture of clopyralid + florasulam from 1 WAT, suggesting their increased efficacy. In several cases, the application of pyroxsulam + florasulam resulted in significant NDVI reductions at 2 WAT. As observed at the end of the growing seasons, the herbicides that reduced NDVI resulted in lower weed biomass. Strong correlations were observed between weed aboveground biomass and NDVI (2 WAT). In particular, R               2               values were 0.8234 to 0.8649, 0.8453, 0.8595, 0.8149, and 0.8925 for the Aliartos, Thiva, Domokos, Larissa, and Orestiada fields, respectively. The overall effects of herbicide application on wheat grain yield were also significant (P {$\leq$} 0.001). Pot experiments confirmed that the high NDVI values in some cases could be attributed to the presence of herbicide-resistant weeds. For instance, the resistance indices of two accessions of catchweed bedstraw (               Galium aparine               L.) to mesosulfuron-methyl + iodosulfuron-methyl-sodium ranged between 9.7 and 13.2, whereas one sterile oat [               Avena sterilis               L. ssp.               ludoviciana               (Durieu) Gillet \& Magne] accession was 8.8 times more resistant to fenoxaprop-               p               -ethyl than a susceptible one. The present study is targeted at making a significant contribution toward establishing cause--effect relationships and presenting a useful tool for developing more effective weed management practices in more arable crops and under different soil and climatic conditions.},
  langid = {english}
}

@incollection{triggsBundleAdjustmentModern2000,
  title = {Bundle {{Adjustment}} --- {{A Modern Synthesis}}},
  booktitle = {Vision {{Algorithms}}: {{Theory}} and {{Practice}}},
  author = {Triggs, Bill and McLauchlan, Philip F. and Hartley, Richard I. and Fitzgibbon, Andrew W.},
  editor = {Goos, Gerhard and Hartmanis, Juris and {van Leeuwen}, Jan and Triggs, Bill and Zisserman, Andrew and Szeliski, Richard},
  year = {2000},
  volume = {1883},
  pages = {298--372},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/3-540-44480-7_21},
  urldate = {2022-12-06},
  abstract = {This paper is a survey of the theory and methods of photogrammetric bundle adjustment, aimed at potential implementors in the computer vision community. Bundle adjustment is the problem of refining a visual reconstruction to produce jointly optimal structure and viewing parameter estimates. Topics covered include: the choice of cost function and robustness; numerical optimization including sparse Newton methods, linearly convergent approximations, updating and recursive methods; gauge (datum) invariance; and quality control. The theory is developed for general robust cost functions rather than restricting attention to traditional nonlinear least squares.},
  isbn = {978-3-540-67973-8 978-3-540-44480-0},
  langid = {english}
}

@article{tschierschEstablishmentIntegratedProtocols2017,
  title = {Establishment of Integrated Protocols for Automated High Throughput Kinetic Chlorophyll Fluorescence Analyses},
  author = {Tschiersch, Henning and Junker, Astrid and Meyer, Rhonda C. and Altmann, Thomas},
  year = {2017},
  month = jul,
  journal = {Plant Methods},
  volume = {13},
  number = {1},
  pages = {54},
  issn = {1746-4811},
  doi = {10.1186/s13007-017-0204-4},
  urldate = {2021-12-18},
  abstract = {Automated plant phenotyping has been established as a powerful new tool in studying plant growth, development and response to various types of biotic or abiotic stressors. Respective facilities mainly apply non-invasive imaging based methods, which enable the continuous quantification of the dynamics of plant growth and physiology during developmental progression. However, especially for plants of larger size, integrative, automated and high throughput measurements of complex physiological parameters such as photosystem II efficiency determined through kinetic chlorophyll fluorescence analysis remain a challenge.},
  keywords = {Chlorophyll fluorescence imaging (CFI),High throughput screening,Photosynthesis,Plant phenotyping,PSII operating efficiency}
}

@article{tuckerRedPhotographicInfrared1979,
  title = {Red and Photographic Infrared Linear Combinations for Monitoring Vegetation},
  author = {Tucker, Compton J.},
  year = {1979},
  month = may,
  journal = {Remote Sensing of Environment},
  volume = {8},
  number = {2},
  pages = {127--150},
  issn = {0034-4257},
  doi = {10.1016/0034-4257(79)90013-0},
  urldate = {2023-03-24},
  abstract = {In situ collected spectrometer data were used to evaluate and quantify the relationships between various linear combinations of red and photographic infrared radiances and experimental plot biomass, leaf water content, and chlorophyll content. The radiance variables evaluated included the red and photographic infrared (IR) radiance and the linear combinations of the IR/red ratio, the square root of the IR/red ratio, the IR-red difference, the vegetation index, and the transformed vegetation index. In addition, the corresponding green and red linear combinations were evaluated for comparative purposes. Three data sets were used from June, September, and October sampling periods. Regression analysis showed the increased utility of the IR and red linear combinations vis-{\`a}-vis the same green and red linear combinations. The red and IR linear combinations had 7\% and 14\% greater regression significance than the green and red linear combinations for the June and September sampling periods, respectively. The vegetation index, transformed vegetation index, and square root of the IR/red ratio were the most significant, followed closely by the IR/red ratio. Less than a 6\% difference separated the highest and lowest of these four ER and red linear combinations. The use of these linear combinations was shown to be sensitive primarily to the green leaf area or green leaf biomass. As such, these linear combinations of the red and photographic IR radiances can be employed to monitor the photosynthetically active biomass of plant canopies.},
  langid = {english}
}

@article{uddlingEvaluatingRelationshipLeaf2007,
  title = {Evaluating the Relationship between Leaf Chlorophyll Concentration and {{SPAD-502}} Chlorophyll Meter Readings},
  author = {Uddling, J. and {Gelang-Alfredsson}, J. and Piikki, K. and Pleijel, H.},
  year = {2007},
  month = mar,
  journal = {Photosynthesis Research},
  volume = {91},
  number = {1},
  pages = {37--46},
  issn = {0166-8595, 1573-5079},
  doi = {10.1007/s11120-006-9077-5},
  urldate = {2022-09-19},
  langid = {english}
}

@article{uddlingEvaluatingRelationshipLeaf2007a,
  title = {Evaluating the Relationship between Leaf Chlorophyll Concentration and {{SPAD-502}} Chlorophyll Meter Readings},
  author = {Uddling, J. and {Gelang-Alfredsson}, J. and Piikki, K. and Pleijel, H.},
  year = {2007},
  month = jan,
  journal = {Photosynthesis Research},
  volume = {91},
  number = {1},
  pages = {37--46},
  issn = {1573-5079},
  doi = {10.1007/s11120-006-9077-5},
  urldate = {2022-09-19},
  abstract = {Relationships between chlorophyll concentration ([chl]) and SPAD values were determined for birch, wheat, and potato. For all three species, the relationships were non-linear with an increasing slope with increasing SPAD. The relationships for birch and wheat were strong (r2~{$\sim~$}0.9), while the potato relationship was comparatively weak (r2~{$\sim~$}0.5). Birch and wheat had very similar relationships when the chlorophyll concentration was expressed per unit leaf area, but diverged when it was expressed per unit fresh weight. Furthermore, wheat showed similar SPAD--[chl] relationships for two different cultivars and during two different growing seasons. The curvilinear shape of the SPAD--[chl] relationships agreed well with the simulated effects of non-uniform chlorophyll distribution across the leaf surface and multiple scattering, causing deviations from linearity in the high and low SPAD range, respectively. The effect of non-uniformly distributed chlorophyll is likely to be more important in explaining the non-linearity in the empirical relationships, since the effect of scattering was predicted to be comparatively weak. The simulations were based on the algorithm for the calculation of SPAD-502 output values. We suggest that SPAD calibration curves should generally be parameterised as non-linear equations, and we hope that the relationships between [chl] and SPAD and the simulations of the present study can facilitate the interpretation of chlorophyll meter calibrations in relation to optical properties of leaves in future studies.},
  langid = {english},
  keywords = {Absorbance,Chlorophyll,Non-uniform chlorophyll distribution,Reflectance,Scattering,SPAD}
}

@book{vanrossumPython3Reference2009,
  title = {Python 3 {{Reference Manual}}},
  author = {Van Rossum, Guido and Drake, Fred L.},
  year = {2009},
  publisher = {CreateSpace},
  address = {Scotts Valley, CA},
  isbn = {1-4414-1269-7}
}

@article{verreetRegionalMonitoringDisease2000,
  title = {Regional {{Monitoring}} for {{Disease Prediction}} and {{Optimization}} of {{Plant Protection Measuares}}: {{The IPM Wheat Model}}},
  shorttitle = {Regional {{Monitoring}} for {{Disease Prediction}} and {{Optimization}} of {{Plant Protection Measuares}}},
  author = {Verreet, J. A. and Klink, H. and Hoffmann, G. M.},
  year = {2000},
  month = aug,
  journal = {Plant Disease},
  volume = {84},
  number = {8},
  pages = {816--826},
  issn = {0191-2917, 1943-7692},
  doi = {10.1094/PDIS.2000.84.8.816},
  urldate = {2023-01-13},
  langid = {english}
}

@article{vianiSnowMetricsProxy2023,
  title = {Snow {{Metrics}} as {{Proxy}} to {{Assess Sarcoptic Mange}} in {{Wild Boar}}: {{Preliminary Results}} in {{Aosta Valley}} ({{Italy}})},
  author = {Viani, Annalisa and Orusa, Tommaso and {Borgogno-Mondino}, Enrico and Orusa, Riccardo},
  year = {2023},
  journal = {Life},
  volume = {13},
  number = {4},
  pages = {987}
}

@article{virletFieldScanalyzerAutomated2016,
  title = {Field {{Scanalyzer}}: {{An}} Automated Robotic Field Phenotyping Platform for Detailed Crop Monitoring},
  shorttitle = {Field {{Scanalyzer}}},
  author = {Virlet, Nicolas and Sabermanesh, Kasra and {Sadeghi-Tehran}, Pouria and Hawkesford, Malcolm J. and Virlet, Nicolas and Sabermanesh, Kasra and {Sadeghi-Tehran}, Pouria and Hawkesford, Malcolm J.},
  year = {2016},
  month = nov,
  journal = {Functional Plant Biology},
  volume = {44},
  number = {1},
  pages = {143--153},
  publisher = {CSIRO PUBLISHING},
  issn = {1445-4416, 1445-4416},
  doi = {10.1071/FP16163},
  urldate = {2023-01-13},
  abstract = {Current approaches to field phenotyping are laborious or permit the use of only a few sensors at a time. In an effort to overcome this, a fully automated robotic field phenotyping platform with a dedicated sensor array that may be accurately positioned in three dimensions and mounted on fixed rails has been established, to facilitate continual and high-throughput monitoring of crop performance. Employed sensors comprise of high-resolution visible, chlorophyll fluorescence and thermal infrared cameras, two hyperspectral imagers and dual 3D laser scanners. The sensor array facilitates specific growth measurements and identification of key growth stages with dense temporal and spectral resolution. Together, this platform produces a detailed description of canopy development across the crops entire lifecycle, with a high-degree of accuracy and reproducibility.},
  langid = {english}
}

@article{wahabzadaMetroMapsPlant2015,
  title = {Metro {{Maps}} of {{Plant Disease Dynamics}}---{{Automated Mining}} of {{Differences Using Hyperspectral Images}}},
  author = {Wahabzada, Mirwaes and Mahlein, Anne-Katrin and Bauckhage, Christian and Steiner, Ulrike and Oerke, Erich-Christian and Kersting, Kristian},
  year = {2015},
  month = jan,
  journal = {PLOS ONE},
  volume = {10},
  number = {1},
  pages = {e0116902},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0116902},
  urldate = {2023-01-13},
  abstract = {Understanding the response dynamics of plants to biotic stress is essential to improve management practices and breeding strategies of crops and thus to proceed towards a more sustainable agriculture in the coming decades. In this context, hyperspectral imaging offers a particularly promising approach since it provides non-destructive measurements of plants correlated with internal structure and biochemical compounds. In this paper, we present a cascade of data mining techniques for fast and reliable data-driven sketching of complex hyperspectral dynamics in plant science and plant phenotyping. To achieve this, we build on top of a recent linear time matrix factorization technique, called Simplex Volume Maximization, in order to automatically discover archetypal hyperspectral signatures that are characteristic for particular diseases. The methods were applied on a data set of barley leaves (Hordeum vulgare) diseased with foliar plant pathogens Pyrenophora teres, Puccinia hordei and Blumeria graminis hordei. Towards more intuitive visualizations of plant disease dynamics, we use the archetypal signatures to create structured summaries that are inspired by metro maps, i.e. schematic diagrams of public transport networks. Metro maps of plant disease dynamics produced on several real-world data sets conform to plant physiological knowledge and explicitly illustrate the interaction between diseases and plants. Most importantly, they provide an abstract and interpretable view on plant disease progression.},
  langid = {english},
  keywords = {Barley,Disease dynamics,Leaves,Pathogenesis,Pathogens,Plant pathology,Plant physiology,Powdery mildew}
}

@article{wahabzadaPlantPhenotypingUsing2016,
  title = {Plant {{Phenotyping}} Using {{Probabilistic Topic Models}}: {{Uncovering}} the {{Hyperspectral Language}} of {{Plants}}},
  shorttitle = {Plant {{Phenotyping}} Using {{Probabilistic Topic Models}}},
  author = {Wahabzada, Mirwaes and Mahlein, Anne-Katrin and Bauckhage, Christian and Steiner, Ulrike and Oerke, Erich-Christian and Kersting, Kristian},
  year = {2016},
  month = mar,
  journal = {Scientific Reports},
  volume = {6},
  number = {1},
  pages = {22482},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/srep22482},
  urldate = {2023-01-13},
  abstract = {Modern phenotyping and plant disease detection methods, based on optical sensors and information technology, provide promising approaches to plant research and precision farming. In particular, hyperspectral imaging have been found to reveal physiological and structural characteristics in plants and to allow for tracking physiological dynamics due to environmental effects. In this work, we present an approach to plant phenotyping that integrates non-invasive sensors, computer vision, as well as data mining techniques and allows for monitoring how plants respond to stress. To uncover latent hyperspectral characteristics of diseased plants reliably and in an easy-to-understand way, we ``wordify'' the hyperspectral images, i.e., we turn the images into a corpus of text documents. Then, we apply probabilistic topic models, a well-established natural language processing technique that identifies content and topics of documents. Based on recent regularized topic models, we demonstrate that one can track automatically the development of three foliar diseases of barley. We also present a visualization of the topics that provides plant scientists an intuitive tool for hyperspectral imaging. In short, our analysis and visualization of characteristic topics found during symptom development and disease progress reveal the hyperspectral language of plant diseases.},
  copyright = {2016 The Author(s)},
  langid = {english},
  keywords = {Data mining,High-throughput screening,Image processing,Plant sciences}
}

@article{walczynaEnhancingAnomalyDetection2025,
  title = {Enhancing {{Anomaly Detection Through Latent Space Manipulation}} in {{Autoencoders}}: {{A Comparative Analysis}}},
  shorttitle = {Enhancing {{Anomaly Detection Through Latent Space Manipulation}} in {{Autoencoders}}},
  author = {Walczyna, Tomasz and Jankowski, Damian and Piotrowski, Zbigniew},
  year = {2025},
  month = jan,
  journal = {Applied Sciences},
  volume = {15},
  number = {1},
  pages = {286},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-3417},
  doi = {10.3390/app15010286},
  urldate = {2025-01-05},
  abstract = {This article explores the practical implementation of autoencoders for anomaly detection, emphasizing their latent space manipulation and applicability across various domains. This study highlights the impact of optimizing parameter configurations, lightweight architectures, and training methodologies to enhance anomaly detection performance. A comparative analysis of autoencoders, Variational Autoencoders, and their modified counterparts was conducted within a tailored experimental environment designed to simulate real-world scenarios. The results demonstrate that these models, when fine-tuned, achieve significant improvements in detection accuracy, specificity, and sensitivity while maintaining computational efficiency. The findings underscore the importance of lightweight, practical models and the integration of streamlined training processes in developing effective anomaly detection systems. This study provides valuable insights into advancing machine learning methods for real-world applications and sets the stage for further refinement of autoencoder-based approaches.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {anomalies,autoencoders,deep learning,detection of anomalies,machine learning,neural networks}
}

@article{wangAdaptiveThresholdingAlgorithm2013,
  title = {An {{Adaptive Thresholding}} Algorithm of Field Leaf Image},
  author = {Wang, Jianlun and He, Jianlei and Han, Yu and Ouyang, Changqi and Li, Daoliang},
  year = {2013},
  month = aug,
  journal = {Computers and Electronics in Agriculture},
  volume = {96},
  pages = {23--39},
  issn = {0168-1699},
  doi = {10.1016/j.compag.2013.04.014},
  urldate = {2023-01-13},
  abstract = {In this paper, we analyze the background and foreground images of jujube leaf, and propose a new Adaptive Thresholding algorithm that can segment single leaves in a leaf image extracted randomly from an online system. We use the OTSU and CANNY operators to segment the area of the target leaf by choosing the thresholds with the Mapping Function, the Shape Identification algorithm and pattern recognition. The optimization process of the algorithm, which includes Mapping Function, the Shape Identification algorithm, morphological methods and logical operations, is designed to precisely obtain the entire leaf edge. This algorithm has an advantage when segmenting complicated leaf images that contain overlapping laminas and have an uneven gray scale in the leaf region itself. Experiments show that this algorithm is both feasible and effective in segmenting jujube leaf images from real-time video systems, and we can obtain clear, smooth, accurate edge images. The algorithm can be used for other kinds of leaf or fruit image segmentation tasks after debugging and improvement.},
  langid = {english},
  keywords = {Adaptive Thresholding,Image processing,Jujube leaf,Mapping Function,Online image,Segmentation algorithms},
  file = {/home/samuelebumbaca/Zotero/storage/SXECZ44H/S0168169913000884.html}
}

@article{wangCurveskeletonExtractionUsing2008,
  title = {Curve-Skeleton Extraction Using Iterative Least Squares Optimization},
  author = {Wang, Yu-Shuen and Lee, Tong-Yee},
  year = {2008},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {14},
  number = {4},
  pages = {926--936},
  publisher = {IEEE},
  urldate = {2024-06-10},
  file = {/home/samuelebumbaca/Zotero/storage/72LXEEW2/OpenURL.html}
}

@article{wangNonDestructiveMeasurementThreeDimensional2020,
  title = {Non-{{Destructive Measurement}} of {{Three-Dimensional Plants Based}} on {{Point Cloud}}},
  author = {Wang, Yawei and Chen, Yifei},
  year = {2020},
  month = apr,
  journal = {Plants},
  volume = {9},
  number = {5},
  pages = {571},
  issn = {2223-7747},
  doi = {10.3390/plants9050571},
  urldate = {2021-12-18},
  abstract = {In agriculture, information about the spatial distribution of plant growth is valuable for applications. Quantitative study of the characteristics of plants plays an important role in the plants' growth and development research, and non-destructive measurement of the height of plants based on machine vision technology is one of the difficulties. We propose a methodology for three-dimensional reconstruction under growing plants by Kinect v2.0 and explored the measure growth parameters based on three-dimensional (3D) point cloud in this paper. The strategy includes three steps---firstly, preprocessing 3D point cloud data, completing the 3D plant registration through point cloud outlier filtering and surface smooth method; secondly, using the locally convex connected patches method to segment the leaves and stem from the plant model; extracting the feature boundary points from the leaf point cloud, and using the contour extraction algorithm to get the feature boundary lines; finally, calculating the length, width of the leaf by Euclidean distance, and the area of the leaf by surface integral method, measuring the height of plant using the vertical distance technology. The results show that the automatic extraction scheme of plant information is effective and the measurement accuracy meets the need of measurement standard. The established 3D plant model is the key to study the whole plant information, which reduces the inaccuracy of occlusion to the description of leaf shape and conducive to the study of the real plant growth status.},
  langid = {english}
}

@article{wangSimplifiedEmpiricalLine2015,
  title = {A {{Simplified Empirical Line Method}} of {{Radiometric Calibration}} for {{Small Unmanned Aircraft Systems-Based Remote Sensing}}},
  author = {Wang, Chuyuan and Myint, Soe W.},
  year = {2015},
  month = may,
  journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  volume = {8},
  number = {5},
  pages = {1876--1885},
  issn = {2151-1535},
  doi = {10.1109/JSTARS.2015.2422716},
  abstract = {The use of small unmanned aircraft systems (sUAS) to acquire very high-resolution multispectral imagery has attracted growing attention recently; however, no systematic, feasible, and convenient radiometric calibration method has been specifically developed for sUAS remote sensing. In this research, we used a modified color infrared (CIR) digital single-lens reflex (DSLR) camera as the sensor and the DJI S800 hexacopter sUAS as the platform to collect imagery. Results show that the relationship between the natural logarithm of measured surface reflectance and image raw, unprocessed digital numbers (DNs) is linear and the y-intercept of the linear equation can be theoretically interpreted as the minimal possible surface reflectance that can be detected by each sensor waveband. The empirical line calibration equation for every single band image can be built using the y-intercept as one data point, and the natural log-transformed measured reflectance and image DNs of a gray calibration target as another point in the coordinate system. Image raw DNs are therefore converted to reflectance using the calibration equation. The Mann-Whitney U test results suggest that the difference between the measured and the predicted reflectance values of 13 tallgrass sampling quadrats is not statistically significant. The method theory developed in this study can be employed for other sUAS-based remote sensing applications.},
  keywords = {Calibration,Cameras,Earth,Empirical line,radiometric calibration,Radiometry,Remote sensing,Satellites,small unmanned aircraft systems (sUAS),Surface waves,very high resolution},
  file = {/home/samuelebumbaca/Zotero/storage/6LT8QAQF/7098353.html}
}

@article{wanRGBDPointCloud2021,
  title = {{{RGB-D Point Cloud Registration Based}} on {{Salient Object Detection}}},
  author = {Wan, Teng and Du, Shaoyi and Cui, Wenting and Yao, Runzhao and Ge, Yuyan and Li, Ce and Gao, Yue and Zheng, Nanning},
  year = {2021},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  pages = {1--13},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2021.3053274},
  urldate = {2021-12-19}
}

@article{wen3DPhytomerbasedGeometric2021,
  title = {{{3D}} Phytomer-Based Geometric Modelling Method for Plants---the Case of Maize},
  author = {Wen, Weiliang and Wang, Yongjian and Wu, Sheng and Liu, Kai and Gu, Shenghao and Guo, Xinyu},
  editor = {Buckley, Tom},
  year = {2021},
  month = oct,
  journal = {AoB PLANTS},
  volume = {13},
  number = {5},
  pages = {plab055},
  issn = {2041-2851},
  doi = {10.1093/aobpla/plab055},
  urldate = {2021-12-18},
  abstract = {Abstract              Geometric plant modelling is crucial in in silico plants. Existing geometric modelling methods have focused on the topological structure and basic organ profiles, simplifying the morphological features. However, the models cannot effectively differentiate cultivars, limiting FSPM application in crop breeding and management. This study proposes a 3D phytomer-based geometric modelling method with maize (Zea Mays) as the representative plant. Specifically, conversion methods between skeleton and mesh models of 3D phytomer are specified. This study describes the geometric modelling of maize shoots and populations by assembling 3D phytomers. Results show that the method can quickly and efficiently construct 3D models of maize plants and populations, with the ability to show morphological, structural and functional differences among four representative cultivars. The method takes into account both the geometric modelling efficiency and 3D detail features to achieve automatic operation of geometric modelling through the standardized description of 3D phytomers. Therefore, this study provides a theoretical and technical basis for the research and application of in silico plants.},
  langid = {english}
}

@article{wendelIlluminationCompensationGround2017,
  title = {Illumination Compensation in Ground Based Hyperspectral Imaging},
  author = {Wendel, Alexander and Underwood, James},
  year = {2017},
  month = jul,
  journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
  volume = {129},
  pages = {162--178},
  issn = {0924-2716},
  doi = {10.1016/j.isprsjprs.2017.04.010},
  urldate = {2023-01-13},
  abstract = {Hyperspectral imaging has emerged as an important tool for analysing vegetation data in agricultural applications. Recently, low altitude and ground based hyperspectral imaging solutions have come to the fore, providing very high resolution data for mapping and studying large areas of crops in detail. However, these platforms introduce a unique set of challenges that need to be overcome to ensure consistent, accurate and timely acquisition of data. One particular problem is dealing with changes in environmental illumination while operating with natural light under cloud cover, which can have considerable effects on spectral shape. In the past this has been commonly achieved by imaging known reference targets at the time of data acquisition, direct measurement of irradiance, or atmospheric modelling. While capturing a reference panel continuously or very frequently allows accurate compensation for illumination changes, this is often not practical with ground based platforms, and impossible in aerial applications. This paper examines the use of an autonomous unmanned ground vehicle (UGV) to gather high resolution hyperspectral imaging data of crops under natural illumination. A process of illumination compensation is performed to extract the inherent reflectance properties of the crops, despite variable illumination. This work adapts a previously developed subspace model approach to reflectance and illumination recovery. Though tested on a ground vehicle in this paper, it is applicable to low altitude unmanned aerial hyperspectral imagery also. The method uses occasional observations of reference panel training data from within the same or other datasets, which enables a practical field protocol that minimises in-field manual labour. This paper tests the new approach, comparing it against traditional methods. Several illumination compensation protocols for high volume ground based data collection are presented based on the results. The findings in this paper are applicable not only to robotics or agricultural applications, but most very low altitude or ground based hyperspectral sensors operating with natural light.},
  langid = {english},
  keywords = {Atmospheric correction,Ground based,Hyperspectral,Illumination compensation,Reflectance retrieval,Robotics}
}

@article{westPotentialOpticalCanopy2003,
  title = {The {{Potential}} of {{Optical Canopy Measurement}} for {{Targeted Control}} of {{Field Crop Diseases}}},
  author = {West, Jon and Bravo, Cedric and Oberti, Roberto and Lemaire, Dimitri and Moshou, Dimitrios and McCartney, H},
  year = {2003},
  month = feb,
  journal = {Annual review of phytopathology},
  volume = {41},
  pages = {593--614},
  doi = {10.1146/annurev.phyto.41.121702.103726},
  abstract = {There is increasing pressure to reduce the use of pesticides in modern crop production to decrease the environmental impact of current practice and to lower production costs. It is therefore imperative that sprays are only applied when and where needed. Since diseases in fields are frequently patchy, sprays may be applied unnecessarily to disease-free areas. Disease control could be more efficient if disease patches within fields could be identified and spray applied only to the infected areas. Recent developments in optical sensor technology have the potential to enable direct detection of foliar disease under field conditions. This review assesses recent developments in the use of optical methods for detecting foliar disease, evaluates the likely benefits of spatially selective disease control in field crops, and discusses practicalities and limitations of using optical disease detection systems for crop protection in precision pest management.}
}

@article{wuDetectionSegmentationMultiple2009,
  title = {Detection and {{Segmentation}} of {{Multiple}}, {{Partially Occluded Objects}} by {{Grouping}}, {{Merging}}, {{Assigning Part Detection Responses}}},
  author = {Wu, Bo and Nevatia, Ram},
  year = {2009},
  month = apr,
  journal = {International Journal of Computer Vision},
  volume = {82},
  number = {2},
  pages = {185--204},
  issn = {1573-1405},
  doi = {10.1007/s11263-008-0194-9},
  urldate = {2023-01-13},
  abstract = {We propose a method that detects and segments multiple, partially occluded objects in images. A part hierarchy is defined for the object class. Both the segmentation and detection tasks are formulated as binary classification problem. A whole-object segmentor and several part detectors are learned by boosting local shape feature based weak classifiers. Given a new image, the part detectors are applied to obtain a number of part responses. All the edge pixels in the image that positively contribute to the part responses are extracted. A joint likelihood of multiple objects is defined based on the part detection responses and the object edges. Computation of the joint likelihood includes an inter-object occlusion reasoning that is based on the object silhouettes extracted with the whole-object segmentor. By maximizing the joint likelihood, part detection responses are grouped, merged, and assigned to multiple object hypotheses. The proposed approach is demonstrated with the class of pedestrians. The experimental results show that our method outperforms the previous ones.},
  langid = {english},
  keywords = {Object detection,Object segmentation}
}

@article{wuResearchMaizeMultispectral2015,
  title = {{[Research on maize multispectral image accurate segmentation and chlorophyll index estimation]}},
  author = {Wu, Qian and Sun, Hong and Li, Min-zan and Song, Yuan-yuan and Zhang, Yan-e},
  year = {2015},
  month = jan,
  journal = {Guang Pu Xue Yu Guang Pu Fen Xi = Guang Pu},
  volume = {35},
  number = {1},
  pages = {178--183},
  issn = {1000-0593},
  abstract = {In order to rapidly acquire maize growing information in the field, a non-destructive method of maize chlorophyll content index measurement was conducted based on multi-spectral imaging technique and imaging processing technology. The experiment was conducted at Yangling in Shaanxi province of China and the crop was Zheng-dan 958 planted in about 1 000 m X 600 m experiment field. Firstly, a 2-CCD multi-spectral image monitoring system was available to acquire the canopy images. The system was based on a dichroic prism, allowing precise separation of the visible (Blue (B), Green (G), Red (R): 400-700 nm) and near-infrared (NIR, 760-1 000 nm) band. The multispectral images were output as RGB and NIR images via the system vertically fixed to the ground with vertical distance of 2 m and angular field of 50{$^\circ$}. SPAD index of each sample was'measured synchronously to show the chlorophyll content index. Secondly, after the image smoothing using adaptive smooth filtering algorithm, the NIR maize image was selected to segment the maize leaves from background, because there was a big difference showed in gray histogram between plant and soil background. The NIR image segmentation algorithm was conducted following steps of preliminary and accuracy segmentation: (1) The results of OTSU image segmentation method and the variable threshold algorithm were discussed. It was revealed that the latter was better one in corn plant and weed segmentation. As a result, the variable threshold algorithm based on local statistics was selected for the preliminary image segmentation. The expansion and corrosion were used to optimize the segmented image. (2) The region labeling algorithm was used to segment corn plants from soil and weed background with an accuracy of 95. 59 \%. And then, the multi-spectral image of maize canopy was accurately segmented in R, G and B band separately. Thirdly, the image parameters were abstracted based on the segmented visible and NIR images. The average gray value of each channel was calculated including red (ARed), green (AGreen), blue (ABlue), and near-infrared (ANIR). Meanwhile, the vegetation indices (NDVI (normalized difference vegetation index), RVI (ratio vegetation index); and NDGI(normalized difference green index)) which are widely used in remote sensing were applied. The chlorophyll index detecting model based on partial least squares regression method (PLSR) was built with detecting R2=0. 5960 and predicting R2= 0. 568 5. It was feasible to diagnose chlorophyll index of maize based on multi-spectral images.},
  langid = {chi},
  pmid = {25993844},
  keywords = {Algorithms,Chlorophyll,Least-Squares Analysis,Models Theoretical,Plant Leaves,Regression Analysis,Soil,Spectrum Analysis,Zea mays}
}

@book{wyattRadiometricCalibrationTheory2012,
  title = {Radiometric {{Calibration}}: {{Theory}} and {{Methods}}},
  shorttitle = {Radiometric {{Calibration}}},
  author = {Wyatt, Clair},
  year = {2012},
  month = dec,
  publisher = {Elsevier},
  abstract = {Approx.214 pages},
  googlebooks = {MDvdvecbTLoC},
  isbn = {978-0-323-16009-4},
  langid = {english},
  keywords = {Technology & Engineering / Sensors}
}

@article{yangAutomaticSkeletonExtraction2020,
  title = {Towards Automatic Skeleton Extraction with Skeleton Grafting},
  author = {Yang, Cong and Indurkhya, Bipin and See, John and Grzegorzek, Marcin},
  year = {2020},
  journal = {IEEE transactions on visualization and computer graphics},
  volume = {27},
  number = {12},
  pages = {4520--4532},
  publisher = {IEEE},
  urldate = {2024-06-10},
  file = {/home/samuelebumbaca/Zotero/storage/588PTXZL/OpenURL.html}
}

@inproceedings{yangDeepSpectralClustering2019,
  title = {Deep {{Spectral Clustering Using Dual Autoencoder Network}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Yang, Xu and Deng, Cheng and Zheng, Feng and Yan, Junchi and Liu, Wei},
  year = {2019},
  pages = {4066--4075},
  urldate = {2025-01-13}
}

@article{yanikogluAutomaticPlantIdentification2014,
  title = {Automatic Plant Identification from Photographs},
  author = {Yanikoglu, B. and Aptoula, E. and Tirkaz, C.},
  year = {2014},
  month = aug,
  journal = {Machine Vision and Applications},
  volume = {25},
  number = {6},
  pages = {1369--1383},
  issn = {1432-1769},
  doi = {10.1007/s00138-014-0612-7},
  urldate = {2023-01-13},
  abstract = {We present a plant identification system for automatically identifying the plant in a given image. In addition to common difficulties faced in object recognition, such as light, pose and orientation variations, there are further difficulties particular to this problem, such as changing leaf shapes according to plant age and changes in the overall shape due to leaf composition. Our system uses a rich variety of shape, texture and color features, some being specific to the plant domain. The system has achieved the best overall score in the ImageCLEF'12 plant identification campaign in both the automatic and human-assisted categories. We report the results of this system on the publicly available ImageCLEF'12 plant dataset, as well as the effectiveness of individual features. The results show 61 and 81~\% accuracies in classifying the 126 different plant species in the top-1 and top-5 choices.},
  langid = {english},
  keywords = {Color image segmentation,Leaf shape,Mathematical morphology,Plant identification}
}

@article{yenNewCriterionAutomatic1995,
  title = {A New Criterion for Automatic Multilevel Thresholding},
  author = {Yen, Jui-Cheng and Chang, Fu-Juay and Chang, Shyang},
  year = {1995},
  month = mar,
  journal = {IEEE Transactions on Image Processing},
  volume = {4},
  number = {3},
  pages = {370--378},
  issn = {1941-0042},
  doi = {10.1109/83.366472},
  abstract = {A new criterion for multilevel thresholding is proposed. The criterion is based on the consideration of two factors. The first one is the discrepancy between the thresholded and original images and the second one is the number of bits required to represent the thresholded image. Based on a new maximum correlation criterion for bilevel thresholding, the discrepancy is defined and then a cost function that takes both factors into account is proposed for multilevel thresholding. By minimizing the cost function, the classification number that the gray-levels should be classified and the threshold values can be determined automatically. In addition, the cost function is proven to possess a unique minimum under very mild conditions. Computational analyses indicate that the number of required mathematical operations in the implementation of our algorithm is much less than that of maximum entropy criterion. Finally, simulation results are included to demonstrate their effectiveness.{$<>$}},
  keywords = {Algorithm design and analysis,Analytical models,Application software,Computational complexity,Computational modeling,Computer industry,Cost function,Entropy,Image processing,Target recognition},
  file = {/home/samuelebumbaca/Zotero/storage/3796G8FE/366472.html}
}

@article{yinMultileafTrackingFluorescence2014,
  title = {Multi-Leaf Tracking from Fluorescence Plant Videos},
  author = {Yin, Xi and Liu, Xiaoming and Chen, Jin and Kramer, David M.},
  year = {2014},
  month = jan,
  journal = {2014 IEEE International Conference on Image Processing, ICIP 2014},
  series = {2014 {{IEEE International Conference}} on {{Image Processing}}, {{ICIP}} 2014},
  pages = {408--412},
  doi = {10.1109/ICIP.2014.7025081},
  urldate = {2023-01-13},
  abstract = {Driven by the plant phenotyping application, this paper proposes a new leaf tracking framework to jointly segment, align and track multiple leaves from fluorescence plant videos. Our framework consists of two steps. First, leaf alignment is applied to one video frame to generate a collection of leaf candidates. Second, we define a set of transformation parameters operated on the leaf candidates in order to optimize the alignment in the subsequent video frame according to an objective function. Gradient descent is employed to solve this optimization problem. Experimental results show that the proposed multi-leaf tracking algorithm is superior to the image-based leaf alignment method in terms of three quantitative metrics.},
  keywords = {alignment,Leaf tracking,multi-leaf}
}

@inproceedings{yogenderRoleGroundControl2020,
  title = {Role of {{Ground Control Points}} ({{GCPs}}) in {{Integration}} of {{Terrestrial Laser Scanner}} ({{TLS}}) and {{Close-range Photogrammetry}} ({{CRP}})},
  booktitle = {Applications of {{Geomatics}} in {{Civil Engineering}}},
  author = {{Yogender} and Raghavendra, S. and Kushwaha, S. K. P.},
  editor = {Ghosh, Jayanta Kumar and {da Silva}, Irineu},
  year = {2020},
  series = {Lecture {{Notes}} in {{Civil Engineering}}},
  pages = {531--537},
  publisher = {Springer},
  address = {Singapore},
  doi = {10.1007/978-981-13-7067-0_42},
  abstract = {The need for GCPs is increasingly more important with the increase in higher accuracy requirements and increase in user expectations. GCPs (Ground control points) are necessary for orientation and placement of photographs and 3D models in the spatial coordinate system, and they play a key role in co-registration of two point clouds. This paper deals with the assessment of the role of Ground Control Points in Co-registration of CRP and TLS point clouds by point-pair selection methodology and Automatic co-registration algorithm. In this work, the point cloud is generated from multiple overlapping sequences of images using Close-range Photogrammetry (CRP) and Terrestrial Laser Scanning (TLS) for a building over the planar surface. GCPs were collected by the total station to register the TLS and CRP point cloud. Overlapping photographs are processed in Agisoft PhotoScan software. TLS point cloud was generated from Riegl VZ 400 and GCPs were used to geo-reference it in Cloud Compare software. Various subsets of both point clouds are co-registered by the point-pair co-registration method and by Automatic point detection fine co-registration. Two subsets for each of CRP and TLS point cloud are considered in such a way that one is having some common overlap and other is having no common feature. GCPs registered point clouds integrate precisely as compared to that of the non-registered point cloud. The RMS error achieved in case of geo-referenced point cloud co-registration was 0.0091645433 m and in non-geo-referenced co-registration was found to be 0.03327466 m. In this study, it was also found that error is significantly higher in Automatic point detection method as compared to that of conventional point-pair selection co-registration. From this study, it is observed that higher accuracy of co-registration is achieved in the case of geo-referenced models by point-pair selection method. So, GCPs are the prerequisite for the effective and precise co-registration of 3D point clouds.},
  isbn = {978-981-13-7067-0},
  langid = {english},
  keywords = {Close-range photogrammetry,Co-registration,Geo-referencing,Ground control points,Point cloud,Terrestrial laser scanning}
}

@article{yonghuailiuAutomaticRangeImage2010,
  title = {Automatic {{Range Image Registration}} in the {{Markov Chain}}},
  author = {{Yonghuai Liu}},
  year = {2010},
  month = jan,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {32},
  number = {1},
  pages = {12--29},
  issn = {0162-8828},
  doi = {10.1109/TPAMI.2008.280},
  urldate = {2021-12-19}
}

@article{yonghuailiuPenalizingClosestPoint2011,
  title = {Penalizing {{Closest Point Sharing}} for {{Automatic Free Form Shape Registration}}},
  author = {{Yonghuai Liu}},
  year = {2011},
  month = may,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {33},
  number = {5},
  pages = {1058--1064},
  issn = {0162-8828},
  doi = {10.1109/TPAMI.2010.207},
  urldate = {2021-12-19}
}

@article{yuImageAnalysisPipeline2017,
  title = {An Image Analysis Pipeline for Automated Classification of Imaging Light Conditions and for Quantification of Wheat Canopy Cover Time Series in Field Phenotyping},
  author = {Yu, Kang and Kirchgessner, Norbert and Grieder, Christoph and Walter, Achim and Hund, Andreas},
  year = {2017},
  month = mar,
  journal = {Plant Methods},
  volume = {13},
  number = {1},
  pages = {15},
  issn = {1746-4811},
  doi = {10.1186/s13007-017-0168-4},
  urldate = {2023-01-13},
  abstract = {Robust segmentation of canopy cover (CC) from large amounts of images taken under different illumination/light conditions in the field is essential for high throughput field phenotyping (HTFP). We attempted to address this challenge by evaluating different vegetation indices and segmentation methods for analyzing images taken at varying illuminations throughout the early growth phase of wheat in the field. 40,000 images taken on 350 wheat genotypes in two consecutive years were assessed for this purpose.},
  langid = {english},
  keywords = {Canopy cover,Color vegetation index,High throughput field phenotyping,Image analysis,Image segmentation,Light contrast,Machine learning}
}

@inproceedings{yusongSurfaceModellingPlants2007,
  title = {Surface {{Modelling}} of {{Plants}} from {{Stereo Images}}},
  booktitle = {Sixth {{International Conference}} on 3-{{D Digital Imaging}} and {{Modeling}} ({{3DIM}} 2007)},
  author = {{Yu Song} and Wilson, R. and Edmondson, R. and Parsons, N.},
  year = {2007},
  month = aug,
  pages = {312--319},
  publisher = {IEEE},
  address = {Montreal, QC},
  doi = {10.1109/3DIM.2007.55},
  urldate = {2023-01-13},
  abstract = {Plants are characterised by a range of complex and variable attributes, and measuring these attributes accurately and reliably is a major challenge for the industry. In this paper, we investigate creating a surface model of plant from images taken by a stereo pair of cameras. The proposed modelling architecture comprises a fast stereo algorithm to estimate depths in the scene and a model of the scene based on visual appearance and 3D geometry measurements. Our stereo algorithm employs a coarse-fine strategy for disparity estimation. We develop a weighting method and use Kalman filter to refine estimations across scales. A selforganising map is applied to reconstruct a surface from these sample points created by the stereo algorithm. We compare and evaluate our stereo results against other popular stereo algorithms, and also demonstrate that the proposed surface model can be used to extract useful plant features that can be of importance in plant management and assessing quality for marketing.},
  isbn = {978-0-7695-2939-4},
  langid = {english}
}

@article{zackAutomaticMeasurementSister1977,
  title = {Automatic Measurement of Sister Chromatid Exchange Frequency.},
  author = {Zack, G W and Rogers, W E and Latt, S A},
  year = {1977},
  month = jul,
  journal = {Journal of Histochemistry \& Cytochemistry},
  volume = {25},
  number = {7},
  pages = {741--753},
  publisher = {Journal of Histochemistry \& Cytochemistry},
  issn = {0022-1554},
  doi = {10.1177/25.7.70454},
  urldate = {2023-01-25},
  abstract = {An automatic system for detecting and counting sister chromatid exchanges in human chromosomes has been developed. Metaphase chromosomes from lymphocytes which had incorporated 5-bromodeoxyuridine for two replication cycles were treated with the dye 33258 Hoechst and photodegraded so that the sister chromatids exhibited differential Giemsa staining. A computer-controlled television-microscope system was used to acquire digitized metaphase spread images by direct scanning of microscope slides. Individual objects in the images were identified by a thresholding procedure. The probability that each object was a single, separate chromosome was estimated from size and shape measurements. An analysis of the spatial relationships of the dark-chromatid regions of each object yielded a set of possible exchange locations and estimated probabilities that such locations corresponded to sister chromatid exchanges. A normalized estimate of the sister chromatid exchange frequency was obtained by summing the joint probabilities that a location contained an exchange within a single, separate chromosome over the set of chromosomes from one or more cells and dividing by the expected value of the total chromosome area analyzed. Comparison with manual scoring of exchanges showed satisfactory agreement up to levels of approximately 30 sister chromatid exchanges/cell, or slightly more than twice control levels. The processing time for this automated sister chromatid exchange detection system was comparable to that of manual scoring.},
  langid = {english}
}

@article{zaka-ud-dinClassificationDiseaseTomato2018,
  title = {Classification of {{Disease}} in {{Tomato Plants}}' {{Leaf Using Image Segmentation}} and {{SVM}}},
  author = {{Zaka-Ud-Din}, Muhammad and Adnan, Syed and Ahmad, Wakeel and Aziz, Sumair and Rashid, Junaid and Ismail, Waqar and Iqbal, Javed},
  year = {2018},
  month = aug,
  abstract = {Plant Disease recognition and classification play vital role in agriculture field. Product quality, quantity or productivity of plants is harshly affected by slight negligence in this domain. Huge amount of human work load for crops intensive care in vast farms can be reduced by automatic system accomplished of perceiving and classifying plant illnesses at early phases. This paper presents image processing framework for plant disease identification and classification. Our proposed workflow consists of three stages that are images segmentation, feature extraction and classification. For segmentation we use multithresholding then that of other common segmentation techniques. We used GLCM for feature extraction and Support Vector Machines for classification. We use GLCM texture feature as it gives pixel level information and SVM due to its robustness and optimality. Experiments were conducted on Tomato leaf dataset comprising of 4 different classes. Proposed framework achieved 98.3\% overall accuracy with 10- fold cross validation.}
}

@article{zhangDetectingPowderyMildew2012,
  title = {Detecting Powdery Mildew of Winter Wheat Using Leaf Level Hyperspectral Measurements},
  author = {Zhang, Jing-Cheng and Pu, Rui-liang and Wang, Ji-hua and Huang, Wen-jiang and Yuan, Lin and Luo, Ju-hua},
  year = {2012},
  month = jul,
  journal = {Computers and Electronics in Agriculture},
  volume = {85},
  pages = {13--23},
  issn = {0168-1699},
  doi = {10.1016/j.compag.2012.03.006},
  urldate = {2023-01-13},
  abstract = {Powdery mildew (Blumeria graminis) is one of the most destructive diseases, which has a significant impact on the production of winter wheat. Detecting powdery mildew via spectral measurement and analysis is a possible alternative to traditional methods in obtaining the spatial distribution information of the disease. In this study, hyperspectral reflectances of normal and powdery mildew infected leaves were measured with a spectroradiometer in a laboratory. A total of 32 spectral features (SFs) were extracted from the lab spectra and examined through a correlation analysis and an independent t-test associated with the disease severity. Two regression models: multivariate linear regression (MLR) and partial least square regression (PLSR) were developed for estimating the disease severity of powdery mildew. In addition, the fisher linear discriminant analysis (FLDA) was also adopted for discriminating the three healthy levels (normal, slightly-damaged and heavily-damaged) of powdery mildew with the extracted SFs. The experimental results indicated that (1) most SFs showed a clear response to powdery mildew; (2) for estimating the disease severity with SFs, the PLSR model outperformed the MLR model, with a relative root mean square error (RMSE) of 0.23 and a coefficient of determination (R2) of 0.80 when using seven components; (3) for discrimination analysis, a higher accuracy was produced for the heavily-damaged leaves by FLDA with both producer's and user's accuracies over 90\%; (4) the selected broad-band SFs revealed a great potential in estimating the disease severity and discriminating severity levels. The results imply that multispectral remote sensing is a cost effective method in the detection and mapping of powdery mildew.},
  langid = {english},
  keywords = {Cross validation,Fisher linear discriminate analysis (FLDA),Partial least square regression (PLSR),Powdery mildew,Spectral feature}
}

@article{zhangHighThroughputPhenotypingSeed2018,
  title = {High-{{Throughput Phenotyping}} of {{Seed}}/{{Seedling Evaluation Using Digital Image Analysis}}},
  author = {Zhang, Chongyuan and Si, Yongsheng and Lamkey, Jacob and Boydston, Rick and {Garland-Campbell}, Kimberly and Sankaran, Sindhuja},
  year = {2018},
  month = may,
  journal = {Agronomy},
  volume = {8},
  number = {5},
  pages = {63},
  issn = {2073-4395},
  doi = {10.3390/agronomy8050063},
  urldate = {2022-01-28},
  langid = {english}
}

@article{zhangPlantDiseaseLeaf2019,
  title = {Plant Disease Leaf Image Segmentation Based on Superpixel Clustering and {{EM}} Algorithm},
  author = {Zhang, Shanwen and You, Zhuhong and Wu, Xiaowei},
  year = {2019},
  month = feb,
  journal = {Neural Computing and Applications},
  volume = {31},
  number = {2},
  pages = {1225--1232},
  issn = {1433-3058},
  doi = {10.1007/s00521-017-3067-8},
  urldate = {2023-09-11},
  abstract = {Plant disease leaf image segmentation plays an important role in the plant disease detection through leaf symptoms. A novel segmentation method of plant disease leaf image is proposed based on a hybrid clustering. The whole color leaf image is firstly divided into a number of compact and nearly uniform superpixels by superpixel clustering, which can provide useful clustering cues to guide image segmentation to accelerate the convergence speed of the expectation maximization (EM) algorithm, and then, the lesion pixels are quickly and accurately segmented from each superpixel by EM algorithm. The experimental results and the comparison results with similar approaches demonstrate that the proposed method is effective and has high practical value for plant disease detection.},
  langid = {english},
  keywords = {EM algorithm,Plant disease detection,Plant disease leaf image segmentation,Superpixel clustering}
}

@article{zhangRobust3DPoint2018,
  title = {Robust {{3D}} Point Cloud Registration Based on Bidirectional {{Maximum Correntropy Criterion}}},
  author = {Zhang, Xuetao and Jian, Libo and Xu, Meifeng},
  editor = {Yang, You},
  year = {2018},
  month = may,
  journal = {PLOS ONE},
  volume = {13},
  number = {5},
  pages = {e0197542},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0197542},
  urldate = {2021-12-19},
  langid = {english}
}

@misc{zhongJianZhongDevVariationalAutoencoderPytorch2024,
  title = {{{JianZhongDev}}/{{VariationalAutoencoderPytorch}}},
  author = {Zhong, Jian},
  year = {2024},
  month = dec,
  urldate = {2025-01-05},
  abstract = {Quick guide on building and training variational autoencoder using Pytorch.},
  copyright = {GPL-3.0}
}

@article{zhouAccurateRobustNonrigid2018,
  title = {Accurate and {{Robust Non-rigid Point Set Registration}} Using {{Student}}'s-t {{Mixture Model}} with {{Prior Probability Modeling}}},
  author = {Zhou, Zhiyong and Tu, Jianfei and Geng, Chen and Hu, Jisu and Tong, Baotong and Ji, Jiansong and Dai, Yakang},
  year = {2018},
  month = dec,
  journal = {Scientific Reports},
  volume = {8},
  number = {1},
  pages = {8742},
  issn = {2045-2322},
  doi = {10.1038/s41598-018-26288-6},
  urldate = {2021-12-19},
  langid = {english}
}

@incollection{zhouAutomaticSegmentationMultiple2020,
  title = {Automatic {{Segmentation}} of {{Multiple Organs}} on {{3D CT Images}} by {{Using Deep Learning Approaches}}},
  booktitle = {Deep {{Learning}} in {{Medical Image Analysis}}},
  author = {Zhou, Xiangrong},
  editor = {Lee, Gobert and Fujita, Hiroshi},
  year = {2020},
  volume = {1213},
  pages = {135--147},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-33128-3_9},
  urldate = {2021-12-18},
  isbn = {978-3-030-33127-6 978-3-030-33128-3},
  langid = {english}
}

@article{zhouComprehensiveSurveyDeep2024,
  title = {A {{Comprehensive Survey}} on {{Deep Clustering}}: {{Taxonomy}}, {{Challenges}}, and {{Future Directions}}},
  shorttitle = {A {{Comprehensive Survey}} on {{Deep Clustering}}},
  author = {Zhou, Sheng and Xu, Hongjia and Zheng, Zhuonan and Chen, Jiawei and Li, Zhao and Bu, Jiajun and Wu, Jia and Wang, Xin and Zhu, Wenwu and Ester, Martin},
  year = {2024},
  month = nov,
  journal = {ACM Comput. Surv.},
  volume = {57},
  number = {3},
  pages = {69:1--69:38},
  issn = {0360-0300},
  doi = {10.1145/3689036},
  urldate = {2025-01-13},
  abstract = {Clustering is a fundamental machine learning task, which aim at assigning instances into groups so that similar samples belong to the same cluster while dissimilar samples belong to different clusters. Shallow clustering methods usually assume that data are collected and expressed as feature vectors within which clustering is performed. However, clustering high-dimensional data, such as images, texts, videos, and graphs, poses significant challenges for clustering tasks, such as indiscriminate representation and intricate relationships among instances. Over the past decades, deep learning has achieved remarkable success in effective representation learning and modeling complex relationships. Motivated by these advancements, Deep Clustering seeks to improve clustering outcomes through deep learning techniques, garnering considerable interest from both academia and industry. Despite many contributions to this vibrant area of research, the lack of systematic analysis and a comprehensive taxonomy has hindered progress in this field. In this survey, we first explore how deep learning can be integrated into deep clustering and identify two fundamental components: the representation learning module and the clustering module. Then, we summarize and analyze the representative design of these two modules. Furthermore, we introduce a novel taxonomy of deep clustering based on how these two modules interact, specifically through multistage, generative, iterative, and simultaneous approaches. In addition, we present well-known benchmark datasets, evaluation metrics, and open-source tools to clearly demonstrate different experimental approaches. Finally, we examine the practical applications of deep clustering and propose challenging areas for future research.}
}

@article{zhouEvaluatingGeometricMeasurement2018,
  title = {Evaluating {{Geometric Measurement Accuracy Based}} on {{3D Reconstruction}} of {{Automated Imagery}} in a {{Greenhouse}}},
  author = {Zhou, Jing and Fu, Xiuqing and Schumacher, Leon and Zhou, Jianfeng},
  year = {2018},
  month = jul,
  journal = {Sensors},
  volume = {18},
  number = {7},
  pages = {2270},
  doi = {10.3390/s18072270},
  urldate = {2021-12-22},
  abstract = {Geometric dimensions of plants are significant parameters for showing plant dynamic responses to environmental variations. An image-based high-throughput phenotyping platform was developed to automatically measure geometric dimensions of plants in a greenhouse. The goal of this paper was to evaluate the accuracy in geometric measurement using the Structure from Motion (SfM) method from images acquired using the automated image-based platform. Images of nine artificial objects of different shapes were taken under 17 combinations of three different overlaps in x and y directions, respectively, and two different spatial resolutions (SRs) with three replicates. Dimensions in x, y and z of these objects were measured from 3D models reconstructed using the SfM method to evaluate the geometric accuracy. A metric power of unit (POU) was proposed to combine the effects of image overlap and SR. Results showed that measurement error of dimension in z is the least affected by overlap and SR among the three dimensions and measurement error of dimensions in x and y increased following a power function with the decrease of POU (R2 = 0.78 and 0.88 for x and y respectively). POUs from 150 to 300 are a preferred range to obtain reasonable accuracy and efficiency for the developed image-based high-throughput phenotyping system. As a study case, the developed system was used to measure the height of 44 plants using an optimal POU in greenhouse environment. The results showed a good agreement (R2 = 92\% and Root Mean Square Error = 9.4 mm) between the manual and automated method.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {3D model reconstruction,geometric accuracy,high-throughput phenotyping,processing efficiency,structure from motion}
}

@article{zhouHIDESComputerBasedHerbicide2005,
  title = {{{HIDES}}: {{A Computer-Based Herbicide Injury Diagnostic Expert System}}},
  shorttitle = {{{HIDES}}},
  author = {Zhou, Jingkai and Messersmith, Calvin G. and Harrington, Janet D.},
  year = {2005},
  journal = {Weed Technology},
  volume = {19},
  number = {2},
  eprint = {3989738},
  eprinttype = {jstor},
  pages = {486--491},
  publisher = {[Cambridge University Press, Weed Science Society of America]},
  issn = {0890-037X},
  urldate = {2023-08-18},
  abstract = {Diagnosis of herbicide injury can be complex because of the large number and interaction of factors leading to herbicide injury. Computer-based expert systems have great potential to assist users, particularly nonexperts, in accurate diagnosis of herbicide injury. Rule-based and case-based reasoning are the most widely used forms of expert systems, and each system has strengths and limitations. Approaches that integrate rule-based and case-based reasoning may augment the positive aspects of the two reasoning methods and simultaneously minimize their negative aspects. The Herbicide Injury Diagnostic Expert System (HIDES) integrates rule-based and case-based reasoning and uses field-specific information, injury symptoms, herbicide use history, and herbicide information to diagnose crop injury from herbicides. The HIDES program uses a set of rules to identify suspect herbicide(s) that is the candidate for causing the observed injury and possible sources of the suspect herbicide(s). Case-based reasoning is used to propose a probable cause of injury by making an analogy to previously solved cases. A four-step procedure is followed when using HIDES: information collection, suspect herbicide identification, suspect herbicide source determination, injury reason suggestion, and knowledge accumulation.}
}

@article{zhouRGBDSalientObject2021,
  title = {{{RGB-D}} Salient Object Detection: {{A}} Survey},
  shorttitle = {{{RGB-D}} Salient Object Detection},
  author = {Zhou, Tao and Fan, Deng-Ping and Cheng, Ming-Ming and Shen, Jianbing and Shao, Ling},
  year = {2021},
  month = mar,
  journal = {Computational Visual Media},
  volume = {7},
  number = {1},
  pages = {37--69},
  issn = {2096-0433, 2096-0662},
  doi = {10.1007/s41095-020-0199-z},
  urldate = {2021-12-19},
  abstract = {Abstract                              Salient object detection, which simulates human visual perception in locating the most significant object(s) in a scene, has been widely applied to various computer vision tasks. Now, the advent of depth sensors means that depth maps can easily be captured; this additional spatial information can boost the performance of salient object detection. Although various RGB-D based salient object detection models with promising performance have been proposed over the past several years, an in-depth understanding of these models and the challenges in this field remains lacking. In this paper, we provide a comprehensive survey of RGB-D based salient object detection models from various perspectives, and review related benchmark datasets in detail. Further, as light fields can also provide depth maps, we review salient object detection models and popular benchmark datasets from this domain too. Moreover, to investigate the ability of existing models to detect salient objects, we have carried out a comprehensive attribute-based evaluation of several representative RGB-D based salient object detection models. Finally, we discuss several challenges and open directions of RGB-D based salient object detection for future research. All collected models, benchmark datasets, datasets constructed for attribute-based evaluation, and related code are publicly available at                https://github.com/taozh2017/RGBD-SODsurvey                .},
  langid = {english}
}

@article{zhuRegistrationMultiViewPoint2020,
  title = {Registration of {{Multi-View Point Sets Under}} the {{Perspective}} of {{Expectation-Maximization}}},
  author = {Zhu, Jihua and Guo, Rui and Li, Zhongyu and Zhang, Jing and Pang, Shanmin},
  year = {2020},
  journal = {IEEE Transactions on Image Processing},
  volume = {29},
  pages = {9176--9189},
  issn = {1057-7149, 1941-0042},
  doi = {10.1109/TIP.2020.3024096},
  urldate = {2021-12-19}
}

@article{zhuReviewPointSet2019,
  title = {A {{Review}} of {{Point Set Registration}}: {{From Pairwise Registration}} to {{Groupwise Registration}}},
  shorttitle = {A {{Review}} of {{Point Set Registration}}},
  author = {Zhu, Hao and Guo, Bin and Zou, Ke and Li, Yongfu and Yuen, Ka-Veng and Mihaylova, Lyudmila and Leung, Henry},
  year = {2019},
  month = mar,
  journal = {Sensors},
  volume = {19},
  number = {5},
  pages = {1191},
  issn = {1424-8220},
  doi = {10.3390/s19051191},
  urldate = {2021-12-19},
  abstract = {This paper presents a comprehensive literature review on point set registration. The state-of-the-art modeling methods and algorithms for point set registration are discussed and summarized. Special attention is paid to methods for pairwise registration and groupwise registration. Some of the most prominent representative methods are selected to conduct qualitative and quantitative experiments. From the experiments we have conducted on 2D and 3D data, CPD-GL pairwise registration algorithm and JRMPC groupwise registration algorithm seem to outperform their rivals both in accuracy and computational complexity. Furthermore, future research directions and avenues in the area are identified.},
  langid = {english}
}

@article{ziamtsovMachineLearningApproaches2019,
  title = {Machine {{Learning Approaches}} to {{Improve Three Basic Plant Phenotyping Tasks Using Three-Dimensional Point Clouds}}},
  author = {Ziamtsov, Illia and Navlakha, Saket},
  year = {2019},
  month = dec,
  journal = {Plant Physiology},
  volume = {181},
  number = {4},
  pages = {1425--1440},
  issn = {0032-0889, 1532-2548},
  doi = {10.1104/pp.19.00524},
  urldate = {2021-12-18},
  langid = {english}
}

@article{ziamtsovPlant3DP3D2020,
  title = {Plant {{3D}} ({{P3D}}): A Plant Phenotyping Toolkit for {{3D}} Point Clouds},
  shorttitle = {Plant {{3D}} ({{P3D}})},
  author = {Ziamtsov, Illia and Navlakha, Saket},
  editor = {Xu, Jinbo},
  year = {2020},
  month = jun,
  journal = {Bioinformatics},
  volume = {36},
  number = {12},
  pages = {3949--3950},
  issn = {1367-4803, 1460-2059},
  doi = {10.1093/bioinformatics/btaa220},
  urldate = {2021-12-18},
  abstract = {Abstract                              Motivation                Developing methods to efficiently analyze 3D point cloud data of plant architectures remain challenging for many phenotyping applications. Here, we describe a tool that tackles four core phenotyping tasks: classification of cloud points into stem and lamina points, graph skeletonization of the stem points, segmentation of individual lamina and whole leaf labeling. These four tasks are critical for numerous downstream phenotyping goals, such as quantifying plant biomass, performing morphological analyses of plant shapes and uncovering genotype to phenotype relationships. The Plant 3D tool provides an intuitive graphical user interface, a fast 3D rendering engine for visualizing plants with millions of cloud points, and several graph-theoretic and machine-learning algorithms for 3D architecture analyses.                                            Availability and implementation                P3D is open-source and implemented in C++. Source code and Windows installer are freely available at https://github.com/iziamtso/P3D/.                                            Contact                iziamtso@ucsd.edu or navlakha@cshl.edu                                            Supplementary information                Supplementary data are available at Bioinformatics online.},
  langid = {english}
}

@article{zilvanConvolutionalVariationalAutoencoderbased2022,
  title = {Convolutional Variational Autoencoder-Based Feature Learning for Automatic Tea Clone Recognition},
  author = {Zilvan, Vicky and Ramdan, Ade and Heryana, Ana and Krisnandi, Dikdik and Suryawati, Endang and Yuwana, R. Sandra and Kusumo, R. Budiarianto S. and Pardede, Hilman F.},
  year = {2022},
  month = jun,
  journal = {Journal of King Saud University - Computer and Information Sciences},
  volume = {34},
  number = {6, Part B},
  pages = {3332--3342},
  issn = {1319-1578},
  doi = {10.1016/j.jksuci.2021.01.020},
  urldate = {2025-01-05},
  abstract = {It is common to have various clones from cross-seedlings or unintended planting by the farmers in a tea plantation. Since each tea clone has distinctive features such as quality, resistance to diseases, etc., visual inspections are usually conducted on the plantations to segment areas with different tea clones within the plantation to produce crops with consistent quality. However, this would be costly and time-consuming. In this work, we apply machine learning and develop an application to recognize tea clones automatically. We propose a convolutional variational autoencoder-based feature learning algorithm to produce robust features against data distortions. There are two main advantages of using this algorithm for feature learning. First, there is no need to design complex handcrafted features for classifications, usually conducted in machine learning. Second, the resulting features are more robust when tested with data taken from unideal conditions. The proposed method is evaluated using the original and the distorted image. Our proposed method achieves the best performance of 0.83 (83\%) for the original image test, 0.75 (75\%) for the gaussian blur image test, and 0.78 (78\%) for the median blur image test. This is a much more robust result than VGGNet16, a popular supervised deep convolutional neural network.},
  keywords = {Convolutional variational autoencoder,Deep learning,Feature learning,Tea clones recognition}
}

@misc{ZoteroYourPersonal,
  title = {Zotero {\textbar} {{Your}} Personal Research Assistant},
  urldate = {2022-09-06},
  howpublished = {https://www.zotero.org/},
  file = {/home/samuelebumbaca/Zotero/storage/ZW7HUUKG/www.zotero.org.html}
}

@article{zouDegreesFreedomLasso2007,
  title = {On the ``Degrees of Freedom'' of the Lasso},
  author = {Zou, Hui and Hastie, Trevor and Tibshirani, Robert},
  year = {2007},
  month = oct,
  journal = {The Annals of Statistics},
  volume = {35},
  number = {5},
  pages = {2173--2192},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/009053607000000127},
  urldate = {2025-03-16},
  abstract = {We study the effective degrees of freedom of the lasso in the framework of Stein's unbiased risk estimation (SURE). We show that the number of nonzero coefficients is an unbiased estimate for the degrees of freedom of the lasso---a conclusion that requires no special assumption on the predictors. In addition, the unbiased estimator is shown to be asymptotically consistent. With these results on hand, various model selection criteria---Cp, AIC and BIC---are available, which, along with the LARS algorithm, provide a principled and efficient approach to obtaining the optimal lasso fit with the computational effort of a single ordinary least-squares fit.},
  keywords = {62J05,62J07,90C46,Degrees of freedom,LARS algorithm,Lasso,Model selection,SURE,unbiased estimate},
  file = {/home/samuelebumbaca/Zotero/storage/XGIPBUA2/Zou et al. - 2007 - On the “degrees of freedom” of the lasso.pdf}
}
