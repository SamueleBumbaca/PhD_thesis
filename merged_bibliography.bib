@book{agrestiIntroductionCategoricalData2018,
  title = {An {{Introduction}} to {{Categorical Data Analysis}}},
  author = {Agresti, Alan},
  year = {2018},
  month = nov,
  publisher = {John Wiley \& Sons},
  abstract = {A valuable new edition of a standard reference The use of statistical methods for categorical data has increased dramatically, particularly for applications in the biomedical and social sciences. An Introduction to Categorical Data Analysis, Third Edition summarizes these methods and shows readers how to use them using software. Readers will find a unified generalized linear models approach that connects logistic regression and loglinear models for discrete data with normal regression for continuous data. Adding to the value in the new edition is: {$\bullet$} Illustrations of the use of R software to perform all the analyses in the book {$\bullet$} A new chapter on alternative methods for categorical data, including smoothing and regularization methods (such as the lasso), classification methods such as linear discriminant analysis and classification trees, and cluster analysis {$\bullet$} New sections in many chapters introducing the Bayesian approach for the methods of that chapter {$\bullet$} More than 70 analyses of data sets to illustrate application of the methods, and about 200 exercises, many containing other data sets {$\bullet$} An appendix showing how to use SAS, Stata, and SPSS, and an appendix with short solutions to most odd-numbered exercises Written in an applied, nontechnical style, this book illustrates the methods using a wide variety of real data, including medical clinical trials, environmental questions, drug use by teenagers, horseshoe crab mating, basketball shooting, correlates of happiness, and much more. An Introduction to Categorical Data Analysis, Third Edition is an invaluable tool for statisticians and biostatisticians as well as methodologists in the social and behavioral sciences, medicine and public health, marketing, education, and the biological and agricultural sciences.},
  googlebooks = {ukNxDwAAQBAJ},
  isbn = {978-1-119-40526-9},
  langid = {english},
  keywords = {Mathematics / General,Mathematics / Probability & Statistics / General,Mathematics / Probability & Statistics / Stochastic Processes}
}

@article{agresti_exact_2001,
	title = {Exact inference for categorical data: recent advances and continuing controversies},
	volume = {20},
	copyright = {Copyright © 2001 John Wiley \& Sons, Ltd.},
	issn = {1097-0258},
	shorttitle = {Exact inference for categorical data},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.738},
	doi = {10.1002/sim.738},
	abstract = {Methods for exact small-sample analyses with categorical data have been increasingly well developed in recent years. A variety of exact methods exist, primarily using the approach that eliminates unknown parameters by conditioning on their sufficient statistics. In addition, a variety of algorithms now exist for implementing the methods. This paper briefly summarizes the exact approaches and describes recent developments. Controversy continues about the appropriateness of some exact methods, primarily relating to their conservative nature because of discreteness. This issue is examined for two simple problems in which discreteness can be severe – interval estimation of a proportion and the odds ratio. In general, adjusted exact methods based on the mid-P-value seem a reasonable way of reducing the severity of this problem. Copyright © 2001 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {17-18},
	urldate = {2025-06-29},
	journal = {Statistics in Medicine},
	author = {Agresti, Alan},
	year = {2001},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.738},
	pages = {2709--2722},
}

@article{alomStateoftheArtSurveyDeep2019,
  title = {A {{State-of-the-Art Survey}} on {{Deep Learning Theory}} and {{Architectures}}},
  author = {Alom, Md Zahangir and Taha, Tarek M. and Yakopcic, Chris and Westberg, Stefan and Sidike, Paheding and Nasrin, Mst Shamima and Hasan, Mahmudul and Van Essen, Brian C. and Awwal, Abdul A. S. and Asari, Vijayan K.},
  year = {2019},
  month = mar,
  journal = {Electronics},
  volume = {8},
  number = {3},
  pages = {292},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2079-9292},
  doi = {10.3390/electronics8030292},
  urldate = {2025-03-30},
  abstract = {In recent years, deep learning has garnered tremendous success in a variety of application domains. This new field of machine learning has been growing rapidly and has been applied to most traditional application domains, as well as some new areas that present more opportunities. Different methods have been proposed based on different categories of learning, including supervised, semi-supervised, and un-supervised learning. Experimental results show state-of-the-art performance using deep learning when compared to traditional machine learning approaches in the fields of image processing, computer vision, speech recognition, machine translation, art, medical imaging, medical information processing, robotics and control, bioinformatics, natural language processing, cybersecurity, and many others. This survey presents a brief survey on the advances that have occurred in the area of Deep Learning (DL), starting with the Deep Neural Network (DNN). The survey goes on to cover Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), including Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRU), Auto-Encoder (AE), Deep Belief Network (DBN), Generative Adversarial Network (GAN), and Deep Reinforcement Learning (DRL). Additionally, we have discussed recent developments, such as advanced variant DL techniques based on these DL approaches. This work considers most of the papers published after 2012 from when the history of deep learning began. Furthermore, DL approaches that have been explored and evaluated in different application domains are also included in this survey. We also included recently developed frameworks, SDKs, and benchmark datasets that are used for implementing and evaluating deep learning approaches. There are some surveys that have been published on DL using neural networks and a survey on Reinforcement Learning (RL). However, those papers have not discussed individual advanced techniques for training large-scale deep learning models and the recently developed method of generative models.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {auto-encoder (AE),convolutional neural network (CNN),deep belief network (DBN),deep learning,deep reinforcement learning (DRL),generative adversarial network (GAN),recurrent neural network (RNN),restricted Boltzmann machine (RBM),transfer learning}
}

@article{araujoMachineLearningApplications2023,
  title = {Machine {{Learning Applications}} in {{Agriculture}}: {{Current Trends}}, {{Challenges}}, and {{Future Perspectives}}},
  shorttitle = {Machine {{Learning Applications}} in {{Agriculture}}},
  author = {Ara{\'u}jo, Sara Oleiro and Peres, Ricardo Silva and Ramalho, Jos{\'e} Cochicho and Lidon, Fernando and Barata, Jos{\'e}},
  year = {2023},
  month = dec,
  journal = {Agronomy},
  volume = {13},
  number = {12},
  pages = {2976},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2073-4395},
  doi = {10.3390/agronomy13122976},
  urldate = {2025-03-30},
  abstract = {Progress in agricultural productivity and sustainability hinges on strategic investments in technological research. Evolving technologies such as the Internet of Things, sensors, robotics, Artificial Intelligence, Machine Learning, Big Data, and Cloud Computing are propelling the agricultural sector towards the transformative Agriculture 4.0 paradigm. The present systematic literature review employs the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) methodology to explore the usage of Machine Learning in agriculture. The study investigates the foremost applications of Machine Learning, including crop, water, soil, and animal management, revealing its important role in revolutionising traditional agricultural practices. Furthermore, it assesses the substantial impacts and outcomes of Machine Learning adoption and highlights some challenges associated with its integration in agricultural systems. This review not only provides valuable insights into the current landscape of Machine Learning applications in agriculture, but it also outlines promising directions for future research and innovation in this rapidly evolving field.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {Agriculture 4.0,machine learning,PRISMA,systematic reviews and meta analytics}
}

@article{arnalbarbedoDigitalImageProcessing2013,
  title = {Digital Image Processing Techniques for Detecting, Quantifying and Classifying Plant Diseases},
  author = {Arnal Barbedo, Jayme Garcia},
  year = {2013},
  month = dec,
  journal = {SpringerPlus},
  volume = {2},
  number = {1},
  pages = {660},
  issn = {2193-1801},
  doi = {10.1186/2193-1801-2-660},
  urldate = {2025-03-26},
  abstract = {This paper presents a survey on methods that use digital image processing techniques to detect, quantify and classify plant diseases from digital images in the visible spectrum. Although disease symptoms can manifest in any part of the plant, only methods that explore visible symptoms in leaves and stems were considered. This was done for two main reasons: to limit the length of the paper and because methods dealing with roots, seeds and fruits have some peculiarities that would warrant a specific survey. The selected proposals are divided into three classes according to their objective: detection, severity quantification, and classification. Each of those classes, in turn, are subdivided according to the main technical solution used in the algorithm. This paper is expected to be useful to researchers working both on vegetable pathology and pattern recognition, providing a comprehensive and accessible overview of this important field of research.},
  langid = {english},
  keywords = {Diseased Region,Powdery Mildew,Radial Basis Function,Texture Feature}
}

@article{barbedoAutomaticMethodDetect2014,
  title = {An {{Automatic Method}} to {{Detect}} and {{Measure Leaf Disease Symptoms Using Digital Image Processing}}},
  author = {Barbedo, Jayme Garcia Arnal},
  year = {2014},
  month = dec,
  journal = {Plant Disease},
  volume = {98},
  number = {12},
  pages = {1709--1716},
  publisher = {Scientific Societies},
  issn = {0191-2917},
  doi = {10.1094/PDIS-03-14-0290-RE},
  urldate = {2025-03-26},
  abstract = {A method is presented to detect and quantify leaf symptoms using conventional color digital images. The method was designed to be completely automatic, eliminating the possibility of human error and reducing time taken to measure disease severity. The program is capable of dealing with images containing multiple leaves, further reducing the time taken. Accurate results are possible when the symptoms and leaf veins have similar color and shade characteristics. The algorithm is subject to one constraint: the background must be as close to white or black as possible. Tests showed that the method provided accurate estimates over a wide variety of conditions, being robust to variation in size, shape, and color of leaves; symptoms; and leaf veins. Low rates of false positives and false negatives occurred due to extrinsic factors such as issues with image capture and the use of extreme file compression ratios.}
}

@article{barbedoFactorsInfluencingUse2018,
  title = {Factors Influencing the Use of Deep Learning for Plant Disease Recognition},
  author = {Barbedo, Jayme G. A.},
  year = {2018},
  month = aug,
  journal = {Biosystems Engineering},
  volume = {172},
  pages = {84--91},
  issn = {1537-5110},
  doi = {10.1016/j.biosystemseng.2018.05.013},
  urldate = {2025-03-23},
  abstract = {Deep learning is quickly becoming one of the most important tools for image classification. This technology is now beginning to be applied to the tasks of plant disease classification and recognition. The positive results that are being obtained using this approach hide some issues that are seldom taken into account in the respective experiments. This article presents an investigation into the main factors that affect the design and effectiveness of deep neural nets applied to plant pathology. An in-depth analysis of the subject, in which advantages and shortcomings are highlighted, should lead to more realistic conclusions on the subject. The arguments used throughout the text are built upon both studies found in the literature and experiments carried out using an image database carefully built to reflect and reproduce many of the conditions expected to be found in practice. This database, which contains almost 50,000 images, is being made freely available for academic purposes.},
  keywords = {Deep neural nets,Disease classification,Image database,Image processing,Transfer learning}
}

@article{baySpeededUpRobustFeatures2008,
  title = {Speeded-{{Up Robust Features}} ({{SURF}})},
  author = {Bay, Herbert and Ess, Andreas and Tuytelaars, Tinne and Van Gool, Luc},
  year = {2008},
  month = jun,
  journal = {Computer Vision and Image Understanding},
  series = {Similarity {{Matching}} in {{Computer Vision}} and {{Multimedia}}},
  volume = {110},
  number = {3},
  pages = {346--359},
  issn = {1077-3142},
  doi = {10.1016/j.cviu.2007.09.014},
  urldate = {2025-03-29},
  abstract = {This article presents a novel scale- and rotation-invariant detector and descriptor, coined SURF (Speeded-Up Robust Features). SURF approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster. This is achieved by relying on integral images for image convolutions; by building on the strengths of the leading existing detectors and descriptors (specifically, using a Hessian matrix-based measure for the detector, and a distribution-based descriptor); and by simplifying these methods to the essential. This leads to a combination of novel detection, description, and matching steps. The paper encompasses a detailed description of the detector and descriptor and then explores the effects of the most important parameters. We conclude the article with SURF's application to two challenging, yet converse goals: camera calibration as a special case of image registration, and object recognition. Our experiments underline SURF's usefulness in a broad range of topics in computer vision.},
  keywords = {Camera calibration,Feature description,Interest points,Local features,Object recognition}
}

@article{berryResistedRiseRandomisation2015,
  title = {The Resisted Rise of Randomisation in Experimental Design: {{British}} Agricultural Science, c.1910-1930},
  shorttitle = {The Resisted Rise of Randomisation in Experimental Design},
  author = {Berry, Dominic},
  year = {2015},
  month = sep,
  journal = {History and Philosophy of the Life Sciences},
  volume = {37},
  number = {3},
  pages = {242--260},
  issn = {0391-9714},
  doi = {10.1007/s40656-015-0076-8},
  abstract = {The most conspicuous form of agricultural experiment is the field trial, and within the history of such trials, the arrival of the randomised control trial (RCT) is considered revolutionary. Originating with R.A. Fisher within British agricultural science in the 1920s and 1930s, the RCT has since become one of the most prodigiously used experimental techniques throughout the natural and social sciences. Philosophers of science have already scrutinised the epistemological uniqueness of RCTs, undermining their status as the 'gold standard' in experimental design. The present paper introduces a historical case study from the origins of the RCT, uncovering the initially cool reception given to this method by agricultural scientists at the University of Cambridge and the (Cambridge based) National Institute of Agricultural Botany. Rather than giving further attention to the RCT, the paper focuses instead on a competitor method-the half-drill strip-which both predated the RCT and remained in wide use for at least a decade beyond the latter's arrival. In telling this history, John Pickstone's Ways of Knowing is adopted, as the most flexible and productive way to write the history of science, particularly when sciences and scientists have to work across a number of different kinds of place. It is shown that those who resisted the RCT did so in order to preserve epistemic and social goals that randomisation would have otherwise run a tractor through.},
  langid = {english},
  pmid = {26205200},
  keywords = {Agriculture,History 20th Century,Randomized Controlled Trials as Topic,Research Design,United Kingdom}
}

@article{bockPhytopathometryGlossaryTwentyfirst2022,
  title = {A Phytopathometry Glossary for the Twenty-First Century: Towards Consistency and Precision in Intra- and Inter-Disciplinary Dialogues},
  shorttitle = {A Phytopathometry Glossary for the Twenty-First Century},
  author = {Bock, Clive H. and Pethybridge, Sarah J. and Barbedo, Jayme G. A. and Esker, Paul D. and Mahlein, Anne-Katrin and Del Ponte, Emerson M.},
  year = {2022},
  month = feb,
  journal = {Tropical Plant Pathology},
  volume = {47},
  number = {1},
  pages = {14--24},
  issn = {1983-2052},
  doi = {10.1007/s40858-021-00454-0},
  urldate = {2025-03-26},
  abstract = {Phytopathometry can be defined as the branch of plant pathology (phytopathology) that is concerned with estimation or measurement of the amount of plant disease expressed by symptoms of disease or signs of a pathogen on a single or group of specimens. Phytopathometry is critical for many reasons, including analyzing yield loss due to disease, breeding for disease resistance, evaluating and comparing disease control methods, understanding coevolution, and studying disease epidemiology and pathogen ecology. Phytopathometry underpins all activities in plant pathology and extends into related disciplines, such as agronomy, horticulture, and plant breeding. Considering this central role, phytopathometry warrants status as a formally recognized branch of plant pathology. The glossary defines terms and concepts used in phytopathometry based on disease symptoms or visible pathogen structures and includes those terms commonly used in the visual estimation of disease severity and sensor-based methods of disease measurement. Relevant terms from the intersecting disciplines of measurement science, statistics, psychophysics, robotics, and artificial intelligence are also included. In particular, a new, broader definition is proposed for ``disease severity,'' and the terms ``disease measurement'' and ``disease estimate'' are specifically defined. It is hoped that the glossary contributes to a more unified cross-discipline approach to research in, and application of the tools available to phytopathometry.},
  langid = {english},
  keywords = {Accuracy,Disease severity,Estimate,Imaging,Measurement,Plant pathology,Reliability,Sensors,Visual}
}

@article{bockPlantDiseaseSeverity2010,
  title = {Plant {{Disease Severity Estimated Visually}}, by {{Digital Photography}} and {{Image Analysis}}, and by {{Hyperspectral Imaging}}},
  author = {Bock, C. H. and , G. H., Poole and , P. E., Parker and {and Gottwald}, T. R.},
  year = {2010},
  month = mar,
  journal = {Critical Reviews in Plant Sciences},
  volume = {29},
  number = {2},
  pages = {59--107},
  publisher = {Taylor \& Francis},
  issn = {0735-2689},
  doi = {10.1080/07352681003617285},
  urldate = {2025-03-26},
  abstract = {Reliable, precise and accurate estimates of disease severity are important for predicting yield loss, monitoring and forecasting epidemics, for assessing crop germplasm for disease resistance, and for understanding fundamental biological processes including co-evolution. Disease assessments that are inaccurate and/or imprecise might lead to faulty conclusions being drawn from the data, which in turn can lead to incorrect actions being taken in disease management decisions. Plant disease can be quantified in several different ways. This review considers plant disease severity assessment at the scale of individual plant parts or plants, and describes our current understanding of the sources and causes of assessment error, a better understanding of which is required before improvements can be targeted. The review also considers how these can be identified using various statistical tools. Indeed, great strides have been made in the last thirty years in identifying the sources of assessment error inherent to visual rating, and this review highlights ways that assessment errors can be reduced---particularly by training raters or using assessment aids. Lesion number in relation to area infected is known to influence accuracy and precision of visual estimates---the greater the number of lesions for a given area infected results in more overestimation. Furthermore, there is a widespread tendency to overestimate disease severity at low severities ({$<$}10\%). Both interrater and intrarater reliability can be variable, particularly if training or rating aids are not used. During the last eighty years acceptable accuracy and precision of visual disease assessments have often been achieved using disease scales, particularly because of the time they allegedly save, and the ease with which they can be learned, but recent work suggests there can be some disadvantages to their use. This review considers new technologies that offer opportunity to assess disease with greater objectivity (reliability, precision, and accuracy). One of these, visible light photography and digital image analysis has been increasingly used over the last thirty years, as software has become more sophisticated and user-friendly. Indeed, some studies have produced very accurate estimates of disease using image analysis. In contrast, hyperspectral imagery is relatively recent and has not been widely applied in plant pathology. Nonetheless, it offers interesting and potentially discerning opportunities to assess disease. As plant disease assessment becomes better understood, it is against the backdrop of concepts of reliability, precision and accuracy (and agreement) in plant pathology and measurement science. This review briefly describes these concepts in relation to plant disease assessment. Various advantages and disadvantages of the different approaches to disease assessment are described. For each assessment method some future research priorities are identified that would be of value in better understanding the theory of disease assessment, as it applies to improving and fully realizing the potential of image analysis and hyperspectral imagery.},
  keywords = {error,hyperspectral imagery,image analysis,plant disease assessment,remote sensing,variance}
}

@article{bockSpecialIssuePhytopathometry2022,
  title = {A Special Issue on Phytopathometry --- Visual Assessment, Remote Sensing, and Artificial Intelligence in the Twenty-First Century},
  author = {Bock, Clive H. and Barbedo, Jayme G. A. and Mahlein, Anne-Katrin and Del Ponte, Emerson M.},
  year = {2022},
  month = feb,
  journal = {Tropical Plant Pathology},
  volume = {47},
  number = {1},
  pages = {1--4},
  issn = {1983-2052},
  doi = {10.1007/s40858-022-00498-w},
  urldate = {2025-03-26},
  langid = {english}
}

@article{bockVisualEstimatesFully2020,
  title = {From Visual Estimates to Fully Automated Sensor-Based Measurements of Plant Disease Severity: Status and Challenges for Improving Accuracy},
  shorttitle = {From Visual Estimates to Fully Automated Sensor-Based Measurements of Plant Disease Severity},
  author = {Bock, Clive H. and Barbedo, Jayme G. A. and Del Ponte, Emerson M. and Bohnenkamp, David and Mahlein, Anne-Katrin},
  year = {2020},
  month = apr,
  journal = {Phytopathology Research},
  volume = {2},
  number = {1},
  pages = {9},
  issn = {2524-4167},
  doi = {10.1186/s42483-020-00049-8},
  urldate = {2025-03-26},
  abstract = {The severity of plant diseases, traditionally the proportion of the plant tissue exhibiting symptoms, is a key quantitative variable to know for many diseases and is prone to error. Good quality disease severity data should be accurate (close to the true value). Earliest quantification of disease severity was by visual estimates. Sensor-based image analysis including visible spectrum and hyperspectral and multispectral sensors are established technologies that promise to substitute, or complement visual ratings. Indeed, these technologies have measured disease severity accurately under controlled conditions but are yet to demonstrate their full potential for accurate measurement under field conditions. Sensor technology is advancing rapidly, and artificial intelligence may help overcome issues for automating severity measurement under hyper-variable field conditions. The adoption of appropriate scales, training, instruction and aids (standard area diagrams) has contributed to improved accuracy of visual estimates. The apogee of accuracy for visual estimation is likely being approached, and any remaining increases in accuracy are likely to be small. Due to automation and rapidity, sensor-based measurement offers potential advantages compared with visual estimates, but the latter will remain important for years to come. Mobile, automated sensor-based systems will become increasingly common in controlled conditions and, eventually, in the field for measuring plant disease severity for the purpose of research and decision making.},
  langid = {english},
  keywords = {Accuracy,Artificial intelligence,Assessment,Deep learning,Digital technologies,Disease severity,Machine learning,Mobile device,Phenotyping,Precision,Precision agriculture,Sensor}
}

@article{bockVisualEstimatesFully2020a,
  title = {From Visual Estimates to Fully Automated Sensor-Based Measurements of Plant Disease Severity: Status and Challenges for Improving Accuracy},
  shorttitle = {From Visual Estimates to Fully Automated Sensor-Based Measurements of Plant Disease Severity},
  author = {Bock, Clive H. and Barbedo, Jayme G. A. and Del Ponte, Emerson M. and Bohnenkamp, David and Mahlein, Anne-Katrin},
  year = {2020},
  month = apr,
  journal = {Phytopathology Research},
  volume = {2},
  number = {1},
  pages = {9},
  issn = {2524-4167},
  doi = {10.1186/s42483-020-00049-8},
  urldate = {2025-03-26},
  abstract = {The severity of plant diseases, traditionally the proportion of the plant tissue exhibiting symptoms, is a key quantitative variable to know for many diseases and is prone to error. Good quality disease severity data should be accurate (close to the true value). Earliest quantification of disease severity was by visual estimates. Sensor-based image analysis including visible spectrum and hyperspectral and multispectral sensors are established technologies that promise to substitute, or complement visual ratings. Indeed, these technologies have measured disease severity accurately under controlled conditions but are yet to demonstrate their full potential for accurate measurement under field conditions. Sensor technology is advancing rapidly, and artificial intelligence may help overcome issues for automating severity measurement under hyper-variable field conditions. The adoption of appropriate scales, training, instruction and aids (standard area diagrams) has contributed to improved accuracy of visual estimates. The apogee of accuracy for visual estimation is likely being approached, and any remaining increases in accuracy are likely to be small. Due to automation and rapidity, sensor-based measurement offers potential advantages compared with visual estimates, but the latter will remain important for years to come. Mobile, automated sensor-based systems will become increasingly common in controlled conditions and, eventually, in the field for measuring plant disease severity for the purpose of research and decision making.},
  langid = {english},
  keywords = {Accuracy,Artificial intelligence,Assessment,Deep learning,Digital technologies,Disease severity,Machine learning,Mobile device,Phenotyping,Precision,Precision agriculture,Sensor}
}

@article{bockVisualEstimatesFully2020b,
  title = {From Visual Estimates to Fully Automated Sensor-Based Measurements of Plant Disease Severity: Status and Challenges for Improving Accuracy},
  shorttitle = {From Visual Estimates to Fully Automated Sensor-Based Measurements of Plant Disease Severity},
  author = {Bock, Clive H. and Barbedo, Jayme G. A. and Del Ponte, Emerson M. and Bohnenkamp, David and Mahlein, Anne-Katrin},
  year = {2020},
  month = apr,
  journal = {Phytopathology Research},
  volume = {2},
  number = {1},
  pages = {9},
  issn = {2524-4167},
  doi = {10.1186/s42483-020-00049-8},
  urldate = {2025-03-30},
  abstract = {The severity of plant diseases, traditionally the proportion of the plant tissue exhibiting symptoms, is a key quantitative variable to know for many diseases and is prone to error. Good quality disease severity data should be accurate (close to the true value). Earliest quantification of disease severity was by visual estimates. Sensor-based image analysis including visible spectrum and hyperspectral and multispectral sensors are established technologies that promise to substitute, or complement visual ratings. Indeed, these technologies have measured disease severity accurately under controlled conditions but are yet to demonstrate their full potential for accurate measurement under field conditions. Sensor technology is advancing rapidly, and artificial intelligence may help overcome issues for automating severity measurement under hyper-variable field conditions. The adoption of appropriate scales, training, instruction and aids (standard area diagrams) has contributed to improved accuracy of visual estimates. The apogee of accuracy for visual estimation is likely being approached, and any remaining increases in accuracy are likely to be small. Due to automation and rapidity, sensor-based measurement offers potential advantages compared with visual estimates, but the latter will remain important for years to come. Mobile, automated sensor-based systems will become increasingly common in controlled conditions and, eventually, in the field for measuring plant disease severity for the purpose of research and decision making.},
  langid = {english},
  keywords = {Accuracy,Artificial intelligence,Assessment,Deep learning,Digital technologies,Disease severity,Machine learning,Mobile device,Phenotyping,Precision,Precision agriculture,Sensor}
}

@misc{bommasaniOpportunitiesRisksFoundation2022,
  title = {On the {{Opportunities}} and {{Risks}} of {{Foundation Models}}},
  author = {Bommasani, Rishi and Hudson, Drew A. and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S. and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and Brynjolfsson, Erik and Buch, Shyamal and Card, Dallas and Castellon, Rodrigo and Chatterji, Niladri and Chen, Annie and Creel, Kathleen and Davis, Jared Quincy and Demszky, Dora and Donahue, Chris and Doumbouya, Moussa and Durmus, Esin and Ermon, Stefano and Etchemendy, John and Ethayarajh, Kawin and {Fei-Fei}, Li and Finn, Chelsea and Gale, Trevor and Gillespie, Lauren and Goel, Karan and Goodman, Noah and Grossman, Shelby and Guha, Neel and Hashimoto, Tatsunori and Henderson, Peter and Hewitt, John and Ho, Daniel E. and Hong, Jenny and Hsu, Kyle and Huang, Jing and Icard, Thomas and Jain, Saahil and Jurafsky, Dan and Kalluri, Pratyusha and Karamcheti, Siddharth and Keeling, Geoff and Khani, Fereshte and Khattab, Omar and Koh, Pang Wei and Krass, Mark and Krishna, Ranjay and Kuditipudi, Rohith and Kumar, Ananya and Ladhak, Faisal and Lee, Mina and Lee, Tony and Leskovec, Jure and Levent, Isabelle and Li, Xiang Lisa and Li, Xuechen and Ma, Tengyu and Malik, Ali and Manning, Christopher D. and Mirchandani, Suvir and Mitchell, Eric and Munyikwa, Zanele and Nair, Suraj and Narayan, Avanika and Narayanan, Deepak and Newman, Ben and Nie, Allen and Niebles, Juan Carlos and Nilforoshan, Hamed and Nyarko, Julian and Ogut, Giray and Orr, Laurel and Papadimitriou, Isabel and Park, Joon Sung and Piech, Chris and Portelance, Eva and Potts, Christopher and Raghunathan, Aditi and Reich, Rob and Ren, Hongyu and Rong, Frieda and Roohani, Yusuf and Ruiz, Camilo and Ryan, Jack and R{\'e}, Christopher and Sadigh, Dorsa and Sagawa, Shiori and Santhanam, Keshav and Shih, Andy and Srinivasan, Krishnan and Tamkin, Alex and Taori, Rohan and Thomas, Armin W. and Tram{\`e}r, Florian and Wang, Rose E. and Wang, William and Wu, Bohan and Wu, Jiajun and Wu, Yuhuai and Xie, Sang Michael and Yasunaga, Michihiro and You, Jiaxuan and Zaharia, Matei and Zhang, Michael and Zhang, Tianyi and Zhang, Xikun and Zhang, Yuhui and Zheng, Lucia and Zhou, Kaitlyn and Liang, Percy},
  year = {2022},
  month = jul,
  number = {arXiv:2108.07258},
  eprint = {2108.07258},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2108.07258},
  urldate = {2025-03-26},
  abstract = {AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Computer Science - Machine Learning}
}

@article{brienMultiphaseExperimentsLeast2011,
  title = {Multiphase {{Experiments}} with at {{Least One Later Laboratory Phase}}. {{I}}. {{Orthogonal Designs}}},
  author = {Brien, C. J. and Harch, B. D. and Correll, R. L. and Bailey, R. A.},
  year = {2011},
  month = sep,
  journal = {Journal of Agricultural, Biological, and Environmental Statistics},
  volume = {16},
  number = {3},
  pages = {422--450},
  issn = {1537-2693},
  doi = {10.1007/s13253-011-0060-z},
  urldate = {2025-03-30},
  abstract = {The paper provides a systematic approach to designing the laboratory phase of a multiphase experiment, taking into account previous phases. General principles are outlined for experiments in which orthogonal designs can be employed. Multiphase experiments occur widely, although their multiphase nature is often not recognized. The need to randomize the material produced from the first phase in the laboratory phase is emphasized. Factor-allocation diagrams are used to depict the randomizations in a design and the use of skeleton analysis-of-variance (ANOVA) tables to evaluate their properties discussed. The methods are illustrated using a scenario and a case study. A basis for categorizing designs is suggested. This article has supplementary material online.},
  langid = {english},
  keywords = {Analysis of variance,Experimental design,Laboratory experiments,Multi-phase experiments,Multiple randomizations,Multitiered experiments,Two-phase experiments}
}

@article{brownCloseRangeCameraCalibration2002,
  title = {Close-{{Range Camera Calibration}}},
  author = {Brown, Duane},
  year = {2002},
  month = dec,
  journal = {Photogramm. Eng.},
  volume = {37}
}

@misc{brownLanguageModelsAre2020,
  title = {Language {{Models}} Are {{Few-Shot Learners}}},
  author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and {Herbert-Voss}, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  year = {2020},
  month = jul,
  number = {arXiv:2005.14165},
  eprint = {2005.14165},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2005.14165},
  urldate = {2025-03-26},
  abstract = {Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language}
}

@article{bullockDataIntensiveFarmManagement2019,
  title = {The {{Data-Intensive Farm Management Project}}: {{Changing Agronomic Research Through On-Farm Precision Experimentation}}},
  shorttitle = {The {{Data-Intensive Farm Management Project}}},
  author = {Bullock, David S. and Boerngen, Maria and Tao, Haiying and Maxwell, Bruce and Luck, Joe D. and Shiratsuchi, Luciano and Puntel, Laila and Martin, Nicolas F.},
  year = {2019},
  journal = {Agronomy Journal},
  volume = {111},
  number = {6},
  pages = {2736--2746},
  issn = {1435-0645},
  doi = {10.2134/agronj2019.03.0165},
  urldate = {2025-03-29},
  abstract = {The Data-Intensive Farm Management (DIFM) project works with participating farmers, using precision technology to inexpensively design and run randomized agronomic field trials on whole commercial farm fields, to provide data-based, site-specific farm input management guidance, thus providing economic and environmental benefits. This article lays out a conceptual framework used by the multidisciplinary DIFM research team to facilitate collaboration and then presents details of DIFM's procedures for what it calls on-farm precision experimentation (OFPE), which includes field trial design and implementation, data generation, processing, and management, and analysis. It is argued that DIFM's data and the agricultural ``Big Data'' currently being collected with remote and proximal sensors are complementary; that is, more of either increases the value of the other. In 2019, DIFM and affiliates conducted over 120 trials, ranging from 10 to 100 ha in size, on maize, wheat, soybeans, cotton, and barley in eight US states, Argentina, Brazil, and South Africa. The DIFM is developing cyberinfrastructure to ``scale up'' its activities, to permit researchers and crop consultants worldwide to work with farmers to conduct trials, then process and manage the data. In Addition, DIFM is in the early stages of developing a software system for semi-automatic data analytics, and a cloud-based farm management aid, the purpose of which is to facilitate conversations between agronomists and farmers about implementing data-driven input management decisions. The proposed framework allows researchers, agronomists, and farmers to carry out on-farm precision experimentation using novel digital tools. Core Ideas The Data-Intensive Farm Management project's on-farm trials can generate massive amounts varied managed input data. The Data-Intensive Farm Management project's data fill a gap in agricultural ``Big Data,'' to enable data-intensive crop management. The Data-Intensive Farm Management project's protocols support trial design, data processing and analysis. The Data-Intensive Farm Management project can be implemented by researchers, consultants, and farmers in diverse agronomic scenarios.},
  copyright = {{\copyright} 2019 The author(s).},
  langid = {english}
}

@article{bumbacaSupportingScreeningNew2024,
  title = {Supporting {{Screening}} of {{New Plant Protection Products}} through a {{Multispectral Photogrammetric Approach Integrated}} with {{AI}}},
  author = {Bumbaca, Samuele and {Borgogno-Mondino}, Enrico},
  year = {2024},
  month = feb,
  journal = {Agronomy},
  volume = {14},
  number = {2},
  pages = {306},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2073-4395},
  doi = {10.3390/agronomy14020306},
  urldate = {2025-03-23},
  abstract = {This work was aimed at developing a prototype system based on multispectral digital photogrammetry to support tests required by international regulations for new Plant Protection Products (PPPs). In particular, the goal was to provide a system addressing the challenges of a new PPP evaluation with a higher degree of objectivity with respect to the current one, which relies on expert evaluations. The system uses Digital Photogrammetry, which is applied to multispectral acquisitions and Artificial Intelligence (AI). The goal of this paper is also to simplify the present screening process, moving it towards more objective and quantitative scores about phytotoxicity. The implementation of an opportunely trained AI model for phytotoxicity prediction aims to convert ordinary human visual observations, which are presently provided with a discrete scale (forbidding a variance analysis), into a continuous variable. The technical design addresses the need for a reduced dataset for training the AI model and relating discrete observations, as usually performed, to some proxy variables derived from the photogrammetric multispectral 3D model. To achieve this task, an appropriate photogrammetric multispectral system was designed. The system operates in multi-nadiral-view mode over a bench within a greenhouse exploiting an active system for lighting providing uniform and diffuse illumination. The whole system is intended to reduce the environmental variability of acquisitions tending to a standard situation. The methodology combines advanced image processing, image radiometric calibration, and machine learning techniques to predict the General Phytotoxicity percentage index (PHYGEN), a crucial measure of phytotoxicity. Results show that the system can generate reliable estimates of PHYGEN, compliant with existing accuracy standards (even from previous PPPs symptom severity models), using limited training datasets. The proposed solution addressing this challenge is the adoption of the Logistic Function with LASSO model regularization that has been shown to overcome the limitations of a small sample size (typical of new PPP trials). Additionally, it provides the estimate of a numerical continuous index (a percentage), which makes it possible to tackle the objectivity problem related to human visual evaluation that is presently based on an ordinal discrete scale. In our opinion, the proposed prototype system could have significant potential in improving the screening process for new PPPs. In fact, it works specifically for new PPPs screening and, despite this, it has an accuracy consistent with the one ordinarily accepted for human visual approaches. Additionally, it provides a higher degree of objectivity and repeatability.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {computer vision,diagnostic,digitalization,machine learning,plant protection product}
}

@article{caslerFundamentalsExperimentalDesign2015,
  title = {Fundamentals of {{Experimental Design}}: {{Guidelines}} for {{Designing Successful Experiments}}},
  shorttitle = {Fundamentals of {{Experimental Design}}},
  author = {Casler, Michael D.},
  year = {2015},
  journal = {Agronomy Journal},
  volume = {107},
  number = {2},
  pages = {692--705},
  issn = {1435-0645},
  doi = {10.2134/agronj2013.0114},
  urldate = {2025-03-30},
  abstract = {We often think of experimental designs as analogous to recipes in a cookbook. We look for something that we like, something that satisfies our needs, and frequently return to those that have become our long-standing favorites. We can easily become complacent, favoring the tried-and-true designs (or recipes) over those that contain unknown or untried ingredients or those that are too complex for our tastes and skills. Instead, I prefer to think of experimental designs as a creative series of decisions that are meant to solve one or more problems. These problems may be real or imagined---we may have direct evidence of a past or current problem or we may simply want insurance against future potential problems. The most significant manifestation of a ``problem'' or a ``failed'' design is unsatisfactory P values that prevent us from developing inferences about treatment differences. Four basic tenets or pillars of experimental design--- replication, randomization, blocking, and size of experimental units--- can be used creatively, intelligently, and consciously to solve both real and perceived problems in comparative experiments. Because research is expensive, both in terms of grant funds and the emotional costs invested in grant competition and administration, biological experiments should be designed under the mantra ``failure is not an option.'' Guidelines and advice provided in this review are designed to reduce the probability of failure for researchers who are willing to question, evaluate, and possibly modify their decision-making processes.},
  copyright = {{\copyright} 2015 The Authors.},
  langid = {english}
}

@article{castrignanoGeostatisticalApproachModelling2017,
  title = {A Geostatistical Approach for Modelling and Combining Spatial Data with Different Support},
  author = {Castrignan{\`o}, A. and Quarto, R. and Venezia, A. and Buttafuoco, G.},
  year = {2017},
  month = jan,
  journal = {Advances in Animal Biosciences},
  volume = {8},
  number = {2},
  pages = {594--599},
  issn = {2040-4700},
  doi = {10.1017/S2040470017000048},
  urldate = {2025-03-29}
}

@misc{chalapathyDeepLearningAnomaly2019,
  title = {Deep {{Learning}} for {{Anomaly Detection}}: {{A Survey}}},
  shorttitle = {Deep {{Learning}} for {{Anomaly Detection}}},
  author = {Chalapathy, Raghavendra and Chawla, Sanjay},
  year = {2019},
  month = jan,
  number = {arXiv:1901.03407},
  eprint = {1901.03407},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1901.03407},
  urldate = {2025-03-23},
  abstract = {Anomaly detection is an important problem that has been well-studied within diverse research areas and application domains. The aim of this survey is two-fold, firstly we present a structured and comprehensive overview of research methods in deep learning-based anomaly detection. Furthermore, we review the adoption of these methods for anomaly across various application domains and assess their effectiveness. We have grouped state-of-the-art research techniques into different categories based on the underlying assumptions and approach adopted. Within each category we outline the basic anomaly detection technique, along with its variants and present key assumptions, to differentiate between normal and anomalous behavior. For each category, we present we also present the advantages and limitations and discuss the computational complexity of the techniques in real application domains. Finally, we outline open issues in research and challenges faced while adopting these techniques.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning}
}

@misc{chenSimpleFrameworkContrastive2020,
  title = {A {{Simple Framework}} for {{Contrastive Learning}} of {{Visual Representations}}},
  author = {Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  year = {2020},
  month = jul,
  number = {arXiv:2002.05709},
  eprint = {2002.05709},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2002.05709},
  urldate = {2025-03-26},
  abstract = {This paper presents SimCLR: a simple framework for contrastive learning of visual representations. We simplify recently proposed contrastive self-supervised learning algorithms without requiring specialized architectures or a memory bank. In order to understand what enables the contrastive prediction tasks to learn useful representations, we systematically study the major components of our framework. We show that (1) composition of data augmentations plays a critical role in defining effective predictive tasks, (2) introducing a learnable nonlinear transformation between the representation and the contrastive loss substantially improves the quality of the learned representations, and (3) contrastive learning benefits from larger batch sizes and more training steps compared to supervised learning. By combining these findings, we are able to considerably outperform previous methods for self-supervised and semi-supervised learning on ImageNet. A linear classifier trained on self-supervised representations learned by SimCLR achieves 76.5\% top-1 accuracy, which is a 7\% relative improvement over previous state-of-the-art, matching the performance of a supervised ResNet-50. When fine-tuned on only 1\% of the labels, we achieve 85.8\% top-5 accuracy, outperforming AlexNet with 100X fewer labels.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning}
}

@article{colominaUnmannedAerialSystems2014,
  title = {Unmanned Aerial Systems for Photogrammetry and Remote Sensing: {{A}} Review},
  shorttitle = {Unmanned Aerial Systems for Photogrammetry and Remote Sensing},
  author = {Colomina, I. and Molina, P.},
  year = {2014},
  journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
  volume = {92},
  pages = {79--97},
  issn = {09242716},
  doi = {10.1016/j.isprsjprs.2014.02.013},
  urldate = {2025-03-29},
  abstract = {(2014) Colomina, Molina. ISPRS Journal of Photogrammetry and Remote Sensing. We discuss the evolution and state-of-the-art of the use of Unmanned Aerial Systems (UAS) in the field of Photogrammetry...},
  langid = {british}
}

@misc{ControllableDataGeneration,
  title = {Controllable {{Data Generation}} by {{Deep Learning}}: {{A Review}}},
  urldate = {2025-03-26},
  howpublished = {https://arxiv.org/html/2207.09542}
}

@misc{ControllableDataGenerationa,
  title = {Controllable {{Data Generation}} by {{Deep Learning}}: {{A Review}}},
  urldate = {2025-03-26},
  howpublished = {https://arxiv.org/html/2207.09542}
}

@book{cressieStatisticsSpatialData2015,
  title = {Statistics for {{Spatial Data}}},
  author = {Cressie, Noel},
  year = {2015},
  month = mar,
  publisher = {John Wiley \& Sons},
  abstract = {The Wiley Classics Library consists of selected books that have been made more accessible to consumers in an effort to increase global appeal and general circulation. With these new unabridged softcover volumes, Wiley hopes to extend the lives of these works by making them available to future generations of statisticians, mathematicians, and scientists. Spatial statistics --- analyzing spatial data through statistical models --- has proven exceptionally versatile, encompassing problems ranging from the microscopic to the astronomic. However, for the scientist and engineer faced only with scattered and uneven treatments of the subject in the scientific literature, learning how to make practical use of spatial statistics in day-to-day analytical work is very difficult. Designed exclusively for scientists eager to tap into the enormous potential of this analytical tool and upgrade their range of technical skills, Statistics for Spatial Data is a comprehensive, single-source guide to both the theory and applied aspects of spatial statistical methods. The hard-cover edition was hailed by Mathematical Reviews as an "excellent book which will become a basic reference." This paper-back edition of the 1993 edition, is designed to meet the many technological challenges facing the scientist and engineer. Concentrating on the three areas of geostatistical data, lattice data, and point patterns, the book sheds light on the link between data and model, revealing how design, inference, and diagnostics are an outgrowth of that link. It then explores new methods to reveal just how spatial statistical models can be used to solve important problems in a host of areas in science and engineering. Discussion includes:  Exploratory spatial data analysis Spectral theory for stationary processes Spatial scale Simulation methods for spatial processes Spatial bootstrapping Statistical image analysis and remote sensing Computational aspects of model fitting Application of models to disease mapping  Designed to accommodate the practical needs of the professional, it features a unified and common notation for its subject as well as many detailed examples woven into the text, numerous illustrations (including graphs that illuminate the theory discussed) and over 1,000 references. Fully balancing theory with applications, Statistics for Spatial Data, Revised Edition is an exceptionally clear guide on making optimal use of one of the ascendant analytical tools of the decade, one that has begun to capture the imagination of professionals in biology, earth science, civil, electrical, and agricultural engineering, geography, epidemiology, and ecology.},
  googlebooks = {MzN\_BwAAQBAJ},
  isbn = {978-1-119-11518-2},
  langid = {english},
  keywords = {Mathematics / General,Mathematics / Probability & Statistics / General,Mathematics / Probability & Statistics / Stochastic Processes}
}

@misc{DeepTransferLearning,
  title = {Deep Transfer Learning for Image Classification: A Survey},
  shorttitle = {Deep Transfer Learning for Image Classification},
  journal = {ar5iv},
  urldate = {2025-03-26},
  abstract = {Deep neural networks such as convolutional neural networks (CNNs) and transformers have achieved many successes in image classification in recent years. It has been consistently demonstrated that best practice for imag{\dots}},
  howpublished = {https://ar5iv.labs.arxiv.org/html/2205.09904},
  langid = {english}
}

@article{depetrisRPASbasedPhotogrammetrySupport2020,
  title = {{{RPAS-based}} Photogrammetry to Support Tree Stability Assessment: {{Longing}} for Precision Arboriculture},
  shorttitle = {{{RPAS-based}} Photogrammetry to Support Tree Stability Assessment},
  author = {De Petris, Samuele and Sarvia, Filippo and {Borgogno-Mondino}, Enrico},
  year = {2020},
  month = nov,
  journal = {Urban Forestry \& Urban Greening},
  volume = {55},
  pages = {126862},
  issn = {1618-8667},
  doi = {10.1016/j.ufug.2020.126862},
  urldate = {2025-03-29},
  abstract = {Tree stability evaluation is an important issue with great practical implications. In the recent years, tree potential to cause harm has been increasing in consequence of climate change effects, mainly related to windstorms and tree diseases that represent the main tree failure causes. A tree owner has a duty of safety, imposed by civil and penal laws; consequently, he must operate an appropriate tree management to avoid foreseeable injuries or harms. A relevant problem arises when tree monitoring concern wide areas (extensive contexts), like natural park or urban forest; in these situations a variety of management factors have to be taken into account: the spatial size of the monitored areas; the great heterogeneity of trees vegetative conditions; the relevant number of trees; the balance between environmental protection and safe use of the area; the conspicuous cost of controls and technical interventions. With these premises an efficient planning tool is mandatory to manage this complex resource. Geomatics can support these requirements by integrating different techniques like survey, spatialization and modelling of territorial/environmental variables. In this work authors propose a new approach, hereinafter called ``Precision Arboriculture'' (PA), for tree management, fitting extensive contexts requirements. The proposed workflow is mainly based on RPAS photogrammetry technique and is specifically aimed at (i) accurately estimating single tree parameters; (ii) developing a robust algorithm to assess tree stability with the aim of reducing costs by better addressing ground controls through a spatially based management tool. This technology proved to generate estimates of the main dendrometric parameters with accuracies consistent (sometime higher) than the one ordinary required in the arboricultural context. Nevertheless, some ground data are however needed to calibrate models and testing accuracy of estimates. The proposed methodology proved to be able to generate an easy to use tool (Tree Safety Factor map) for better address ground controls aimed at testing tree stability and reducing the correlated hazard. Safety Factor map enhances critical trees addressing mitigation actions like tree removal, pruning, static bracing, limitations of people transit under potential tree fall area. The adoption of a quantitative index permits to better balance costs and benefits in a more objective way, improving economic efficiency of urban forestry and natural park policies. The method is configuring a new approach in arboricultural field involving new technologies, like RPAS photogrammetric survey and skills moving towards a ``Precision Arboriculture'' concept.},
  keywords = {CHM,Single tree parameters,Static integrated assessment,Tree stability index}
}

@misc{devlinBERTPretrainingDeep2019,
  title = {{{BERT}}: {{Pre-training}} of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  shorttitle = {{{BERT}}},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  year = {2019},
  month = may,
  number = {arXiv:1810.04805},
  eprint = {1810.04805},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1810.04805},
  urldate = {2025-03-26},
  abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language}
}

@misc{directive_91_414_EEC,
  title = {Council {{Directive}} 91/414/{{EEC}} of 15 {{July}} 1991 Concerning the Placing of Plant Protection Products on the Market},
  author = {{Council of the European Communities}},
  year = {1991},
  volume = {L 230},
  pages = {1--32},
  urldate = {2025-03-12}
}

@misc{dosovitskiyImageWorth16x162021,
  title = {An {{Image}} Is {{Worth}} 16x16 {{Words}}: {{Transformers}} for {{Image Recognition}} at {{Scale}}},
  shorttitle = {An {{Image}} Is {{Worth}} 16x16 {{Words}}},
  author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  year = {2021},
  month = jun,
  number = {arXiv:2010.11929},
  eprint = {2010.11929},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2010.11929},
  urldate = {2025-03-23},
  abstract = {While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning}
}

@misc{EC_Regulation_1107_2009,
  title = {Regulation ({{EC}}) {{No}} 1107/2009 of the {{European Parliament}} and of the {{Council}} of 21 {{October}} 2009 Concerning the Placing of Plant Protection Products on the Market},
  author = {{European Parliament and Council}},
  year = {2009},
  volume = {L 309},
  pages = {1--50},
  urldate = {2025-03-12}
}

@techreport{EPPO_PP1_135,
  title = {{{PP}} 1/135(4) Phytotoxicity Assessment},
  author = {{EPPO}},
  year = {2014},
  institution = {{European and Mediterranean Plant Protection Organization}},
  urldate = {2025-03-12}
}

@techreport{EPPO_PP1_152,
  title = {{{PP}} 1/152 {{Design}} and Analysis of Efficacy Evaluation Trials},
  author = {{EPPO}},
  year = {2012},
  institution = {{European and Mediterranean Plant Protection Organization}},
  urldate = {2025-03-12}
}

@techreport{EPPO_PP1_181,
  title = {{{PP}} 1/181(5) {{Conduct}} and Reporting of Efficacy Evaluation Trials, Including Good Experimental Practice},
  author = {{EPPO}},
  year = {2021},
  institution = {{European and Mediterranean Plant Protection Organization}},
  urldate = {2025-03-12}
}

@techreport{EPPO_PP1_93,
  title = {{{PP}} 1/93(3) Weeds in Cereals},
  author = {{EPPO}},
  year = {2015},
  institution = {{European and Mediterranean Plant Protection Organization}},
  urldate = {2025-03-12}
}

@misc{EURLex1997265,
  title = {Council Directive 97/57/{{EC}} of 22 September 1997, Uniform {{Principles}} for Evaluation and Authorisation of Plant Protection Products},
  author = {{European Commission}},
  year = {1997},
  volume = {L 265},
  pages = {87--109},
  urldate = {2025-03-12}
}

@article{EWRS_score,
  title = {Einheitliche Codierung Der Ph{\"a}nologischen Entwicklungsstadien Mono- Und Dikotyler Pflanzen - Erweiterte {{BBCH-skala}}, Allgemein},
  author = {Bleiholder, H. and {van den Boom}, T. and Langel{\"u}ddeke, P. and Stauss, R.},
  year = {1991},
  journal = {Nachrichtenblatt des Deutschen Pflanzenschutzdienstes},
  volume = {43},
  pages = {265--270}
}

@misc{FacebookresearchDinov22025,
  title = {Facebookresearch/Dinov2},
  year = {2025},
  month = mar,
  urldate = {2025-03-23},
  abstract = {PyTorch code and models for the DINOv2 self-supervised learning method.},
  copyright = {Apache-2.0},
  howpublished = {Meta Research}
}

@article{ferentinosDeepLearningModels2018,
  title = {Deep Learning Models for Plant Disease Detection and Diagnosis},
  author = {Ferentinos, Konstantinos P.},
  year = {2018},
  month = feb,
  journal = {Computers and Electronics in Agriculture},
  volume = {145},
  pages = {311--318},
  issn = {0168-1699},
  doi = {10.1016/j.compag.2018.01.009},
  urldate = {2025-03-23},
  abstract = {In this paper, convolutional neural network models were developed to perform plant disease detection and diagnosis using simple leaves images of healthy and diseased plants, through deep learning methodologies. Training of the models was performed with the use of an open database of 87,848 images, containing 25 different plants in a set of 58 distinct classes of [plant, disease] combinations, including healthy plants. Several model architectures were trained, with the best performance reaching a 99.53\% success rate in identifying the corresponding [plant, disease] combination (or healthy plant). The significantly high success rate makes the model a very useful advisory or early warning tool, and an approach that could be further expanded to support an integrated plant disease identification system to operate in real cultivation conditions.},
  keywords = {Artificial intelligence,Convolutional neural networks,Machine learning,Pattern recognition,Plant disease identification}
}

@incollection{fisherStatisticalMethodsResearch1992,
  title = {Statistical {{Methods}} for {{Research Workers}}},
  booktitle = {Breakthroughs in {{Statistics}}: {{Methodology}} and {{Distribution}}},
  author = {Fisher, R. A.},
  editor = {Kotz, Samuel and Johnson, Norman L.},
  year = {1992},
  pages = {66--70},
  publisher = {Springer},
  address = {New York, NY},
  doi = {10.1007/978-1-4612-4380-9_6},
  urldate = {2025-03-14},
  abstract = {The prime object of this book is to put into the hands of research workers, and especially of biologists, the means of applying statistical tests accurately to numerical data accumulated in their own laboratories or available in the literature.},
  isbn = {978-1-4612-4380-9},
  langid = {english}
}

@incollection{fisherStatisticalMethodsResearch1992a,
  title = {Statistical {{Methods}} for {{Research Workers}}},
  booktitle = {Breakthroughs in {{Statistics}}: {{Methodology}} and {{Distribution}}},
  author = {Fisher, R. A.},
  editor = {Kotz, Samuel and Johnson, Norman L.},
  year = {1992},
  pages = {66--70},
  publisher = {Springer},
  address = {New York, NY},
  doi = {10.1007/978-1-4612-4380-9_6},
  urldate = {2025-03-17},
  abstract = {The prime object of this book is to put into the hands of research workers, and especially of biologists, the means of applying statistical tests accurately to numerical data accumulated in their own laboratories or available in the literature.},
  isbn = {978-1-4612-4380-9},
  langid = {english}
}

@article{furukawaAccurateDenseRobust2010,
  title = {Accurate, {{Dense}}, and {{Robust Multiview Stereopsis}}},
  author = {Furukawa, Yasutaka and Ponce, Jean},
  year = {2010},
  month = aug,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {32},
  number = {8},
  pages = {1362--1376},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2009.161},
  urldate = {2025-03-30},
  abstract = {This paper proposes a novel algorithm for multiview stereopsis that outputs a dense set of small rectangular patches covering the surfaces visible in the images. Stereopsis is implemented as a match, expand, and filter procedure, starting from a sparse set of matched keypoints, and repeatedly expanding these before using visibility constraints to filter away false matches. The keys to the performance of the proposed algorithm are effective techniques for enforcing local photometric consistency and global visibility constraints. Simple but effective methods are also proposed to turn the resulting patch model into a mesh which can be further refined by an algorithm that enforces both photometric consistency and regularization constraints. The proposed approach automatically detects and discards outliers and obstacles and does not require any initialization in the form of a visual hull, a bounding box, or valid depth ranges. We have tested our algorithm on various data sets including objects with fine surface details, deep concavities, and thin structures, outdoor scenes observed from a restricted set of viewpoints, and "crowded" scenes where moving obstacles appear in front of a static structure of interest. A quantitative evaluation on the Middlebury benchmark [1] shows that the proposed method outperforms all others submitted so far for four out of the six data sets.},
  keywords = {3D/stereo scene analysis,Benchmark testing,Buildings,Computer vision,Image motion analysis,Image reconstruction,Layout,Matched filters,modeling and recovery of physical attributes,motion,Motion analysis,Photometry,Robustness,shape.,Solid modeling}
}

@book{gburAnalysisGeneralizedLinear2020,
  title = {Analysis of {{Generalized Linear Mixed Models}} in the {{Agricultural}} and {{Natural Resources Sciences}}},
  author = {Gbur, Edward E. and Stroup, Walter W. and McCarter, Kevin S. and Durham, Susan and Young, Linda J. and Christman, Mary and West, Mark and Kramer, Matthew},
  year = {2020},
  month = jan,
  publisher = {John Wiley \& Sons},
  abstract = {Generalized Linear Mixed Models in the Agricultural and Natural Resources Sciences provides readers with an understanding and appreciation for the design and analysis of mixed models for non-normally distributed data. It is the only publication of its kind directed specifically toward the agricultural and natural resources sciences audience. Readers will especially benefit from the numerous worked examples based on actual experimental data and the discussion of pitfalls associated with incorrect analyses.},
  googlebooks = {BgnMDwAAQBAJ},
  isbn = {978-0-89118-182-8},
  langid = {english},
  keywords = {Science / Life Sciences / Horticulture,Technology & Engineering / Agriculture / Agronomy / Crop Science,Technology & Engineering / Agriculture / General}
}

@book{gburAnalysisGeneralizedLinear2020a,
  title = {Analysis of {{Generalized Linear Mixed Models}} in the {{Agricultural}} and {{Natural Resources Sciences}}},
  author = {Gbur, Edward E. and Stroup, Walter W. and McCarter, Kevin S. and Durham, Susan and Young, Linda J. and Christman, Mary and West, Mark and Kramer, Matthew},
  year = {2020},
  month = jan,
  publisher = {John Wiley \& Sons},
  abstract = {Generalized Linear Mixed Models in the Agricultural and Natural Resources Sciences provides readers with an understanding and appreciation for the design and analysis of mixed models for non-normally distributed data. It is the only publication of its kind directed specifically toward the agricultural and natural resources sciences audience. Readers will especially benefit from the numerous worked examples based on actual experimental data and the discussion of pitfalls associated with incorrect analyses.},
  googlebooks = {BgnMDwAAQBAJ},
  isbn = {978-0-89118-182-8},
  langid = {english},
  keywords = {Science / Life Sciences / Horticulture,Technology & Engineering / Agriculture / Agronomy / Crop Science,Technology & Engineering / Agriculture / General}
}

@misc{GeneralizedLinearModels,
  title = {Generalized Linear Models by {{P}}. {{McCullagh}} {\textbar} {{Open Library}}},
  urldate = {2025-03-26},
  howpublished = {https://openlibrary.org/books/OL1911874M/Generalized\_linear\_models}
}

@article{gilmourAccountingNaturalExtraneous1997,
  title = {Accounting for {{Natural}} and {{Extraneous Variation}} in the {{Analysis}} of {{Field Experiments}}},
  author = {Gilmour, Arthur R. and Cullis, Brian R. and Verbyla, Ar{\=u}nas P.},
  year = {1997},
  journal = {Journal of Agricultural, Biological, and Environmental Statistics},
  volume = {2},
  number = {3},
  eprint = {1400446},
  eprinttype = {jstor},
  pages = {269--293},
  publisher = {[International Biometric Society, Springer]},
  issn = {1085-7117},
  doi = {10.2307/1400446},
  urldate = {2025-03-29},
  abstract = {We identify three major components of spatial variation in plot errors from field experiments and extend the two-dimensional spatial procedures of Cullis and Gleeson (1991) to account for them. The components are nonstationary, large-scale (global) variation across the field, stationary variation within the trial (natural variation or local trend), and extraneous variation that is often induced by experimental procedures and is predominantly aligned with rows and columns. We present a strategy for identifying a model for the plot errors that uses a trellis plot of residuals, a perspective plot of the sample variogram and, where possible, likelihood ratio tests to identify which components are present. We demonstrate the strategy using two illustrative examples. We conclude that although there is no one model that adequately fits all field experiments, the separable autoregressive model is dominant. However, there is often additional identifiable variation present.}
}

@book{gomarascaBasicsGeomatics2009,
  title = {Basics of {{Geomatics}}},
  author = {Gomarasca, Mario A.},
  year = {2009},
  month = sep,
  publisher = {Springer Science \& Business Media},
  abstract = {Geomatics is a neologism, the use of which is becoming increasingly widespread, even if it is not still universally accepted. It includes several disciplines and te- niques for the study of the Earth's surface and its environments, and computer science plays a decisive role. A more meaningful and appropriate expression is G- spatial Information or GeoInformation. Geo-spatial Information embeds topography in its more modern forms (measurements with electronic instrumentation, sophisticated techniques of data analysis and network compensation, global satellite positioning techniques, laser scanning, etc.), analytical and digital photogrammetry, satellite and airborne remote sensing, numerical cartography, geographical information systems, decision support systems, WebGIS, etc. These specialized elds are intimately interrelated in terms of both the basic science and the results pursued: rigid separation does not allow us to discover several common aspects and the fundamental importance assumed in a search for solutions in the complex survey context. The objective pursued by Mario A. Gomarasca, one that is only apparently modest, is to publish an integrated text on the surveying theme, containing simple and comprehensible concepts relevant to experts in Geo-spatial Information and/or speci cally in one of the disciplines that compose it. At the same time, the book is rigorous and synthetic, describing with precision the main instruments and methods connected to the multiple techniques available today.},
  googlebooks = {BAQ3FJiXDGsC},
  isbn = {978-1-4020-9014-1},
  langid = {english},
  keywords = {Computers / Artificial Intelligence / Computer Vision & Pattern Recognition,Nature / Natural Resources,Science / Earth Sciences / Geography,Technology & Engineering / Environmental / General,Technology & Engineering / Remote Sensing & Geographic Information Systems}
}

@book{gomarascaElementiDiGeomatica2004,
  title = {{Elementi di geomatica: con elementi di geodesia e cartografia, fotogrammetria, telerilevamento, informatica, sistemi di ripresa, sistemi di posizionamento satellitare, elaborazione digitale delle immagini, sistemi informativi territoriali, sistemi di supporto alle decisioni, SIT in rete, INSPIRE e GMES, dizionario tecnico, acronimi}},
  shorttitle = {{Elementi di geomatica}},
  author = {Gomarasca, Mario A.},
  year = {2004},
  publisher = {Associazione italiana di rilevamento},
  googlebooks = {FesfAQAAIAAJ},
  isbn = {978-88-900943-7-8},
  langid = {italian},
  keywords = {Science / Earth Sciences / Geography}
}

@book{goodfellowDeepLearning2016,
  title = {Deep {{Learning}}},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year = {2016},
  publisher = {MIT Press}
}

@book{goovaertsGeostatisticsNaturalResources1997,
  title = {Geostatistics for {{Natural Resources Evaluation}}},
  author = {Goovaerts, Pierre},
  year = {1997},
  publisher = {Oxford University Press},
  abstract = {This text fulfills a need for an advanced-level work covering both the theory and application of geostatistics. It covers the most important areas of geostatistical methodology, introducing tools for description, quantitative modeling of spatial continuity, spatial prediction, and assessment of local uncertainty and stochastic simulation. It also details the theoretical background underlying most GSLIB programs. The tools are applied to an environmental data set, but the book includes a general presentation of algorithms intended for students and practitioners in such diverse fields as soil science, mining, petroleum, remote sensing, hydrogeology, and the environmental sciences.},
  isbn = {978-0-19-511538-3},
  langid = {english},
  keywords = {Mathematics / Applied,Science / Earth Sciences / Geology,Science / Earth Sciences / Hydrology,Science / Life Sciences / Botany,Science / Life Sciences / Ecology,Social Science / Statistics,Technology & Engineering / Remote Sensing & Geographic Information Systems}
}

@book{hartleyMultipleViewGeometry2003,
  title = {Multiple {{View Geometry}} in {{Computer Vision}}},
  author = {Hartley, Richard and Zisserman, Andrew},
  year = {2003},
  publisher = {Cambridge University Press},
  abstract = {A basic problem in computer vision is to understand the structure of a real world scene given several images of it. Techniques for solving this problem are taken from projective geometry and photogrammetry. Here, the authors cover the geometric principles and their algebraic representation in terms of camera projection matrices, the fundamental matrix and the trifocal tensor. The theory and methods of computation of these entities are discussed with real examples, as is their use in the reconstruction of scenes from multiple images. The new edition features an extended introduction covering the key ideas in the book (which itself has been updated with additional examples and appendices) and significant new results which have appeared since the first edition. Comprehensive background material is provided, so readers familiar with linear algebra and basic numerical methods can understand the projective geometry and estimation algorithms presented, and implement the algorithms directly from the book.},
  googlebooks = {si3R3Pfa98QC},
  isbn = {978-0-521-54051-3},
  langid = {english},
  keywords = {Computers / Artificial Intelligence / Computer Vision & Pattern Recognition,Computers / Software Development & Engineering / Computer Graphics,Mathematics / Applied,Mathematics / Geometry / General,Technology & Engineering / Robotics}
}

@book{hastieElementsStatisticalLearning2009,
  title = {The {{Elements}} of {{Statistical Learning}}},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year = {2009},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {Springer},
  address = {New York, NY},
  doi = {10.1007/978-0-387-84858-7},
  urldate = {2025-03-26},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-0-387-84857-0 978-0-387-84858-7},
  keywords = {Averaging,Boosting,classification,clustering,data mining,machine learning,Projection pursuit,Random Forest,supervised learning,Support Vector Machine,unsupervised learning}
}

@misc{He2016deep,
  title = {He2016deep},
  journal = {Bing},
  urldate = {2025-03-26},
  abstract = {Intelligent search from Bing makes it easier to quickly find what you're looking for and rewards you.},
  howpublished = {https://www.bing.com/search?q=he2016deep\&cvid=0410f7e82dca4d7c967613a4434fb341\&gs\_lcrp=EgRlZGdlKgYIABBFGDkyBggAEEUYOTIICAEQ6QcY\_FXSAQczNzlqMGo5qAIIsAIB\&FORM=ANAB01\&PC=U531},
  langid = {english}
}

@misc{heDeepResidualLearning2015,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  year = {2015},
  month = dec,
  number = {arXiv:1512.03385},
  eprint = {1512.03385},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1512.03385},
  urldate = {2025-03-23},
  abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@misc{heMomentumContrastUnsupervised2020,
  title = {Momentum {{Contrast}} for {{Unsupervised Visual Representation Learning}}},
  author = {He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  year = {2020},
  month = mar,
  number = {arXiv:1911.05722},
  eprint = {1911.05722},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1911.05722},
  urldate = {2025-03-26},
  abstract = {We present Momentum Contrast (MoCo) for unsupervised visual representation learning. From a perspective on contrastive learning as dictionary look-up, we build a dynamic dictionary with a queue and a moving-averaged encoder. This enables building a large and consistent dictionary on-the-fly that facilitates contrastive unsupervised learning. MoCo provides competitive results under the common linear protocol on ImageNet classification. More importantly, the representations learned by MoCo transfer well to downstream tasks. MoCo can outperform its supervised pre-training counterpart in 7 detection/segmentation tasks on PASCAL VOC, COCO, and other datasets, sometimes surpassing it by large margins. This suggests that the gap between unsupervised and supervised representation learning has been largely closed in many vision tasks.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{henebryMakingSenseRemotely2011,
  title = {Making {{Sense}} of {{Remotely Sensing Vegetation}}},
  author = {Henebry, Geoffrey M.},
  year = {2011},
  month = jul,
  journal = {BioScience},
  volume = {61},
  number = {7},
  pages = {568--569},
  issn = {0006-3568},
  doi = {10.1525/bio.2011.61.7.13},
  urldate = {2025-03-29},
  abstract = {Remote Sensing of Vegetation: Principles, Techniques, and Applications. Hamlyn G. Jones and Robin A. Vaughan. Oxford University Press, 2010. 400 pp., illus. \$55.00 (ISBN 9780199207794 paper).An ever-expanding constellation of Earth-observing sensors provides us with a virtual tsunami of data, much of it now freely available. But channeling this digital torrent into useful information about the vegetated land surfaces requires a skillful blending of radiation physics, image processing, ecophysiology, and landscape ecology. This can be a complicated endeavor for the uninitiated. Most textbooks on remote sensing aim to survey the technology and applications broadly. Moreover, the recent rapid growth of online and open-access journals has increased the heterogeneity of an increasingly global remote-sensing literature.}
}

@book{henglPracticalGuideGeostatistical2007,
  title = {A {{Practical Guide}} to {{Geostatistical Mapping}} of {{Environmental Variables}}},
  author = {Hengl, Tomislav},
  year = {2007},
  publisher = {{European commission. Joint research centre. Institute for environment and sustainability (Ispra, Italie)}},
  abstract = {Geostatistical mapping can be defined as analytical production of maps by using field observations, auxiliary information and a computer program that calculates values at locations of interest. Today, increasingly the heart of a mapping project is, in fact, the computer program that implements some (geo)statistical algorithm to a given point data set. Purpose of this guide is to assist you in producing quality maps by using fully-operational tools, without a need for serious additional investments. It will first introduce you the to the basic principles of geostatistical mapping and regression-kriging, as the key prediction technique, then it will guide you through four software packages: ILWIS GIS, R+gstat, SAGA GIS and Google Earth, which will be used to prepare the data, run analysis and make final layouts. These materials have been used for the five-days advanced training course "Hands-on-geostatistics: merging GIS and spatial statistics", that is regularly organized by the author and collaborators. Visit the course website to obtain a copy of the datasets used in this exercise. [R{\'e}sum{\'e} de l'auteur].},
  googlebooks = {HdNEzQEACAAJ},
  isbn = {978-92-79-06904-8},
  langid = {english}
}

@inproceedings{huangDenselyConnectedConvolutional2017,
  title = {Densely {{Connected Convolutional Networks}}},
  booktitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Huang, Gao and Liu, Zhuang and {van der Maaten}, Laurens and Weinberger, Kilian Q.},
  year = {2017},
  pages = {4700--4708},
  urldate = {2025-03-23}
}

@article{hueteOverviewRadiometricBiophysical2002,
  title = {Overview of the Radiometric and Biophysical Performance of the {{MODIS}} Vegetation Indices},
  author = {Huete, A and Didan, K and Miura, T and Rodriguez, E. P and Gao, X and Ferreira, L. G},
  year = {2002},
  month = nov,
  journal = {Remote Sensing of Environment},
  series = {The {{Moderate Resolution Imaging Spectroradiometer}} ({{MODIS}}): A New Generation of {{Land Surface Monitoring}}},
  volume = {83},
  number = {1},
  pages = {195--213},
  issn = {0034-4257},
  doi = {10.1016/S0034-4257(02)00096-2},
  urldate = {2025-03-29},
  abstract = {We evaluated the initial 12 months of vegetation index product availability from the Moderate Resolution Imaging Spectroradiometer (MODIS) on board the Earth Observing System-Terra platform. Two MODIS vegetation indices (VI), the normalized difference vegetation index (NDVI) and enhanced vegetation index (EVI), are produced at 1-km and 500-m resolutions and 16-day compositing periods. This paper presents an initial analysis of the MODIS NDVI and EVI performance from both radiometric and biophysical perspectives. We utilize a combination of site-intensive and regionally extensive approaches to demonstrate the performance and validity of the two indices. Our results showed a good correspondence between airborne-measured, top-of-canopy reflectances and VI values with those from the MODIS sensor at four intensively measured test sites representing semi-arid grass/shrub, savanna, and tropical forest biomes. Simultaneously derived field biophysical measures also demonstrated the scientific utility of the MODIS VI. Multitemporal profiles of the MODIS VIs over numerous biome types in North and South America well represented their seasonal phenologies. Comparisons of the MODIS-NDVI with the NOAA-14, 1-km AVHRR-NDVI temporal profiles showed that the MODIS-based index performed with higher fidelity. The dynamic range of the MODIS VIs are presented and their sensitivities in discriminating vegetation differences are evaluated in sparse and dense vegetation areas. We found the NDVI to asymptotically saturate in high biomass regions such as in the Amazon while the EVI remained sensitive to canopy variations.}
}

@misc{hughesOpenAccessRepository2016,
  title = {An Open Access Repository of Images on Plant Health to Enable the Development of Mobile Disease Diagnostics},
  author = {Hughes, David P. and Salathe, Marcel},
  year = {2016},
  month = apr,
  number = {arXiv:1511.08060},
  eprint = {1511.08060},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1511.08060},
  urldate = {2025-03-23},
  abstract = {Human society needs to increase food production by an estimated 70\% by 2050 to feed an expected population size that is predicted to be over 9 billion people. Currently, infectious diseases reduce the potential yield by an average of 40\% with many farmers in the developing world experiencing yield losses as high as 100\%. The widespread distribution of smartphones among crop growers around the world with an expected 5 billion smartphones by 2020 offers the potential of turning the smartphone into a valuable tool for diverse communities growing food. One potential application is the development of mobile disease diagnostics through machine learning and crowdsourcing. Here we announce the release of over 50,000 expertly curated images on healthy and infected leaves of crops plants through the existing online platform PlantVillage. We describe both the data and the platform. These data are the beginning of an on-going, crowdsourcing effort to enable computer vision approaches to help solve the problem of yield losses in crop plants due to infectious diseases.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computers and Society}
}

@misc{IPPC,
  title = {International Standards for Phytosanitary Measures (Ispms)},
  author = {{International Plant Protection Convention}},
  year = {2022},
  urldate = {2025-03-12}
}

@article{jinEfficientGeostatisticalAnalysis2021,
  title = {An Efficient Geostatistical Analysis Tool for On-Farm Experiments Targeted at Localised Treatment},
  author = {Jin, Huidong and Shuvo Bakar, K. and Henderson, Brent L. and Bramley, Robert G. V. and Gobbett, David L.},
  year = {2021},
  month = may,
  journal = {Biosystems Engineering},
  volume = {205},
  pages = {121--136},
  issn = {1537-5110},
  doi = {10.1016/j.biosystemseng.2021.02.009},
  urldate = {2025-03-29},
  abstract = {On farm experimentation (OFE) has been a long-standing method for farmers to assess alternative management at scales relevant to their farming practices. Through the use of spatially distributed designs, whether simple strips or other `whole-of-block' trials, OFE can provide information such as which treatment should be recommended at specific locations, and make important contributions to precision agriculture. However, when treatment response data sets become large, such as with tens of thousands of field observations that are readily collected using on-the-go sensors, existing geostatistical systems for analysing such experiments become computationally intensive, if not impossible. To enable farmers, or their consultants, to generate high-resolution treatment response and recommendation maps on their own computers within a reasonable time, we present a fast and adaptive local cokriging tool for non-colocated and non-stationary OFE data. It uses a spatially-varying neighbourhood radius. It has a graphical user interface accessible via QGIS, a free and open source software. The adaptive local cokriging is demonstrated on three OFE examples. It performs indistinguishably from global cokriging on a small data set, but for large data sets, for which global cokriging is impractical, it predicts significantly more accurately than spatial splines or sampling-based cokriging. It outperforms cokriging base on a fixed number of nearest neighbours when this fixed number is not carefully chosen.},
  keywords = {Cokriging,Multivariate analysis tool,On-farm experimentation,Precision agriculture}
}

@book{jonesRemoteSensingVegetation2010,
  title = {Remote {{Sensing}} of {{Vegetation}}: {{Principles}}, {{Techniques}}, and {{Applications}}},
  shorttitle = {Remote {{Sensing}} of {{Vegetation}}},
  author = {Jones, Hamlyn G. and Vaughan, Robin A.},
  year = {2010},
  month = jul,
  publisher = {OUP Oxford},
  abstract = {Remote sensing is becoming an increasingly important tool for agriculturalists, ecologists, and land managers for the study of Earth's agricultural and natural vegetation, and can be applied to further our understanding of key environmental issues, including climate change and ecosystem management. This timely introduction offers an accessible yet rigorous treatment of the basics of remote sensing at all scales, illustrating its practical application to the study of vegetation. Despite a quantitative approach, the advanced mathematics and complex models common in modern remote sensing literature is demystified through clear explanations that emphasise the key underlying principles, and the core physical aspects are explained in the biological context of vegetation and its adaptation to its specific environment. Various techniques and instruments are addressed, making this a valuable source of reference, and the advantages and disadvantages of these are further illustrated through worked examples and case studies. {$\cdot$} Rigorous physical and mathematical principles presented in a way readily understood by those without a strong mathematical background {$\cdot$} Boxes throughout summarize key information and concepts {$\cdot$} The student is directed to carefully chosen further reading articles, allowing them to explore key topics in more detail Online Resource Centre The Online Resource Centre to accompany Remote Sensing of Vegetation features: For Students: {$\cdot$} Links to useful websites For lecturers: {$\cdot$} Figures from the book in electronic format, ready to download},
  googlebooks = {sTmcAQAAQBAJ},
  isbn = {978-0-19-920779-4},
  langid = {english},
  keywords = {Gardening / Vegetables,Nature / Plants / General,Science / Earth Sciences / Geography,Science / Life Sciences / Biology,Science / Life Sciences / Ecology,Science / Space Science / Astronomy,Technology & Engineering / Remote Sensing & Geographic Information Systems}
}

@book{journelMiningGeostatistics2003,
  title = {Mining {{Geostatistics}}},
  author = {Journel, A. G. and Journel, Andre G. and Huijbregts, Ch J.},
  year = {2003},
  publisher = {Blackburn Press},
  abstract = {First published in 1978, this book was the first complete reference work on the subject of mining geostatistics, an attempt to synthesize the practical experience gained by researchers from the Centre de Morphologie Mathematique in France and by mining engineers and geologists all over the world who contributed their ideas. It was designed for students and engineers who wished to apply geostatistics to practical problems occurring in the lifetime of a mine and for this reason was built around typical problems, progressing from the simplest to the most complicated: structural analysis, guiding exploration, estimation of in situ resources and recoverable reserves, numerical models of deposits, simulation of mining and homogenization processes, ore grade control in production. The techniques developed are illustrated by a large number of case studies and, as an aid to the reader, each chapter begins with a summary of the contents and there is a guide to the notation used. "The book is a practical treatise, written by practicing mining engineers and intended for other practicing engineers . the best summary of geostatistical theory as it stands at the present time and as one of the standard reference texts for the next few years." Mining Magazine "This is the book for which so many of us have been waiting: a practical, authoritative and scholarly work on geostatistics applied to mining. It is well written, well illustrated and usable both as a textbook for advanced students of mining geology and as a reference book for professionals.. Altogether a good book, the best available on the subject." C. J. Dixon in IMM Bulletin},
  googlebooks = {Id1GAAAAYAAJ},
  isbn = {978-1-930665-91-0},
  langid = {english},
  keywords = {Science / Earth Sciences / Geology,Technology & Engineering / Mining}
}

@article{kamilarisDeepLearningAgriculture2018,
  title = {Deep Learning in Agriculture: {{A}} Survey},
  shorttitle = {Deep Learning in Agriculture},
  author = {Kamilaris, Andreas and {Prenafeta-Boldu}, Francesc X.},
  year = {2018},
  month = apr,
  journal = {Computers and Electronics in Agriculture},
  volume = {147},
  eprint = {1807.11809},
  primaryclass = {cs},
  pages = {70--90},
  issn = {01681699},
  doi = {10.1016/j.compag.2018.02.016},
  urldate = {2025-03-26},
  abstract = {Deep learning constitutes a recent, modern technique for image processing and data analysis, with promising results and large potential. As deep learning has been successfully applied in various domains, it has recently entered also the domain of agriculture. In this paper, we perform a survey of 40 research efforts that employ deep learning techniques, applied to various agricultural and food production challenges. We examine the particular agricultural problems under study, the specific models and frameworks employed, the sources, nature and pre-processing of data used, and the overall performance achieved according to the metrics used at each work under study. Moreover, we study comparisons of deep learning with other existing popular techniques, in respect to differences in classification or regression performance. Our findings indicate that deep learning provides high accuracy, outperforming existing commonly used image processing techniques.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning}
}

@misc{katafuchiImagebasedPlantDisease2021,
  title = {Image-Based {{Plant Disease Diagnosis}} with {{Unsupervised Anomaly Detection Based}} on {{Reconstructability}} of {{Colors}}},
  author = {Katafuchi, Ryoya and Tokunaga, Terumasa},
  year = {2021},
  month = sep,
  number = {arXiv:2011.14306},
  eprint = {2011.14306},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2011.14306},
  urldate = {2025-03-23},
  abstract = {This paper proposes an unsupervised anomaly detection technique for image-based plant disease diagnosis. The construction of large and publicly available datasets containing labeled images of healthy and diseased crop plants led to growing interest in computer vision techniques for automatic plant disease diagnosis. Although supervised image classifiers based on deep learning can be a powerful tool for plant disease diagnosis, they require a huge amount of labeled data. The data mining technique of anomaly detection includes unsupervised approaches that do not require rare samples for training classifiers. We propose an unsupervised anomaly detection technique for image-based plant disease diagnosis that is based on the reconstructability of colors; a deep encoder-decoder network trained to reconstruct the colors of {\textbackslash}textit\{healthy\} plant images should fail to reconstruct colors of symptomatic regions. Our proposed method includes a new image-based framework for plant disease detection that utilizes a conditional adversarial network called pix2pix and a new anomaly score based on CIEDE2000 color difference. Experiments with PlantVillage dataset demonstrated the superiority of our proposed method compared to an existing anomaly detector at identifying diseased crop images in terms of accuracy, interpretability and computational efficiency.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning}
}

@article{koldasbayevaChallengesDatadrivenGeospatial2024,
  title = {Challenges in Data-Driven Geospatial Modeling for Environmental Research and Practice},
  author = {Koldasbayeva, Diana and Tregubova, Polina and Gasanov, Mikhail and Zaytsev, Alexey and Petrovskaia, Anna and Burnaev, Evgeny},
  year = {2024},
  month = dec,
  journal = {Nature Communications},
  volume = {15},
  number = {1},
  pages = {10700},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-024-55240-8},
  urldate = {2025-03-26},
  abstract = {Machine learning-based geospatial applications offer unique opportunities for environmental monitoring due to domains and scales adaptability and computational efficiency. However, the specificity of environmental data introduces biases in straightforward implementations. We identify a streamlined pipeline to enhance model accuracy, addressing issues like imbalanced data, spatial autocorrelation, prediction errors, and the nuances of model generalization and uncertainty estimation. We examine tools and techniques for overcoming these obstacles and provide insights into future geospatial AI developments. A big picture of the field is completed from advances in data processing in general, including the demands of industry-related solutions relevant to outcomes of applied sciences.},
  copyright = {2024 The Author(s)},
  langid = {english},
  keywords = {Biogeography,Environmental impact}
}

@misc{kornblithBetterImageNetModels2019,
  title = {Do {{Better ImageNet Models Transfer Better}}?},
  author = {Kornblith, Simon and Shlens, Jonathon and Le, Quoc V.},
  year = {2019},
  month = jun,
  number = {arXiv:1805.08974},
  eprint = {1805.08974},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1805.08974},
  urldate = {2025-03-26},
  abstract = {Transfer learning is a cornerstone of computer vision, yet little work has been done to evaluate the relationship between architecture and transfer. An implicit hypothesis in modern computer vision research is that models that perform better on ImageNet necessarily perform better on other vision tasks. However, this hypothesis has never been systematically tested. Here, we compare the performance of 16 classification networks on 12 image classification datasets. We find that, when networks are used as fixed feature extractors or fine-tuned, there is a strong correlation between ImageNet accuracy and transfer accuracy (\$r = 0.99\$ and \$0.96\$, respectively). In the former setting, we find that this relationship is very sensitive to the way in which networks are trained on ImageNet; many common forms of regularization slightly improve ImageNet accuracy but yield penultimate layer features that are much worse for transfer learning. Additionally, we find that, on two small fine-grained image classification datasets, pretraining on ImageNet provides minimal benefits, indicating the learned features from ImageNet do not transfer well to fine-grained tasks. Together, our results show that ImageNet architectures generalize well across datasets, but ImageNet features are less general than previously suggested.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning}
}

@incollection{kozaAutomatedDesignBoth1996,
  title = {Automated {{Design}} of {{Both}} the {{Topology}} and {{Sizing}} of {{Analog Electrical Circuits Using Genetic Programming}}},
  booktitle = {Artificial {{Intelligence}} in {{Design}} '96},
  author = {Koza, John R. and Bennett, Forrest H. and Andre, David and Keane, Martin A.},
  editor = {Gero, John S. and Sudweeks, Fay},
  year = {1996},
  pages = {151--170},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-94-009-0279-4_9},
  urldate = {2025-03-26},
  abstract = {This paper describes an automated process for designing analog electrical circuits based on the principles of natural selection, sexual recombination, and developmental biology. The design process starts with the random creation of a large population of program trees composed of circuit-constructing functions. Each program tree specifies the steps by which a fully developed circuit is to be progressively developed from a common embryonic circuit appropriate for the type of circuit that the user wishes to design. The fitness measure is a user-written computer program that may incorporate any calculable characteristic or combination of characteristics of the circuit. The population of program trees is genetically bred over a series of many generations using genetic programming. Genetic programming is driven by a fitness measure and employs genetic operations such as Darwinian reproduction, sexual recombination (crossover), and occasional mutation to create offspring. This automated evolutionary process produces both the topology of the circuit and the numerical values for each component. This paper describes how genetic programming can evolve the circuit for a difficult-to-design low-pass filter.},
  isbn = {978-94-009-0279-4},
  langid = {english}
}

@book{krausPhotogrammetryGeometryImages2007,
  title = {Photogrammetry: {{Geometry}} from {{Images}} and {{Laser Scans}}},
  shorttitle = {Photogrammetry},
  author = {Kraus, Karl},
  year = {2007},
  publisher = {Walter de Gruyter},
  abstract = {This textbook deals with the basics and methods of photogrammetry and laser scanning which are used to determine the form and location of objects, with measurements provided by sensors placed in air planes as well as on terrestrial platforms. Many examples and exercises with solutions are included.  Photogrammetry, Laserscanning.},
  isbn = {978-3-11-019007-6},
  langid = {english},
  keywords = {Photography / Techniques / General,Science / Earth Sciences / Geography,Science / Earth Sciences / Geology,Science / Earth Sciences / Hydrology,Science / Earth Sciences / Mineralogy,Science / General,Science / Physics / Geophysics,Technology & Engineering / Remote Sensing & Geographic Information Systems,Technology & Engineering / Signals & Signal Processing}
}

@article{kumleEstimatingPowerGeneralized2021,
  title = {Estimating Power in (Generalized) Linear Mixed Models: {{An}} Open Introduction and Tutorial in {{R}}},
  shorttitle = {Estimating Power in (Generalized) Linear Mixed Models},
  author = {Kumle, Levi and V{\~o}, Melissa L.-H. and Draschkow, Dejan},
  year = {2021},
  month = dec,
  journal = {Behavior Research Methods},
  volume = {53},
  number = {6},
  pages = {2528--2543},
  issn = {1554-3528},
  doi = {10.3758/s13428-021-01546-0},
  urldate = {2025-03-13},
  abstract = {Abstract                            Mixed-effects models are a powerful tool for modeling fixed and random effects simultaneously, but do not offer a feasible analytic solution for estimating the probability that a test correctly rejects the null hypothesis. Being able to estimate this probability, however, is critical for sample size planning, as power is closely linked to the reliability and replicability of empirical findings. A flexible and very intuitive alternative to               analytic               power solutions are               simulation-based               power analyses. Although various tools for conducting simulation-based power analyses for mixed-effects models are available, there is lack of guidance on how to appropriately use them. In this tutorial, we discuss how to estimate power for mixed-effects models in different use cases: first, how to use models that were fit on available (e.g. published) data to determine sample size; second, how to determine the number of stimuli required for sufficient power; and finally, how to conduct sample size planning without available data. Our examples cover both linear and generalized linear models and we provide code and resources for performing simulation-based power analyses on openly accessible data sets. The present work therefore helps researchers to navigate sound research design when using mixed-effects models, by summarizing resources, collating available knowledge, providing solutions and tools, and applying them to real-world problems in sample sizing planning when sophisticated analysis procedures like mixed-effects models are outlined as inferential procedures.},
  langid = {english}
}

@article{kumleEstimatingPowerGeneralized2021a,
  title = {Estimating Power in (Generalized) Linear Mixed Models: {{An}} Open Introduction and Tutorial in {{R}}},
  shorttitle = {Estimating Power in (Generalized) Linear Mixed Models},
  author = {Kumle, Levi and V{\~o}, Melissa L.-H. and Draschkow, Dejan},
  year = {2021},
  month = dec,
  journal = {Behavior Research Methods},
  volume = {53},
  number = {6},
  pages = {2528--2543},
  issn = {1554-3528},
  doi = {10.3758/s13428-021-01546-0},
  abstract = {Mixed-effects models are a powerful tool for modeling fixed and random effects simultaneously, but do not offer a feasible analytic solution for estimating the probability that a test correctly rejects the null hypothesis. Being able to estimate this probability, however, is critical for sample size planning, as power is closely linked to the reliability and replicability of empirical findings. A flexible and very intuitive alternative to analytic power solutions are simulation-based power analyses. Although various tools for conducting simulation-based power analyses for mixed-effects models are available, there is lack of guidance on how to appropriately use them. In this tutorial, we discuss how to estimate power for mixed-effects models in different use cases: first, how to use models that were fit on available (e.g. published) data to determine sample size; second, how to determine the number of stimuli required for sufficient power; and finally, how to conduct sample size planning without available data. Our examples cover both linear and generalized linear models and we provide code and resources for performing simulation-based power analyses on openly accessible data sets. The present work therefore helps researchers to navigate sound research design when using mixed-effects models, by summarizing resources, collating available knowledge, providing solutions and tools, and applying them to real-world problems in sample sizing planning when sophisticated analysis procedures like mixed-effects models are outlined as inferential procedures.},
  langid = {english},
  pmcid = {PMC8613146},
  pmid = {33954914},
  keywords = {Computer Simulation,Humans,Linear Models,lme4,Mixed models,mixedpower,Power,R,Reproducibility of Results,Sample Size,Simulation}
}

@article{larkOptimizedSpatialSampling2002,
  title = {Optimized Spatial Sampling of Soil for Estimation of the Variogram by Maximum Likelihood},
  author = {Lark, R. M},
  year = {2002},
  month = jan,
  journal = {Geoderma},
  volume = {105},
  number = {1},
  pages = {49--80},
  issn = {0016-7061},
  doi = {10.1016/S0016-7061(01)00092-1},
  urldate = {2025-03-29},
  abstract = {Recent studies have attempted to optimize the configuration of sample sites for estimation of the variogram by the usual method-of-moments. This paper shows that objective functions can readily be defined for estimation by the method of maximum likelihood. In both cases an objective function can only be defined for a specified variogram so some prior knowledge about the spatial variation of the property of interest is necessary. This paper describes the principles of the method, using Spatial Simulated Annealing for optimization, and applies optimized sample designs to simulated data. For practical applications it seems that the most fruitful way of using the technique is for supplementing simple systematic designs that provide an initial estimate of the variogram.},
  keywords = {Geostatistics,Optimization,Soil sampling,Spatial variation}
}

@article{leeEfficientTwodimensionalSmoothing2013,
  title = {Efficient Two-Dimensional Smoothing with {{P}}{$<$}math{$><$}mi Is="true"{$>$}{{P}}{$<$}/Mi{$><$}/Math{$>$}-Spline {{ANOVA}} Mixed Models and Nested Bases},
  author = {Lee, Dae-Jin and Durb{\'a}n, Mar{\'i}a and Eilers, Paul},
  year = {2013},
  month = may,
  journal = {Computational Statistics \& Data Analysis},
  volume = {61},
  pages = {22--37},
  issn = {0167-9473},
  doi = {10.1016/j.csda.2012.11.013},
  urldate = {2025-03-29},
  abstract = {Low-rank smoothing techniques have gained much popularity in non-standard regression modeling. In particular, penalized splines and tensor product smooths are used as flexible tools to study non-parametric relationships among several covariates. The use of standard statistical software facilitates their use for several types of problems and applications. However, when interaction terms are considered in the modeling, and multiple smoothing parameters need to be estimated standard software does not work well when datasets are large or higher-order interactions are included or need to be tested. In this paper, a general approach for constructing and estimating bivariate smooth models for additive and interaction terms using penalized splines is proposed. The formulation is based on the mixed model representation of the smooth-ANOVA model by Lee and Durb{\'a}n (in~press), and several nested models in terms of random effects components are proposed. Each component has a clear interpretation in terms of function shape and model identifiability constraints. The term PS-ANOVA is coined for this type of models. The estimation method is relatively straightforward based on the algorithm by Schall (1991) for generalized linear mixed models. Further, a simplification of the smooth interaction term is used by constructing lower-rank basis (nested basis). Finally, some simulation studies and real data examples are presented to evaluate the new model and the estimation method.},
  keywords = {Mixed models,Penalized splines,Schall's algorithm,Smooth-ANOVA decomposition}
}

@misc{liuSwinTransformerHierarchical2021,
  title = {Swin {{Transformer}}: {{Hierarchical Vision Transformer}} Using {{Shifted Windows}}},
  shorttitle = {Swin {{Transformer}}},
  author = {Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  year = {2021},
  month = aug,
  number = {arXiv:2103.14030},
  eprint = {2103.14030},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2103.14030},
  urldate = {2025-03-23},
  abstract = {This paper presents a new vision Transformer, called Swin Transformer, that capably serves as a general-purpose backbone for computer vision. Challenges in adapting Transformer from language to vision arise from differences between the two domains, such as large variations in the scale of visual entities and the high resolution of pixels in images compared to words in text. To address these differences, we propose a hierarchical Transformer whose representation is computed with {\textbackslash}textbf\{S\}hifted {\textbackslash}textbf\{win\}dows. The shifted windowing scheme brings greater efficiency by limiting self-attention computation to non-overlapping local windows while also allowing for cross-window connection. This hierarchical architecture has the flexibility to model at various scales and has linear computational complexity with respect to image size. These qualities of Swin Transformer make it compatible with a broad range of vision tasks, including image classification (87.3 top-1 accuracy on ImageNet-1K) and dense prediction tasks such as object detection (58.7 box AP and 51.1 mask AP on COCO test-dev) and semantic segmentation (53.5 mIoU on ADE20K val). Its performance surpasses the previous state-of-the-art by a large margin of +2.7 box AP and +2.6 mask AP on COCO, and +3.2 mIoU on ADE20K, demonstrating the potential of Transformer-based models as vision backbones. The hierarchical design and the shifted window approach also prove beneficial for all-MLP architectures. The code and models are publicly available at{\textasciitilde}{\textbackslash}url\{https://github.com/microsoft/Swin-Transformer\}.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning}
}

@article{lopezEfficiencyIncompleteBlock1995,
  title = {Efficiency of an {{Incomplete Block Design Based}} on {{Geostatistics}} for {{Tillage Experiments}}},
  author = {L{\'o}pez, Mar{\'i}a V. and Arr{\'u}e, Jos{\'e} L.},
  year = {1995},
  journal = {Soil Science Society of America Journal},
  volume = {59},
  number = {4},
  pages = {1104--1111},
  issn = {1435-0661},
  doi = {10.2136/sssaj1995.03615995005900040023x},
  urldate = {2025-03-30},
  abstract = {Spatial dependence of soil properties often reduces the power of conventional statistical methods to detect treatment differences. Control of adverse effects of soil variability is of special interest in long-term experiments when small and slowly developing treatment effects are generally expected to occur, as in tillage research. The main objective of this study was to evaluate the ability of an incomplete block design based on geostatistical concepts to improve the precision of a conservation tillage experiment conducted at four sites in Arag{\'o}n, northeast Spain. A preliminary geostatistical characterization of plow layer variability at these sites showed that, in most instances, soil water content and silt plus clay content were spatially dependent. Maps of kriged estimates of these properties were used to locate the tillage plots according to the proposed design. Using incomplete blocks of Size 2, the method estimates treatment effects by making short-distance comparisons and ensures spatially balanced treatment contrasts through fixed comparison distances. This design was compared with a complete block design using soil and crop data obtained during the first two growing seasons of the tillage experiment. The results of a total of 1050 analysis of variance comparisons revealed that the incomplete block design was, on average, 24\% more efficient than the complete block design. The use of incomplete blocks reduced the average error mean square by 33\% and increased the number of cases with significant tillage treatment differences by 25\% compared with the use of complete blocks.},
  copyright = {{\copyright} 1995 Soil Science Society of America},
  langid = {english}
}

@article{loweDistinctiveImageFeatures2004,
  title = {Distinctive {{Image Features}} from {{Scale-Invariant Keypoints}}},
  author = {Lowe, David G.},
  year = {2004},
  month = nov,
  journal = {International Journal of Computer Vision},
  volume = {60},
  number = {2},
  pages = {91--110},
  issn = {1573-1405},
  doi = {10.1023/B:VISI.0000029664.99615.94},
  abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.}
}

@book{luhmannCloseRangePhotogrammetry3D2019,
  title = {Close-{{Range Photogrammetry}} and {{3D Imaging}}},
  author = {Luhmann, Thomas and Robson, Stuart and Kyle, Stephen and Boehm, Jan},
  year = {2019},
  month = nov,
  publisher = {De Gruyter},
  doi = {10.1515/9783110607253},
  urldate = {2025-03-29},
  abstract = {This is the third edition of the well-known guide to close-range photogrammetry. It provides a thorough presentation of the methods, mathematics, systems and applications which comprise the subject of close-range photogrammetry, which uses accurate imaging techniques to analyse the three-dimensional shape of a wide range of manufactured and natural objects.},
  copyright = {De Gruyter expressly reserves the right to use all content for commercial text and data mining within the meaning of Section 44b of the German Copyright Act.},
  isbn = {978-3-11-060725-3},
  langid = {english}
}

@article{luInstanceFusionRealtimeInstancelevel2020,
  title = {{{InstanceFusion}}: {{Real-time Instance-level 3D Reconstruction Using}} a {{Single RGBD Camera}}},
  shorttitle = {{{InstanceFusion}}},
  author = {Lu, Feixiang and Peng, Haotian and Wu, Hongyu and Yang, Jun and Yang, Xinhang and Cao, Ruizhi and Zhang, Liangjun and Yang, Ruigang and Zhou, Bin},
  year = {2020},
  journal = {Computer Graphics Forum},
  volume = {39},
  number = {7},
  pages = {433--445},
  issn = {1467-8659},
  doi = {10.1111/cgf.14157},
  urldate = {2025-03-26},
  abstract = {We present InstanceFusion, a robust real-time system to detect, segment, and reconstruct instance-level 3D objects of indoor scenes with a hand-held RGBD camera. It combines the strengths of deep learning and traditional SLAM techniques to produce visually compelling 3D semantic models. The key success comes from our novel segmentation scheme and the efficient instance-level data fusion, which are both implemented on GPU. Specifically, for each incoming RGBD frame, we take the advantages of the RGBD features, the 3D point cloud, and the reconstructed model to perform instance-level segmentation. The corresponding RGBD data along with the instance ID are then fused to the surfel-based models. In order to sufficiently store and update these data, we design and implement a new data structure using the OpenGL Shading Language. Experimental results show that our method advances the state-of-the-art (SOTA) methods in instance segmentation and data fusion by a big margin. In addition, our instance segmentation improves the precision of 3D reconstruction, especially in the loop closure. InstanceFusion system runs 20.5Hz on a consumer-level GPU, which supports a number of augmented reality (AR) applications (e.g., 3D model registration, virtual interaction, AR map) and robot applications (e.g., navigation, manipulation, grasping). To facilitate future research and reproduce our system more easily, the source code, data, and the trained model are released on Github: https://github.com/Fancomi2017/InstanceFusion.},
  copyright = {{\copyright} 2020 The Author(s) Computer Graphics Forum {\copyright} 2020 The Eurographics Association and John Wiley \& Sons Ltd. Published by John Wiley \& Sons Ltd.},
  langid = {english},
  keywords = {CCS Concepts,Computing methodologies  Scene understanding,Perception,Vision for robotics}
}

@misc{MachineLearningApplications,
  title = {Machine {{Learning Applications}} in {{Agriculture}}: {{Current Trends}}, {{Challenges}}, and {{Future Perspectives}}},
  urldate = {2025-03-26},
  howpublished = {https://www.mdpi.com/2073-4395/13/12/2976}
}

@article{mahleinHyperspectralSensorsImaging2018,
  type = {Journal {{Article}}},
  title = {Hyperspectral {{Sensors}} and {{Imaging Technologies}} in {{Phytopathology}}: {{State}} of the {{Art}}},
  author = {Mahlein, A.-K. and Kuska, M.T. and Behmann, J. and Polder, G. and Walter, A.},
  year = {2018},
  journal = {Annual Review of Phytopathology},
  volume = {56},
  number = {Volume 56, 2018},
  pages = {535--558},
  publisher = {Annual Reviews},
  issn = {1545-2107},
  doi = {10.1146/annurev-phyto-080417-050100},
  abstract = {Plant disease detection represents a tremendous challenge for research and practical applications. Visual assessment by human raters is time-consuming, expensive, and error prone. Disease rating and plant protection need new and innovative techniques to address forthcoming challenges and trends in agricultural production that require more precision than ever before. Within this context, hyperspectral sensors and imaging techniques---intrinsically tied to efficient data analysis approaches---have shown an enormous potential to provide new insights into plant-pathogen interactions and for the detection of plant diseases. This article provides an overview of hyperspectral sensors and imaging technologies for assessing compatible and incompatible plant-pathogen interactions. Within the progress of digital technologies, the vision, which is increasingly discussed in the society and industry, includes smart and intuitive solutions for assessing plant features in plant phenotyping or for making decisions on plant protection measures in the context of precision agriculture.},
  keywords = {noninvasive}
}

@article{mahleinPlantDiseaseDetection2016,
  title = {Plant {{Disease Detection}} by {{Imaging Sensors}} -- {{Parallels}} and {{Specific Demands}} for {{Precision Agriculture}} and {{Plant Phenotyping}}},
  author = {Mahlein, Anne-Katrin},
  year = {2016},
  month = feb,
  journal = {Plant Disease},
  volume = {100},
  number = {2},
  pages = {241--251},
  publisher = {Scientific Societies},
  issn = {0191-2917},
  doi = {10.1094/PDIS-03-15-0340-FE},
  urldate = {2025-03-29},
  abstract = {Early and accurate detection and diagnosis of plant diseases are key factors in plant production and the reduction of both qualitative and quantitative losses in crop yield. Optical techniques, such as RGB imaging, multi- and hyperspectral sensors, thermography, or chlorophyll fluorescence, have proven their potential in automated, objective, and reproducible detection systems for the identification and quantification of plant diseases at early time points in epidemics. Recently, 3D scanning has also been added as an optical analysis that supplies additional information on crop plant vitality. Different platforms from proximal to remote sensing are available for multiscale monitoring of single crop organs or entire fields. Accurate and reliable detection of diseases is facilitated by highly sophisticated and innovative methods of data analysis that lead to new insights derived from sensor data for complex plant-pathogen systems. Nondestructive, sensor-based methods support and expand upon visual and/or molecular approaches to plant disease assessment. The most relevant areas of application of sensor-based analyses are precision agriculture and plant phenotyping.}
}

@article{martinelliAdvancedMethodsPlant2015,
  title = {Advanced Methods of Plant Disease Detection. {{A}} Review},
  author = {Martinelli, Federico and Scalenghe, Riccardo and Davino, Salvatore and Panno, Stefano and Scuderi, Giuseppe and Ruisi, Paolo and Villa, Paolo and Stroppiana, Daniela and Boschetti, Mirco and Goulart, Luiz R. and Davis, Cristina E. and Dandekar, Abhaya M.},
  year = {2015},
  journal = {Agronomy for Sustainable Development},
  volume = {35},
  number = {1},
  pages = {1--25},
  publisher = {Springer Verlag/EDP Sciences/INRA},
  doi = {10.1007/s13593-014-0246-1},
  urldate = {2025-03-23},
  abstract = {Plant diseases are responsible for major economic losses in the agricultural industry worldwide. Monitoring plant health and detecting pathogen early are essential to reduce disease spread and facilitate effective management practices. DNA-based and serological methods now provide essential tools for accurate plant disease diagnosis, in addition to the traditional visual scouting for symptoms. Although DNA-based and serological methods have revolutionized plant disease detection, they are not very reliable at asymptomatic stage, especially in case of pathogen with systemic diffusion. They need at least 1--2 days for sample harvest, processing, and analysis. Here, we describe modern methods based on nucleic acid and protein analysis. Then, we review innovative approaches currently under development. Our main findings are the following: (1) novel sensors based on the analysis of host responses, e.g., differential mobility spectrometer and lateral flow devices, deliver instantaneous results and can effectively detect early infections directly in the field; (2) biosensors based on phage display and biophotonics can also detect instantaneously infections although they can be integrated with other systems; and (3) remote sensing techniques coupled with spectroscopy-based methods allow high spatialization of results, these techniques may be very useful as a rapid preliminary identification of primary infections. We explain how these tools will help plant disease management and complement serological and DNA-based methods. While serological and PCR-based methods are the most available and effective to confirm disease diagnosis, volatile and biophotonic sensors provide instantaneous results and may be used to identify infections at asymptomatic stages. Remote sensing technologies will be extremely helpful to greatly spatialize diagnostic results. These innovative techniques represent unprecedented tools to render agriculture more sustainable and safe, avoiding expensive use of pesticides in crop protection.},
  keywords = {Biophotonics,Commercial kits,DNA-based methods,Immunological assays,Plant disease,Remote sensing,Spectroscopy,Volatile organic compounds}
}

@article{matheronPrinciplesGeostatistics1963,
  title = {Principles of Geostatistics},
  author = {{Matheron}},
  year = {1963},
  month = dec,
  journal = {Economic Geology},
  volume = {58},
  number = {8},
  pages = {1246--1266},
  publisher = {GeoScienceWorld},
  issn = {0013-0109},
  doi = {10.2113/GSECONGEO.58.8.1246},
  urldate = {2025-03-29},
  abstract = {Knowledge of ore grades and ore reserves as well as error estimation of these values, is fundamental for mining engineers and mining geologists. Until now no appropriate scientific approach to those estimation problems has existed: geostatistics, the principles of which are summarized in this paper, constitutes a new science leading to such an approach. The author criticizes classical statistical methods still in use, and shows some of the main results given by geostatistics. Any ore deposit evaluation as well as proper decision of starting mining operations should be preceded by a geostatistical investigation which may avoid economic failures.},
  langid = {english}
}

@book{meadStatisticalPrinciplesDesign2012,
  title = {Statistical {{Principles}} for the {{Design}} of {{Experiments}}: {{Applications}} to {{Real Experiments}}},
  shorttitle = {Statistical {{Principles}} for the {{Design}} of {{Experiments}}},
  author = {Mead, R. and Gilmour, S. G. and Mead, A.},
  year = {2012},
  month = sep,
  publisher = {Cambridge University Press},
  abstract = {This book is about the statistical principles behind the design of effective experiments and focuses on the practical needs of applied statisticians and experimenters engaged in design, implementation and analysis. Emphasising the logical principles of statistical design, rather than mathematical calculation, the authors demonstrate how all available information can be used to extract the clearest answers to many questions. The principles are illustrated with a wide range of examples drawn from real experiments in medicine, industry, agriculture and many experimental disciplines. Numerous exercises are given to help the reader practise techniques and to appreciate the difference that good design can make to an experimental research project. Based on Roger Mead's excellent Design of Experiments, this new edition is thoroughly revised and updated to include modern methods relevant to applications in industry, engineering and modern biology. It also contains seven new chapters on contemporary topics, including restricted randomisation and fractional replication.},
  googlebooks = {Z\_0LBAAAQBAJ},
  isbn = {978-1-139-57664-2},
  langid = {english},
  keywords = {Mathematics / Applied,Mathematics / Probability & Statistics / General,Medical / Research}
}

@book{meerImagingSpectrometryBasic2001,
  title = {Imaging Spectrometry : Basic Principles and Prospective Applications},
  shorttitle = {Imaging Spectrometry},
  author = {van der Meer, F. D. and de Jong, S. M.},
  year = {2001},
  publisher = {Kluwer Academic},
  urldate = {2025-03-29},
  isbn = {978-1-4020-0194-9},
  langid = {english}
}

@incollection{meerImagingSpectrometryBasic2002,
  title = {Imaging {{Spectrometry}}: {{Basic Analytical Techniques}}},
  shorttitle = {Imaging {{Spectrometry}}},
  booktitle = {Imaging {{Spectrometry}}},
  author = {Meer, Freek Van Der and Jong, Steven De and Bakker, Wim},
  editor = {Meer, Freek D. Van Der and Abrams, Michael and Curran, Paul and Dekker, Arnold and Jong, Steven M. De and Schaepman, Michael and Meer, Freek D. Van Der and Jong, Steven M. De},
  year = {2002},
  volume = {4},
  pages = {17--61},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-0-306-47578-8_2},
  urldate = {2025-03-30},
  isbn = {978-1-4020-0194-9 978-0-306-47578-8}
}

@book{mikhailIntroductionModernPhotogrammetry2001,
  title = {Introduction to {{Modern Photogrammetry}}},
  author = {Mikhail, Edward M. and Bethel, James S. and McGlone, J. Chris},
  year = {2001},
  month = mar,
  publisher = {John Wiley \& Sons},
  abstract = {This text is designed to give students a strong grounding in the mathematical basis of photogrammetry while introducing them to related fields, such as remote sensing and digital image processing.Suitable for undergraduate photogrammetry courses typically aimed at junior and senior students, and for graduate-level courses at the Master's level. Excellent reference for those working in related fields.},
  googlebooks = {D4h8EAAAQBAJ},
  isbn = {978-0-471-30924-6},
  langid = {english},
  keywords = {Technology & Engineering / Civil / General,Technology & Engineering / Environmental / General}
}

@article{minasnyEfficiencyVariousApproaches2002,
  title = {The Efficiency of Various Approaches to Obtaining Estimates of Soil Hydraulic Properties},
  author = {Minasny, Budiman and McBratney, Alex B},
  year = {2002},
  month = may,
  journal = {Geoderma},
  volume = {107},
  number = {1},
  pages = {55--70},
  issn = {0016-7061},
  doi = {10.1016/S0016-7061(01)00138-0},
  urldate = {2025-03-29},
  abstract = {A formal analysis was carried out to evaluate the efficiency of the different methods in predicting water retention and hydraulic conductivity. Efficiency can be defined in terms of effort, cost or value of information. The analysis identified the contribution of individual sources of measurement errors to the overall uncertainty. The value of information summarises the quality of the prediction, the cost of information, the application of predicted hydraulic properties, and the effect of spatial variability. For single measurements, the inverse disc-permeameter analysis is economically more efficient than using pedotransfer functions or measuring hydraulic properties in the laboratory. However, given the large amount of spatial variation of soil hydraulic properties it is found that lots of cheap and imprecise measurements, e.g. by hand texturing, are more efficient than a few expensive precise ones.},
  keywords = {Hydraulic conductivity,Inverse problem,Soil-water balance,Uncertainty analysis}
}

@misc{ModelsPretrainedWeights,
  title = {Models and Pre-Trained Weights --- {{Torchvision}} Main Documentation},
  urldate = {2025-03-23},
  howpublished = {https://pytorch.org/vision/master/models.html}
}

@article{mohantyUsingDeepLearning2016,
  title = {Using {{Deep Learning}} for {{Image-Based Plant Disease Detection}}},
  author = {Mohanty, Sharada P. and Hughes, David P. and Salath{\'e}, Marcel},
  year = {2016},
  month = sep,
  journal = {Frontiers in Plant Science},
  volume = {7},
  publisher = {Frontiers},
  issn = {1664-462X},
  doi = {10.3389/fpls.2016.01419},
  urldate = {2025-03-23},
  abstract = {{$<$}p{$>$}Crop diseases are a major threat to food security, but their rapid identification remains difficult in many parts of the world due to the lack of the necessary infrastructure. The combination of increasing global smartphone penetration and recent advances in computer vision made possible by deep learning has paved the way for smartphone-assisted disease diagnosis. Using a public dataset of 54,306 images of diseased and healthy plant leaves collected under controlled conditions, we train a deep convolutional neural network to identify 14 crop species and 26 diseases (or absence thereof). The trained model achieves an accuracy of 99.35\% on a held-out test set, demonstrating the feasibility of this approach. Overall, the approach of training deep learning models on increasingly large and publicly available image datasets presents a clear path toward smartphone-assisted crop disease diagnosis on a massive global scale.{$<$}/p{$>$}},
  langid = {english},
  keywords = {Crop diseases,deep learning,digital epidemiology,Disease diagnosis,machine learning}
}

@article{mullerGeostatisticalModellingPython2022,
  title = {Geostatistical Modelling in {{Python}}},
  shorttitle = {{{GSTools}} v1.3},
  author = {M{\"u}ller, Sebastian and Sch{\"u}ler, Lennart and Zech, Alraune and He{\ss}e, Falk},
  year = {2022},
  month = apr,
  journal = {Geoscientific Model Development},
  volume = {15},
  number = {7},
  pages = {3161--3182},
  publisher = {Copernicus GmbH},
  issn = {1991-959X},
  doi = {10.5194/gmd-15-3161-2022},
  urldate = {2025-03-29},
  abstract = {Geostatistics as a subfield of statistics accounts for the spatial correlations encountered in many applications of, for example, earth sciences. Valuable information can be extracted from these correlations, also helping to address the often encountered burden of data scarcity. Despite the value of additional data, the use of geostatistics still falls short of its potential. This problem is often connected to the lack of user-friendly software hampering the use and application of geostatistics. We therefore present GSTools, a Python-based software suite for solving a wide range of geostatistical problems. We chose Python due to its unique balance between usability, flexibility, and efficiency and due to its adoption in the scientific community. GSTools provides methods for generating random fields; it can perform kriging, variogram estimation and much more. We demonstrate its abilities by virtue of a series of example applications detailing their use.},
  langid = {english}
}

@article{nexUAV3DMapping2014,
  title = {{{UAV}} for {{3D}} Mapping Applications : A Review},
  shorttitle = {{{UAV}} for {{3D}} Mapping Applications},
  author = {Nex, F. C. and Remondino, F.},
  year = {2014},
  journal = {Applied geomatics},
  volume = {6},
  number = {1},
  pages = {1--2015},
  publisher = {Springer},
  issn = {1866-9298},
  doi = {10.1007/s12518-013-0120-x},
  urldate = {2025-03-29},
  langid = {english}
}

@book{oliverGeostatisticalApplicationsPrecision2010,
  title = {Geostatistical {{Applications}} for {{Precision Agriculture}}},
  editor = {Oliver, M.A.},
  year = {2010},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-90-481-9133-8},
  urldate = {2025-03-29},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-90-481-9132-1 978-90-481-9133-8},
  langid = {english},
  keywords = {geostatistics,kriging,paper,Precision Agriculture,simulation,Site-specific Management,Variogram}
}

@article{onofriNewMethodAnalysis2010,
  title = {A New Method for the Analysis of Germination and Emergence Data of Weed Species},
  author = {Onofri, A and Gresta, F and Tei, F},
  year = {2010},
  journal = {Weed Research},
  volume = {50},
  number = {3},
  pages = {187--198},
  issn = {1365-3180},
  doi = {10.1111/j.1365-3180.2010.00776.x},
  urldate = {2025-03-30},
  abstract = {Onofri A, Gresta F \& Tei F (2010). A new method for the analysis of germination and emergence data of weed species. Weed Research50, 187--198. Summary Due to their peculiar characteristics, seed germination and emergence assays may pose problems for data analysis, due to non-normal error distribution and serial correlation between the numbers of seeds counted on different dates from the same experimental unit (Petri dish, pot, plot). Furthermore, it is necessary to consider viable seeds that have not germinated/emerged at the end of an experiment (censored observations), as well as late germination/emergence flushes, that relate to genotypic differences within natural occurring seed populations. Traditional methods of data analysis may not be optimal for dealing with these problems. Therefore, survival analysis may represent an appropriate alternative. In this analysis, the time course of germination/emergence is described by using a non-parametric step function (`germination function') and the effect of factors and covariates on `germination functions' is assessed by Accelerated Failure Time regression and expressed in terms of `time ratios'. These parameters measure how a change in the explanatory variables changes (prolongs/shortens) the time to germination of a seed lot. This paper presents four examples of the application of survival analysis on seed germination/emergence studies. Results are discussed and compared with those obtained with more traditional techniques.},
  copyright = {{\copyright} 2010 The Authors. Journal Compilation {\copyright} 2010 European Weed Research Society},
  langid = {english},
  keywords = {accelerated failure time models,emergence,frailty effects,germination,survival analysis,time ratios,weed seeds}
}

@misc{oquabDINOv2LearningRobust2024,
  title = {{{DINOv2}}: {{Learning Robust Visual Features}} without {{Supervision}}},
  shorttitle = {{{DINOv2}}},
  author = {Oquab, Maxime and Darcet, Timoth{\'e}e and Moutakanni, Th{\'e}o and Vo, Huy and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and {El-Nouby}, Alaaeldin and Assran, Mahmoud and Ballas, Nicolas and Galuba, Wojciech and Howes, Russell and Huang, Po-Yao and Li, Shang-Wen and Misra, Ishan and Rabbat, Michael and Sharma, Vasu and Synnaeve, Gabriel and Xu, Hu and Jegou, Herv{\'e} and Mairal, Julien and Labatut, Patrick and Joulin, Armand and Bojanowski, Piotr},
  year = {2024},
  month = feb,
  number = {arXiv:2304.07193},
  eprint = {2304.07193},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2304.07193},
  urldate = {2025-03-23},
  abstract = {The recent breakthroughs in natural language processing for model pretraining on large quantities of data have opened the way for similar foundation models in computer vision. These models could greatly simplify the use of images in any system by producing all-purpose visual features, i.e., features that work across image distributions and tasks without finetuning. This work shows that existing pretraining methods, especially self-supervised methods, can produce such features if trained on enough curated data from diverse sources. We revisit existing approaches and combine different techniques to scale our pretraining in terms of data and model size. Most of the technical contributions aim at accelerating and stabilizing the training at scale. In terms of data, we propose an automatic pipeline to build a dedicated, diverse, and curated image dataset instead of uncurated data, as typically done in the self-supervised literature. In terms of models, we train a ViT model (Dosovitskiy et al., 2020) with 1B parameters and distill it into a series of smaller models that surpass the best available all-purpose features, OpenCLIP (Ilharco et al., 2021) on most of the benchmarks at image and pixel levels.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{other_scores,
  title = {Nonlinear Regression Analysis and Its Applications},
  author = {Bates, D. M. and Watts, D. G.},
  year = {1988},
  journal = {Journal of Agricultural, Biological, and Environmental Statistics},
  volume = {1},
  number = {1},
  pages = {120--135}
}

@book{paineAerialPhotographyImage2012,
  title = {Aerial {{Photography}} and {{Image Interpretation}}},
  author = {Paine, David P. and Kiser, James D.},
  year = {2012},
  month = feb,
  publisher = {John Wiley \& Sons},
  abstract = {The new, completely updated edition of the aerial photography classic Extensively revised to address today's technological advances, Aerial Photography and Image Interpretation, Third Edition offers a thorough survey of the technology, techniques, processes, and methods used to create and interpret aerial photographs. The new edition also covers other forms of remote sensing with topics that include the most current information on orthophotography (including digital), soft copy photogrammetry, digital image capture and interpretation, GPS, GIS, small format aerial photography, statistical analysis and thematic mapping errors, and more. A basic introduction is also given to nonphotographic and space-based imaging platforms and sensors, including Landsat, lidar, thermal, and multispectral. This new Third Edition features:  Additional coverage of the specialized camera equipment used in aerial photography A strong focus on aerial photography and image interpretation, allowing for a much more thorough presentation of the techniques, processes, and methods than is possible in the broader remote sensing texts currently available Straightforward, user-friendly writing style Expanded coverage of digital photography Test questions and summaries for quick review at the end of each chapter  Written in a straightforward style supplemented with hundreds of photographs and illustrations, Aerial Photography and Image Interpretation, Third Edition is the most in-depth resource for undergraduate students and professionals in such fields as forestry, geography, environmental science, archaeology, resource management, surveying, civil and environmental engineering, natural resources, and agriculture.},
  googlebooks = {ESZHAAAAQBAJ},
  isbn = {978-1-118-11264-9},
  langid = {english},
  keywords = {Nature / Natural Resources,Technology & Engineering / Civil / General,Technology & Engineering / Environmental / General}
}

@article{pandianjImprovedDeepResidual2022,
  title = {An {{Improved Deep Residual Convolutional Neural Network}} for {{Plant Leaf Disease Detection}}},
  author = {Pandian J, Arun and K, Kanchanadevi and Rajalakshmi, N. R. and G Arulkumaran, null},
  year = {2022},
  journal = {Computational Intelligence and Neuroscience},
  volume = {2022},
  pages = {5102290},
  issn = {1687-5273},
  doi = {10.1155/2022/5102290},
  abstract = {In this research, we proposed a novel deep residual convolutional neural network with 197 layers (ResNet197) for the detection of various plant leaf diseases. Six blocks of layers were used to develop ResNet197. ResNet197 was trained and tested using a combined plant leaf disease image dataset. Scaling, cropping, flipping, padding, rotation, affine transformation, saturation, and hue transformation techniques were used to create the augmentation data of the plant leaf disease image dataset. The dataset consisted of 103 diseased and healthy image classes of 22 plants and 154,500 images of healthy and diseased plant leaves. The evolutionary search technique was used to optimise the layers and hyperparameter values of ResNet197. ResNet197 was trained on the combined plant leaf disease image dataset using a graphics processing unit (GPU) environment for 1000 epochs. It produced a 99.58 percentage average classification accuracy on the test dataset. The experimental results were superior to existing ResNet architectures and recent transfer learning techniques.},
  langid = {english},
  pmcid = {PMC9492343},
  pmid = {36156945},
  keywords = {Image Processing Computer-Assisted,Neural Networks Computer,Plant Diseases,Plant Leaves,Rotation}
}

@article{paroliniEmergenceModernStatistics2015,
  title = {The Emergence of Modern Statistics in Agricultural Science: Analysis of Variance, Experimental Design and the Reshaping of Research at {{Rothamsted Experimental Station}}, 1919-1933},
  shorttitle = {The Emergence of Modern Statistics in Agricultural Science},
  author = {Parolini, Giuditta},
  year = {2015},
  journal = {Journal of the History of Biology},
  volume = {48},
  number = {2},
  pages = {301--335},
  issn = {0022-5010},
  doi = {10.1007/s10739-014-9394-z},
  abstract = {During the twentieth century statistical methods have transformed research in the experimental and social sciences. Qualitative evidence has largely been replaced by quantitative results and the tools of statistical inference have helped foster a new ideal of objectivity in scientific knowledge. The paper will investigate this transformation by considering the genesis of analysis of variance and experimental design, statistical methods nowadays taught in every elementary course of statistics for the experimental and social sciences. These methods were developed by the mathematician and geneticist R. A. Fisher during the 1920s, while he was working at Rothamsted Experimental Station, where agricultural research was in turn reshaped by Fisher's methods. Analysis of variance and experimental design required new practices and instruments in field and laboratory research, and imposed a redistribution of expertise among statisticians, experimental scientists and the farm staff. On the other hand the use of statistical methods in agricultural science called for a systematization of information management and made computing an activity integral to the experimental research done at Rothamsted, permanently integrating the statisticians' tools and expertise into the station research programme. Fisher's statistical methods did not remain confined within agricultural research and by the end of the 1950s they had come to stay in psychology, sociology, education, chemistry, medicine, engineering, economics, quality control, just to mention a few of the disciplines which adopted them.},
  langid = {english},
  pmid = {25311906},
  keywords = {Agriculture,Analysis of Variance,England,History 20th Century,Research Design,Statistics as Topic}
}

@article{paroliniPursuitScienceAgriculture2015,
  title = {In Pursuit of a Science of Agriculture: The Role of Statistics in Field Experiments},
  shorttitle = {In Pursuit of a Science of Agriculture},
  author = {Parolini, Giuditta},
  year = {2015},
  month = sep,
  journal = {History and Philosophy of the Life Sciences},
  volume = {37},
  number = {3},
  pages = {261--281},
  issn = {0391-9714},
  doi = {10.1007/s40656-015-0075-9},
  abstract = {Since the beginning of the twentieth century statistics has reshaped the experimental cultures of agricultural research taking part in the subtle dialectic between the epistemic and the material that is proper to experimental systems. This transformation has become especially relevant in field trials and the paper will examine the British agricultural institution, Rothamsted Experimental Station, where statistical methods nowadays popular in the planning and analysis of field experiments were developed in the 1920s. At Rothamsted statistics promoted randomisation over systematic arrangements, factorisation over one-question trials, and emphasised the importance of the experimental error in assessing field trials. These changes in methodology transformed also the material culture of agricultural science, and a new body, the Field Plots Committee, was created to manage the field research of the agricultural institution. Although successful, the vision of field experimentation proposed by the Rothamsted statisticians was not unproblematic. Experimental scientists closely linked to the farming community questioned it in favour of a field research that could be~more easily understood by farmers. The clash between the two agendas reveals how the role attributed to statistics in field experimentation defined different pursuits of agricultural research, alternately conceived of~as a scientists' science or as~a farmers' science.},
  langid = {english},
  pmid = {26149775},
  keywords = {Agriculture,Biostatistics,History 20th Century,Research Design,United Kingdom}
}

@misc{pattersonCarbonEmissionsLarge2021,
  title = {Carbon {{Emissions}} and {{Large Neural Network Training}}},
  author = {Patterson, David and Gonzalez, Joseph and Le, Quoc and Liang, Chen and Munguia, Lluis-Miquel and Rothchild, Daniel and So, David and Texier, Maud and Dean, Jeff},
  year = {2021},
  month = apr,
  number = {arXiv:2104.10350},
  eprint = {2104.10350},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2104.10350},
  urldate = {2025-03-26},
  abstract = {The computation demand for machine learning (ML) has grown rapidly recently, which comes with a number of costs. Estimating the energy cost helps measure its environmental impact and finding greener strategies, yet it is challenging without detailed information. We calculate the energy use and carbon footprint of several recent large models-T5, Meena, GShard, Switch Transformer, and GPT-3-and refine earlier estimates for the neural architecture search that found Evolved Transformer. We highlight the following opportunities to improve energy efficiency and CO2 equivalent emissions (CO2e): Large but sparsely activated DNNs can consume {$<$}1/10th the energy of large, dense DNNs without sacrificing accuracy despite using as many or even more parameters. Geographic location matters for ML workload scheduling since the fraction of carbon-free energy and resulting CO2e vary {\textasciitilde}5X-10X, even within the same country and the same organization. We are now optimizing where and when large models are trained. Specific datacenter infrastructure matters, as Cloud datacenters can be {\textasciitilde}1.4-2X more energy efficient than typical datacenters, and the ML-oriented accelerators inside them can be {\textasciitilde}2-5X more effective than off-the-shelf systems. Remarkably, the choice of DNN, datacenter, and processor can reduce the carbon footprint up to {\textasciitilde}100-1000X. These large factors also make retroactive estimates of energy cost difficult. To avoid miscalculations, we believe ML papers requiring large computational resources should make energy consumption and CO2e explicit when practical. We are working to be more transparent about energy use and CO2e in our future research. To help reduce the carbon footprint of ML, we believe energy usage and CO2e should be a key metric in evaluating models, and we are collaborating with MLPerf developers to include energy usage during training and inference in this industry standard benchmark.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning}
}

@misc{pattersonCarbonEmissionsLarge2021a,
  title = {Carbon {{Emissions}} and {{Large Neural Network Training}}},
  author = {Patterson, David and Gonzalez, Joseph and Le, Quoc and Liang, Chen and Munguia, Lluis-Miquel and Rothchild, Daniel and So, David and Texier, Maud and Dean, Jeff},
  year = {2021},
  month = apr,
  journal = {arXiv e-prints},
  doi = {10.48550/arXiv.2104.10350},
  urldate = {2025-03-26},
  abstract = {The computation demand for machine learning (ML) has grown rapidly recently, which comes with a number of costs. Estimating the energy cost helps measure its environmental impact and finding greener strategies, yet it is challenging without detailed information. We calculate the energy use and carbon footprint of several recent large models-T5, Meena, GShard, Switch Transformer, and GPT-3-and refine earlier estimates for the neural architecture search that found Evolved Transformer. We highlight the following opportunities to improve energy efficiency and CO2 equivalent emissions (CO2e): Large but sparsely activated DNNs can consume {$<$}1/10th the energy of large, dense DNNs without sacrificing accuracy despite using as many or even more parameters. Geographic location matters for ML workload scheduling since the fraction of carbon-free energy and resulting CO2e vary {\textasciitilde}5X-10X, even within the same country and the same organization. We are now optimizing where and when large models are trained. Specific datacenter infrastructure matters, as Cloud datacenters can be {\textasciitilde}1.4-2X more energy efficient than typical datacenters, and the ML-oriented accelerators inside them can be {\textasciitilde}2-5X more effective than off-the-shelf systems. Remarkably, the choice of DNN, datacenter, and processor can reduce the carbon footprint up to {\textasciitilde}100-1000X. These large factors also make retroactive estimates of energy cost difficult. To avoid miscalculations, we believe ML papers requiring large computational resources should make energy consumption and CO2e explicit when practical. We are working to be more transparent about energy use and CO2e in our future research. To help reduce the carbon footprint of ML, we believe energy usage and CO2e should be a key metric in evaluating models, and we are collaborating with MLPerf developers to include energy usage during training and inference in this industry standard benchmark.},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning},
  annotation = {ADS Bibcode: 2021arXiv210410350P}
}

@misc{pattersonCarbonEmissionsLarge2021b,
  title = {Carbon {{Emissions}} and {{Large Neural Network Training}}},
  author = {Patterson, David and Gonzalez, Joseph and Le, Quoc and Liang, Chen and Munguia, Lluis-Miquel and Rothchild, Daniel and So, David and Texier, Maud and Dean, Jeff},
  year = {2021},
  month = apr,
  number = {arXiv:2104.10350},
  eprint = {2104.10350},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2104.10350},
  urldate = {2025-03-26},
  abstract = {The computation demand for machine learning (ML) has grown rapidly recently, which comes with a number of costs. Estimating the energy cost helps measure its environmental impact and finding greener strategies, yet it is challenging without detailed information. We calculate the energy use and carbon footprint of several recent large models-T5, Meena, GShard, Switch Transformer, and GPT-3-and refine earlier estimates for the neural architecture search that found Evolved Transformer. We highlight the following opportunities to improve energy efficiency and CO2 equivalent emissions (CO2e): Large but sparsely activated DNNs can consume {$<$}1/10th the energy of large, dense DNNs without sacrificing accuracy despite using as many or even more parameters. Geographic location matters for ML workload scheduling since the fraction of carbon-free energy and resulting CO2e vary {\textasciitilde}5X-10X, even within the same country and the same organization. We are now optimizing where and when large models are trained. Specific datacenter infrastructure matters, as Cloud datacenters can be {\textasciitilde}1.4-2X more energy efficient than typical datacenters, and the ML-oriented accelerators inside them can be {\textasciitilde}2-5X more effective than off-the-shelf systems. Remarkably, the choice of DNN, datacenter, and processor can reduce the carbon footprint up to {\textasciitilde}100-1000X. These large factors also make retroactive estimates of energy cost difficult. To avoid miscalculations, we believe ML papers requiring large computational resources should make energy consumption and CO2e explicit when practical. We are working to be more transparent about energy use and CO2e in our future research. To help reduce the carbon footprint of ML, we believe energy usage and CO2e should be a key metric in evaluating models, and we are collaborating with MLPerf developers to include energy usage during training and inference in this industry standard benchmark.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning}
}

@article{payneNewTraditionalMethods2006,
  title = {New and {{Traditional Methods}} for the {{Analysis}} of {{Unreplicated Experiments}}},
  author = {Payne, Roger W.},
  year = {2006},
  journal = {Crop Science},
  volume = {46},
  number = {6},
  pages = {2476--2481},
  issn = {1435-0653},
  doi = {10.2135/cropsci2006.04.0273},
  urldate = {2025-03-30},
  abstract = {This paper reviews some traditional and more recent methods for analyzing unreplicated experiments. Such experiments have presented a challenge to statisticians throughout their involvement in agricultural research. At Rothamsted this began in 1919, when R.A. Fisher was appointed to analyze the accumulated data from the classical field experiments. Fisher's experiences with the classicals, which had virtually no replication, must have contributed to his inclusion of replication as one of the key features of a well-designed experiment. Nevertheless, Fisher made good use of Rothamsted's data, for example in his study of the influence of rainfall on yields from the Broadbalk. He also devised the randomization test, which can be used to analyze unreplicated data. More recently, Broadbalk has also been used to study climate change and sustainability. Newer developments have been concerned to find alternatives to use, instead of blocking, to take account of the spatial variation within an experiment. The resulting methods for modeling spatial correlations have allowed experimenters to obtain more precise estimates of treatment effects---or to decrease numbers of replicates---and they can also provide reliable analyses of unreplicated treatments.},
  copyright = {{\copyright} Crop Science Society of America},
  langid = {english}
}

@misc{PDFContributionGeostatistics,
  title = {({{PDF}}) {{The Contribution}} of {{Geostatistics}} to {{Precision Agriculture}}},
  journal = {ResearchGate},
  urldate = {2025-03-29},
  abstract = {PDF {\textbar} On Nov 22, 2016, Gabriele Buttafuoco and others published The Contribution of Geostatistics to Precision Agriculture {\textbar} Find, read and cite all the research you need on ResearchGate},
  howpublished = {https://www.researchgate.net/publication/311307357\_The\_Contribution\_of\_Geostatistics\_to\_Precision\_Agriculture},
  langid = {english}
}

@article{piephoWhyRandomizeAgricultural2013,
  title = {Why {{Randomize Agricultural Experiments}}?},
  author = {Piepho, H. P. and M{\"o}hring, J. and Williams, E. R.},
  year = {2013},
  journal = {Journal of Agronomy and Crop Science},
  volume = {199},
  number = {5},
  pages = {374--383},
  issn = {1439-037X},
  doi = {10.1111/jac.12026},
  urldate = {2025-03-30},
  abstract = {This study illustrates the importance of randomization using two hypothetical field trials, one with a marked systematic trend and the other with a more erratic spatial pattern. The insights from these two examples are reinforced by analysis of a uniformity trial and a small simulation study. Results illustrate that both model-based spatial analysis and randomization-based analysis assuming independent errors are valid with full randomization but may be invalidated when randomization is lacking. It is concluded that randomization provides protection against different forms of spatial trend. The examples given in the study serve as a general reminder that agricultural experiments should be randomized whenever possible.},
  langid = {english},
  keywords = {experimental design,field trial,linear model,randomization,statistics,uniformity trial}
}

@article{polderHypeSpectralImaging2021,
  title = {The Hype in Spectral Imaging},
  author = {Polder, Gerrit and Gowen, Aoife},
  year = {2021},
  month = apr,
  journal = {Spectroscopy Europe},
  pages = {12},
  doi = {10.1255/sew.2021.a12}
}

@article{PP1333,
  title = {{{PP}} 1/333 (1) {{Adoption}} of Digital Technology for Data Generation for the Efficacy Evaluation of Plant Protection Products},
  journal = {EPPO Bulletin},
  volume = {n/a},
  number = {n/a},
  issn = {1365-2338},
  doi = {10.1111/epp.13037},
  urldate = {2025-03-17},
  copyright = {{\copyright} 2024 European and Mediterranean Plant Protection Organization.},
  langid = {english}
}

@article{PP13332024,
  title = {{{{\textsc{PP}}}} 1/333 (1) {{Adoption}} of Digital Technology for Data Generation for the Efficacy Evaluation of Plant Protection Products},
  year = {2024},
  month = nov,
  journal = {EPPO Bulletin},
  pages = {epp.13037},
  issn = {0250-8052, 1365-2338},
  doi = {10.1111/epp.13037},
  urldate = {2025-03-12},
  langid = {english}
}

@article{puntelLeveragingDigitalAgriculture2024,
  title = {Leveraging Digital Agriculture for On-Farm Testing of Technologies},
  author = {Puntel, Laila A. and Thompson, Laura J. and Mieno, Taro},
  year = {2024},
  month = mar,
  journal = {Frontiers in Agronomy},
  volume = {6},
  publisher = {Frontiers},
  issn = {2673-3218},
  doi = {10.3389/fagro.2024.1234232},
  urldate = {2025-03-29},
  abstract = {{$<$}p{$>$}The Precision Nitrogen Project (PNP) worked with more than 80 corn and winter wheat producers to inexpensively design and implement randomized, replicated field strip trials on whole commercial farm fields, and to provide site-specific testing of current nitrogen (N) technologies. This article proposes a conceptual framework and detailed procedure to select the N technology to be tested; design and implement field trials; generate, process, and manage field trial data; and automatically analyze, report, and share benefits from precision N technology. The selection of the N technology was farmer-driven to ensure a good fit and to increase the likelihood of future technology adoption. The technology selection method was called the ``N tiered approach'', which consisted of selecting a technology that progressively increases the level of complexity without exceeding the farmer's learning process or farm logistic constraints. The N tools were classified into (1) crop model-based, (2) remote sensing-based, (3) enhanced efficiency fertilizers, and (4) biologicals. Field strip trials comparing producers' traditional management and the selected N technology were combined with site-specific N rate blocks placed in contrasting areas of the fields. Yield data from the N rate blocks was utilized to derive the site-specific optimal N rate. The benefits of current N technologies were quantified by comparing their yield, profit, and N use efficiency (NUE) to growers' traditional management and to the estimated site-specific optimal N rate. Communication of the trial results back to the growers was crucial to ensure the promotion and adoption of these N technologies farm wide. The framework and overall benefits from N technologies was presented and discussed. The proposed framework allowed researchers, agronomists, and farmers to carry out on-farm precision N experimentation using novel technologies to quantify benefits of digital ag technology and promote adoption.{$<$}/p{$>$}},
  langid = {english},
  keywords = {Data driven,Digital technology,Nitrogen,On farm,Trial design}
}

@article{qiModifiedSoilAdjusted1994,
  title = {A Modified Soil Adjusted Vegetation Index},
  author = {Qi, J. and Chehbouni, A. and Huete, A. R. and Kerr, Y. H. and Sorooshian, S.},
  year = {1994},
  month = may,
  journal = {Remote Sensing of Environment},
  volume = {48},
  number = {2},
  pages = {119--126},
  issn = {0034-4257},
  doi = {10.1016/0034-4257(94)90134-1},
  urldate = {2025-03-29},
  abstract = {There is currently a great deal of interest in the quantitative characterization of temporal and spatial vegetation patterns with remotely sensed data for the study of earth system science and global change. Spectral models and indices are being developed to improve vegetation sensitivity by accounting for atmosphere and soil effects. The soil-adjusted vegetation index (SAVI) was developed to minimize soil influences on canopy spectra by incorporating a soil adjustment factor L into the denominator of the normalized difference vegetation index (NDVI) equation. For optimal adjustment of the soil effect, however, the L factor should vary inversely with the amount of vegetation present. A modified SAVI (MSAVI) that replaces the constant L in the SAVI equation with a variable L function is presented in this article. The L function may be derived by induction or by using the product of the NDVI and weighted difference vegetation index (WDVI). Results based on ground and aircraft-measured cotton canopies are presented. The MSAVI is shown to increase the dynamic range of the vegetation signal while further minimizing the soil background influences, resulting in greater vegetation sensitivity as defined by a ``vegetation signal'' to ``soil noise'' ratio.}
}

@misc{radfordLearningTransferableVisual2021,
  title = {Learning {{Transferable Visual Models From Natural Language Supervision}}},
  author = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  year = {2021},
  month = feb,
  number = {arXiv:2103.00020},
  eprint = {2103.00020},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2103.00020},
  urldate = {2025-03-26},
  abstract = {State-of-the-art computer vision systems are trained to predict a fixed set of predetermined object categories. This restricted form of supervision limits their generality and usability since additional labeled data is needed to specify any other visual concept. Learning directly from raw text about images is a promising alternative which leverages a much broader source of supervision. We demonstrate that the simple pre-training task of predicting which caption goes with which image is an efficient and scalable way to learn SOTA image representations from scratch on a dataset of 400 million (image, text) pairs collected from the internet. After pre-training, natural language is used to reference learned visual concepts (or describe new ones) enabling zero-shot transfer of the model to downstream tasks. We study the performance of this approach by benchmarking on over 30 different existing computer vision datasets, spanning tasks such as OCR, action recognition in videos, geo-localization, and many types of fine-grained object classification. The model transfers non-trivially to most tasks and is often competitive with a fully supervised baseline without the need for any dataset specific training. For instance, we match the accuracy of the original ResNet-50 on ImageNet zero-shot without needing to use any of the 1.28 million training examples it was trained on. We release our code and pre-trained model weights at https://github.com/OpenAI/CLIP.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning}
}

@misc{razavianCNNFeaturesOfftheshelf2014,
  title = {{{CNN Features}} Off-the-Shelf: An {{Astounding Baseline}} for {{Recognition}}},
  shorttitle = {{{CNN Features}} Off-the-Shelf},
  author = {Razavian, Ali Sharif and Azizpour, Hossein and Sullivan, Josephine and Carlsson, Stefan},
  year = {2014},
  month = may,
  number = {arXiv:1403.6382},
  eprint = {1403.6382},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1403.6382},
  urldate = {2025-03-26},
  abstract = {Recent results indicate that the generic descriptors extracted from the convolutional neural networks are very powerful. This paper adds to the mounting evidence that this is indeed the case. We report on a series of experiments conducted for different recognition tasks using the publicly available code and model of the {\textbackslash}overfeat network which was trained to perform object classification on ILSVRC13. We use features extracted from the {\textbackslash}overfeat network as a generic image representation to tackle the diverse range of recognition tasks of object image classification, scene recognition, fine grained recognition, attribute detection and image retrieval applied to a diverse set of datasets. We selected these tasks and datasets as they gradually move further away from the original task and data the {\textbackslash}overfeat network was trained to solve. Astonishingly, we report consistent superior results compared to the highly tuned state-of-the-art systems in all the visual classification tasks on various datasets. For instance retrieval it consistently outperforms low memory footprint methods except for sculptures dataset. The results are achieved using a linear SVM classifier (or \$L2\$ distance in case of retrieval) applied to a feature representation of size 4096 extracted from a layer in the net. The representations are further modified using simple augmentation techniques e.g. jittering. The results strongly suggest that features obtained from deep learning with convolutional nets should be the primary candidate in most visual recognition tasks.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{richterGeostatisticalModelsAgricultural2012,
  title = {Geostatistical {{Models}} in {{Agricultural Field Experiments}}: {{Investigations Based}} on {{Uniformity Trials}}},
  shorttitle = {Geostatistical {{Models}} in {{Agricultural Field Experiments}}},
  author = {Richter, Christel and Kroschewski, B{\"a}rbel},
  year = {2012},
  journal = {Agronomy Journal},
  volume = {104},
  number = {1},
  pages = {91--105},
  issn = {1435-0645},
  doi = {10.2134/agronj2011.0100},
  urldate = {2025-03-30},
  abstract = {The probability of detecting treatment differences can often be increased by using geostatistical instead of classical statistical models. Geostatistical approaches require the selection of the best fitted model from a set of alternative models. This additional analysis effort could be reduced if the same model shows consistently the best fit for a given field or crop. To prove whether this reduction can be expected for designed on-station trials, we analyzed five uniformity trials conducted on the same field. We studied whether different layouts of randomized complete block designs, the positions on the field, and the randomized plans influenced the model decision and analyzed the precision achieved. For this, the designs were shifted across the field, and 1000 randomized plans were projected onto each position. The model fit was evaluated using the corrected Akaike information criterion (AICC). The ranked AICC values were used for assessing model preference. In the means of all crops, designs, and models, the variation of the ranks depended on an individual decision for the combination of position and randomized plan by 62.6\%. Therefore, the best fitted model was not predictable for a single experiment. As in the classical approach, the proper layout of a trial determines precision and unbiasedness of treatment differences. Randomization and blocking still should be the basic principles of experiment planning; however, their roles have partially changed. The detected bias of the Type I errors, both of the t-test and F test, needs further investigation. Basic findings are also valid for on-farm trials.},
  copyright = {{\copyright} 2012 The Authors.},
  langid = {english}
}

@misc{RobustDeepLearningBasedDetector,
  title = {A {{Robust Deep-Learning-Based Detector}} for {{Real-Time Tomato Plant Diseases}} and {{Pests Recognition}}},
  urldate = {2025-03-23},
  howpublished = {https://www.mdpi.com/1424-8220/17/9/2022}
}

@article{rodriguez-alvarezCorrectingSpatialHeterogeneity2018,
  title = {Correcting for Spatial Heterogeneity in Plant Breeding Experiments with {{P-splines}}},
  author = {{Rodr{\'i}guez-{\'A}lvarez}, Mar{\'i}a Xos{\'e} and Boer, Martin P. and {van Eeuwijk}, Fred A. and Eilers, Paul H. C.},
  year = {2018},
  month = mar,
  journal = {Spatial Statistics},
  volume = {23},
  pages = {52--71},
  issn = {2211-6753},
  doi = {10.1016/j.spasta.2017.10.003},
  urldate = {2025-03-29},
  abstract = {An important aim of the analysis of agricultural field experiments is to obtain good predictions for genotypic performance, by correcting for spatial effects. In practice these corrections turn out to be complicated, since there can be different types of spatial effects; those due to management interventions applied to the field plots and those due to various kinds of erratic spatial trends. This paper explores the use of two-dimensional smooth surfaces to model random spatial variation. We propose the use of anisotropic tensor product P-splines to explicitly model large-scale (global trend) and small-scale (local trend) spatial dependence. On top of this spatial field, effects of genotypes, blocks, replicates, and/or other sources of spatial variation are described by a mixed model in a standard way. Each component in the model is shown to have an effective dimension. They are closely related to variance estimation, and helpful for characterising the importance of model components. An important result of this paper is the formal proof of the relation between several definitions of heritability and the effective dimension associated with the genetic component. The practical value of our approach is illustrated by simulations and analyses of large-scale plant breeding experiments. An R-package, SpATS, is provided.},
  keywords = {Effective dimension,Field trials,Heritability,Linear mixed model,Spatial analysis,Tensor product P-splines}
}

@article{rodriguez-alvarezFastSmoothingParameter2015,
  title = {Fast Smoothing Parameter Separation in Multidimensional Generalized {{P-splines}}: The {{SAP}} Algorithm},
  shorttitle = {Fast Smoothing Parameter Separation in Multidimensional Generalized {{P-splines}}},
  author = {{Rodr{\'i}guez-{\'A}lvarez}, Mar{\'i}a Xos{\'e} and Lee, Dae-Jin and Kneib, Thomas and Durb{\'a}n, Mar{\'i}a and Eilers, Paul},
  year = {2015},
  month = sep,
  journal = {Statistics and Computing},
  volume = {25},
  number = {5},
  pages = {941--957},
  issn = {1573-1375},
  doi = {10.1007/s11222-014-9464-2},
  urldate = {2025-03-29},
  abstract = {A new computational algorithm for estimating the smoothing parameters of a multidimensional penalized spline generalized linear model with anisotropic penalty is presented. This new proposal is based on the mixed model representation of a multidimensional P-spline, in which the smoothing parameter for each covariate is expressed in terms of variance components. On the basis of penalized quasi-likelihood methods, closed-form expressions for the estimates of the variance components are obtained. This formulation leads to an efficient implementation that considerably reduces the computational burden. The proposed algorithm can be seen as a generalization of the algorithm by Schall (1991)---for variance components estimation---to deal with non-standard structures of the covariance matrix of the random effects. The practical performance of the proposed algorithm is evaluated by means of simulations, and comparisons with alternative methods are made on the basis of the mean square error criterion and the computing time. Finally, we illustrate our proposal with the analysis of two real datasets: a two dimensional example of historical records of monthly precipitation data in USA and a three dimensional one of mortality data from respiratory disease according to the age at death, the year of death and the month of death.},
  langid = {english},
  keywords = {Anisotropic penalty,Artificial Intelligence,Mixed models,P-splines,Smoothing,Tensor product}
}

@misc{ronnebergerUNetConvolutionalNetworks2015,
  title = {U-{{Net}}: {{Convolutional Networks}} for {{Biomedical Image Segmentation}}},
  shorttitle = {U-{{Net}}},
  author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  year = {2015},
  month = may,
  number = {arXiv:1505.04597},
  eprint = {1505.04597},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1505.04597},
  urldate = {2025-03-26},
  abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@inproceedings{rouseMonitoringVegetationSystems1974,
  title = {Monitoring Vegetation Systems in the {{Great Plains}} with {{ERTS}}},
  author = {Rouse, J. W. and Haas, R. H. and Schell, J. A. and Deering, D. W.},
  year = {1974},
  month = jan,
  urldate = {2025-03-29},
  abstract = {The Great Plains Corridor rangeland project utilizes natural vegetation systems as phenological indicators of seasonal development and climatic effects upon regional growth conditions. A method has been developed for quantitative measurement of vegetation conditions over broad regions using ERTS-1 MSS data. Radiance values recorded in ERTS-1 spectral bands 5 and 7, corrected for sun angle, are used to compute a band ratio parameter which is shown to be correlated with aboveground green biomass on rangelands.},
  keywords = {Geophysics},
  annotation = {NTRS Author Affiliations: Texas A\&M Univ.\\
NTRS Report/Patent Number: PAPER-A20\\
NTRS Document ID: 19740022614\\
NTRS Research Center: Legacy CDMS (CDMS)}
}

@inproceedings{rubleeORBEfficientAlternative2011,
  title = {{{ORB}}: {{An}} Efficient Alternative to {{SIFT}} or {{SURF}}},
  shorttitle = {{{ORB}}},
  booktitle = {2011 {{International Conference}} on {{Computer Vision}}},
  author = {Rublee, Ethan and Rabaud, Vincent and Konolige, Kurt and Bradski, Gary},
  year = {2011},
  month = nov,
  pages = {2564--2571},
  issn = {2380-7504},
  doi = {10.1109/ICCV.2011.6126544},
  urldate = {2025-03-29},
  abstract = {Feature matching is at the base of many computer vision problems, such as object recognition or structure from motion. Current methods rely on costly descriptors for detection and matching. In this paper, we propose a very fast binary descriptor based on BRIEF, called ORB, which is rotation invariant and resistant to noise. We demonstrate through experiments how ORB is at two orders of magnitude faster than SIFT, while performing as well in many situations. The efficiency is tested on several real-world applications, including object detection and patch-tracking on a smart phone.},
  keywords = {Boats}
}

@article{ruffUnifyingReviewDeep2021,
  title = {A {{Unifying Review}} of {{Deep}} and {{Shallow Anomaly Detection}}},
  author = {Ruff, Lukas and Kauffmann, Jacob R. and Vandermeulen, Robert A. and Montavon, Gr{\'e}goire and Samek, Wojciech and Kloft, Marius and Dietterich, Thomas G. and M{\"u}ller, Klaus-Robert},
  year = {2021},
  month = may,
  journal = {Proceedings of the IEEE},
  volume = {109},
  number = {5},
  eprint = {2009.11732},
  primaryclass = {cs},
  pages = {756--795},
  issn = {0018-9219, 1558-2256},
  doi = {10.1109/JPROC.2021.3052449},
  urldate = {2025-03-23},
  abstract = {Deep learning approaches to anomaly detection have recently improved the state of the art in detection performance on complex datasets such as large collections of images or text. These results have sparked a renewed interest in the anomaly detection problem and led to the introduction of a great variety of new methods. With the emergence of numerous such methods, including approaches based on generative models, one-class classification, and reconstruction, there is a growing need to bring methods of this field into a systematic and unified perspective. In this review we aim to identify the common underlying principles as well as the assumptions that are often made implicitly by various methods. In particular, we draw connections between classic 'shallow' and novel deep approaches and show how this relation might cross-fertilize or extend both directions. We further provide an empirical assessment of major existing methods that is enriched by the use of recent explainability techniques, and present specific worked-through examples together with practical advice. Finally, we outline critical open challenges and identify specific paths for future research in anomaly detection.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning}
}

@article{sajithaDeepLearningApproach2024,
  title = {A Deep Learning Approach to Detect Diseases in Pomegranate Fruits via Hybrid Optimal Attention Capsule Network},
  author = {Sajitha, P. and Diana Andrushia, A. and Anand, N. and Naser, M. Z. and Lubloy, Eva},
  year = {2024},
  month = dec,
  journal = {Ecological Informatics},
  volume = {84},
  pages = {102859},
  issn = {1574-9541},
  doi = {10.1016/j.ecoinf.2024.102859},
  urldate = {2025-03-23},
  abstract = {In 2022, the production rate of pomegranate is estimated at approximately 4.8 million metric tons. Unfortunately, these fruits are susceptible to many different kinds of diseases caused by bacterial, viral, and fungal infections. Such diseases can have a major negative impact on fruit quality, production, and the profitability of pomegranate cultivation. Nowadays, several machine learning and deep learning methods are used to identify pomegranate fruit diseases automatically and effectively. In post-harvest pomegranate fruit disease detection, deep learning has great potential to extract complex patterns and features from large datasets. This can improve disease identification accuracy, enabling more efficient disease control, lower crop losses, and better resource management. The proposed work introduces an intelligent deep learning-based approach for accurately detecting pomegranate diseases, begins with Improved Guided Image Filtering (Improved GIF) and resizing to pre-process fruit images, followed by feature extraction (shape, color, texture) using GLCM and GLRLM to streamline classification. Extracted features are then fed into a novel Hybrid Optimal Attention Capsule Network (Hybrid OACapsNet), which classifies the images as normal or diseased, conditions such as bacterial blight, heart rot, and scab. Our analysis indicates that the proposed classifier has a classification accuracy of 99.19~\%, precision of 98.45~\%, recall of 98.41~\%, F1-score of 98.43~\%, and specificity of 99.45~\% compared to other techniques. So this approach offers a framework, which is a feasible solution for automated detection of diseases in fruits, thereby benefiting farmers and supporting their farming operations.},
  keywords = {Deep learning,Fruit disease detection,Hybrid OACapsNet,Pomegranate,Post-harvest technique}
}

@article{sajithaDeepLearningApproach2024a,
  title = {A Deep Learning Approach to Detect Diseases in Pomegranate Fruits via Hybrid Optimal Attention Capsule Network},
  author = {Sajitha, P. and Diana Andrushia, A. and Anand, N. and Naser, M. Z. and Lubloy, Eva},
  year = {2024},
  month = dec,
  journal = {Ecological Informatics},
  volume = {84},
  pages = {102859},
  issn = {1574-9541},
  doi = {10.1016/j.ecoinf.2024.102859},
  urldate = {2025-03-23},
  abstract = {In 2022, the production rate of pomegranate is estimated at approximately 4.8 million metric tons. Unfortunately, these fruits are susceptible to many different kinds of diseases caused by bacterial, viral, and fungal infections. Such diseases can have a major negative impact on fruit quality, production, and the profitability of pomegranate cultivation. Nowadays, several machine learning and deep learning methods are used to identify pomegranate fruit diseases automatically and effectively. In post-harvest pomegranate fruit disease detection, deep learning has great potential to extract complex patterns and features from large datasets. This can improve disease identification accuracy, enabling more efficient disease control, lower crop losses, and better resource management. The proposed work introduces an intelligent deep learning-based approach for accurately detecting pomegranate diseases, begins with Improved Guided Image Filtering (Improved GIF) and resizing to pre-process fruit images, followed by feature extraction (shape, color, texture) using GLCM and GLRLM to streamline classification. Extracted features are then fed into a novel Hybrid Optimal Attention Capsule Network (Hybrid OACapsNet), which classifies the images as normal or diseased, conditions such as bacterial blight, heart rot, and scab. Our analysis indicates that the proposed classifier has a classification accuracy of 99.19~\%, precision of 98.45~\%, recall of 98.41~\%, F1-score of 98.43~\%, and specificity of 99.45~\% compared to other techniques. So this approach offers a framework, which is a feasible solution for automated detection of diseases in fruits, thereby benefiting farmers and supporting their farming operations.},
  keywords = {Deep learning,Fruit disease detection,Hybrid OACapsNet,Pomegranate,Post-harvest technique}
}

@book{salinasruizGeneralizedLinearMixed2023,
  title = {Generalized {{Linear Mixed Models}} with {{Applications}} in {{Agriculture}} and {{Biology}}},
  author = {Salinas Ru{\'i}z, Josafhat and Montesinos L{\'o}pez, Osval Antonio and Hern{\'a}ndez Ram{\'i}rez, Gabriela and Crossa Hiriart, Jose},
  year = {2023},
  publisher = {Springer International Publishing AG},
  address = {Cham, SWITZERLAND},
  urldate = {2025-03-14},
  isbn = {978-3-031-32800-8}
}

@article{sarviaGeometricVsSpectral2024,
  title = {Geometric vs Spectral Content of {{Remotely Piloted Aircraft Systems}} Images in the {{Precision}} Agriculture Context},
  author = {Sarvia, Filippo and De Petris, Samuele and Farbo, Alessandro and {Borgogno-Mondino}, Enrico},
  year = {2024},
  month = sep,
  journal = {The Egyptian Journal of Remote Sensing and Space Sciences},
  volume = {27},
  number = {3},
  pages = {524--531},
  issn = {1110-9823},
  doi = {10.1016/j.ejrs.2024.06.003},
  urldate = {2025-03-29},
  abstract = {In the last years the agricultural sector has been evolving and new technologies, like Unmanned Aerial Vehicles (UAV) and satellites, were introduced to increase crop management efficiency, reducing environmental costs and improving farmers' income. MAIA-S2 sensor is presently one of the most performing optical sensors operating on a Remotely Piloted Aircraft Systems (RPAS); given its spectral features, it aims at supporting a scaling process where monoscopic satellite data (namely Copernicus S2) with high temporal and limited geometric resolution can be integrated with stereoscopic data from RPAS having a very high spatial resolution. In this work, data from MAIA-S2 sensor were used to detect the effects of different fertilization types on corn with reference to a test field located in Carignano (Piemonte region, NW-Italy). Different amounts of top dressing fertilization were applied on corn and an RPAS acquisition operated on 14th June 2021 (corresponding date to the corn stem elongation stage) to explore if any effects could be detectable. Three spectral indices, namely Normalized Difference Vegetation Index, Normalized Difference Red Edge index and Canopy Height Model, computed from at-the-ground reflectance calibrated MAIA-S2 data, were compared to evaluate the correspondent response to the different fertilization rates. Results show that: (i) NDVI poorly detect N-related differences zones; (ii) NDRE and CHM reasonably reflect the different N fertilization doses; (iii) Only CHM proved to be able to detect crop height and, consequently, biomass differences that are known to be induced by different rates of fertilization.},
  keywords = {Canopy height model,Precision farming,RPAS,Spectral index,UAV}
}

@article{sarviaGeometricVsSpectral2024a,
  title = {Geometric vs Spectral Content of {{Remotely Piloted Aircraft Systems}} Images in the {{Precision}} Agriculture Context},
  author = {Sarvia, Filippo and De Petris, Samuele and Farbo, Alessandro and {Borgogno-Mondino}, Enrico},
  year = {2024},
  month = sep,
  journal = {The Egyptian Journal of Remote Sensing and Space Sciences},
  volume = {27},
  number = {3},
  pages = {524--531},
  issn = {1110-9823},
  doi = {10.1016/j.ejrs.2024.06.003},
  urldate = {2025-03-29},
  abstract = {In the last years the agricultural sector has been evolving and new technologies, like Unmanned Aerial Vehicles (UAV) and satellites, were introduced to increase crop management efficiency, reducing environmental costs and improving farmers' income. MAIA-S2 sensor is presently one of the most performing optical sensors operating on a Remotely Piloted Aircraft Systems (RPAS); given its spectral features, it aims at supporting a scaling process where monoscopic satellite data (namely Copernicus S2) with high temporal and limited geometric resolution can be integrated with stereoscopic data from RPAS having a very high spatial resolution. In this work, data from MAIA-S2 sensor were used to detect the effects of different fertilization types on corn with reference to a test field located in Carignano (Piemonte region, NW-Italy). Different amounts of top dressing fertilization were applied on corn and an RPAS acquisition operated on 14th June 2021 (corresponding date to the corn stem elongation stage) to explore if any effects could be detectable. Three spectral indices, namely Normalized Difference Vegetation Index, Normalized Difference Red Edge index and Canopy Height Model, computed from at-the-ground reflectance calibrated MAIA-S2 data, were compared to evaluate the correspondent response to the different fertilization rates. Results show that: (i) NDVI poorly detect N-related differences zones; (ii) NDRE and CHM reasonably reflect the different N fertilization doses; (iii) Only CHM proved to be able to detect crop height and, consequently, biomass differences that are known to be induced by different rates of fertilization.},
  keywords = {Canopy height model,Precision farming,RPAS,Spectral index,UAV}
}

@article{savaryGlobalBurdenPathogens2019,
  title = {The Global Burden of Pathogens and Pests on Major Food Crops},
  author = {Savary, Serge and Willocquet, Laetitia and Pethybridge, Sarah Jane and Esker, Paul and McRoberts, Neil and Nelson, Andy},
  year = {2019},
  month = mar,
  journal = {Nature Ecology \& Evolution},
  volume = {3},
  number = {3},
  pages = {430--439},
  issn = {2397-334X},
  doi = {10.1038/s41559-018-0793-y},
  abstract = {Crop pathogens and pests reduce the yield and quality of agricultural production. They cause substantial economic losses and reduce food security at household, national and global levels. Quantitative, standardized information on crop losses is difficult to compile and compare across crops, agroecosystems and regions. Here, we report on an expert-based assessment of crop health, and provide numerical estimates of yield losses on an individual pathogen and pest basis for five major crops globally and in food security hotspots. Our results document losses associated with 137 pathogens and pests associated with wheat, rice, maize, potato and soybean worldwide. Our yield loss (range) estimates at a global level and per hotspot for wheat (21.5\% (10.1-28.1\%)), rice (30.0\% (24.6-40.9\%)), maize (22.5\% (19.5-41.1\%)), potato (17.2\% (8.1-21.0\%)) and soybean (21.4\% (11.0-32.4\%)) suggest that the highest losses are associated with food-deficit regions with fast-growing populations, and frequently with emerging or re-emerging pests and diseases. Our assessment highlights differences in impacts among crop pathogens and pests and among food security hotspots. This analysis contributes critical information to prioritize crop health management to improve the sustainability of agroecosystems in delivering services to societies.},
  langid = {english},
  pmid = {30718852},
  keywords = {Agriculture,Animals,Climate Change,Crops Agricultural,Food Supply,Host-Pathogen Interactions,Insecta,Mites,Plant Weeds}
}

@book{schabenbergerStatisticalMethodsSpatial2004,
  title = {Statistical {{Methods}} for {{Spatial Data Analysis}}},
  author = {Schabenberger, Oliver and Gotway, Carol A.},
  year = {2004},
  month = dec,
  publisher = {CRC Press},
  abstract = {Understanding spatial statistics requires tools from applied and mathematical statistics, linear model theory, regression, time series, and stochastic processes. It also requires a mindset that focuses on the unique characteristics of spatial data and the development of specialized analytical tools designed explicitly for spatial data analysis. Statistical Methods for Spatial Data Analysis answers the demand for a text that incorporates all of these factors by presenting a balanced exposition that explores both the theoretical foundations of the field of spatial statistics as well as practical methods for the analysis of spatial data. This book is a comprehensive and illustrative treatment of basic statistical theory and methods for spatial data analysis, employing a model-based and frequentist approach that emphasizes the spatial domain. It introduces essential tools and approaches including: measures of autocorrelation and their role in data analysis; the background and theoretical framework supporting random fields; the analysis of mapped spatial point patterns; estimation and modeling of the covariance function and semivariogram; a comprehensive treatment of spatial analysis in the spectral domain; and spatial prediction and kriging. The volume also delivers a thorough analysis of spatial regression, providing a detailed development of linear models with uncorrelated errors, linear models with spatially-correlated errors and generalized linear mixed models for spatial data. It succinctly discusses Bayesian hierarchical models and concludes with reviews on simulating random fields, non-stationary covariance, and spatio-temporal processes.Additional material on the CRC Press website supplements the content of this book. The site provides data sets used as examples in the text, software code that can be used to implement many of the principal methods described and illustrated, and updates to the text itself.},
  googlebooks = {iVJuVLArmZcC},
  isbn = {978-0-203-49198-0},
  langid = {english},
  keywords = {Business & Economics / Industries / Agribusiness,Mathematics / Probability & Statistics / General}
}

@article{schramowskiMakingDeepNeural2020,
  title = {Making Deep Neural Networks Right for the Right Scientific Reasons by Interacting with Their Explanations},
  author = {Schramowski, Patrick and Stammer, Wolfgang and Teso, Stefano and Brugger, Anna and Herbert, Franziska and Shao, Xiaoting and Luigs, Hans-Georg and Mahlein, Anne-Katrin and Kersting, Kristian},
  year = {2020},
  month = aug,
  journal = {Nature Machine Intelligence},
  volume = {2},
  number = {8},
  pages = {476--486},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-020-0212-3},
  urldate = {2025-03-26},
  abstract = {Deep neural networks have demonstrated excellent performances in many real-world applications. Unfortunately, they may show Clever Hans-like behaviour (making use of confounding factors within datasets) to achieve high performance. In this work we introduce the novel learning setting of explanatory interactive learning and illustrate its benefits on a plant phenotyping research task. Explanatory interactive learning adds the scientist into the training loop, who interactively revises the original model by providing feedback on its explanations. Our experimental results demonstrate that explanatory interactive learning can help to avoid Clever Hans moments in machine learning and encourages (or discourages, if appropriate) trust in the underlying model.},
  copyright = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english},
  keywords = {Machine learning,Plant sciences}
}

@misc{schramowskiMakingDeepNeural2024,
  title = {Making Deep Neural Networks Right for the Right Scientific Reasons by Interacting with Their Explanations},
  author = {Schramowski, Patrick and Stammer, Wolfgang and Teso, Stefano and Brugger, Anna and Shao, Xiaoting and Luigs, Hans-Georg and Mahlein, Anne-Katrin and Kersting, Kristian},
  year = {2024},
  month = mar,
  number = {arXiv:2001.05371},
  eprint = {2001.05371},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2001.05371},
  urldate = {2025-03-26},
  abstract = {Deep neural networks have shown excellent performances in many real-world applications. Unfortunately, they may show "Clever Hans"-like behavior -- making use of confounding factors within datasets -- to achieve high performance. In this work, we introduce the novel learning setting of "explanatory interactive learning" (XIL) and illustrate its benefits on a plant phenotyping research task. XIL adds the scientist into the training loop such that she interactively revises the original model via providing feedback on its explanations. Our experimental results demonstrate that XIL can help avoiding Clever Hans moments in machine learning and encourages (or discourages, if appropriate) trust into the underlying model.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning}
}

@inproceedings{seitzComparisonEvaluationMultiView2006,
  title = {A {{Comparison}} and {{Evaluation}} of {{Multi-View Stereo Reconstruction Algorithms}}},
  booktitle = {2006 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}}'06)},
  author = {Seitz, S.M. and Curless, B. and Diebel, J. and Scharstein, D. and Szeliski, R.},
  year = {2006},
  month = jun,
  volume = {1},
  pages = {519--528},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2006.19},
  urldate = {2025-03-29},
  abstract = {This paper presents a quantitative comparison of several multi-view stereo reconstruction algorithms. Until now, the lack of suitable calibrated multi-view image datasets with known ground truth (3D shape models) has prevented such direct comparisons. In this paper, we first survey multi-view stereo algorithms and compare them qualitatively using a taxonomy that differentiates their key properties. We then describe our process for acquiring and calibrating multiview image datasets with high-accuracy ground truth and introduce our evaluation methodology. Finally, we present the results of our quantitative comparison of state-of-the-art multi-view stereo reconstruction algorithms on six benchmark datasets. The datasets, evaluation details, and instructions for submitting new models are available online at http://vision.middlebury.edu/mview.},
  keywords = {Cameras,Educational institutions,Image databases,Image reconstruction,Layout,Reconstruction algorithms,Shape measurement,Stereo image processing,Stereo vision,Taxonomy}
}

@misc{simonyanVeryDeepConvolutional2015,
  title = {Very {{Deep Convolutional Networks}} for {{Large-Scale Image Recognition}}},
  author = {Simonyan, Karen and Zisserman, Andrew},
  year = {2015},
  month = apr,
  number = {arXiv:1409.1556},
  eprint = {1409.1556},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1409.1556},
  urldate = {2025-03-23},
  abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{singhEffectivePlantDisease2024,
  title = {Effective Plant Disease Diagnosis Using {{Vision Transformer}} Trained with Leafy-Generative Adversarial Network-Generated Images},
  author = {Singh, Aadarsh Kumar and Rao, Akhil and Chattopadhyay, Pratik and Maurya, Rahul and Singh, Lokesh},
  year = {2024},
  month = nov,
  journal = {Expert Systems with Applications},
  volume = {254},
  pages = {124387},
  issn = {0957-4174},
  doi = {10.1016/j.eswa.2024.124387},
  urldate = {2025-03-23},
  abstract = {Agriculture, as the foundation of human civilization, is critical to the global economy, providing food for billions. Plant diseases, caused by factors such as bacteria, fungi, viruses, and others, loom large over crop yields, jeopardizing farmers' livelihoods worldwide. Rapid and accurate identification of these diseases is critical for agricultural productivity protection and to date, several automated plant disease diagnosis methods have been developed by researchers worldwide. However, the issue of having limited labeled datasets for certain plant leaf diseases poses a significant challenge in training classification models effectively. This scarcity often results in class imbalance which adversely affects a model's ability to accurately predict all the disease classes. It appears there is a need to explore synthetic data generation techniques to train the model for making a better prediction. Further, the disease prediction model should be lightweight so that it can be conveniently integrated with low-end devices with less computational power that farmers can afford to purchase. In this work, we aim to develop an effective neural augmentation model that can render synthetic disease patterns on uninfected leaf images thereby enhancing the leaf disease dataset by adding artificial samples corresponding to those disease classes for which only minor ground truth information is available. Our work extends the state-of-the-art by introducing a new model for leaf disease augmentation, termed ``LeafyGAN'', that comprises two key elements: a segmentation model and a disease translation model, both of which are GAN-based. The segmentation model is a pix2pix GAN that is trained to separate foreground leaf images from the background and is trained using a combination of L1 loss and standard GAN loss. The disease translation model is a CycleGAN which is trained using a combination of adversarial loss and cycle consistency loss, which uses the generated segmented mask to render synthetic disease patterns to the extracted leaf regions. A lightweight MobileViT model trained using this augmented data has been seen to perform disease diagnosis with a remarkable accuracy of 99.92\% on the PlantVillage dataset and 75.72\% on the PlantDoc dataset. Notably, our model achieves an accuracy that is comparable with the recent CNN and Transformer-based models with a significantly lesser number of parameters.},
  keywords = {Disease pattern generation,Generative adversarial networks,Lightweight Vision Transformers,Plant disease diagnosis}
}

@article{slaetsLinearMixedModels2021,
  title = {Linear Mixed Models and Geostatistics for Designed Experiments in Soil Science: {{Two}} Entirely Different Methods or Two Sides of the Same Coin?},
  shorttitle = {Linear Mixed Models and Geostatistics for Designed Experiments in Soil Science},
  author = {Slaets, Johanna I. F. and Boeddinghaus, Runa S. and Piepho, Hans-Peter},
  year = {2021},
  journal = {European Journal of Soil Science},
  volume = {72},
  number = {1},
  pages = {47--68},
  issn = {1365-2389},
  doi = {10.1111/ejss.12976},
  urldate = {2025-03-30},
  abstract = {Soil scientists are accustomed to geostatistical methods and tools such as semivariograms and kriging for analysis of observational data. Such methods assume and exploit that observations are spatially correlated. Conversely, analysis of variance (ANOVA) of designed experiments assumes that observations from different experimental units are independent, an assumption that is justified based on randomization. It may be beneficial, however, to perform an ANOVA assuming a geostatistical covariance model. Also, it is increasingly common to have multiple observations per experimental unit. Simple ANOVA assuming independence of observations is not appropriate for such data. Instead, a linear mixed model accounting for correlation among observations made on the same plot is required for proper analysis. The purpose of this paper is to demonstrate the benefits of integrating geostatistical covariance structures and ANOVA procedures into a linear mixed modelling framework. Two examples from designed experiments are considered in detail, making a link between terminologies and jargon used in geostatistical analysis on the one hand and linear mixed modelling on the other hand. We provide code in R and SAS for both examples in two supporting companion documents. Highlights Analysis of variance and geostatistical analysis can be joined in a mixed model. Randomization justifies the independence assumption in analysis of variance. Geostatistical models imply a correlation of errors and can improve efficiency. Lacking randomization, spatial correlation can be accounted for in a mixed model.},
  copyright = {{\copyright} 2020 The Authors. European Journal of Soil Science published by John Wiley \& Sons Ltd on behalf of British Society of Soil Science.},
  langid = {english},
  keywords = {analysis of variance,designed experiment,kriging,mean comparison,nugget,polynomial regression,random effect,randomization,range,semivariogram,sill,spatial analysis}
}

@article{stroupRethinkingAnalysisNonNormal2015,
  title = {Rethinking the {{Analysis}} of {{Non-Normal Data}} in {{Plant}} and {{Soil Science}}},
  author = {Stroup, Walter W.},
  year = {2015},
  journal = {Agronomy Journal},
  volume = {107},
  number = {2},
  pages = {811--827},
  issn = {1435-0645},
  doi = {10.2134/agronj2013.0342},
  urldate = {2025-03-30},
  abstract = {The introduction of high-quality, useable generalized linear mixed model (GLMM) software in the mid-2000s changed the conversation regarding the analysis of non-normal data from designed experiments. For well over half a century, the reigning paradigm called for using analysis of variance (ANOVA), either assuming approximate normality of the original data or applying a variance-stabilizing transformation. The appearance of GLMMs creates a dilemma. The ANOVA-based analyses and GLMM-based analyses often yield mutually contradictory results. What results should a researcher report, and how should the choice be justified? If GLMM-based analysis is preferred---and there is increasing evidence that this is the case---approaches to data analysis ingrained while learning ANOVA must be unlearned and relearned. The basic issues associated with the analysis of non-normal data are reviewed here, the thought processes required for GLMMs and how they differ from traditional ANOVA are introduced, and three examples are presented, giving an overview of GLMM-based analysis. The three examples include discussions of what is known to date about the relative merits of GLMM- and ANOVA-based analysis of non-normal data.},
  copyright = {{\copyright} 2015 The Authors.},
  langid = {english}
}

@misc{strubellEnergyPolicyConsiderations2019,
  title = {Energy and {{Policy Considerations}} for {{Deep Learning}} in {{NLP}}},
  author = {Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
  year = {2019},
  month = jun,
  number = {arXiv:1906.02243},
  eprint = {1906.02243},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1906.02243},
  urldate = {2025-03-26},
  abstract = {Recent progress in hardware and methodology for training neural networks has ushered in a new generation of large networks trained on abundant data. These models have obtained notable gains in accuracy across many NLP tasks. However, these accuracy improvements depend on the availability of exceptionally large computational resources that necessitate similarly substantial energy consumption. As a result these models are costly to train and develop, both financially, due to the cost of hardware and electricity or cloud compute time, and environmentally, due to the carbon footprint required to fuel modern tensor processing hardware. In this paper we bring this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training a variety of recently successful neural network models for NLP. Based on these findings, we propose actionable recommendations to reduce costs and improve equity in NLP research and practice.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language}
}

@article{studentProbableErrorMean1908,
  title = {The {{Probable Error}} of a {{Mean}}},
  author = {{Student}},
  year = {1908},
  journal = {Biometrika},
  volume = {6},
  number = {1},
  eprint = {2331554},
  eprinttype = {jstor},
  pages = {1--25},
  publisher = {[Oxford University Press, Biometrika Trust]},
  issn = {0006-3444},
  doi = {10.2307/2331554},
  urldate = {2025-03-14}
}

@book{szeliskiComputerVisionAlgorithms2022,
  title = {Computer {{Vision}}: {{Algorithms}} and {{Applications}}},
  shorttitle = {Computer {{Vision}}},
  author = {Szeliski, Richard},
  year = {2022},
  series = {Texts in {{Computer Science}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {1868-0941, 1868-095X},
  doi = {10.1007/978-3-030-34372-9},
  urldate = {2025-03-29},
  copyright = {https://www.springer.com/tdm},
  isbn = {978-3-030-34371-2 978-3-030-34372-9},
  langid = {english},
  keywords = {3D Reconstruction,Computational Photography,Computer Vision,Deep Learning,Feature Detection and Matching,Image Processing,Image Segmentation,Image Stitching,Image-Based Rendering,Motion Estimation,Scene Recognition,Structure from Motion}
}

@misc{tanEfficientNetRethinkingModel2020,
  title = {{{EfficientNet}}: {{Rethinking Model Scaling}} for {{Convolutional Neural Networks}}},
  shorttitle = {{{EfficientNet}}},
  author = {Tan, Mingxing and Le, Quoc V.},
  year = {2020},
  month = sep,
  number = {arXiv:1905.11946},
  eprint = {1905.11946},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1905.11946},
  urldate = {2025-03-23},
  abstract = {Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up MobileNets and ResNet. To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves state-of-the-art 84.3\% top-1 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet. Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7\%), Flowers (98.8\%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters. Source code is at https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning}
}

@misc{tanEfficientNetRethinkingModel2020a,
  title = {{{EfficientNet}}: {{Rethinking Model Scaling}} for {{Convolutional Neural Networks}}},
  shorttitle = {{{EfficientNet}}},
  author = {Tan, Mingxing and Le, Quoc V.},
  year = {2020},
  month = sep,
  number = {arXiv:1905.11946},
  eprint = {1905.11946},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1905.11946},
  urldate = {2025-03-26},
  abstract = {Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up MobileNets and ResNet. To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves state-of-the-art 84.3\% top-1 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet. Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7\%), Flowers (98.8\%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters. Source code is at https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning}
}

@misc{thapaPlantPathology20202020,
  title = {The {{Plant Pathology}} 2020 Challenge Dataset to Classify Foliar Disease of Apples},
  author = {Thapa, Ranjita and Snavely, Noah and Belongie, Serge and Khan, Awais},
  year = {2020},
  month = apr,
  number = {arXiv:2004.11958},
  eprint = {2004.11958},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2004.11958},
  urldate = {2025-03-23},
  abstract = {Apple orchards in the U.S. are under constant threat from a large number of pathogens and insects. Appropriate and timely deployment of disease management depends on early disease detection. Incorrect and delayed diagnosis can result in either excessive or inadequate use of chemicals, with increased production costs, environmental, and health impacts. We have manually captured 3,651 high-quality, real-life symptom images of multiple apple foliar diseases, with variable illumination, angles, surfaces, and noise. A subset, expert-annotated to create a pilot dataset for apple scab, cedar apple rust, and healthy leaves, was made available to the Kaggle community for 'Plant Pathology Challenge'; part of the Fine-Grained Visual Categorization (FGVC) workshop at CVPR 2020 (Computer Vision and Pattern Recognition). We also trained an off-the-shelf convolutional neural network (CNN) on this data for disease classification and achieved 97\% accuracy on a held-out test set. This dataset will contribute towards development and deployment of machine learning-based automated plant disease classification algorithms to ultimately realize fast and accurate disease detection. We will continue to add images to the pilot dataset for a larger, more comprehensive expert-annotated dataset for future Kaggle competitions and to explore more advanced methods for disease classification and quantification.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing}
}

@book{thenkabailHyperspectralRemoteSensing2016,
  title = {Hyperspectral {{Remote Sensing}} of {{Vegetation}}},
  editor = {Thenkabail, Prasad S. and Lyon, John G.},
  year = {2016},
  month = apr,
  publisher = {CRC Press},
  address = {Boca Raton},
  doi = {10.1201/b11222},
  abstract = {Hyperspectral narrow-band (or imaging spectroscopy) spectral data are fast emerging as practical solutions in modeling and mapping vegetation. Recent research has demonstrated the advances in and merit of hyperspectral data in a range of applications including quantifying agricultural crops, modeling forest canopy biochemical properties, detecting},
  isbn = {978-0-429-19218-0}
}

@article{tocherDesignAnalysisBlock1952,
  title = {The {{Design}} and {{Analysis}} of {{Block Experiments}}},
  author = {Tocher, K. D.},
  year = {1952},
  journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
  volume = {14},
  number = {1},
  pages = {45--91},
  issn = {2517-6161},
  doi = {10.1111/j.2517-6161.1952.tb00101.x},
  urldate = {2025-03-30},
  abstract = {This paper attempts to give a systematic derivation of the principal results of the analysis of block experiments using matrix notation. It also shows how the problem of design can be formulated in an analytical form and illustrates the type of mathematical problem that arises in such a formulation. The systematic approach to the analysis of experiments enables methods to be evolved for performing these analyses on automatic calculating machines and to facilitate this the paper discusses the analysis of spoilt experiments and the iterative solution of the equations arising in the recovery of inter-block information.},
  copyright = {{\copyright} 1952 The Authors},
  langid = {english}
}

@article{todaHowConvolutionalNeural2019,
  title = {How {{Convolutional Neural Networks Diagnose Plant Disease}}},
  author = {Toda, Yosuke and Okura, Fumio},
  year = {2019},
  journal = {Plant Phenomics (Washington, D.C.)},
  volume = {2019},
  pages = {9237136},
  issn = {2643-6515},
  doi = {10.34133/2019/9237136},
  abstract = {Deep learning with convolutional neural networks (CNNs) has achieved great success in the classification of various plant diseases. However, a limited number of studies have elucidated the process of inference, leaving it as an untouchable black box. Revealing the CNN to extract the learned feature as an interpretable form not only ensures its reliability but also enables the validation of the model authenticity and the training dataset by human intervention. In this study, a variety of neuron-wise and layer-wise visualization methods were applied using a CNN, trained with a publicly available plant disease image dataset. We showed that neural networks can capture the colors and textures of lesions specific to respective diseases upon diagnosis, which resembles human decision-making. While several visualization methods were used as they are, others had to be optimized to target a specific layer that fully captures the features to generate consequential outputs. Moreover, by interpreting the generated attention maps, we identified several layers that were not contributing to inference and removed such layers inside the network, decreasing the number of parameters by 75\% without affecting the classification accuracy. The results provide an impetus for the CNN black box users in the field of plant science to better understand the diagnosis process and lead to further efficient use of deep learning for plant disease diagnosis.},
  langid = {english},
  pmcid = {PMC7706313},
  pmid = {33313540}
}

@article{tomislavhenglPracticalGuideGeostatistical2007,
  title = {A {{Practical Guide}} to {{Geostatistical}}  {{Mapping}} of {{Environmental Variables}}},
  author = {{Tomislav Hengl}},
  year = {2007},
  month = sep,
  issn = {1018-5593},
  urldate = {2025-03-29}
}

@inproceedings{torralbaUnbiasedLookDataset2011,
  title = {Unbiased Look at Dataset Bias},
  booktitle = {{{CVPR}} 2011},
  author = {Torralba, Antonio and Efros, Alexei A.},
  year = {2011},
  month = jun,
  pages = {1521--1528},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2011.5995347},
  urldate = {2025-03-26},
  abstract = {Datasets are an integral part of contemporary object recognition research. They have been the chief reason for the considerable progress in the field, not just as source of large amounts of training data, but also as means of measuring and comparing performance of competing algorithms. At the same time, datasets have often been blamed for narrowing the focus of object recognition research, reducing it to a single benchmark performance number. Indeed, some datasets, that started out as data capture efforts aimed at representing the visual world, have become closed worlds unto themselves (e.g. the Corel world, the Caltech-101 world, the PASCAL VOC world). With the focus on beating the latest benchmark numbers on the latest dataset, have we perhaps lost sight of the original purpose? The goal of this paper is to take stock of the current state of recognition datasets. We present a comparison study using a set of popular datasets, evaluated based on a number of criteria including: relative data bias, cross-dataset generalization, effects of closed-world assumption, and sample value. The experimental results, some rather surprising, suggest directions that can improve dataset collection as well as algorithm evaluation protocols. But more broadly, the hope is to stimulate discussion in the community regarding this very important, but largely neglected issue.},
  keywords = {Communities,Internet,Object recognition,Support vector machines,Testing,Training,Visualization}
}

@article{trevisanSpatialVariabilityCrop2021,
  title = {Spatial Variability of Crop Responses to Agronomic Inputs in On-Farm Precision Experimentation},
  author = {Trevisan, R. G. and Bullock, D. S. and Martin, N. F.},
  year = {2021},
  month = apr,
  journal = {Precision Agriculture},
  volume = {22},
  number = {2},
  pages = {342--363},
  issn = {1573-1618},
  doi = {10.1007/s11119-020-09720-8},
  urldate = {2025-03-29},
  abstract = {Within-field variability of crop yield levels has been extensively investigated, but the spatial variability of crop yield responses to agronomic treatments is less understood. On-farm precision experimentation (OFPE) can be a valuable tool for the estimation of in-field variation of optimal input rates and thus improve agronomic decisions. Therefore, the objectives of this study were to investigate the spatial variability of optimal input rates in OFPE and the potential economic benefit of site-specific input management. Mixed geographically weighted regression (GWR) models were used to estimate local yield response functions. The methodology was applied to investigate the spatial variability in corn response to nitrogen and seed rates in four cornfields in Illinois, USA. The results showed that spatial heterogeneity of model parameters was significant in all four fields evaluated. On average, the RMSE of the fitted yield decreased from 1.2~Mg~ha-1 in the non-spatial global model to 0.7~Mg~ha-1 in the GWR model, and the r-squared increased from 10 to 68\%. The average potential gain of using optimized uniform rates of seed and nitrogen was US\$ 65.00~ha-1, while the added potential gain of the site-specific application was US\$ 58.00~ha-1. The combination of OFPE and GWR proved to be an effective tool for testing precision agriculture's central hypothesis of whether optimal input application rates display adequate spatial variability to justify the costs of the variable rate technology itself. The reported results encourage more research on response-based input management recommendations instead of the still widespread focus on yield-based algorithms.},
  langid = {english},
  keywords = {Geographically weighted regression,Nitrogen,Seed,Variable rate application,Yield response functions,Zea mays L.}
}

@inproceedings{triggsBundleAdjustmentModern2000,
  title = {Bundle {{Adjustment}} --- {{A Modern Synthesis}}},
  booktitle = {Vision {{Algorithms}}: {{Theory}} and {{Practice}}},
  author = {Triggs, Bill and McLauchlan, Philip F. and Hartley, Richard I. and Fitzgibbon, Andrew W.},
  editor = {Triggs, Bill and Zisserman, Andrew and Szeliski, Richard},
  year = {2000},
  pages = {298--372},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/3-540-44480-7_21},
  abstract = {This paper is a survey of the theory and methods of photogrammetric bundle adjustment, aimed at potential implementors in the computer vision community. Bundle adjustment is the problem of refining a visual reconstruction to produce jointly optimal structure and viewing parameter estimates. Topics covered include: the choice of cost function and robustness; numerical optimization including sparse Newton methods, linearly convergent approximations, updating and recursive methods; gauge (datum) invariance; and quality control. The theory is developed for general robust cost functions rather than restricting attention to traditional nonlinear least squares.},
  isbn = {978-3-540-44480-0},
  langid = {english},
  keywords = {Bundle Adjustment,Gauge Freedom,Optimization,Scene Reconstruction,Sparse Matrices}
}

@article{tuckerRedPhotographicInfrared1979,
  title = {Red and Photographic Infrared Linear Combinations for Monitoring Vegetation},
  author = {Tucker, Compton J.},
  year = {1979},
  month = may,
  journal = {Remote Sensing of Environment},
  volume = {8},
  number = {2},
  pages = {127--150},
  issn = {0034-4257},
  doi = {10.1016/0034-4257(79)90013-0},
  urldate = {2025-03-29},
  abstract = {In situ collected spectrometer data were used to evaluate and quantify the relationships between various linear combinations of red and photographic infrared radiances and experimental plot biomass, leaf water content, and chlorophyll content. The radiance variables evaluated included the red and photographic infrared (IR) radiance and the linear combinations of the IR/red ratio, the square root of the IR/red ratio, the IR-red difference, the vegetation index, and the transformed vegetation index. In addition, the corresponding green and red linear combinations were evaluated for comparative purposes. Three data sets were used from June, September, and October sampling periods. Regression analysis showed the increased utility of the IR and red linear combinations vis-{\`a}-vis the same green and red linear combinations. The red and IR linear combinations had 7\% and 14\% greater regression significance than the green and red linear combinations for the June and September sampling periods, respectively. The vegetation index, transformed vegetation index, and square root of the IR/red ratio were the most significant, followed closely by the IR/red ratio. Less than a 6\% difference separated the highest and lowest of these four ER and red linear combinations. The use of these linear combinations was shown to be sensitive primarily to the green leaf area or green leaf biomass. As such, these linear combinations of the red and photographic IR radiances can be employed to monitor the photosynthetically active biomass of plant canopies.}
}

@article{vallabhajosyulaNovelHierarchicalFramework2024,
  title = {A Novel Hierarchical Framework for Plant Leaf Disease Detection Using Residual Vision Transformer},
  author = {Vallabhajosyula, Sasikala and Sistla, Venkatramaphanikumar and Kolli, Venkata Krishna Kishore},
  year = {2024},
  month = may,
  journal = {Heliyon},
  volume = {10},
  number = {9},
  pages = {e29912},
  issn = {2405-8440},
  doi = {10.1016/j.heliyon.2024.e29912},
  urldate = {2025-03-23},
  abstract = {Early detection of plant leaf diseases accurately and promptly is very crucial for safeguarding agricultural crop productivity and ensuring food security. During their life cycle, plant leaves get diseased because of multiple factors like bacteria, fungi, weather conditions, etc. In this work, the authors propose a model that aids in the early detection of leaf diseases using a novel hierarchical residual vision transformer using improved Vision Transformer and ResNet9 models. The proposed model can extract more meaningful and discriminating details by reducing the number of trainable parameters with a smaller number of computations. The proposed method is evaluated on the Local Crop dataset, Plant Village dataset, and Extended Plant Village Dataset with 13, 38, and 51 different leaf disease classes. The proposed model is trained using the best trail parameters of Improved Vision Transformer and classified the features using ResNet 9. Performance evaluation is carried out on a wide aspects over the aforementioned datasets and results revealed that the proposed model outperforms other models such as InceptionV3, MobileNetV2, and ResNet50.},
  keywords = {Deep leaning,Inception V3,MobileNetV2,Plant leaf disease detection,Vision transformer}
}

@article{vanesSpatialNatureRandomization1993,
  title = {Spatial {{Nature}} of {{Randomization}} and {{Its Effect}} on the {{Outcome}} of {{Field Experiments}}},
  author = {{van Es}, H. M. and {van Es}, C. L.},
  year = {1993},
  journal = {Agronomy Journal},
  volume = {85},
  number = {2},
  pages = {420--428},
  issn = {1435-0645},
  doi = {10.2134/agronj1993.00021962008500020046x},
  urldate = {2025-03-30},
  abstract = {Many sites used for field trials exhibit a spatially-dependent variance structure in that nearby observations are autocorrelated. This may affect treatment comparisons made at unequal distances. This study investigated (i) the probabilistic nature of randomization with respect to spatial distances in randomized complete block (RCB) designs and (ii) the effect of spatially unbalanced designs on the outcome of field experiments. The mean distance of treatment comparison increases linearly with the number of treatments in the experiment. The lack of spatial balance also increases and is inversely related to the number of replications. This may result in increases in Type II errors for short-distance treatment contrasts and increases in Type I errors for long-distance contrasts. Evaluation of two experimental RCB designs involving four and nine treatments and four replications showed that the randomization process does not ensure spatial balance. Two simulated experiments, each using 50 randomizations based on the Mercer and Hall data showed no adverse effect from spatially unbalanced treatment comparisons if the underlying variance structure is random, but significant effects if spatial autocorrelation is present. Expected variances for long-distance comparisons (5.6\% of all comparisons) were 51\% higher than the error term resulting in tests of treatment differences at ɑ = 0.05 to actually be conducted at the 0.09 error level. Alternative design and analysis methods that ensure spatially balanced treatment comparisons are discussed.},
  copyright = {Copyright {\copyright} American Society of Agronomy},
  langid = {english}
}

@article{wadouxSamplingDesignOptimization2019,
  title = {Sampling Design Optimization for Soil Mapping with Random Forest},
  author = {Wadoux, Alexandre M. J-C. and Brus, Dick J. and Heuvelink, Gerard B. M.},
  year = {2019},
  month = dec,
  journal = {Geoderma},
  volume = {355},
  pages = {113913},
  issn = {0016-7061},
  doi = {10.1016/j.geoderma.2019.113913},
  urldate = {2025-03-29},
  abstract = {Machine learning techniques are widely employed to generate digital soil maps. The map accuracy is partly determined by the number and spatial locations of the measurements used to calibrate the machine learning model. However, determining the optimal sampling design for mapping with machine learning techniques has not yet been considered in detail in digital soil mapping studies. In this paper, we investigate sampling design optimization for soil mapping with random forest. A design is optimized using spatial simulated annealing by minimizing the mean squared prediction error (MSE). We applied this approach to mapping soil organic carbon for a part of Europe using subsamples of the LUCAS dataset. The optimized subsamples are used as input for the random forest machine learning model, using a large set of readily available environmental data as covariates. We also predicted the same soil property using subsamples selected by simple random sampling, conditioned Latin Hypercube sampling (cLHS), spatial coverage sampling and feature space coverage sampling. Distributions of the estimated population MSEs are obtained through repeated random splitting of the LUCAS dataset, serving as the population of interest, into subsets used for validation, testing and selection of calibration samples, and repeated selection of calibration samples with the various sampling designs. The differences between the medians of the MSE distributions were tested for significance using the non-parametric Mann-Whitney test. The process was repeated for different sample sizes. We also analyzed the spread of the optimized designs in both geographic and feature space to reveal their characteristics. Results show that optimization of the sampling design by minimizing the MSE is worthwhile for small sample sizes. However, an important disadvantage of sampling design optimization using MSE is that it requires known values of the soil property at all locations and as a consequence is only feasible for subsampling an existing dataset. For larger sample sizes, the effect of using an MSE optimized design diminishes. In this case, we recommend to use a sample spread uniformly in the feature (i.e. covariate) space of the most important random forest covariates. The results also show that for our case study, cLHS sampling performs worse than the other sampling designs for mapping with random forest. We stress that comparison of sampling designs for calibration by splitting the data just once is very sensitive to the data split that one happens to use if the validation set is small.},
  keywords = {-means,Conditioned Latin Hypercube,LUCAS,Optimal design,Pedometrics,Random forest,Spatial coverage,Spatial simulated annealing,Uncertainty assessment}
}

@article{wangControllableDataGeneration2024,
  title = {Controllable {{Data Generation}} by {{Deep Learning}}: {{A Review}}},
  shorttitle = {Controllable {{Data Generation}} by {{Deep Learning}}},
  author = {Wang, Shiyu and Du, Yuanqi and Guo, Xiaojie and Pan, Bo and Qin, Zhaohui and Zhao, Liang},
  year = {2024},
  month = oct,
  journal = {ACM Computing Surveys},
  volume = {56},
  number = {9},
  eprint = {2207.09542},
  primaryclass = {cs},
  pages = {1--38},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3648609},
  urldate = {2025-03-26},
  abstract = {Designing and generating new data under targeted properties has been attracting various critical applications such as molecule design, image editing and speech synthesis. Traditional hand-crafted approaches heavily rely on expertise experience and intensive human efforts, yet still suffer from the insufficiency of scientific knowledge and low throughput to support effective and efficient data generation. Recently, the advancement of deep learning has created the opportunity for expressive methods to learn the underlying representation and properties of data. Such capability provides new ways of determining the mutual relationship between the structural patterns and functional properties of the data and leveraging such relationships to generate structural data, given the desired properties. This article is a systematic review that explains this promising research area, commonly known as controllable deep data generation. First, the article raises the potential challenges and provides preliminaries. Then the article formally defines controllable deep data generation, proposes a taxonomy on various techniques and summarizes the evaluation metrics in this specific domain. After that, the article introduces exciting applications of controllable deep data generation, experimentally analyzes and compares existing works. Finally, this article highlights the promising future directions of controllable deep data generation and identifies five potential challenges.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning}
}

@article{wanOptimizingUAVbasedUncooled2024,
  title = {Optimizing {{UAV-based}} Uncooled Thermal Cameras in Field Conditions for Precision Agriculture},
  author = {Wan, Quanxing and Smigaj, Magdalena and Brede, Benjamin and Kooistra, Lammert},
  year = {2024},
  month = nov,
  journal = {International Journal of applied Earth Observation and Geoinformation},
  volume = {134},
  pages = {104184},
  publisher = {Elsevier},
  issn = {1569-8432},
  doi = {10.1016/j.jag.2024.104184},
  urldate = {2025-03-29},
  langid = {english}
}

@book{websterGeostatisticsEnvironmentalScientists2007,
  title = {Geostatistics for {{Environmental Scientists}}},
  author = {Webster, Richard and Oliver, Margaret A.},
  year = {2007},
  month = oct,
  publisher = {John Wiley \& Sons},
  abstract = {Geostatistics is essential for environmental scientists. Weather and climate vary from place to place, soil varies at every scale at which it is examined, and even man-made attributes -- such as the distribution of pollution -- vary. The techniques used in geostatistics are ideally suited to the needs of environmental scientists, who use them to make the best of sparse data for prediction, and top plan future surveys when resources are limited. Geostatistical technology has advanced much in the last few years and many of these developments are being incorporated into the practitioner's repertoire. This second edition describes these techniques for environmental scientists. Topics such as stochastic simulation, sampling, data screening, spatial covariances, the variogram and its modeling, and spatial prediction by kriging are described in rich detail. At each stage the underlying theory is fully explained, and the rationale behind the choices given, allowing the reader to appreciate the assumptions and constraints involved.},
  googlebooks = {WBwSyvIvNY8C},
  isbn = {978-0-470-51726-0},
  langid = {english},
  keywords = {Mathematics / General,Mathematics / Probability & Statistics / General,Mathematics / Probability & Statistics / Stochastic Processes}
}

@article{westobyStructurefromMotionPhotogrammetryLowcost2012,
  title = {`{{Structure-from-Motion}}' Photogrammetry: {{A}} Low-Cost, Effective Tool for Geoscience Applications},
  shorttitle = {`{{Structure-from-Motion}}' Photogrammetry},
  author = {Westoby, M. J. and Brasington, J. and Glasser, N. F. and Hambrey, M. J. and Reynolds, J. M.},
  year = {2012},
  month = dec,
  journal = {Geomorphology},
  volume = {179},
  pages = {300--314},
  issn = {0169-555X},
  doi = {10.1016/j.geomorph.2012.08.021},
  urldate = {2025-03-29},
  abstract = {High-resolution topographic surveying is traditionally associated with high capital and logistical costs, so that data acquisition is often passed on to specialist third party organisations. The high costs of data collection are, for many applications in the earth sciences, exacerbated by the remoteness and inaccessibility of many field sites, rendering cheaper, more portable surveying platforms (i.e. terrestrial laser scanning or GPS) impractical. This paper outlines a revolutionary, low-cost, user-friendly photogrammetric technique for obtaining high-resolution datasets at a range of scales, termed `Structure-from-Motion' (SfM). Traditional softcopy photogrammetric methods require the 3-D location and pose of the camera(s), or the 3-D location of ground control points to be known to facilitate scene triangulation and reconstruction. In contrast, the SfM method solves the camera pose and scene geometry simultaneously and automatically, using a highly redundant bundle adjustment based on matching features in multiple overlapping, offset images. A comprehensive introduction to the technique is presented, followed by an outline of the methods used to create high-resolution digital elevation models (DEMs) from extensive photosets obtained using a consumer-grade digital camera. As an initial appraisal of the technique, an SfM-derived DEM is compared directly with a similar model obtained using terrestrial laser scanning. This intercomparison reveals that decimetre-scale vertical accuracy can be achieved using SfM even for sites with complex topography and a range of land-covers. Example applications of SfM are presented for three contrasting landforms across a range of scales including; an exposed rocky coastal cliff; a breached moraine-dam complex; and a glacially-sculpted bedrock ridge. The SfM technique represents a major advancement in the field of photogrammetry for geoscience applications. Our results and experiences indicate SfM is an inexpensive, effective, and flexible approach to capturing complex topography.},
  keywords = {Close-range photogrammetry,Digital elevation model (DEM),SFMToolkit,Structure-from-Motion (SfM),Terrestrial laser scanning (TLS)}
}

@article{westobyStructurefromMotionPhotogrammetryLowcost2012a,
  title = {`{{Structure-from-Motion}}' Photogrammetry: {{A}} Low-Cost, Effective Tool for Geoscience Applications},
  shorttitle = {`{{Structure-from-Motion}}' Photogrammetry},
  author = {Westoby, M. J. and Brasington, J. and Glasser, N. F. and Hambrey, M. J. and Reynolds, J. M.},
  year = {2012},
  month = dec,
  journal = {Geomorphology},
  volume = {179},
  pages = {300--314},
  issn = {0169-555X},
  doi = {10.1016/j.geomorph.2012.08.021},
  urldate = {2025-03-30},
  abstract = {High-resolution topographic surveying is traditionally associated with high capital and logistical costs, so that data acquisition is often passed on to specialist third party organisations. The high costs of data collection are, for many applications in the earth sciences, exacerbated by the remoteness and inaccessibility of many field sites, rendering cheaper, more portable surveying platforms (i.e. terrestrial laser scanning or GPS) impractical. This paper outlines a revolutionary, low-cost, user-friendly photogrammetric technique for obtaining high-resolution datasets at a range of scales, termed `Structure-from-Motion' (SfM). Traditional softcopy photogrammetric methods require the 3-D location and pose of the camera(s), or the 3-D location of ground control points to be known to facilitate scene triangulation and reconstruction. In contrast, the SfM method solves the camera pose and scene geometry simultaneously and automatically, using a highly redundant bundle adjustment based on matching features in multiple overlapping, offset images. A comprehensive introduction to the technique is presented, followed by an outline of the methods used to create high-resolution digital elevation models (DEMs) from extensive photosets obtained using a consumer-grade digital camera. As an initial appraisal of the technique, an SfM-derived DEM is compared directly with a similar model obtained using terrestrial laser scanning. This intercomparison reveals that decimetre-scale vertical accuracy can be achieved using SfM even for sites with complex topography and a range of land-covers. Example applications of SfM are presented for three contrasting landforms across a range of scales including; an exposed rocky coastal cliff; a breached moraine-dam complex; and a glacially-sculpted bedrock ridge. The SfM technique represents a major advancement in the field of photogrammetry for geoscience applications. Our results and experiences indicate SfM is an inexpensive, effective, and flexible approach to capturing complex topography.},
  keywords = {Close-range photogrammetry,Digital elevation model (DEM),SFMToolkit,Structure-from-Motion (SfM),Terrestrial laser scanning (TLS)}
}

@article{williamsOptimalityContrastsBlock2015,
  title = {Optimality and {{Contrasts}} in {{Block Designs}} with {{Unequal Treatment Replication}}},
  author = {Williams, Emlyn and Piepho, Hans-Peter},
  year = {2015},
  journal = {Australian \& New Zealand Journal of Statistics},
  volume = {57},
  number = {2},
  pages = {203--209},
  issn = {1467-842X},
  doi = {10.1111/anzs.12116},
  urldate = {2025-03-30},
  abstract = {The computer construction of optimal or near-optimal experimental designs is common in practice. Search procedures are often based on the non-zero eigenvalues of the information matrix of the design. Minimising the average of the pairwise treatment variances can also be used as a search criterion. For equal treatment replication these approaches are equivalent to maximising the harmonic mean of the design's canonical efficiency factors, but differ when treatments are unequally replicated. This paper investigates the extent of these differences and discusses some apparent inconsistencies previously observed when comparing the optimality of equally and unequally replicated designs.},
  copyright = {{\copyright} 2015 Australian Statistical Publishing Association Inc. Published by Wiley Publishing Asia Pty Ltd.},
  langid = {english},
  keywords = {block designs,efficiency factors,optimality,treatment contrasts}
}

@book{wolfElementsPhotogrammetryApplication2013,
  title = {Elements of {{Photogrammetry}} with {{Application}} in {{GIS}}, {{Fourth Edition}}},
  author = {Wolf, Paul R. and DeWitt, Bon A. and Wilkinson, Benjamin E.},
  year = {2013},
  month = oct,
  publisher = {McGraw Hill Professional},
  abstract = {The definitive guide to photogrammetry--fully updated Thoroughly revised to cover the latest technological advances in the field, Elements of Photogrammetry with Applications in GIS, Fourth Edition, provides complete details on the foundational principles of photogrammetry as well as important advanced concepts. Significant changes in the instruments and procedures used in modern photogrammetry, including laser scanning, are discussed. Example problems clarify computational procedures and extensive photographs and diagrams illustrate the material presented in this comprehensive resource. Coverage includes:  Principles of photography and imaging Cameras and other imaging devices Image measurements and refinements Object space coordinate systems Vertical photographs Stereoscopic viewing Stereoscopic parallax Stereoscopic plotting instruments Laser scanning systems Elementary methods of planimetric mapping for GIS Titled and oblique photographs Introduction to analytical photogrammetry Topographic mapping and spatial data collection Fundamental principles of digital image processing Photogrammetric applications in GIS Control for aerial photogrammetry Aerotriangulation Project planning Terrestrial and close-range photogrammetry},
  googlebooks = {bCx5rmWMHyAC},
  isbn = {978-0-07-176111-6},
  langid = {english},
  keywords = {Technology & Engineering / Civil / General}
}

@article{WTO_SPS_Agreement,
  title = {The {{WTO}} Agreement on the Application of Sanitary and Phytosanitary Measures ({{SPS}} Agreement)},
  author = {{World Trade Organization}},
  year = {1995},
  journal = {World Trade Organization},
  urldate = {2025-03-12}
}

@misc{zophRethinkingPretrainingSelftraining2020,
  title = {Rethinking {{Pre-training}} and {{Self-training}}},
  author = {Zoph, Barret and Ghiasi, Golnaz and Lin, Tsung-Yi and Cui, Yin and Liu, Hanxiao and Cubuk, Ekin D. and Le, Quoc V.},
  year = {2020},
  month = nov,
  number = {arXiv:2006.06882},
  eprint = {2006.06882},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2006.06882},
  urldate = {2025-03-26},
  abstract = {Pre-training is a dominant paradigm in computer vision. For example, supervised ImageNet pre-training is commonly used to initialize the backbones of object detection and segmentation models. He et al., however, show a surprising result that ImageNet pre-training has limited impact on COCO object detection. Here we investigate self-training as another method to utilize additional data on the same setup and contrast it against ImageNet pre-training. Our study reveals the generality and flexibility of self-training with three additional insights: 1) stronger data augmentation and more labeled data further diminish the value of pre-training, 2) unlike pre-training, self-training is always helpful when using stronger data augmentation, in both low-data and high-data regimes, and 3) in the case that pre-training is helpful, self-training improves upon pre-training. For example, on the COCO object detection dataset, pre-training benefits when we use one fifth of the labeled data, and hurts accuracy when we use all labeled data. Self-training, on the other hand, shows positive improvements from +1.3 to +3.4AP across all dataset sizes. In other words, self-training works well exactly on the same setup that pre-training does not work (using ImageNet to help COCO). On the PASCAL segmentation dataset, which is a much smaller dataset than COCO, though pre-training does help significantly, self-training improves upon the pre-trained model. On COCO object detection, we achieve 54.3AP, an improvement of +1.5AP over the strongest SpineNet model. On PASCAL segmentation, we achieve 90.5 mIOU, an improvement of +1.5\% mIOU over the previous state-of-the-art result by DeepLabv3+.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning}
}

@misc{zotero-1243,
  urldate = {2025-03-12},
  howpublished = {https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=OJ:L:1997:265:FULL}
}

@misc{zotero-1245,
  urldate = {2025-03-12},
  howpublished = {https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=OJ:L:1997:265:FULL}
}

@misc{zotero-1449,
  urldate = {2025-03-23},
  howpublished = {https://openaccess.thecvf.com/content/CVPR2021/papers/Salehi\_Multiresolution\_Knowledge\_Distillation\_for\_Anomaly\_Detection\_CVPR\_2021\_paper.pdf}
}

@misc{zotero-1450,
  urldate = {2025-03-23},
  howpublished = {https://people.csail.mit.edu/wrvb/files/publications/liu2018deep.pdf}
}

@misc{zotero-1464,
  urldate = {2025-03-23},
  howpublished = {https://pdf.sciencedirectassets.com/273474/1-s2.0-S1574954124X00059/1-s2.0-S1574954124004011/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEIX\%2F\%2F\%2F\%2F\%2F\%2F\%2F\%2F\%2F\%2FwEaCXVzLWVhc3QtMSJHMEUCIQD\%2ByF0jnLEk0ShVLoli4s9AldcT06iPuHBM8qFj0cfjtwIgLW\%2F\%2FNp9t397jt6H8hS5kBxtbODHHdeYA8yYZy2ZwolMqvAUI3f\%2F\%2F\%2F\%2F\%2F\%2F\%2F\%2F\%2F\%2FARAFGgwwNTkwMDM1NDY4NjUiDNUjJMeWp\%2FPXgAOLyCqQBWcMZqqOlvNO9PsQWrdcK8lsqoG31Jot1jl3Ze7ddmb9NvvaklQeeDbaMrwkCF9\%2BZmYPyr3XWVbd5edLuNjde5EeaxDMRUOUcEZX2xSUQAXtUAfp8WKYZlzWiDkRto0GC612yI5f9FXt57fmLe6LLK\%2FiKZWNdhfK1lTqAbxas2uLr22sj5M9bfvZ5FaYMmZ0IwtaL1jLokfQG0hpIPTuLRzHmBhoURaOPfI9RdtzELeBENPOrC06P2IndVSq7KqbF1DxgjdimuNgNUisTBR5a5CtXkfw1dnRqNb8LceojxmKp9bjNKIDzIxu6ZVFSl1x6eF\%2Fsnbq4e3\%2BPMjRHC2lEp3xy\%2B5vZN9n0rCA5\%2Biiuc\%2F60iGHKlv4qGPMZ84pi4ngD4alImmp\%2F8xYb5WSS\%2FGnbaG1GcgcFawPR5LXGJdfrWRc6WO9LQuP84WN1OGlvcFwUWKK\%2FIS8xQPIwkESDEMYEQJqsIRDjqdAOBe1hI9s9RihqzwLHdU0QhWf0E6QbGtSHE5miN95sVp7OEHYAnfwp\%2BIf\%2B\%2BcuxTAotvXIRjLV7iwEKx6n8F\%2BQ4\%2BfnddzXFEzaDCrGxfy7NLXWdUV69CYvxCtN2wUI\%2F7yNH7vwPcI90aAtiISFFrxn\%2BwlDpHpjE41ZalORoJWx6AhEYNdtTj\%2FlA0ORklOF4HmDvTJStmXKJSrrytxVzJkbKjE8jcWG6R9tF5KZA2i253cGqN\%2BKMDYCSbv8aYMcH3G03Xs37DpqCFswzRo6d8xi\%2FncvVIoERrqxK\%2FFHbXlpDI6oV5wsCmp0\%2BYJWEp1pns5hM57GeoHifG\%2Ftehry4w5IKETUfNxS9so2pI5ox\%2BfB5WNDf30l2os2XGfBmN\%2FUxj54Zi3Ab7YJKYTcMNPVgb8GOrEBdNlrJaodVDo2iSMhiUGufqOnXYqV2XMBUOzZPybMiSZtt8iKWkpQ\%2Fx8v3ugBXkO21XSuSxgyNYC03nC6T09UddwBD62lpJWU\%2BtOiMQus7bzrJMY4gWRixjM8KZUpRxrFqHmAGcjWDjVDRX\%2B7swxL3URJqjWbBGdm3HILY8qt2hNjjxaXUfhBkKgbxUdP010F1W2fWHtq3Ul\%2F8FXDSvwPn1GPVxF0wZwtRy9xlVKzdjtr\&X-Amz-Algorithm=AWS4-HMAC-SHA256\&X-Amz-Date=20250323T211138Z\&X-Amz-SignedHeaders=host\&X-Amz-Expires=300\&X-Amz-Credential=ASIAQ3PHCVTY3T3Y7MGC\%2F20250323\%2Fus-east-1\%2Fs3\%2Faws4\_request\&X-Amz-Signature=14c743ad138e9da44a7d502dab6e56386653ec2b43218faa05df686323637671\&hash=df35effb639e24a37a09e14a32f5724aa94d054b70eae3791e1070efde6d7f31\&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61\&pii=S1574954124004011\&tid=spdf-5b9f07a9-b7b7-464a-a50d-1cbf2f221732\&sid=b0c16a9e643f20470e4954013ab4a852191agxrqb\&type=client\&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t\&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t\&ua=13115c5155550b065052\&rr=9250ec2368e10e0f\&cc=it}
}

@book{zuurGAMZeroinflatedModels2019,
  title = {{{GAM}} and Zero-Inflated {{Models}}},
  author = {Zuur, Alain F. and Ieno, Elena N. and Savel'ev, Anatolij A. and Zuur, Alain F.},
  year = {2019},
  series = {Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with {{R-INLA}}},
  number = {volume 2},
  publisher = {Highland Statistics Ltd},
  address = {Newburgh, United Kingdom},
  isbn = {978-0-9571741-9-1},
  langid = {english}
}

@article{chiang_quantitative_2020,
	title = {Quantitative {Ordinal} {Scale} {Estimates} of {Plant} {Disease} {Severity}: {Comparing} {Treatments} {Using} a {Proportional} {Odds} {Model}},
	volume = {110},
	issn = {0031-949X, 1943-7684},
	shorttitle = {Quantitative {Ordinal} {Scale} {Estimates} of {Plant} {Disease} {Severity}},
	url = {https://apsjournals.apsnet.org/doi/10.1094/PHYTO-10-18-0372-R},
	doi = {10.1094/PHYTO-10-18-0372-R},
	abstract = {Studies in plant pathology, agronomy, and plant breeding requiring disease severity assessment often use quantitative ordinal scales (i.e., a special type of ordinal scale that uses defined numeric ranges); a frequently used example of such a scale is the Horsfall-Barratt scale. Parametric proportional odds models (POMs) may be used to analyze the ratings obtained from quantitative ordinal scales directly, without converting ratings to percent area affected using range midpoints of such scales (currently a standard procedure). Our aim was to evaluate the performance of the POM for comparing treatments using ordinal estimates of disease severity relative to two alternatives, the midpoint conversions (MCs) and nearest percent estimates (NPEs). A simulation method was implemented and the parameters of the simulation estimated using actual disease severity data from the field. The criterion for comparison of the three approaches was the power of the hypothesis test (the probability to reject the null hypothesis when it is false). Most often, NPEs had superior performance. The performance of the POM was never inferior to using the MC at severity {\textless}40\%. Especially at low disease severity (≤10\%), the POM was superior to using the MC method. Thus, for early onset of disease or for comparing treatments with severities {\textless}40\%, the POM is preferable for analyzing disease severity data based on quantitative ordinal scales when comparing treatments and at severities {\textgreater}40\% is equivalent to other methods.},
	language = {en},
	number = {4},
	urldate = {2025-06-29},
	journal = {Phytopathology®},
	author = {Chiang, K. S. and Liu, H. I. and Chen, Y. L. and El Jarroudi, M. and Bock, C. H.},
	month = apr,
	year = {2020},
	pages = {734--743},
}

@article{moraes_characterizing_2022,
	title = {Characterizing {Heterogeneity} and {Determining} {Sample} {Sizes} for {Accurately} {Estimating} {Wheat} {Fusarium} {Head} {Blight} {Index} in {Research} {Plots}},
	volume = {112},
	issn = {0031-949X, 1943-7684},
	url = {https://apsjournals.apsnet.org/doi/10.1094/PHYTO-04-21-0157-R},
	doi = {10.1094/PHYTO-04-21-0157-R},
	abstract = {Because Fusarium head blight (FHB) intensity is usually highly variable within a plot, the number of spikes rated for FHB index (IND) quantification must be considered when designing experiments. In addition, quantification of sources of IND heterogeneity is crucial for defining sampling protocols. Field experiments were conducted to quantify the variability of IND (“field severity”) at different spatial scales and to investigate the effects of sample size on estimated plot-level mean IND and its accuracy. A total of 216 7-row × 6-m-long plots of a moderately resistant and a susceptible cultivar were spray-inoculated with different Fusarium graminearum spore concentrations at anthesis to generate a range of IND levels. A one-stage cluster sampling approach was used to estimate IND, with an average of 32 spikes rated at each of 10 equally spaced points per plot. Plot-level mean IND ranged from 0.9 to 37.9\%. Heterogeneity of IND, quantified by fitting unconditional hierarchical linear models, was higher among spikes within clusters than among clusters within plots or among plots. The projected relative error of mean IND increased as mean IND decreased, and as sample size decreased to {\textless}100 spikes per plot. Simple random samples were drawn with replacement 50,000 times from the original dataset for each plot and used to estimate the effects of sample sizes on mean IND. Samples of 100 or more spikes resulted in more precise estimates of mean IND than smaller samples. Poor sampling may result in inaccurate estimates of IND and poor interpretation of results.},
	language = {en},
	number = {2},
	urldate = {2025-06-29},
	journal = {Phytopathology®},
	author = {Moraes, Wanderson Bucker and Madden, Laurence V. and Paul, Pierce A.},
	month = feb,
	year = {2022},
	pages = {315--334},
}

@article{chiang_what_2014,
	title = {What {Interval} {Characteristics} {Make} a {Good} {Categorical} {Disease} {Assessment} {Scale}?},
	volume = {104},
	issn = {0031-949X, 1943-7684},
	url = {https://apsjournals.apsnet.org/doi/10.1094/PHYTO-10-13-0279-R},
	doi = {10.1094/PHYTO-10-13-0279-R},
	abstract = {Plant pathologists most often obtain quantitative information on disease severity using visual assessments. Category scales have been used for assessing plant disease severity in field experiments, epidemiological studies, and for screening germplasm. The most widely used category scale is the Horsfall-Barratt (H-B) scale, but reports show that estimates of disease severity using the H-B scale are less precise compared with nearest percent estimates (NPEs) using the 0 to 100\% ratio scale. Few studies have compared different category scales. The objective of this study was to compare NPEs, the H-B midpoint converted data, and four different linear category scales (5 and 10\% increments, with and without additional grades at low severity [0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 15.0, 20.0…100\%, and 0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 30.0…100\%, respectively]). Results of simulations based on known distributions of disease estimation using the type II error rate (the risk of failing to reject H
              0
              when H
              0
              is false) showed that at disease severity ≤5\%, a 10\% category scale had a greater probability of failing to reject H
              0
              when H
              0
              is false compared with all other methods, while the H-B scale performed least well at 20 to 50\% severity. The 5\% category scale performed as well as NPEs except when disease severity was ≤1\%. Both the 5 and 10\% category scales with the additional grades included performed as well as NPEs. These results were confirmed with a mixed model analysis and bootstrap analysis of the original rater assessment data. A better knowledge of the advantages and disadvantages of category scale types will provide a basis for plant pathologists and plant breeders seeking to maximize accuracy and reliability of assessments to make an informed decision when choosing a disease assessment method.},
	language = {en},
	number = {6},
	urldate = {2025-06-29},
	journal = {Phytopathology®},
	author = {Chiang, Kuo-Szu and Liu, Shih-Chia and Bock, Clive H. and Gottwald, Tim R.},
	month = jun,
	year = {2014},
	pages = {575--585},
}

@article{stevenson_overview_2001,
	title = {An overview of the injury severity score and the new injury severity score},
	volume = {7},
	issn = {1353-8047},
	doi = {10.1136/ip.7.1.10},
	abstract = {OBJECTIVE: The research was undertaken to describe the injury severity score (ISS) and the new injury severity score (NISS) and to illustrate their statistical properties.
DESIGN: Descriptive analysis and assessment of the distribution of these scales.
METHODS: Three data sources--the National Pediatric Trauma Registry; the Massachusetts Uniform Hospital Discharge Data Set; and a trauma registry from an urban level I trauma center in Massachusetts--were used to describe the distribution of the ISS and NISS among injured patients.
RESULTS: The ISS/NISS was found to have a positively skewed distribution and transformation did not improve their skewness.
CONCLUSION: The findings suggest that for statistical or analytical purposes the ISS/ NISS should not be considered a continuous variable, particularly if ISS/NISS is treated as a continuous variable for correlation with an outcome measure.},
	language = {eng},
	number = {1},
	journal = {Injury Prevention: Journal of the International Society for Child and Adolescent Injury Prevention},
	author = {Stevenson, M. and Segui-Gomez, M. and Lescohier, I. and Di Scala, C. and McDonald-Smith, G.},
	month = mar,
	year = {2001},
	pmid = {11289527},
	pmcid = {PMC1730702},
	keywords = {Adolescent, Adult, Aged, Child, Child, Preschool, Cross-Sectional Studies, Female, Humans, Infant, Infant, Newborn, Injury Severity Score, Male, Middle Aged, Prognosis, Reproducibility of Results, United States, Wounds and Injuries},
	pages = {10--13},
}

@article{acutis_perfunctory_2012,
	title = {Perfunctory analysis of variance in agronomy, and its consequences in experimental results interpretation},
	volume = {43},
	issn = {1161-0301},
	url = {https://www.sciencedirect.com/science/article/pii/S1161030112000883},
	doi = {10.1016/j.eja.2012.06.006},
	abstract = {Analysis of variance (ANOVA) is based on two main assumptions, i.e., normality and homogeneity of the variances of the populations samples are collected from. In order to verify the correct application of ANOVA in agronomic research, we revised the two most recent years of two high ranked journals concerning agronomy: European Journal of Agronomy and Field Crops Research. The main issues considered were: presence of tests for normality and homogeneity of variance, and eventually the possibility of identifying problems due to analysis carried out on data not matching these assumptions and to incorrect applications of multiple comparisons. Forty-six percent of the reviewed papers uses ANOVA and, in 60\% of these papers, assumptions are not verified at all (and frequently there are evidences that assumptions are not met), or there is a misuse of multiple comparison tests. We also pointed out that the more relevant risk of transmitting erroneous information to the scientific community comes from the use of wrong techniques for multiple comparisons, in particular when protected least significant difference (LSD) test is used. This was demonstrated through exemplifications carried out using Monte Carlo simulations that showed an unacceptable rate of type-III errors found with the protected LSD methods for means separation. We think this study could represent a useful warning on how to avoid misleading conclusions from agronomic experiments due to the incorrect application of classical statistical techniques (i.e., procedures not fully controlling the type-I error rate at experimentwise level).},
	urldate = {2025-06-29},
	journal = {European Journal of Agronomy},
	author = {Acutis, Marco and Scaglia, Barbara and Confalonieri, Roberto},
	month = nov,
	year = {2012},
	keywords = {Homoscedasticity, LSD, Multiple comparisons, Type-I error rate, Type-III error rate},
	pages = {129--135},
}

@article{aquiles_e_effect_2024,
	title = {The effect of spatial lag on modeling geomatic covariates using analysis of variance},
	volume = {16},
	issn = {1866-928X},
	url = {https://doi.org/10.1007/s12518-024-00579-2},
	doi = {10.1007/s12518-024-00579-2},
	abstract = {In recent years, statistical methods have been developed that include spatial considerations, for example, those that incorporate data with georeferencing. The descriptive part of geographical information systems currently provides many visualization and analysis tools; however, in terms of analysis, these systems are still quite limited, therefore, ignorance of these limitations may result in data with spatial effects being treated with conventional statistical methods for non-spatial use, which can certainly invalidate the excellent work of data capture with advanced tools such as those that are used daily in the geomatic context. This prompted the current document, drawing attention to how geomatic information analyzed with statistical methods that imply independence in modeled observations can be invalid. The Moran index is compared with a proposal for a spatial lag coefficient in the context of experimental design so that users of variance analysis do not apply this well-known procedure in a ritualistic way, perhaps revising some assumptions and perhaps ignoring more important ones. The distortion of the p value generated from the analysis of variance is clear in the presence of spatial dependence. In this case, it is associated with the lag or spatial overlap. The methodology is easy to apply in other designs with the development of the design matrix, its reparameterization and the choice of the respective weight matrix. This may cause users to reconsider the traditional method of analysis and incorporate some appropriate analysis methodology to address spatial effects present in data or in outputs from the modeling process.},
	number = {3},
	journal = {Applied Geomatics},
	author = {Aquiles E., Darghan C. and Darlley S., Taborda L. and Nair J., González S. and Carlos A., Rivera M. and Jesús E., Ospina N.},
	month = sep,
	year = {2024},
	pages = {779--788},
}

@article{slaets_linear_2021,
	title = {Linear mixed models and geostatistics for designed experiments in soil science: {Two} entirely different methods or two sides of the same coin?},
	volume = {72},
	issn = {1365-2389},
	shorttitle = {Linear mixed models and geostatistics for designed experiments in soil science},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ejss.12976},
	doi = {10.1111/ejss.12976},
	abstract = {Soil scientists are accustomed to geostatistical methods and tools such as semivariograms and kriging for analysis of observational data. Such methods assume and exploit that observations are spatially correlated. Conversely, analysis of variance (ANOVA) of designed experiments assumes that observations from different experimental units are independent, an assumption that is justified based on randomization. It may be beneficial, however, to perform an ANOVA assuming a geostatistical covariance model. Also, it is increasingly common to have multiple observations per experimental unit. Simple ANOVA assuming independence of observations is not appropriate for such data. Instead, a linear mixed model accounting for correlation among observations made on the same plot is required for proper analysis. The purpose of this paper is to demonstrate the benefits of integrating geostatistical covariance structures and ANOVA procedures into a linear mixed modelling framework. Two examples from designed experiments are considered in detail, making a link between terminologies and jargon used in geostatistical analysis on the one hand and linear mixed modelling on the other hand. We provide code in R and SAS for both examples in two supporting companion documents. Highlights Analysis of variance and geostatistical analysis can be joined in a mixed model. Randomization justifies the independence assumption in analysis of variance. Geostatistical models imply a correlation of errors and can improve efficiency. Lacking randomization, spatial correlation can be accounted for in a mixed model.},
	language = {en},
	number = {1},
	urldate = {2025-06-29},
	journal = {European Journal of Soil Science},
	author = {Slaets, Johanna I. F. and Boeddinghaus, Runa S. and Piepho, Hans-Peter},
	year = {2021},
	note = {\_eprint: https://bsssjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/ejss.12976},
	keywords = {analysis of variance, designed experiment, kriging, mean comparison, nugget, polynomial regression, random effect, randomization, range, semivariogram, sill, spatial analysis},
	pages = {47--68},
}

@article{millar_remedies_2004,
	series = {Models in {Fisheries} {Research}: {GLMs}, {GAMS} and {GLMMs}},
	title = {Remedies for pseudoreplication},
	volume = {70},
	issn = {0165-7836},
	url = {https://www.sciencedirect.com/science/article/pii/S016578360400181X},
	doi = {10.1016/j.fishres.2004.08.016},
	abstract = {Pseudoreplication is the failure of a statistical analysis to properly incorporate the true structure of randomness present in the data. It has been well documented and studied in the ecological literature but has received little attention in the fisheries literature. Avoiding pseudoreplication in analyses of fisheries data can be difficult due to the complexity of the statistical procedures required. However, recent developments in statistical methodology are decreasing the extent to which pseudoreplication has to be tolerated. Seven examples are given here, beginning with simple design-based remedies and progressing to more challenging examples including the model-based remedies of mixed-effects modelling, generalized linear mixed models, state-space models, and geostatistics.},
	number = {2},
	urldate = {2025-06-29},
	journal = {Fisheries Research},
	author = {Millar, Russell B. and Anderson, Marti J.},
	month = dec,
	year = {2004},
	keywords = {Generalized linear mixed models, Geostatistics, Maximum likelihood, Mixed-effects, Nonparametric MANOVA, Overdispersion, Pseudoreplication, Random effects, Sequential population analysis, State-space models},
	pages = {397--407},
}

@article{Piepho_2011,
author = {Piepho, Hans-Peter and Richter, Christel and Spilke, Joachim and Hartung, Karin and Kunick, Arndt and Thöle, Heinrich},
year = {2011},
month = {11},
pages = {721-735},
title = {Statistical aspects of on-farm experimentation},
volume = {62},
journal = {Crop and Pasture Science},
doi = {10.1071/CP11175}
}

@article{alexopoulos_complementary_2023,
	title = {Complementary {Use} of {Ground}-{Based} {Proximal} {Sensing} and {Airborne}/{Spaceborne} {Remote} {Sensing} {Techniques} in {Precision} {Agriculture}: {A} {Systematic} {Review}},
	volume = {13},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2073-4395},
	shorttitle = {Complementary {Use} of {Ground}-{Based} {Proximal} {Sensing} and {Airborne}/{Spaceborne} {Remote} {Sensing} {Techniques} in {Precision} {Agriculture}},
	url = {https://www.mdpi.com/2073-4395/13/7/1942},
	doi = {10.3390/agronomy13071942},
	abstract = {As the global population continues to increase, projected to reach an estimated 9.7 billion people by 2050, there will be a growing demand for food production and agricultural resources. Transition toward Agriculture 4.0 is expected to enhance agricultural productivity through the integration of advanced technologies, increase resource efficiency, ensure long-term food security by applying more sustainable farming practices, and enhance resilience and climate change adaptation. By integrating technologies such as ground IoT sensing and remote sensing, via both satellite and Unmanned Aerial Vehicles (UAVs), and exploiting data fusion and data analytics, farming can make the transition to a more efficient, productive, and sustainable paradigm. The present work performs a systematic literature review (SLR), identifying the challenges associated with UAV, Satellite, and Ground Sensing in their application in agriculture, comparing them and discussing their complementary use to facilitate Precision Agriculture (PA) and transition to Agriculture 4.0.},
	language = {en},
	number = {7},
	urldate = {2025-06-29},
	journal = {Agronomy},
	author = {Alexopoulos, Angelos and Koutras, Konstantinos and Ali, Sihem Ben and Puccio, Stefano and Carella, Alessandro and Ottaviano, Roberta and Kalogeras, Athanasios},
	month = jul,
	year = {2023},
	note = {Number: 7
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {challenges, IoT, Precision Agriculture, proximal sensing, remote sensing, satellite, UAV},
	pages = {1942},
}


@incollection{antoniou_chapter_2023,
	series = {Earth {Observation}},
	title = {Chapter 8 - {On} volunteered geographic information quality: a framework for sharing data quality information},
	isbn = {978-0-323-98983-1},
	shorttitle = {Chapter 8 - {On} volunteered geographic information quality},
	url = {https://www.sciencedirect.com/science/article/pii/B9780323989831000090},
	abstract = {One of the most challenging issues regarding the use of volunteered geographic information (VGI) is data quality. The usually loose, nonhierarchical, and uncontrolled production process of VGI is based on contributions from non-GI professionals which raises concerns about the overall quality and fitness-for-purpose of such spatial data. At the same time, new sources of uncertainty have surfaced, which mainly relate to the underlying socio-economic factors of the areas mapped. In this context, established quality evaluation methods are hard to implement. The chapter describes a new quality evaluation framework that will facilitate VGI data acceptance. The chapter argues that the main obstacle to VGI acceptance is that there is imbalanced information regarding the overall VGI data quality between VGI producers and VGI consumers. A new framework for VGI quality evaluation is suggested, which is based on Economic theories. The work of Akerlof, Spence, and Stiglitz on the analysis of markets with asymmetric information, for which they were awarded the Nobel Prize in Economics, is used as the backbone for the suggested VGI quality evaluation framework. In the course of the chapter, the concepts and the positions of the three Nobel Prize laureates are discussed and ways to be implemented in addressing the issue of VGI data quality evaluation are presented.},
	urldate = {2025-06-29},
	booktitle = {Geoinformatics for {Geosciences}},
	publisher = {Elsevier},
	author = {Antoniou, Vyron},
	editor = {Stathopoulos, Nikolaos and Tsatsaris, Andreas and Kalogeropoulos, Kleomenis},
	month = jan,
	year = {2023},
	doi = {10.1016/B978-0-323-98983-1.00009-0},
	keywords = {quality evaluation, quality framework, Volunteered geographic information},
	pages = {149--160},
}


@article{zhao_grain_2011,
	title = {Grain separation loss monitoring system in combine harvester},
	volume = {76},
	issn = {0168-1699},
	url = {https://www.sciencedirect.com/science/article/pii/S0168169911000354},
	doi = {https://doi.org/10.1016/j.compag.2011.01.016},
	abstract = {Based on laboratory experimental results obtained with an axial threshing test-rig with tangential feeding, cumulative distribution functions of separated grain in axial and radial directions of threshing rotor were built. Based on the analysis of the relationship between grain separation loss and grain separation flux in an area under the concave, an indirect grain separation loss monitoring method is presented in this paper. Piezo-electric polyvinylidene fluoride (PVDF) film was selected as sensitive material to design a grain flux sensor. While grain and material-other-than-grain (MOG) separated in the monitoring area impact on piezo-electric PVDF films, different electric charges are generated. After signal progressing with a charge amplifier, frequency discrimination and wave shaping, the number of grain can be counted by a microcontroller (MCU) and the grain separation loss of combine harvester can be measured in real-time. Field test results indicated that the measurement errors of grain separation loss recorded by the monitoring system relative to the loss checked manually were less than 12\%.},
	number = {2},
	journal = {Computers and Electronics in Agriculture},
	author = {Zhao, Zhan and Li, Yaoming and Chen, Jin and Xu, Jiaojiao},
	year = {2011},
	keywords = {Combine harvester, Grain flux sensor, Grain separation loss, Piezo-electric PVDF film, Real-time monitoring},
	pages = {183--188},
}

@article{cisternas_systematic_2020,
	title = {Systematic literature review of implementations of precision agriculture},
	volume = {176},
	issn = {0168-1699},
	url = {https://www.sciencedirect.com/science/article/pii/S0168169920312357},
	doi = {10.1016/j.compag.2020.105626},
	abstract = {Agriculture production highly depends on water and soil factors which increasingly need to be utilized efficiently. Precision agriculture, through the set of information technologies that it uses, allows to effectively manage these resources. This work aims to gather the existing knowledge on technologies used in precision agriculture and ways to discern the most appropriate one for different contexts in agricultural processes. A systematic literature review is performed to identify precision agriculture implementations and to answer questions such as the type of technologies used, criteria for their comparison and selection, and the existence of frameworks that help to decide what technologies to implement. A total of 3,949 publications were reviewed, of which 259 addressed the posed research questions. The findings are that remote sensors are the most used technology, the required knowledge is an important criterion for deciding to implement precision agriculture, and no framework was found that guides its implementation.},
	urldate = {2025-06-29},
	journal = {Computers and Electronics in Agriculture},
	author = {Cisternas, Isabel and Velásquez, Ignacio and Caro, Angélica and Rodríguez, Alfonso},
	month = sep,
	year = {2020},
	keywords = {Information technologies, Precision agriculture, Precision agriculture implementations, Systematic literature review},
	pages = {105626},
}


@article{mondino_considerazioni_2017,
	title = {Considerazioni su costi e mercato potenziali del telerilevamento da {SAPR} in {Italia} nel settore vitivinicolo},
	url = {https://iris.unito.it/handle/2318/1643737},
	abstract = {I sistemi SAPR (Sistemi Aeromobili a Pilotaggio Remoto) si stanno configurando sempre più come un nuovo strumento di lavoro per molte professioni. Le caratteristiche che ne guidano la diffusione sono la relativa economicità e la sostanziale indipendenza dell’operatore da parti terze. All’accoppiata favorevole “SAPR + sensori ultraleggeri a basso costo” il merito di aver sdoganato e proposto al grande pubblico discipline tecniche come la fotogrammetria e il telerilevamento, introducendole in professioni ed ambiti produttivi più tradizionali. Tuttavia, benché ne sia stata ormai dimostrata l’utilità per applicazioni metriche, meno dimostrabile, allo stato attuale, è la loro efficacia nell’ambito del telerilevamento, dove l’alto grado di automazione, che pure gli algoritmi di trattamento delle immagini hanno raggiunto, non riesce a garantire una analoga semplicità di utilizzo e di lettura dell’informazione. In particolare nel settore agronomico, dove questi sistemi sono immaginati per la conduzione “mirata” delle pratiche colturali (agricoltura di precisione), il trasferimento tecnologico deve essere guidato in modo rigoroso, evitando le improvvisazioni che potrebbero portare, prima che il settore parta, ad un suo affossamento. E’ infatti vero che le tecniche di telerilevamento devono ancora dimostrare agli operatori di settore di poter generare informazioni in grado di indirizzare le loro pratiche agronomiche meglio di quanto possibile con approcci più tradizionali. Soprattutto, devono ancora dimostrare che i costi sono compatibili con quelli di conduzione ordinari, o che comunque la valenza economica (o ambientale) dei benefici prodotti copra almeno i costi sostenuti.},
	language = {ita},
	urldate = {2025-06-29},
	journal = {AIT Conference 11° Workshop tematico di Telerilevamento},
	author = {Mondino, Borgogno and Corrado, Enrico},
	year = {2017},
	note = {Accepted: 2017-06-30T09:06:36Z},
}
@article{blandinoeffetto2016,
  author = {Blandino, M. and Testa, G. and Quaglini, L. and Reyneri, A.},
  title = {Effetto Della Densità Colturale e Dell'Applicazione di Fungicidi Sulla Produzione e la Qualità del Mais da Granella e da Trinciato},
  year = {2016},
  address = {Rome, Italy},
  publisher = {ITA}
}

@article{10287390,
  author = {Lu, D. and Ye, J. and Wang, Y. and Yu, Z.},
  title = {Plant Detection and Counting: Enhancing Precision Agriculture in UAV and General Scenes},
  journal = {IEEE Access},
  year = {2023},
  volume = {11},
  pages = {116196--116205},
  doi = {10.1109/ACCESS.2023.3325747}
}

@article{Saatkamp2019AResearchAF,
  author = {Saatkamp, A. and Cochrane, A. and Commander, L. and Guja, L. and Jimenez-Alfaro, B. and Larson, J. and Nicotra, A. and Poschlod, P. and Silveira, F.A.O. and Cross, A. and others},
  title = {A research agenda for seed-trait functional ecology},
  journal = {New Phytol.},
  year = {2019},
  volume = {221},
  pages = {1764--1775},
  doi = {10.1111/nph.15502}
}

@article{rs13051030,
  author = {De Petris, S. and Sarvia, F. and Gullino, M. and Tarantino, E. and Borgogno-Mondino, E.},
  title = {Sentinel-1 Polarimetry to Map Apple Orchard Damage after a Storm},
  journal = {Remote Sens.},
  year = {2021},
  volume = {13},
  pages = {1030},
  doi = {10.3390/rs13051030}
}

@article{PP13332024,
  author = {{PP}},
  title = {Adoption of Digital Technology for Data Generation for the Efficacy Evaluation of Plant Protection Products},
  journal = {EPPO Bull.},
  year = {2025},
  volume = {55},
  pages = {14--19},
  doi = {10.1111/epp.13037}
}

@article{zouMaizeTasselsDetection2020,
  author = {Zou, H. and Lu, H. and Li, Y. and Liu, L. and Cao, Z.},
  title = {Maize Tassels Detection: A Benchmark of the State of the Art},
  journal = {Plant Methods},
  year = {2020},
  volume = {16},
  pages = {108},
  doi = {10.1186/s13007-020-00651-z}
}

@article{linMicrosoftCOCOCommon2015,
  author = {Lin, T.Y. and Maire, M. and Belongie, S. and Bourdev, L. and Girshick, R. and Hays, J. and Perona, P. and Ramanan, D. and Zitnick, C.L. and Dollár, P.},
  title = {Microsoft COCO: Common Objects in Context},
  journal = {arXiv},
  year = {2015},
  note = {arXiv:1405.0312},
  doi = {10.48550/arXiv.1405.0312}
}

@book{krausPhotogrammetryGeometryImages2011,
  author = {Kraus, K.},
  title = {Photogrammetry: Geometry from Images and Laser Scans},
  publisher = {De Gruyter},
  address = {Berlin, Germany},
  year = {2011},
  doi = {10.1515/9783110892871}
}

@article{pugh_comparison_2021,
  author = {Pugh, N.A. and Thorp, K.R. and Gonzalez, E.M. and Elshikha, D.E.M. and Pauli, D.},
  title = {Comparison of image georeferencing strategies for agricultural applications of small unoccupied aircraft systems},
  journal = {Plant Phenome J.},
  year = {2021},
  volume = {4},
  pages = {e20026},
  doi = {10.1002/ppj2.20026}
}

@article{dhonju_web_2023,
  author = {Dhonju, H.K. and Walsh, K.B. and Bhattarai, T.},
  title = {Web Mapping for Farm Management Information Systems: A Review and Australian Orchard Case Study},
  journal = {Agronomy},
  year = {2023},
  volume = {13},
  pages = {2563},
  doi = {10.3390/agronomy13102563}
}

@article{habib_automated_2016,
  author = {Habib, A. and Han, Y. and Xiong, W. and He, F. and Zhang, Z. and Crawford, M.},
  title = {Automated Ortho-Rectification of UAV-Based Hyperspectral Data over an Agricultural Field Using Frame RGB Imagery},
  journal = {Remote Sens.},
  year = {2016},
  volume = {8},
  pages = {796},
  doi = {10.3390/rs8100796}
}

@article{de_petris_rpas-based_2020,
  author = {De Petris, S. and Sarvia, F. and Borgogno-Mondino, E.},
  title = {RPAS-based photogrammetry to support tree stability assessment: Longing for precision arboriculture},
  journal = {Urban For. Urban Green.},
  year = {2020},
  volume = {55},
  pages = {126862},
  doi = {10.1016/j.ufug.2020.126862}
}

@article{zhang_georeferencing_2022,
  author = {Zhang, S. and Barrett, H.A. and Baros, S.V. and Neville, P.R.H. and Talasila, S. and Sinclair, L.L.},
  title = {Georeferencing Accuracy Assessment of Historical Aerial Photos Using a Custom-Built Online Georeferencing Tool},
  journal = {ISPRS Int. J. Geo-Inf.},
  year = {2022},
  volume = {11},
  pages = {582},
  doi = {10.3390/ijgi11120582}
}

@article{farjon_deep-learning-based_2023,
  author = {Farjon, G. and Huijun, L. and Edan, Y.},
  title = {Deep-learning-based counting methods, datasets, and applications in agriculture: A review},
  journal = {Precis. Agric.},
  year = {2023},
  volume = {24},
  pages = {1683--1711},
  doi = {10.1007/s11119-023-10034-8}
}

@article{meierBBCHSystemCoding2009,
  author = {Meier, U. and Bleiholder, H. and Buhr, L. and Feller, C. and Hack, H. and Heß, M. and Lancashire, P.D. and Schnock, U. and Stauß, R. and van den Boom, T. and others},
  title = {The BBCH System to Coding the Phenological Growth Stages of Plants-History and Publications},
  journal = {J. Für Kult.},
  year = {2009},
  volume = {61},
  pages = {41--52},
  doi = {10.5073/JfK.2009.02.01}
}

@article{davidPlantDetectionCounting2021,
  author = {David, E. and Daubige, G. and Joudelat, F. and Burger, P. and Comar, A. and de Solan, B. and Baret, F.},
  title = {Plant Detection and Counting from High-Resolution RGB Images Acquired from UAVs: Comparison between Deep-Learning and Handcrafted Methods with Application to Maize, Sugar Beet, and Sunflower},
  journal = {bioRxiv},
  year = {2021},
  doi = {10.1101/2021.04.27.441631}
}

@article{liuIntegrateNetDeepLearning2022,
  author = {Liu, W. and Zhou, J. and Wang, B. and Costa, M. and Kaeppler, S.M. and Zhang, Z.},
  title = {IntegrateNet: A Deep Learning Network for Maize Stand Counting From UAV Imagery by Integrating Density and Local Count Maps},
  journal = {IEEE Geosci. Remote Sens. Lett.},
  year = {2022},
  volume = {19},
  pages = {6512605},
  doi = {10.1109/LGRS.2022.3186544}
}

@misc{Maize_seedingDatasetOverview,
  title = {Maize\_seeding Dataset $>$ Overview},
  howpublished = {\url{https://universe.roboflow.com/objectdetection-hytat/maize\_seeding}},
  note = {accessed on 20 June 2025}
}

@misc{MaizeseedlingdetectionDatasetOverview,
  title = {Maize-Seedling-Detection Dataset $>$ Overview},
  howpublished = {\url{https://universe.roboflow.com/fyxdds-icloud-com/maize-seedling-detection}},
  note = {accessed on 20 June 2025}
}

@book{fao2024,
  author = {FAO},
  title = {Agricultural Production Statistics 2010--2023},
  publisher = {FAOSTAT},
  address = {Rome, Italy},
  year = {2024}
}

@article{torres-sanchez_early_2021,
  author = {Torres-Sánchez, J. and Mesas-Carrascosa, F.J. and Jiménez-Brenes, F.M. and de Castro, A.I. and López-Granados, F.},
  title = {Early Detection of Broad-Leaved and Grass Weeds in Wide Row Crops Using Artificial Neural Networks and UAV Imagery},
  journal = {Agronomy},
  year = {2021},
  volume = {11},
  pages = {749},
  doi = {10.3390/agronomy11040749}
}

@article{zhang2020cut,
  author = {Zhang, Z. and Cao, R. and Peng, C. and Liu, R. and Sun, Y. and Zhang, M. and Li, H.},
  title = {Cut-edge detection method for rice harvesting based on machine vision},
  journal = {Agronomy},
  year = {2020},
  volume = {10},
  pages = {590},
  doi = {10.3390/agronomy10040590}
}

@article{garcia-martinezDigitalCountCorn2020,
  author = {García-Martínez, H. and Flores-Magdaleno, H. and Khalil-Gardezi, A. and Ascencio-Hernández, R. and Tijerina-Chávez, L. and Vázquez-Peña, M.A. and Mancilla-Villa, O.R.},
  title = {Digital Count of Corn Plants Using Images Taken by Unmanned Aerial Vehicles and Cross Correlation of Templates},
  journal = {Agronomy},
  year = {2020},
  volume = {10},
  pages = {469},
  doi = {10.3390/agronomy10040469}
}

@article{lecunDeepLearning2015,
  author = {LeCun, Y. and Bengio, Y. and Hinton, G.},
  title = {Deep Learning},
  journal = {Nature},
  year = {2015},
  volume = {521},
  pages = {436--444},
  doi = {10.1038/nature14539}
}

@misc{FasterRCNNRealTime,
  title = {Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
  howpublished = {\url{https://ieeexplore-ieee-org.bibliopass.unito.it/document/7485869}},
  note = {accessed on 20 June 2025}
}

@misc{YouOnlyLook,
  title = {You Only Look Once: Unified, Real-Time Object Detection},
  howpublished = {\url{https://ieeexplore-ieee-org.bibliopass.unito.it/document/7780460}},
  note = {accessed on 20 June 2025}
}

@inproceedings{vaswaniAttentionAllYou2017,
  author = {Vaswani, A. and Shazeer, N. and Parmar, N. and Uszkoreit, J. and Jones, L. and Gomez, A.N. and Kaiser, Ł. and Polosukhin, I.},
  title = {Attention Is All You Need},
  booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
  year = {2017},
  pages = {6000--6010},
  address = {Long Beach, CA, USA}
}

@article{carionEndtoEndObjectDetection2020,
  author = {Carion, N. and Massa, F. and Synnaeve, G. and Usunier, N. and Kirillov, A. and Zagoruyko, S.},
  title = {End-to-End Object Detection with Transformers},
  journal = {arXiv},
  year = {2020},
  note = {arXiv:2005.12872},
  doi = {10.48550/arXiv.2005.12872}
}

@article{dosovitskiyImageWorth16x162021,
  author = {Dosovitskiy, A. and Beyer, L. and Kolesnikov, A. and Weissenborn, D. and Zhai, X. and Unterthiner, T. and Dehghani, M. and Minderer, M. and Heigold, G. and Gelly, S. and others},
  title = {An Image Is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  journal = {arXiv},
  year = {2021},
  note = {arXiv:2010.11929},
  doi = {10.48550/arXiv.2010.11929}
}

@article{14090575ImageNetLarge,
  author = {Russakovsky, O. and Deng, J. and Su, H. and Krause, J. and Satheesh, S. and Ma, S. and Fei-Fei, L.},
  title = {ImageNet Large Scale Visual Recognition Challenge},
  journal = {Int. J. Comput. Vis.},
  year = {2014},
  volume = {115},
  pages = {211--252},
  doi = {10.1007/s11263-015-0816-y}
}

@inproceedings{zongDETRsCollaborativeHybrid2023,
  author = {Zong, Z. and Song, G. and Liu, Y.},
  title = {DETRs with Collaborative Hybrid Assignments Training},
  booktitle = {Proceedings of the 2023 IEEE/CVF International Conference on Computer Vision (ICCV)},
  year = {2023},
  pages = {6725--6735},
  address = {Paris, France},
  doi = {10.1109/ICCV51070.2023.00621}
}

@article{khanSurveyVisionTransformers2023,
  author = {Khan, A. and Rauf, Z. and Sohail, A. and Khan, A.R. and Asif, H. and Asif, A. and Farooq, U.},
  title = {A Survey of the Vision Transformers and Their CNN-transformer Based Variants},
  journal = {Artif. Intell. Rev.},
  year = {2023},
  volume = {56},
  pages = {2917--2970},
  doi = {10.1007/s10462-023-10595-0}
}

@article{badgujarAgriculturalObjectDetection2024,
  author = {Badgujar, C.M. and Poulose, A. and Gan, H.},
  title = {Agricultural Object Detection with You Only Look Once (YOLO) Algorithm: A Bibliometric and Systematic Literature Review},
  journal = {Comput. Electron. Agric.},
  year = {2024},
  volume = {223},
  pages = {109090},
  doi = {10.1016/j.compag.2024.109090}
}

@article{rekavandiTransformersSmallObject2023,
  author = {Rekavandi, A.M. and Rashidi, S. and Boussaid, F. and Hoefs, S. and Akbas, E. and Bennamoun, M.},
  title = {Transformers in Small Object Detection: A Benchmark and Survey of State-of-the-Art},
  journal = {arXiv},
  year = {2023},
  note = {arXiv:2309.04902},
  doi = {10.48550/arXiv.2309.04902}
}

@article{liTransformerObjectDetection2023,
  author = {Li, Y. and Miao, N. and Ma, L. and Shuang, F. and Huang, X.},
  title = {Transformer for Object Detection: Review and Benchmark},
  journal = {Eng. Appl. Artif. Intell.},
  year = {2023},
  volume = {126},
  pages = {107021},
  doi = {10.1016/j.engappai.2023.107021}
}

@article{zhaoDETRsBeatYOLOs2024,
  author = {Zhao, Y. and Lv, W. and Xu, S. and Wei, J. and Wang, G. and Dang, Q. and Liu, Y. and Chen, J.},
  title = {DETRs Beat YOLOs on Real-time Object Detection},
  journal = {arXiv},
  year = {2024},
  note = {arXiv:2304.08069},
  doi = {10.48550/arXiv.2304.08069}
}

@article{khanamYOLOv11OverviewKey2024,
  author = {Khanam, R. and Hussain, M.},
  title = {YOLOv11: An Overview of the Key Architectural Enhancements},
  journal = {arXiv},
  year = {2024},
  note = {arXiv:2410.17725},
  doi = {10.48550/arXiv.2410.17725}
}

@article{liMetaSGDLearningLearn2017,
  author = {Li, Z. and Zhou, F. and Chen, F. and Li, H.},
  title = {Meta-SGD: Learning to Learn Quickly for Few-Shot Learning},
  journal = {arXiv},
  year = {2017},
  note = {arXiv:1707.09835},
  doi = {10.48550/arXiv.1707.09835}
}

@inproceedings{bansalZeroShotObjectDetection2018,
  author = {Bansal, A. and Sikka, K. and Sharma, G. and Chellappa, R. and Divakaran, A.},
  title = {Zero-Shot Object Detection},
  booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
  year = {2018},
  pages = {384--400},
  address = {Munich, Germany}
}

@article{kangFewshotObjectDetection2019,
  author = {Kang, B. and Liu, Z. and Wang, X. and Yu, F. and Feng, J. and Darrell, T.},
  title = {Few-Shot Object Detection via Feature Reweighting},
  journal = {arXiv},
  year = {2019},
  note = {arXiv:1812.01866},
  doi = {10.48550/arXiv.1812.01866}
}

@article{mindererScalingOpenVocabularyObject2023,
  author = {Minderer, M. and Gritsenko, A. and Houlsby, N.},
  title = {Scaling Open-Vocabulary Object Detection},
  journal = {Adv. Neural Inf. Process. Syst.},
  year = {2023},
  volume = {36},
  pages = {72983--73007}
}

@inproceedings{liuGroundingDINOMarrying2025,
  author = {Liu, S. and Zeng, Z. and Ren, T. and Li, F. and Zhang, H. and Yang, J. and Jiang, Q. and Li, C. and Yang, J. and Su, H. and others},
  title = {Grounding DINO: Marrying DINO with Grounded Pre-training for Open-Set Object Detection},
  booktitle = {Proceedings of the Computer Vision---ECCV 2024},
  year = {2025},
  pages = {38--55},
  address = {Milan, Italy},
  publisher = {Springer},
  doi = {10.1007/978-3-031-72970-6_3}
}

@article{karamiAutomaticPlantCounting2020,
  author = {Karami, A. and Crawford, M. and Delp, E.J.},
  title = {Automatic Plant Counting and Location Based on a Few-Shot Learning Technique},
  journal = {IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens.},
  year = {2020},
  volume = {13},
  pages = {5872--5886},
  doi = {10.1109/JSTARS.2020.3025790}
}

@inproceedings{wangAdvancingImageRecognition2024,
  author = {Wang, D. and Parthasarathy, R. and Pan, X.},
  title = {Advancing Image Recognition: Towards Lightweight Few-shot Learning Model for Maize Seedling Detection},
  booktitle = {Proceedings of the 2024 International Conference on Smart City and Information System},
  year = {2024},
  pages = {635--639},
  address = {Kuala Lumpur, Malaysia},
  doi = {10.1145/3685088.3685198}
}

@article{barretoAutomaticUAVbasedCounting2021,
  author = {Barreto, A. and Lottes, P. and Ispizua Yamati, F.R. and Baumgarten, S. and Wolf, N.A. and Stachniss, C. and Mahlein, A.K. and Paulus, S.},
  title = {Automatic UAV-based Counting of Seedlings in Sugar-Beet Field and Extension to Maize and Strawberry},
  journal = {Comput. Electron. Agric.},
  year = {2021},
  volume = {191},
  pages = {106493},
  doi = {10.1016/j.compag.2021.106493}
}

@article{kitanoCornPlantCounting2019,
  author = {Kitano, B.T. and Mendes, C.C.T. and Geus, A.R. and Oliveira, H.C. and Souza, J.R.},
  title = {Corn Plant Counting Using Deep Learning and UAV Images},
  journal = {IEEE Geosci. Remote Sens. Lett.},
  year = {2019},
  volume = {16},
  pages = {1--5},
  doi = {10.1109/LGRS.2019.2930549}
}

@article{andvaagCountingCanolaGeneralizable2024,
  author = {Andvaag, E. and Krys, K. and Shirtliffe, S.J. and Stavness, I.},
  title = {Counting Canola: Toward Generalizable Aerial Plant Detection Models},
  journal = {Plant Phenomics},
  year = {2024},
  volume = {6},
  pages = {0268},
  doi = {10.34133/plantphenomics.0268}
}

@article{sunRevisitingUnreasonableEffectiveness2017,
  author = {Sun, C. and Shrivastava, A. and Singh, S. and Gupta, A.},
  title = {Revisiting Unreasonable Effectiveness of Data in Deep Learning Era},
  journal = {arXiv},
  year = {2017},
  note = {arXiv:1707.02968},
  doi = {10.48550/arXiv.1707.02968}
}

@inproceedings{alhazmiEffectsAnnotationQuality2021,
  author = {Alhazmi, K. and Alsumari, W. and Seppo, I. and Podkuiko, L. and Simon, M.},
  title = {Effects of Annotation Quality on Model Performance},
  booktitle = {Proceedings of the 2021 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)},
  year = {2021},
  pages = {063--067},
  address = {Jeju Island, Republic of Korea},
  doi = {10.1109/ICAIIC51459.2021.9415271}
}

@article{hestnessDeepLearningScaling2017,
  author = {Hestness, J. and Narang, S. and Ardalani, N. and Diamos, G. and Jun, H. and Kianinejad, H. and Patwary, M.M.A. and Yang, Y. and Zhou, Y.},
  title = {Deep Learning Scaling Is Predictable, Empirically},
  journal = {arXiv},
  year = {2017},
  note = {arXiv:1712.00409},
  doi = {10.48550/arXiv.1712.00409}
}

@inproceedings{mahmoodHowMuchMore2022,
  author = {Mahmood, R. and Lucas, J. and Acuna, D. and Li, D. and Philion, J. and Alvarez, J.M. and Yu, Z. and Fidler, S. and Law, M.T.},
  title = {How Much More Data Do I Need? Estimating Requirements for Downstream Tasks},
  booktitle = {Proceedings of the 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year = {2022},
  pages = {275--284},
  address = {New Orleans, LA, USA},
  doi = {10.1109/CVPR52688.2022.00037}
}

@article{nguyenEvaluationDeepLearning2020,
  author = {Nguyen, N.D. and Do, T. and Ngo, T.D. and Le, D.D. and Valenti, C.F.},
  title = {An Evaluation of Deep Learning Methods for Small Object Detection},
  journal = {JECE},
  year = {2020},
  volume = {2020},
  pages = {8856387},
  doi = {10.1155/2020/3189691}
}

@inproceedings{duSpineNetLearningScalePermuted2020,
  author = {Du, X. and Lin, T.Y. and Jin, P. and Ghiasi, G. and Tan, M. and Cui, Y. and Le, Q.V. and Song, X.},
  title = {SpineNet: Learning Scale-Permuted Backbone for Recognition and Localization},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year = {2020},
  pages = {11592--11601},
  address = {Seattle, WA, USA}
}

@article{shortenSurveyImageData2019,
  author = {Shorten, C. and Khoshgoftaar, T.M.},
  title = {A Survey on Image Data Augmentation for Deep Learning},
  journal = {J. Big Data},
  year = {2019},
  volume = {6},
  pages = {60},
  doi = {10.1186/s40537-019-0197-0}
}

@article{liuEstimatingMaizeSeedling2022,
  author = {Liu, S. and Yin, D. and Feng, H. and Li, Z. and Xu, X. and Shi, L. and Jin, X.},
  title = {Estimating Maize Seedling Number with UAV RGB Images and Advanced Image Processing Methods},
  journal = {Precis. Agric.},
  year = {2022},
  volume = {23},
  pages = {1604--1632},
  doi = {10.1007/s11119-022-09899-y}
}

@article{velumaniEstimatesMaizePlant2021,
  author = {Velumani, K. and Lopez-Lozano, R. and Madec, S. and Guo, W. and Gillet, J. and Comar, A. and Baret, F.},
  title = {Estimates of Maize Plant Density from UAV RGB Images Using Faster-RCNN Detection Model: Impact of the Spatial Resolution},
  journal = {Plant Phenomics},
  year = {2021},
  volume = {2021},
  pages = {9824843},
  doi = {10.34133/2021/9824843}
}

@misc{bumbaca202515235602,
  author = {Bumbaca, S.},
  title = {The Original Dataset for the Paper ``On the minimum dataset requirements for fine-tuning an object detector for arable crop plant counting: A case study on maize seedlings''},
  publisher = {Zenodo},
  year = {2025},
  doi = {10.5281/zenodo.15235602}
}

@inproceedings{krizhevskyImageNetClassificationDeep2012,
  author = {Krizhevsky, A. and Sutskever, I. and Hinton, G.E.},
  title = {ImageNet Classification with Deep Convolutional Neural Networks},
  booktitle = {Advances in Neural Information Processing Systems},
  year = {2012},
  volume = {25},
  publisher = {Curran Associates, Inc.},
  address = {Nice, France}
}

@incollection{fischlerRandomSampleConsensus1987,
  author = {Fischler, M.A. and Bolles, R.C.},
  title = {Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography},
  booktitle = {Readings in Computer Vision},
  publisher = {Morgan Kaufmann},
  address = {San Francisco, CA, USA},
  year = {1987},
  pages = {726--740},
  doi = {10.1016/B978-0-08-051581-6.50070-2}
}

@article{tervenComprehensiveReviewYOLO2023,
  author = {Terven, J. and Córdova-Esparza, D.M. and Romero-González, J.A.},
  title = {A Comprehensive Review of YOLO Architectures in Computer Vision: From YOLOv1 to YOLOv8 and YOLO-NAS},
  journal = {Mach. Learn. Knowl. Extr.},
  year = {2023},
  volume = {5},
  pages = {1680--1716},
  doi = {10.3390/make5040083}
}

@misc{jocherGitHubUltralyticsYOLO2023,
  author = {Jocher, G. and Qiu, J. and Chaurasia, A.},
  title = {GitHub Ultralytics YOLO},
  year = {2023},
  howpublished = {\url{https://github.com/ultralytics/ultralytics}},
  note = {accessed on 16 April 2025}
}

@article{oquabDINOv2LearningRobust2024,
  author = {Oquab, M. and Darcet, T. and Moutakanni, T. and Vo, H. and Szafraniec, M. and Khalidov, V. and Fernandez, P. and Haziza, D. and Massa, F. and El-Nouby, A. and others},
  title = {DINOv2: Learning Robust Visual Features without Supervision},
  journal = {arXiv},
  year = {2024},
  note = {arXiv:2304.07193},
  doi = {10.48550/arXiv.2304.07193}
}

@article{fuCrossDomainFewShotObject2024,
  author = {Fu, Y. and Wang, Y. and Pan, Y. and Huai, L. and Qiu, X. and Shangguan, Z. and Liu, T. and Fu, Y. and Gool, L.V. and Jiang, X.},
  title = {Cross-Domain Few-Shot Object Detection via Enhanced Open-Set Object Detector},
  journal = {arXiv},
  year = {2024},
  note = {arXiv:2402.03094},
  doi = {10.48550/arXiv.2402.03094}
}

@inproceedings{wolfTransformersStateoftheArtNatural2020,
  author = {Wolf, T. and Debut, L. and Sanh, V. and Chaumond, J. and Delangue, C. and Moi, A. and Cistac, P. and Rault, T. and Louf, R. and Funtowicz, M. and others},
  title = {Transformers: State-of-the-Art Natural Language Processing},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
  year = {2020},
  pages = {38--45},
  address = {Online}
}

@article{zhu_harnessing_2024,
  author = {Zhu, H. and Qin, S. and Su, M. and Lin, C. and Li, A. and Gao, J.},
  title = {Harnessing Large Vision and Language Models in Agriculture: A Review},
  journal = {arXiv},
  year = {2024},
  note = {arXiv:2407.19679},
  doi = {10.48550/arXiv.2407.19679}
}

@article{s24186109,
  author = {Zhou, Y. and Yan, H. and Ding, K. and Cai, T. and Zhang, Y.},
  title = {Few-Shot Image Classification of Crop Diseases Based on Vision–Language Models},
  journal = {Sensors},
  year = {2024},
  volume = {24},
  pages = {6109},
  doi = {10.3390/s24186109}
}

@article{chen_taskclip_2024,
  author = {Chen, H. and Huang, W. and Ni, Y. and Yun, S. and Liu, Y. and Wen, F. and Velasquez, A. and Latapie, H. and Imani, M.},
  title = {TaskCLIP: Extend Large Vision-Language Model for Task Oriented Object Detection},
  journal = {arXiv},
  year = {2024},
  note = {arXiv:2403.08108},
  doi = {10.48550/arXiv.2403.08108}
}

@article{chicco_coefficient_2021,
  author = {Chicco, D. and Warrens, M.J. and Jurman, G.},
  title = {The coefficient of determination R-squared is more informative than SMAPE, MAE, MAPE, MSE and RMSE in regression analysis evaluation},
  journal = {PeerJ Comput. Sci.},
  year = {2021},
  volume = {7},
  pages = {e623},
  doi = {10.7717/peerj-cs.623}
}

@book{draper1998applied,
  author = {Draper, N.R. and Smith, H.},
  title = {Applied Regression Analysis},
  publisher = {John Wiley \& Sons},
  address = {Hoboken, NJ, USA},
  year = {1998},
  volume = {326}
}

@article{ARMSTRONG199269,
  author = {Armstrong, J. and Collopy, F.},
  title = {Error measures for generalizing about forecasting methods: Empirical comparisons},
  journal = {Int. J. Forecast.},
  year = {1992},
  volume = {8},
  pages = {69--80},
  doi = {10.1016/0169-2070(92)90008-W}
}

@article{everingham_pascal_2010,
  author = {Everingham, M. and Van Gool, L. and Williams, C.K.I. and Winn, J. and Zisserman, A.},
  title = {The Pascal Visual Object Classes (VOC) Challenge},
  journal = {Int. J. Comput. Vis.},
  year = {2010},
  volume = {88},
  pages = {303--338},
  doi = {10.1007/s11263-009-0275-4}
}

@article{vianna_analysis_2024,
  author = {Vianna, L.S. and Gonçalves, A.L. and Souza, J.A.},
  title = {Analysis of learning curves in predictive modeling using exponential curve fitting with an asymptotic approach},
  journal = {PLoS ONE},
  year = {2024},
  volume = {19},
  pages = {e0299811},
  doi = {10.1371/journal.pone.0299811}
}

@inproceedings{akyonSlicingAidedHyper2022,
  author = {Akyon, F.C. and Altinuc, S.O. and Temizel, A.},
  title = {Slicing Aided Hyper Inference and Fine-tuning for Small Object Detection},
  booktitle = {Proceedings of the 2022 IEEE International Conference on Image Processing (ICIP)},
  year = {2022},
  pages = {966--970},
  address = {Bordeaux, France},
  doi = {10.1109/ICIP46576.2022.9897990}
}

@article{xuDeViTDecomposingVision2023,
  author = {Xu, G. and Hao, Z. and Luo, Y. and Hu, H. and An, J. and Mao, S.},
  title = {DeViT: Decomposing Vision Transformers for Collaborative Inference in Edge Devices},
  journal = {arXiv},
  year = {2023},
  note = {arXiv:2309.05015},
  doi = {10.1109/TMC.2023.3315138}
}

@inproceedings{wuOptimizingConnectedComponent2005,
  author = {Wu, K. and Otoo, E. and Shoshani, A.},
  title = {Optimizing Connected Component Labeling Algorithms},
  booktitle = {Proceedings of the Medical Imaging 2005: Image Processing},
  year = {2005},
  address = {San Diego, CA, USA}
}
@misc{accrediaEA402Rev03,
  title = {{{EA-4}}/02 Rev.03 - {{Evaluation}} of the {{Uncertainty}} of {{Measurement}} in Calibration},
  author = {{accredia}},
  journal = {Accredia},
  urldate = {2023-01-12},
  langid = {american},
  file = {/home/samuelebumbaca/Zotero/storage/SC83YICB/ea-4-02-rev-03-evaluation-of-the-uncertainty-of-measurement-in-calibration.html}
}

@misc{adzemovicRobotmurlockVariationalAutoEncoder2024,
  title = {Robotmurlock/{{VariationalAutoEncoder}}},
  author = {Ad{\v z}emovi{\'c}, Momir},
  year = {2024},
  month = nov,
  urldate = {2025-01-05},
  abstract = {Implementation of the Auto-Encoding Variational Bayes paper in Pytorch with detailed explanation.},
  keywords = {deep-learning,variational-autoencoder,variational-inference}
}

@misc{AgisoftMetashape2102023,
  title = {Agisoft {{Metashape}} 2.1.0},
  year = {2023},
  month = oct,
  annotation = {Published: Agisoft Metashape Software}
}

@misc{AgiSoftPhotoScanProfessional,
  title = {{{AgiSoft PhotoScan Professional}} ({{Version}} 1.2.6) ({{Software}}). (2016*). {{Retrieved}} from {{http://www.agisoft.com/downloads/installer/}}}
}

@article{agrestiAnalysisOrdinalCategorical,
  title = {Analysis of {{Ordinal Categorical Data}}},
  author = {Agresti, Alan},
  urldate = {2023-12-21},
  isbn = {9780470594001},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/T6SEVIVR/9780470594001.html}
}

@book{agrestiAnalysisOrdinalCategorical2010,
  title = {Analysis of Ordinal Categorical Data},
  author = {Agresti, Alan},
  year = {2010},
  volume = {656},
  publisher = {John Wiley \& Sons}
}

@book{agrestiFoundationsStatisticsData2021,
  title = {Foundations of {{Statistics}} for {{Data Scientists}}: {{With R}} and {{Python}}},
  shorttitle = {Foundations of {{Statistics}} for {{Data Scientists}}},
  author = {Agresti, Alan and Kateri, Maria},
  year = {2021},
  month = nov,
  edition = {1st edition},
  publisher = {{Chapman and Hall/CRC}},
  address = {Boca Raton},
  abstract = {Foundations of Statistics for Data Scientists: With R and Python is designed as a textbook for a one- or two-term introduction to mathematical statistics for students training to become data scientists. It is an in-depth presentation of the topics in statistical science with which any data scientist should be familiar, including probability distributions, descriptive and inferential statistical methods, and linear modeling. The book assumes knowledge of basic calculus, so the presentation can focus on "why it works" as well as "how to do it." Compared to traditional "mathematical statistics" textbooks, however, the book has less emphasis on probability theory and more emphasis on using software to implement statistical methods and to conduct simulations to illustrate key concepts. All statistical analyses in the book use R software, with an appendix showing the same analyses with Python.Key Features:Shows the elements of statistical science that are important for students who plan to become data scientists.Includes Bayesian and regularized fitting of models (e.g., showing an example using the lasso), classification and clustering, and implementing methods with modern software (R and Python).Contains nearly 500 exercises.The book also introduces modern topics that do not normally appear in mathematical statistics texts but are highly relevant for data scientists, such as Bayesian inference, generalized linear models for non-normal responses (e.g., logistic regression and Poisson loglinear models), and regularized model fitting. The nearly 500 exercises are grouped into "Data Analysis and Applications" and "Methods and Concepts." Appendices introduce R and Python and contain solutions for odd-numbered exercises. The book's website (http://stat4ds.rwth-aachen.de/) has expanded R, Python, and Matlab appendices and all data sets from the examples and exercises.},
  isbn = {978-0-367-74845-6},
  langid = {english}
}

@misc{alanovStyleDomainEfficientLightweight2023,
  title = {{{StyleDomain}}: {{Efficient}} and {{Lightweight Parameterizations}} of {{StyleGAN}} for {{One-shot}} and {{Few-shot Domain Adaptation}}},
  shorttitle = {{{StyleDomain}}},
  author = {Alanov, Aibek and Titov, Vadim and Nakhodnov, Maksim and Vetrov, Dmitry},
  year = {2023},
  month = sep,
  number = {arXiv:2212.10229},
  eprint = {2212.10229},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-07-23},
  abstract = {Domain adaptation of GANs is a problem of fine-tuning GAN models pretrained on a large dataset (e.g. StyleGAN) to a specific domain with few samples (e.g. painting faces, sketches, etc.). While there are many methods that tackle this problem in different ways, there are still many important questions that remain unanswered. In this paper, we provide a systematic and in-depth analysis of the domain adaptation problem of GANs, focusing on the StyleGAN model. We perform a detailed exploration of the most important parts of StyleGAN that are responsible for adapting the generator to a new domain depending on the similarity between the source and target domains. As a result of this study, we propose new efficient and lightweight parameterizations of StyleGAN for domain adaptation. Particularly, we show that there exist directions in StyleSpace (StyleDomain directions) that are sufficient for adapting to similar domains. For dissimilar domains, we propose Affine+ and AffineLight+ parameterizations that allows us to outperform existing baselines in few-shot adaptation while having significantly less training parameters. Finally, we examine StyleDomain directions and discover their many surprising properties that we apply for domain mixing and cross-domain image morphing. Source code can be found at https://github.com/AIRI-Institute/StyleDomain.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning}
}

@article{alcalaWorldTradeOrganization2020,
  title = {The {{World Trade Organization Agreement}} on the {{Application}} of {{Sanitary}} and {{Phytosanitary Measures}} and Veterinary Control Procedures.},
  author = {Alcala, R. and Vitikkala, H. and Ferlet, G.},
  year = {2020},
  month = jan,
  journal = {El Acuerdo sobre la Aplicaci{\'o}n de Medidas Sanitarias y Fitosanitarias de la Organizaci{\'o}n Mundial del Comercio y los procedimientos de control veterinario.},
  volume = {39},
  number = {1},
  pages = {253--261},
  publisher = {Organisation Mondiale de la Sante Animale},
  issn = {02531933}
}

@inproceedings{alenya3DModellingLeaves2011,
  title = {{{3D}} Modelling of Leaves from Color and {{ToF}} Data for Robotized Plant Measuring},
  booktitle = {2011 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Alenya, G. and Dellen, B. and Torras, C.},
  year = {2011},
  month = may,
  pages = {3408--3414},
  publisher = {IEEE},
  address = {Shanghai, China},
  doi = {10.1109/ICRA.2011.5980092},
  urldate = {2023-01-13},
  isbn = {978-1-61284-386-5}
}

@article{aliPredictionDryDirectseeded2014,
  title = {Prediction of Dry Direct-Seeded Rice Yields Using Chlorophyll Meter, Leaf Color Chart and {{GreenSeeker}} Optical Sensor in Northwestern {{India}}},
  author = {Ali, A.M. and Thind, H.S. and Sharma, S. and {Varinderpal-Singh}},
  year = {2014},
  month = may,
  journal = {Field Crops Research},
  volume = {161},
  pages = {11--15},
  issn = {03784290},
  doi = {10.1016/j.fcr.2014.03.001},
  urldate = {2022-09-19},
  langid = {english}
}

@article{aliUseImageAnalysis2013,
  title = {Use of {{Image Analysis}} to {{Assess Color Response}} on {{Plants Caused}} by {{Herbicide Application}}},
  author = {Ali, Asif and Streibig, Jens C. and Duus, Joachim and Andreasen, Christian},
  year = {2013},
  journal = {Weed Technology},
  volume = {27},
  number = {3},
  eprint = {43702644},
  eprinttype = {jstor},
  pages = {604--611},
  publisher = {[Cambridge University Press, Weed Science Society of America]},
  issn = {0890-037X},
  urldate = {2023-03-24},
  abstract = {In herbicide-selectivity experiments, response can be measured by visual inspection, stand counts, plant mortality, and biomass. Some response types are relative to nontreated control. We developed a nondestructive method by analyzing digital color images to quantify color changes in leaves caused by herbicides. The range of color components of green and nongreen parts of the plants and soil in Hue, Saturation, and Brightness (HSB) color space were used for segmentation. The canopy color changes of barley, winter wheat, red fescue, and brome fescue caused by doses of a glyphosate and diflufenican mixture, cycloxydim, diquat dibromide, and fluazifop-p-butyl were described with a log-logistic dose---response model, and the relationship between visual inspection and image analysis was calculated at the effective doses that cause 50\% and 90\% response (ED{$_{50}$} and ED{$_{90}$}, respectively). The ranges of HSB components for the green and nongreen parts of the plants and soil were different. The relative potencies were not significantly different from one, indicating that visual and image analysis estimations were about the same. The comparison results suggest that image analysis can be used to assess color changes of plants in response to some herbicides and may have the potential to provide an objective measurement of symptoms. En experimentos de selectividad de herbicidas, la respuesta puede ser medida mediante inspecci{\'o}n visual, conteo de plantas establecidas, mortalidad de plantas y biomasa. Algunos tipos de respuesta son relativos al testigo no-tratado. Nosotros desarrollamos un m{\'e}todo no-destructivo que analiza im{\'a}genes digitales a color para cuantificar cambios en el color de las hojas causados por herbicidas. El rango de los componentes de color de partes verdes y no-verdes de las plantas y el suelo en el {\'a}mbito de tono, saturaci{\'o}n y brillo (HSB) de color fue usado para la segmentaci{\'o}n. Los cambios en el color del dosel de cebada, trigo de invierno, Festuca rubra y Vulpia bromoides causados por dosis de una mezcla de glyphosate y diflufenican, cycloxydim, diquat dibromide, y fluazifop-p-butyl fueron descritos con un modelo log-log{\'i}stico de respuesta a dosis, y la relaci{\'o}n entre la inspecci{\'o}n visual y el an{\'a}lisis de imagen fue calculada a dosis efectivas que causaron una respuesta del 50\% y 90\% (ED{$_{50}$} y ED{$_{90}$}, respectivamente). Lo{\c s} rangos de los componentes de HSB para las partes verdes y no-verdes de las plantas y el suelo fueron diferentes. Las potencias relativas no fueron significativamente diferentes de uno, indicando que las estimaciones del an{\'a}lisis visual y del de imagen fueron casi las mismas. Los resultados de la comparaci{\'o}n sugieren que el an{\'a}lisis de imagen puede ser usado para evaluar los cambios de color de las plantas en respuesta a algunos herbicidas y podr{\'i}a tener potencial para brindar una medida objetiva de los s{\'i}ntomas.}
}

@article{aliUseImageAnalysis2013a,
  title = {Use of {{Image Analysis}} to {{Assess Color Response}} on {{Plants Caused}} by {{Herbicide Application}}},
  author = {Ali, Asif and Streibig, Jens C. and Duus, Joachim and Andreasen, Christian},
  year = {2013},
  month = sep,
  journal = {Weed Technology},
  volume = {27},
  number = {3},
  pages = {604--611},
  publisher = {Cambridge University Press},
  issn = {0890-037X, 1550-2740},
  doi = {10.1614/WT-D-12-00136.1},
  urldate = {2023-03-24},
  abstract = {In herbicide-selectivity experiments, response can be measured by visual inspection, stand counts, plant mortality, and biomass. Some response types are relative to nontreated control. We developed a nondestructive method by analyzing digital color images to quantify color changes in leaves caused by herbicides. The range of color components of green and nongreen parts of the plants and soil in Hue, Saturation, and Brightness (HSB) color space were used for segmentation. The canopy color changes of barley, winter wheat, red fescue, and brome fescue caused by doses of a glyphosate and diflufenican mixture, cycloxydim, diquat dibromide, and fluazifop-p-butyl were described with a log-logistic dose--response model, and the relationship between visual inspection and image analysis was calculated at the effective doses that cause 50\% and 90\% response (ED50 and ED90, respectively). The ranges of HSB components for the green and nongreen parts of the plants and soil were different. The relative potencies were not significantly different from one, indicating that visual and image analysis estimations were about the same. The comparison results suggest that image analysis can be used to assess color changes of plants in response to some herbicides and may have the potential to provide an objective measurement of symptoms., En experimentos de selectividad de herbicidas, la respuesta puede ser medida mediante inspecci{\'o}n visual, conteo de plantas establecidas, mortalidad de plantas y biomasa. Algunos tipos de respuesta son relativos al testigo no-tratado. Nosotros desarrollamos un m{\'e}todo no-destructivo que analiza im{\'a}genes digitales a color para cuantificar cambios en el color de las hojas causados por herbicidas. El rango de los componentes de color de partes verdes y no-verdes de las plantas y el suelo en el {\'a}mbito de tono, saturaci{\'o}n y brillo (HSB) de color fue usado para la segmentaci{\'o}n. Los cambios en el color del dosel de cebada, trigo de invierno, Festuca rubra y Vulpia bromoides causados por dosis de una mezcla de glyphosate y diflufenican, cycloxydim, diquat dibromide, y fluazifop-p-butyl fueron descritos con un modelo log-log{\'i}stico de respuesta a dosis, y la relaci{\'o}n entre la inspecci{\'o}n visual y el an{\'a}lisis de imagen fue calculada a dosis efectivas que causaron una respuesta del 50\% y 90\% (ED50 y ED90, respectivamente). Los rangos de los componentes de HSB para las partes verdes y no-verdes de las plantas y el suelo fueron diferentes. Las potencias relativas no fueron significativamente diferentes de uno, indicando que las estimaciones del an{\'a}lisis visual y del de imagen fueron casi las mismas. Los resultados de la comparaci{\'o}n sugieren que el an{\'a}lisis de imagen puede ser usado para evaluar los cambios de color de las plantas en respuesta a algunos herbicidas y podr{\'i}a tener potencial para brindar una medida objetiva de los s{\'i}ntomas.},
  langid = {english},
  keywords = {barley,brome fescue,Cycloxydim,diflufenican,diquat dibromide,Festuca rubra L.,fluazifop-p-butyl,glyphosate,Herbicide efficacy,Hordeum vulgare L.,logarithmic sprayer,red fescue,Triticum aestivum L.,visual inspection,Vulpia bromoides (L.) S.F. Gray,weeds management,wheat}
}

@article{aliUseImageAnalysis2013b,
  title = {Use of {{Image Analysis}} to {{Assess Color Response}} on {{Plants Caused}} by {{Herbicide Application}}},
  author = {Ali, Asif and Streibig, Jens C. and Duus, Joachim and Andreasen, Christian},
  year = {2013},
  journal = {Weed Technology},
  volume = {27},
  number = {3},
  eprint = {43702644},
  eprinttype = {jstor},
  pages = {604--611},
  publisher = {[Cambridge University Press, Weed Science Society of America]},
  issn = {0890-037X},
  urldate = {2023-03-24},
  abstract = {In herbicide-selectivity experiments, response can be measured by visual inspection, stand counts, plant mortality, and biomass. Some response types are relative to nontreated control. We developed a nondestructive method by analyzing digital color images to quantify color changes in leaves caused by herbicides. The range of color components of green and nongreen parts of the plants and soil in Hue, Saturation, and Brightness (HSB) color space were used for segmentation. The canopy color changes of barley, winter wheat, red fescue, and brome fescue caused by doses of a glyphosate and diflufenican mixture, cycloxydim, diquat dibromide, and fluazifop-p-butyl were described with a log-logistic dose---response model, and the relationship between visual inspection and image analysis was calculated at the effective doses that cause 50\% and 90\% response (ED{$_{50}$} and ED{$_{90}$}, respectively). The ranges of HSB components for the green and nongreen parts of the plants and soil were different. The relative potencies were not significantly different from one, indicating that visual and image analysis estimations were about the same. The comparison results suggest that image analysis can be used to assess color changes of plants in response to some herbicides and may have the potential to provide an objective measurement of symptoms. En experimentos de selectividad de herbicidas, la respuesta puede ser medida mediante inspecci{\'o}n visual, conteo de plantas establecidas, mortalidad de plantas y biomasa. Algunos tipos de respuesta son relativos al testigo no-tratado. Nosotros desarrollamos un m{\'e}todo no-destructivo que analiza im{\'a}genes digitales a color para cuantificar cambios en el color de las hojas causados por herbicidas. El rango de los componentes de color de partes verdes y no-verdes de las plantas y el suelo en el {\'a}mbito de tono, saturaci{\'o}n y brillo (HSB) de color fue usado para la segmentaci{\'o}n. Los cambios en el color del dosel de cebada, trigo de invierno, Festuca rubra y Vulpia bromoides causados por dosis de una mezcla de glyphosate y diflufenican, cycloxydim, diquat dibromide, y fluazifop-p-butyl fueron descritos con un modelo log-log{\'i}stico de respuesta a dosis, y la relaci{\'o}n entre la inspecci{\'o}n visual y el an{\'a}lisis de imagen fue calculada a dosis efectivas que causaron una respuesta del 50\% y 90\% (ED{$_{50}$} y ED{$_{90}$}, respectivamente). Lo{\c s} rangos de los componentes de HSB para las partes verdes y no-verdes de las plantas y el suelo fueron diferentes. Las potencias relativas no fueron significativamente diferentes de uno, indicando que las estimaciones del an{\'a}lisis visual y del de imagen fueron casi las mismas. Los resultados de la comparaci{\'o}n sugieren que el an{\'a}lisis de imagen puede ser usado para evaluar los cambios de color de las plantas en respuesta a algunos herbicidas y podr{\'i}a tener potencial para brindar una medida objetiva de los s{\'i}ntomas.}
}

@article{almasriImpactPrimaryInfection2017,
  title = {Impact of Primary Infection Site of {{Fusarium}} Species on Head Blight Development in Wheat Ears Evaluated by {{IR-thermography}}},
  author = {Al Masri, A. and Hau, B. and Dehne, H.-W. and Mahlein, A.-K. and Oerke, E.-C.},
  year = {2017},
  month = apr,
  journal = {European Journal of Plant Pathology},
  volume = {147},
  number = {4},
  pages = {855--868},
  issn = {1573-8469},
  doi = {10.1007/s10658-016-1051-2},
  urldate = {2023-01-13},
  abstract = {The effect of the primary infection site by Fusarium graminearum and F. culmorum within wheat ears on Fusarium head blight (FHB) was investigated under controlled conditions. FHB development was assessed visually and thermographically following inoculation by: (i) spraying ears, or injecting inoculum into spikelets on (ii) tip, (iii) centre and (iv) base of the ears, separately. Fusarium infection significantly increased the temperature span within ears 6~days post inoculation (dpi), especially infections starting at the ear tip. The temperature difference between air and ear was negatively correlated to FHB severity and enabled disease detection even 29 dpi. F. culmorum caused significant higher disease severity neither reflected in the frequency of infected kernels nor in thousand kernel weight (TKW). Spray inoculations had the strongest effect on TKW, whereas tip inoculations had no effect. Centre and base inoculations had intermediate effects on TKW, although FHB levels did not differ with the same trend among inoculation scenarios. The overall low correlations among FHB severity, infected kernels and TKW are explained by the pathogen spread within ears -- downwards more than upwards -- and the effect on yield formation which is lower for infections of the upper parts of ears. An exponential model showed high goodness of fit for gradients of infected kernels within ears (R2~{$\geq~$}70) except tip infection with F. culmorum. This study confirmed that FHB is a function of the primary infection site within ears. Thermography was useful to differentiate among infection scenarios and may be applied in breeding for FHB resistance.},
  langid = {english},
  keywords = {Fusarium culmorum,Fusarium graminearum,Fusarium head blight,Thermography,Wheat}
}

@misc{AmericanJournalBotany,
  title = {American {{Journal}} of {{Botany}}},
  urldate = {2023-01-13},
  howpublished = {https://bsapubs.onlinelibrary.wiley.com/doi/full/10.2307/2657019}
}

@misc{AnalysisOrdinalCategorical,
  title = {Analysis of {{Ordinal Categorical Data}} {\textbar} {{Wiley Series}} in {{Probability}} and {{Statistics}}},
  urldate = {2023-12-21},
  howpublished = {https://onlinelibrary.wiley.com/doi/book/10.1002/9780470594001},
  file = {/home/samuelebumbaca/Zotero/storage/TXLPXXRZ/9780470594001.html}
}

@article{aneAgricultureFourthIndustrial2019,
  title = {Agriculture in the {{Fourth Industrial Revolution}}},
  author = {Ane, Tanjea and Yasmin, Suraiya},
  year = {2019},
  month = dec,
  journal = {Annals of Bangladesh Agriculture},
  volume = {23},
  doi = {10.3329/aba.v23i2.50060},
  abstract = {Agriculture and industry are tied up and both are complementary to each other. The fourth industrial revolution is an advanced digital technology, it focuses an opportunity that could change the environment in the way human think and work. The farms and factories must implement smart technology to move very fast and it should be an innovative applications to embrace the fourth industrial revolution robustly for Bangladesh. The fourth industrial revolution concept combines artificial intelligence and big data that have achieved significant attention and popularity in precision farming like in monitoring, diagnosing insect pests, measuring soil moisture, diagnosing harvest time and monitoring crop health status and reducing complicated monitoring by human. Industry that extend precision agriculture using artificial intelligence with robotic technology in fourth industrial revolution and its application is embedding into smart observation that retrieve real-time information from field level data with minor human interference. The fourth industrial revolution builds a smart farming technology which brings advanced and sustainable changes for both production and agroprocessing. The fourth industrial revolution extends farms production and also increase their value. This paper reviewed the past effects of industrial revolution, discussed expanded benefit into smart farming and predicted impacts of fourth industrial revolution in Bangladesh agriculture.}
}

@misc{Anomaly_detection_with_embeddingsipynbColab,
  title = {Anomaly\_detection\_with\_embeddings.Ipynb - {{Colab}}},
  urldate = {2025-01-05},
  howpublished = {https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/Anomaly\_detection\_with\_embeddings.ipynb}
}

@article{ashourlooEvaluatingEffectDifferent2014,
  title = {Evaluating the {{Effect}} of {{Different Wheat Rust Disease Symptoms}} on {{Vegetation Indices Using Hyperspectral Measurements}}},
  author = {Ashourloo, Davoud and Mobasheri, Mohammad Reza and Huete, Alfredo},
  year = {2014},
  month = jun,
  journal = {Remote Sensing},
  volume = {6},
  number = {6},
  pages = {5107--5123},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2072-4292},
  doi = {10.3390/rs6065107},
  urldate = {2023-01-13},
  abstract = {Spectral Vegetation Indices (SVIs) have been widely used to indirectly detect plant diseases. The aim of this research is to evaluate the effect of different disease symptoms on SVIs and introduce suitable SVIs to detect rust disease. Wheat leaf rust is one of the prevalent diseases and has different symptoms including yellow, orange, dark brown, and dry areas. The reflectance spectrum data for healthy and infected leaves were collected using a spectroradiometer in the 450 to 1000 nm range. The ratio of the  disease-affected area to the total leaf area and the proportion of each disease symptoms were obtained using RGB digital images. As the disease severity increases, so does the scattering of all SVI values. The indices were categorized into three groups based on their accuracies in disease detection. A few SVIs showed an accuracy of more than 60\% in classification. In the first group, NBNDVI, NDVI, PRI, GI, and RVSI showed the highest amount of classification accuracy. The second and third groups showed classification accuracies of about 20\% and 40\% respectively. Results show that few indices have the ability to indirectly detect plant disease.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {hyperspectral data,vegetation index,wheat rust disease}
}

@misc{AssessingLeafPigment,
  title = {Assessing Leaf Pigment Content and Activity with a Reflectometer {\textbar} {{The New Phytologist}} {\textbar} {{Cambridge Core}}},
  urldate = {2023-01-13},
  howpublished = {https://www.cambridge.org/core/journals/new-phytologist/article/abs/assessing-leaf-pigment-content-and-activity-with-a-reflectometer/070BA29E75C935E961BABA4E1BA135D5}
}

@book{atkinsonCloseRangePhotogrammetry1996,
  title = {Close Range Photogrammetry and Machine Vision},
  editor = {Atkinson, Keith B.},
  year = {1996},
  edition = {Reprinted},
  publisher = {Whittles},
  address = {Caithness},
  isbn = {978-1-870325-73-8},
  langid = {english}
}

@article{auSkeletonExtractionMesh2008,
  title = {Skeleton Extraction by Mesh Contraction},
  author = {Au, Oscar Kin-Chung and Tai, Chiew-Lan and Chu, Hung-Kuo and {Cohen-Or}, Daniel and Lee, Tong-Yee},
  year = {2008},
  month = aug,
  journal = {ACM Transactions on Graphics},
  volume = {27},
  number = {3},
  pages = {1--10},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/1360612.1360643},
  urldate = {2024-06-10},
  abstract = {Extraction of curve-skeletons is a fundamental problem with many applications in computer graphics and visualization. In this paper, we present a simple and robust skeleton extraction method based on mesh contraction. The method works directly on the mesh domain, without pre-sampling the mesh model into a volumetric representation. The method first contracts the mesh geometry into zero-volume skeletal shape by applying implicit Laplacian smoothing with global positional constraints. The contraction does not alter the mesh connectivity and retains the key features of the original mesh. The contracted mesh is then converted into a 1D curve-skeleton through a connectivity surgery process to remove all the collapsed faces while preserving the shape of the contracted mesh and the original topology. The centeredness of the skeleton is refined by exploiting the induced skeleton-mesh mapping. In addition to producing a curve skeleton, the method generates other valuable information about the object's geometry, in particular, the skeleton-vertex correspondence and the local thickness, which are useful for various applications. We demonstrate its effectiveness in mesh segmentation and skinning animation.},
  langid = {english}
}

@article{bakerMechanisticModelsMachine2018,
  title = {Mechanistic Models versus Machine Learning, a Fight Worth Fighting for the Biological Community?},
  author = {Baker, Ruth E. and Pe{\~n}a, Jose-Maria and Jayamohan, Jayaratnam and J{\'e}rusalem, Antoine},
  year = {2018},
  month = may,
  journal = {Biology Letters},
  volume = {14},
  number = {5},
  pages = {20170660},
  publisher = {Royal Society},
  doi = {10.1098/rsbl.2017.0660},
  urldate = {2023-03-24},
  abstract = {Ninety per cent of the world's data have been generated in the last 5 years (Machine learning: the power and promise of computers that learn by example. Report no. DES4702. Issued April 2017. Royal Society). A small fraction of these data is collected with the aim of validating specific hypotheses. These studies are led by the development of mechanistic models focused on the causality of input--output relationships. However, the vast majority is aimed at supporting statistical or correlation studies that bypass the need for causality and focus exclusively on prediction. Along these lines, there has been a vast increase in the use of machine learning models, in particular in the biomedical and clinical sciences, to try and keep pace with the rate of data generation. Recent successes now beg the question of whether mechanistic models are still relevant in this area. Said otherwise, why should we try to understand the mechanisms of disease progression when we can use machine learning tools to directly predict disease outcome?},
  keywords = {machine learning,mechanistic modelling,quantitative biology}
}

@article{baoParallelStructureMotion2021,
  title = {Parallel {{Structure}} from {{Motion}} for {{Sparse Point Cloud Generation}} in {{Large-Scale Scenes}}},
  author = {Bao, Yongtang and Lin, Pengfei and Li, Yao and Qi, Yue and Wang, Zhihui and Du, Wenxiang and Fan, Qing},
  year = {2021},
  month = jun,
  journal = {Sensors},
  volume = {21},
  number = {11},
  pages = {3939},
  issn = {1424-8220},
  doi = {10.3390/s21113939},
  urldate = {2021-12-19},
  abstract = {Scene reconstruction uses images or videos as input to reconstruct a 3D model of a real scene and has important applications in smart cities, surveying and mapping, military, and other fields. Structure from motion (SFM) is a key step in scene reconstruction, which recovers sparse point clouds from image sequences. However, large-scale scenes cannot be reconstructed using a single compute node. Image matching and geometric filtering take up a lot of time in the traditional SFM problem. In this paper, we propose a novel divide-and-conquer framework to solve the distributed SFM problem. First, we use the global navigation satellite system (GNSS) information from images to calculate the GNSS neighborhood. The number of images matched is greatly reduced by matching each image to only valid GNSS neighbors. This way, a robust matching relationship can be obtained. Second, the calculated matching relationship is used as the initial camera graph, which is divided into multiple subgraphs by the clustering algorithm. The local SFM is executed on several computing nodes to register the local cameras. Finally, all of the local camera poses are integrated and optimized to complete the global camera registration. Experiments show that our system can accurately and efficiently solve the structure from motion problem in large-scale scenes.},
  langid = {english}
}

@article{barbedoDeepLearningApplied2022,
  title = {Deep Learning Applied to Plant Pathology: The Problem of Data Representativeness},
  shorttitle = {Deep Learning Applied to Plant Pathology},
  author = {Barbedo, Jayme G. A.},
  year = {2022},
  month = feb,
  journal = {Tropical Plant Pathology},
  volume = {47},
  number = {1},
  pages = {85--94},
  issn = {1983-2052},
  doi = {10.1007/s40858-021-00459-9},
  urldate = {2023-09-12},
  abstract = {The rise of deep learning techniques has profoundly impacted both research and applications of pattern and object recognition in digital images. In plant pathology, the number of scientific articles on the use of deep learning for disease classification using images has grown steadily for at least a decade and targeted most important agricultural crops. Results have been encouraging, with accuracies of many prediction models usually approaching 100\%. It is now widely accepted that, enough data being available, deep learning models can solve most of the image classification problems. However, determining what ``enough'' means in each context is far from trivial because this involves not only the number of samples used for training, but also the quality, in particular the representativeness of the dataset. More important than having a large sample size is to guarantee that all the variability associated to a given classification problem is represented in the dataset. Achieving this goal is particularly challenging for plant disease images because the agricultural environment is non-structured and highly dynamic, containing numerous variables that introduce variability to the problem. To make matters even more difficult, image annotation is time consuming and prone to inconsistencies due to its subjectivity. As a result, all studies in the literature employ datasets that represent only a fraction of the whole range of the variability, and many of these do not even acknowledge the limitations of the experimental conditions. Experiments with limited scope are valuable in the early stages of emerging research topics, but the application of deep learning to plant pathology has matured to the point where new studies need to contribute something more substantial. Unfortunately, many of the recent publications have been redundant, differing from previous research only by the adoption of slightly different experimental setups and improved model architectures. To move forward, new studies in this field need to address the data gap problem more effectively. This article delves deep into some technical and practical issues to achieve this goal and to increase the usefulness of the future studies. Although this article is dedicated primarily to proximal images, many of the remarks also hold for images captured using unmanned aerial vehicles.},
  langid = {english},
  keywords = {Disease recognition,Image analysis,Image datasets,Plant disease}
}

@article{barbedoFactorsInfluencingUse2018,
  title = {Factors Influencing the Use of Deep Learning for Plant Disease Recognition},
  author = {Barbedo, Jayme G. A.},
  year = {2018},
  month = aug,
  journal = {Biosystems Engineering},
  volume = {172},
  pages = {84--91},
  issn = {1537-5110},
  doi = {10.1016/j.biosystemseng.2018.05.013},
  urldate = {2023-12-17},
  abstract = {Deep learning is quickly becoming one of the most important tools for image classification. This technology is now beginning to be applied to the tasks of plant disease classification and recognition. The positive results that are being obtained using this approach hide some issues that are seldom taken into account in the respective experiments. This article presents an investigation into the main factors that affect the design and effectiveness of deep neural nets applied to plant pathology. An in-depth analysis of the subject, in which advantages and shortcomings are highlighted, should lead to more realistic conclusions on the subject. The arguments used throughout the text are built upon both studies found in the literature and experiments carried out using an image database carefully built to reflect and reproduce many of the conditions expected to be found in practice. This database, which contains almost 50,000 images, is being made freely available for academic purposes.},
  keywords = {Deep neural nets,Disease classification,Image database,Image processing,Transfer learning},
  file = {/home/samuelebumbaca/Zotero/storage/CDQ32AQS/S1537511018303027.html}
}

@article{barbedoNovelAlgorithmSemiautomatic2016,
  title = {A Novel Algorithm for Semi-Automatic Segmentation of Plant Leaf Disease Symptoms Using Digital Image Processing},
  author = {Barbedo, J. G. A.},
  year = {2016},
  month = aug,
  journal = {Tropical Plant Pathology},
  volume = {41},
  number = {4},
  pages = {210--224},
  issn = {1983-2052},
  doi = {10.1007/s40858-016-0090-8},
  urldate = {2023-09-11},
  abstract = {A new computer algorithm is proposed to differentiate signs and symptoms of plant disease from asymptomatic tissues in plant leaves. The simple algorithm manipulates the histograms of the H (from HSV color space) and a (from the L*a*b* color space) color channels. All steps in the algorithmic process are automatic, with the exception of the final step in which the user decides which channel (H or a) provides the better differentiation. An in-depth analysis of the problem of disease symptom differentiation is also presented, in which issues such as lesion delimitation, illumination, leaf venation interference, leaf ruggedness, among others, are thoroughly discussed. The proposed algorithm was tested under a wide variety of conditions, which included 19 plant species, 82 diseases, and images gathered under controlled and uncontrolled environmental conditions. The algorithm proved useful for a wide variety of plant diseases and conditions, although some situations may require alternative solutions.},
  langid = {english},
  keywords = {Color histograms,Color space transformations,Disease diagnosis,Leaf symptoms}
}

@article{barnhartUseHighresolutionUnmanned2021,
  title = {Use of High-Resolution Unmanned Aerial Systems Imagery and Machine Learning to Evaluate Grain Sorghum Tolerance to Mesotrione},
  author = {Barnhart, Isaac and Chaudhari, Sushila and Pandian, Balaji A. and Vara Prasad, P. V. and Ciampitti, Ignacio A. and Jugulam, Mithila},
  year = {2021},
  month = mar,
  journal = {Journal of Applied Remote Sensing},
  volume = {15},
  number = {01},
  issn = {1931-3195},
  doi = {10.1117/1.JRS.15.014516},
  urldate = {2022-09-20}
}

@article{basyouniUseNondestructiveSensors2016,
  title = {Use of {{Nondestructive Sensors}} to {{Assess Nitrogen Status}} in {{Potted Dianthus}} ({{Dianthus}} Chinensis {{L}}.) {{Production}}},
  author = {Basyouni, Rania and Dunn, Bruce and Goad, Carla},
  year = {2016},
  month = jul,
  journal = {Canadian Journal of Plant Science},
  pages = {CJPS-2016-0059},
  issn = {0008-4220, 1918-1833},
  doi = {10.1139/CJPS-2016-0059},
  urldate = {2022-09-19},
  langid = {english}
}

@article{basyouniUseNondestructiveSensors2016a,
  title = {Use of {{Nondestructive Sensors}} to {{Assess Nitrogen Status}} in {{Potted Dianthus}} ({{Dianthus}} Chinensis {{L}}.) {{Production}}},
  author = {Basyouni, Rania and Dunn, Bruce and Goad, Carla},
  year = {2016},
  month = jul,
  journal = {Canadian Journal of Plant Science},
  pages = {CJPS-2016-0059},
  issn = {0008-4220, 1918-1833},
  doi = {10.1139/CJPS-2016-0059},
  urldate = {2022-09-19},
  langid = {english}
}

@article{behmannReviewAdvancedMachine2015,
  title = {A Review of Advanced Machine Learning Methods for the Detection of Biotic Stress in Precision Crop Protection},
  author = {Behmann, Jan and Mahlein, Anne-Katrin and Rumpf, Till and R{\"o}mer, Christoph and Pl{\"u}mer, Lutz},
  year = {2015},
  month = jun,
  journal = {Precision Agriculture},
  volume = {16},
  number = {3},
  pages = {239--260},
  issn = {1573-1618},
  doi = {10.1007/s11119-014-9372-7},
  urldate = {2023-01-13},
  abstract = {Effective crop protection requires early and accurate detection of biotic stress. In recent years, remarkable results have been achieved in the early detection of weeds, plant diseases and insect pests in crops. These achievements are related both to the development of non-invasive, high resolution optical sensors and data analysis methods that are able to cope with the resolution, size and complexity of the signals from these sensors. Several methods of machine learning have been utilized for precision agriculture such as support vector machines and neural networks for classification (supervised learning); k-means and self-organizing maps for clustering (unsupervised learning). These methods are able to calculate both linear and non-linear models, require few statistical assumptions and adapt flexibly to a wide range of data characteristics. Successful applications include the early detection of plant diseases based on spectral features and weed detection based on shape descriptors with supervised or unsupervised learning methods. This review gives a short introduction into machine learning, analyses its potential for precision crop protection and provides an overview of instructive examples from different fields of precision agriculture.},
  langid = {english},
  keywords = {Data analysis,Machine learning,Optical sensors,Plant diseases,Stress detection,Weed detection}
}

@article{berdugoSensorsImagingTechniques2013,
  title = {Sensors and Imaging Techniques for the Assessment of the Delay of Wheat Senescence Induced by Fungicides},
  author = {Berdugo, Carlos Andres and Mahlein, Anne-Katrin and Steiner, Ulrike and Dehne, Heinz-Wilhelm and Oerke, Erich-Christian and Berdugo, Carlos Andres and Mahlein, Anne-Katrin and Steiner, Ulrike and Dehne, Heinz-Wilhelm and Oerke, Erich-Christian},
  year = {2013},
  month = may,
  journal = {Functional Plant Biology},
  volume = {40},
  number = {7},
  pages = {677--689},
  publisher = {CSIRO PUBLISHING},
  issn = {1445-4416, 1445-4416},
  doi = {10.1071/FP12351},
  urldate = {2023-01-13},
  abstract = {Near-range and remote sensing techniques are excellent alternatives to destructive methods for measuring beneficial effects of fungicides on plant physiology. Different noninvasive sensors and imaging techniques have been used and compared to measure the effects of three fungicidal compounds (bixafen, fluoxastrobin and prothioconazole) on wheat (Triticum aestivum L.) physiology under disease-free conditions in the greenhouse. Depending on the fungicidal treatment, changes in green leaf area and yield parameters were observed. Chlorophyll fluorescence of leaves was useful for measuring differences in the effective quantum yield of PSII. Reflectance measurements of wheat leaves were highly sensitive to changes in plant vitality. The spectral vegetation indices were useful for determining the differences among treatments in terms of leaf senescence, pigments and water content. The analysis of ear and leaf surface temperature was reliable for detecting effects of fungicides on plant senescence. Using nondestructive sensors, it was possible to assess a delay in senescence of wheat due to fungicide application. Furthermore, it was deduced that sensors and imaging methods are useful tools to estimate the effects of fungicides on wheat physiology. Physiological parameters measured by the sensors were actually more sensitive than yield parameters to assess the effect caused by fungicide application on wheat physiology.},
  langid = {english}
}

@article{bergstrasserHyperARTNoninvasiveQuantification2015,
  title = {{{HyperART}}: Non-Invasive Quantification of Leaf Traits Using Hyperspectral Absorption-Reflectance-Transmittance Imaging},
  shorttitle = {{{HyperART}}},
  author = {Bergstr{\"a}sser, Sergej and Fanourakis, Dimitrios and Schmittgen, Simone and {Cendrero-Mateo}, Maria Pilar and Jansen, Marcus and Scharr, Hanno and Rascher, Uwe},
  year = {2015},
  month = jan,
  journal = {Plant Methods},
  volume = {11},
  number = {1},
  pages = {1},
  issn = {1746-4811},
  doi = {10.1186/s13007-015-0043-0},
  urldate = {2023-01-13},
  abstract = {Combined assessment of leaf reflectance and transmittance is currently limited to spot (point) measurements. This study introduces a tailor-made hyperspectral absorption-reflectance-transmittance imaging (HyperART) system, yielding a non-invasive determination of both reflectance and transmittance of the whole leaf. We addressed its applicability for analysing plant traits, i.e. assessing Cercospora beticola disease severity or leaf chlorophyll content. To test the accuracy of the obtained data, these were compared with reflectance and transmittance measurements of selected leaves acquired by the point spectroradiometer ASD FieldSpec, equipped with the FluoWat device.},
  langid = {english},
  keywords = {Absorption,Cercospora beticola,Chlorophyll content,FieldSpec,FluoWat,Hyperspectral imaging,Imaging spectroscopy,Non-invasive phenotyping,Reflectance,Transmittance}
}

@article{bethmannSEMIGLOBALMATCHINGOBJECT2015,
  title = {{{SEMI-GLOBAL MATCHING IN OBJECT SPACE}}},
  author = {Bethmann, F. and Luhmann, T.},
  year = {2015},
  month = mar,
  journal = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  volume = {XL-3/W2},
  pages = {23--30},
  issn = {2194-9034},
  doi = {10.5194/isprsarchives-XL-3-W2-23-2015},
  urldate = {2022-11-24},
  abstract = {Semi-Global Matching (SGM) is a widespread algorithm for image matching which is used for very different applications, ranging from real-time applications (e.g. for generating 3D data for driver assistance systems) to aerial image matching. Originally developed for stereo-image matching, several extensions have been proposed to use more than two images within the matching process (multibaseline matching, multi-view stereo). These extensions still perform the image matching in (rectified) stereo images and combine the pairwise results afterwards to create the final solution. This paper proposes an alternative approach which is suitable for the introduction of an arbitrary number of images into the matching process and utilizes image matching by using non-rectified images. The new method differs from the original SGM method mainly in two aspects: Firstly, the cost calculation is formulated in object space within a dense voxel raster by using the grey (or colour) values of all images instead of pairwise cost calculation in image space. Secondly, the semi-global (path-wise) minimization process is transferred into object space as well, so that the result of semiglobal optimization leads to index maps (instead of disparity maps) which directly indicate the 3D positions of the best matches. Altogether, this yields to an essential simplification of the matching process compared to multi-view stereo (MVS) approaches. After a description of the new method, results achieved from two different datasets (close-range and aerial) are presented and discussed.},
  langid = {english}
}

@article{bingjianRobustPointSet2011,
  title = {Robust {{Point Set Registration Using Gaussian Mixture Models}}},
  author = {{Bing Jian} and Vemuri, B C},
  year = {2011},
  month = aug,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {33},
  number = {8},
  pages = {1633--1645},
  issn = {0162-8828},
  doi = {10.1109/TPAMI.2010.223},
  urldate = {2021-12-19}
}

@article{biskupStereoImagingSystem2007,
  title = {A Stereo Imaging System for Measuring Structural Parameters of Plant Canopies},
  author = {Biskup, Bernhard and Scharr, Hanno and Schurr, Ulrich and Rascher, Uwe},
  year = {2007},
  journal = {Plant, Cell \& Environment},
  volume = {30},
  number = {10},
  pages = {1299--1308},
  issn = {1365-3040},
  doi = {10.1111/j.1365-3040.2007.01702.x},
  urldate = {2023-01-13},
  abstract = {Plants constantly adapt their leaf orientation in response to fluctuations in the environment, to maintain radiation use efficiency in the face of varying intensity and incidence direction of sunlight. Various methods exist for measuring structural canopy parameters such as leaf angle distribution. However, direct methods tend to be labour-intensive, while indirect methods usually give statistical information on stand level rather than on individual leaves. We present an area-based, binocular stereo system composed of commercially available components that allows three-dimensional reconstruction of small- to medium-sized canopies on the level of single leaves under field conditions. Spatial orientation of single leaves is computed with automated processes using modern, well-established stereo matching and segmentation techniques, which were adapted for the properties of plant canopies, providing high spatial and temporal resolution (angle measurements with an accuracy of approx. {\textpm}5{$^\circ$} and a maximum sampling rate of three frames per second). The applicability of our approach is demonstrated in three case studies: (1) the dihedral leaflet angle of an individual soybean was tracked to monitor nocturnal and daytime leaf movement showing different frequencies and amplitudes; (2) drought stress was diagnosed in soybean by quantifying changes in the zenith leaflet angle distribution; and (3) the diurnal course of the zenith leaf angle distribution of a closed soybean canopy was measured.},
  langid = {english},
  keywords = {3D reconstruction,canopy,leaf movement,screening,stereo imaging,systems biology}
}

@article{blackburnHyperspectralRemoteSensing2007,
  title = {Hyperspectral Remote Sensing of Plant Pigments},
  author = {Blackburn, George Alan},
  year = {2007},
  month = mar,
  journal = {Journal of Experimental Botany},
  volume = {58},
  number = {4},
  pages = {855--867},
  issn = {0022-0957},
  doi = {10.1093/jxb/erl123},
  urldate = {2023-01-13},
  abstract = {The dynamics of pigment concentrations are diagnostic of a range of plant physiological properties and processes. This paper appraises the developing technologies and analytical methods for quantifying pigments non-destructively and repeatedly across a range of spatial scales using hyperspectral remote sensing. Progress in deriving predictive relationships between various characteristics and transforms of hyperspectral reflectance data are evaluated and the roles of leaf and canopy radiative transfer models are reviewed. Requirements are identified for more extensive intercomparisons of different approaches and for further work on the strategies for interpreting canopy scale data. The paper examines the prospects for extending research to the wider range of pigments in addition to chlorophyll, testing emerging methods of hyperspectral analysis and exploring the fusion of hyperspectral and LIDAR remote sensing. In spite of these opportunities for further development and the refinement of techniques, current evidence of an expanding range of applications in the ecophysiological, environmental, agricultural, and forestry sciences highlights the growing value of hyperspectral remote sensing of plant pigments.}
}

@article{bockDiseaseSeverityEstimates2015,
  title = {Disease {{Severity Estimates}}---{{Effects}} of {{Rater Accuracy}} and {{Assessment Methods}} for {{Comparing Treatments}}},
  author = {Bock, C. H. and El Jarroudi, M. and Kouadio, L. A. and Mackels, C. and Chiang, K.-S. and Delfosse, P.},
  year = {2015},
  month = aug,
  journal = {Plant Disease},
  volume = {99},
  number = {8},
  pages = {1104--1112},
  issn = {0191-2917, 1943-7692},
  doi = {10.1094/PDIS-09-14-0925-RE},
  urldate = {2023-09-19},
  abstract = {Assessment of disease severity is required for several purposes in plant pathology; most often, the estimates are made visually. It is established that visual estimates can be inaccurate and unreliable. The ramifications of biased or imprecise estimates by raters have not been fully explored using empirical data, partly because of the logistical difficulties involved in different raters assessing the same leaves for which actual disease has been measured in a replicated experiment with multiple treatments. In this study, nearest percent estimates (NPEs) of Septoria leaf blotch (SLB) on leaves of winter wheat from nontreated and fungicide-treated plots were assessed in both 2006 and 2007 by four raters and compared with assumed actual values measured using image analysis. Lin's concordance correlation (LCC, {$\rho$}               c               ) was used to assess agreement between the two approaches. NPEs were converted to Horsfall-Barratt (HB) midpoints and were compared with actual values. The estimates of SLB severity from fungicide-treated and nontreated plots were analyzed using generalized linear mixed modeling to ascertain effects of rater using both the NPE and HB values. Rater 1 showed good accuracy ({$\rho$}               c               = 0.986 to 0.999), while raters 3 and 4 were less accurate ({$\rho$}               c               = 0.205 to 0.936). Conversion to the HB scale had little effect on bias but reduced numerically both precision and accuracy for most raters on most assessment dates (precision, r = -0.001 to -0.132; and accuracy, {$\rho$}               c               = -0.003 to -0.468). Interrater reliability was also reduced slightly by conversion of estimates to HB midpoint values. Estimates of mean SLB severity were significantly different between image analysis and raters 2, 3, and 4, and there were frequently significant differences among raters (F = 151 to 1,260, P = 0.001 to P {$<$} 0.0001). Only on 26 June 2007 did conversion to the HB scale change the means separation ranking of rater estimates. Nonetheless, image analysis and all raters were able to differentiate control and treated-plot treatments (F = 116 to 1,952, P = 0.002 to P {$<$} 0.0001, depending on date and rater). Conversion of NPEs to the HB scale tended to reduce F values slightly (2006: NPEs, F = 116 to 276, P = 0.002 to 0.0005; and, for the HB-converted values, F = 101 to 270, P = 0.002 to 0.0005; 2007: NPEs, F = 164 to 1,952, P = 0.001 to P {$<$} 0.0001; and, for HB-converted values, F = 126 to 1,633, P = 0.002 to P {$<$} 0.0001). The results reaffirm the need for accurate and reliable disease assessment to minimize over- or underestimates compared with actual disease, and the data we present support the view that, where multiple raters are deployed, they should be assigned in a manner to reduce any potential effect of rater differences on the analysis.},
  langid = {english}
}

@article{bockPlantDiseaseSeverity2010,
  title = {Plant {{Disease Severity Estimated Visually}}, by {{Digital Photography}} and {{Image Analysis}}, and by {{Hyperspectral Imaging}}},
  author = {Bock, C. H. and Poole, G. H. and Parker, P. E. and Gottwald, T. R.},
  year = {2010},
  month = mar,
  journal = {Critical Reviews in Plant Sciences},
  volume = {29},
  number = {2},
  pages = {59--107},
  publisher = {Taylor \& Francis},
  issn = {0735-2689},
  doi = {10.1080/07352681003617285},
  urldate = {2023-01-13},
  abstract = {Reliable, precise and accurate estimates of disease severity are important for predicting yield loss, monitoring and forecasting epidemics, for assessing crop germplasm for disease resistance, and for understanding fundamental biological processes including co-evolution. Disease assessments that are inaccurate and/or imprecise might lead to faulty conclusions being drawn from the data, which in turn can lead to incorrect actions being taken in disease management decisions. Plant disease can be quantified in several different ways. This review considers plant disease severity assessment at the scale of individual plant parts or plants, and describes our current understanding of the sources and causes of assessment error, a better understanding of which is required before improvements can be targeted. The review also considers how these can be identified using various statistical tools. Indeed, great strides have been made in the last thirty years in identifying the sources of assessment error inherent to visual rating, and this review highlights ways that assessment errors can be reduced---particularly by training raters or using assessment aids. Lesion number in relation to area infected is known to influence accuracy and precision of visual estimates---the greater the number of lesions for a given area infected results in more overestimation. Furthermore, there is a widespread tendency to overestimate disease severity at low severities ({$<$}10\%). Both interrater and intrarater reliability can be variable, particularly if training or rating aids are not used. During the last eighty years acceptable accuracy and precision of visual disease assessments have often been achieved using disease scales, particularly because of the time they allegedly save, and the ease with which they can be learned, but recent work suggests there can be some disadvantages to their use. This review considers new technologies that offer opportunity to assess disease with greater objectivity (reliability, precision, and accuracy). One of these, visible light photography and digital image analysis has been increasingly used over the last thirty years, as software has become more sophisticated and user-friendly. Indeed, some studies have produced very accurate estimates of disease using image analysis. In contrast, hyperspectral imagery is relatively recent and has not been widely applied in plant pathology. Nonetheless, it offers interesting and potentially discerning opportunities to assess disease. As plant disease assessment becomes better understood, it is against the backdrop of concepts of reliability, precision and accuracy (and agreement) in plant pathology and measurement science. This review briefly describes these concepts in relation to plant disease assessment. Various advantages and disadvantages of the different approaches to disease assessment are described. For each assessment method some future research priorities are identified that would be of value in better understanding the theory of disease assessment, as it applies to improving and fully realizing the potential of image analysis and hyperspectral imagery.},
  keywords = {error,hyperspectral imagery,image analysis,plant disease assessment,remote sensing,variance}
}

@article{bockPlantDiseaseSeverity2022,
  title = {Plant Disease Severity Estimated Visually: A Century of Research, Best Practices, and Opportunities for Improving Methods and Practices to Maximize Accuracy},
  shorttitle = {Plant Disease Severity Estimated Visually},
  author = {Bock, Clive H. and Chiang, Kuo-Szu and Del Ponte, Emerson M.},
  year = {2022},
  month = feb,
  journal = {Tropical Plant Pathology},
  volume = {47},
  number = {1},
  pages = {25--42},
  issn = {1983-2052},
  doi = {10.1007/s40858-021-00439-z},
  urldate = {2023-01-13},
  abstract = {Plant disease quantification, mainly the intensity of disease symptoms on individual units (severity), is the basis for a plethora of research and applied purposes in plant pathology and related disciplines. These include evaluating treatment effect, monitoring epidemics, understanding yield loss, and phenotyping for host resistance. Although sensor technology has been available to measure disease severity using the visible spectrum or other spectral range imaging, it is visual sensing and perception that still dominates, especially in field research. Awareness of the importance of accuracy of visual estimates of severity began in 1892, when Cobb developed a set of diagrams as an aid to guide estimates of rust severity in wheat. Since that time, various approaches, some of them based on principles of psychophysics, have provided a foundation to understand sources of error during the estimation process as well as to develop different disease scales and disease-specific illustrations indicating the diseased area on specimens, similar to that developed by Cobb, and known as standard area diagrams (SADs). Several rater-related (experience, inherent ability, training) and technology-related (instruction, scales, and SADs) characteristics have been shown to affect accuracy. This review provides a historical perspective of visual severity assessment, accounting for concepts, tools, changing paradigms, and methods to maximize accuracy of estimates. A list of best-operating practices in plant disease quantification and future research on the topic is presented based on the current knowledge.},
  langid = {english}
}

@article{bockVisualEstimatesFully2020,
  title = {From Visual Estimates to Fully Automated Sensor-Based Measurements of Plant Disease Severity: Status and Challenges for Improving Accuracy},
  shorttitle = {From Visual Estimates to Fully Automated Sensor-Based Measurements of Plant Disease Severity},
  author = {Bock, Clive H. and Barbedo, Jayme G. A. and Del Ponte, Emerson M. and Bohnenkamp, David and Mahlein, Anne-Katrin},
  year = {2020},
  month = apr,
  journal = {Phytopathology Research},
  volume = {2},
  number = {1},
  pages = {9},
  issn = {2524-4167},
  doi = {10.1186/s42483-020-00049-8},
  urldate = {2023-09-07},
  abstract = {The severity of plant diseases, traditionally the proportion of the plant tissue exhibiting symptoms, is a key quantitative variable to know for many diseases and is prone to error. Good quality disease severity data should be accurate (close to the true value). Earliest quantification of disease severity was by visual estimates. Sensor-based image analysis including visible spectrum and hyperspectral and multispectral sensors are established technologies that promise to substitute, or complement visual ratings. Indeed, these technologies have measured disease severity accurately under controlled conditions but are yet to demonstrate their full potential for accurate measurement under field conditions. Sensor technology is advancing rapidly, and artificial intelligence may help overcome issues for automating severity measurement under hyper-variable field conditions. The adoption of appropriate scales, training, instruction and aids (standard area diagrams) has contributed to improved accuracy of visual estimates. The apogee of accuracy for visual estimation is likely being approached, and any remaining increases in accuracy are likely to be small. Due to automation and rapidity, sensor-based measurement offers potential advantages compared with visual estimates, but the latter will remain important for years to come. Mobile, automated sensor-based systems will become increasingly common in controlled conditions and, eventually, in the field for measuring plant disease severity for the purpose of research and decision making.},
  keywords = {Accuracy,Artificial intelligence,Assessment,Deep learning,Digital technologies,Disease severity,Machine learning,Mobile device,Phenotyping,Precision,Precision agriculture,Sensor},
  file = {/home/samuelebumbaca/Zotero/storage/Z7IXYKLV/s42483-020-00049-8.html}
}

@article{bogueRobotsPoisedRevolutionise2016,
  title = {Robots Poised to Revolutionise Agriculture},
  author = {Bogue, Robert},
  year = {2016},
  month = jan,
  journal = {Industrial Robot: An International Journal},
  volume = {43},
  number = {5},
  pages = {450--456},
  publisher = {Emerald Group Publishing Limited},
  issn = {0143-991X},
  doi = {10.1108/IR-05-2016-0142},
  urldate = {2023-01-13},
  abstract = {Purpose This paper aims to provide details of a number of recent and significant agricultural robot research and development activities. Design/methodology/approach Following an introduction, this first provides a brief overview of agricultural robot research. It then discusses a number of specific activities involving robots for precision weed control and fertiliser application. A selection of harvesting robots and allied technological developments is then considered and is followed by concluding comments. Findings Agricultural robots are the topic of an extensive research and development effort. Several autonomous robots aimed at precision weed control and fertiliser application have reached the pre-production stage. Equally, harvesting robots are at an advanced stage of development. Both classes exploit state-of-the-art machine vision and image processing technologies which are the topic of a major research effort. These developments will contribute to the forecasted rapid growth in the agricultural robot markets during the next decade. Originality/value Robots are expected to play a significant role in meeting the ever increasing demand for food, and this paper provides details of some recent agricultural robot research and development activities.},
  keywords = {Agriculture,Agrochemicals,Food production,Harvesting,Robots}
}

@article{bolanosFeasibilityEarlyYield2023,
  title = {Feasibility of {{Early Yield Prediction}} per {{Coffee Tree Based}} on {{Multispectral Aerial Imagery}}: {{Case}} of {{Arabica Coffee Crops}} in {{Cauca-Colombia}}},
  shorttitle = {Feasibility of {{Early Yield Prediction}} per {{Coffee Tree Based}} on {{Multispectral Aerial Imagery}}},
  author = {Bola{\~n}os, Julian and Corrales, Juan Carlos and Campo, Liseth Viviana},
  year = {2023},
  month = jan,
  journal = {Remote Sensing},
  volume = {15},
  number = {1},
  pages = {282},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2072-4292},
  doi = {10.3390/rs15010282},
  urldate = {2023-03-29},
  abstract = {Crop yield is an important factor for evaluating production processes and determining the profitability of growing coffee. Frequently, the total number of coffee beans per area unit is estimated manually by physically counting the coffee cherries, the branches, or the flowers. However, estimating yield requires an investment in time and work, so it is not usual for small producers. This paper studies a non-intrusive and attainable alternative to predicting coffee crop yield through multispectral aerial images. The proposal is designed for small low-tech producers monitored by capturing aerial photos with a MapIR camera on an unmanned aerial vehicle. This research shows how to predict yields in the early stages of the coffee tree productive cycle, such as at flowering by using aerial imagery. Physical and spectral descriptors were evaluated as predictors for yield prediction models. The results showed correlations between the selected predictors and 370 yield samples of a Colombian Arabica coffee crop. The coffee tree volume, the Normalized Difference Vegetation Index (NDVI), and the Coffee Ripeness Index (CRI) showed the highest values with 71\%, 55\%, and 63\%, respectively. Further, these predictors were used as the inputs for regression models to analyze their precision in predicting coffee crop yield. The validation stage concluded that Linear Regression and Stochastic Descending Gradient Regression were better models with determination coefficient values of 56\% and 55\%, respectively, which are promising for predicting yield.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {coffee,crop yield,image segmentation,MapIR,multispectral,predictor,UAV}
}

@article{borgognomondinoMultitemporalImageCoregistration2015,
  title = {Multi-Temporal Image Co-Registration Improvement for a Better Representation and Quantification of Risky Situations: The {{Belvedere Glacier}} Case Study},
  shorttitle = {Multi-Temporal Image Co-Registration Improvement for a Better Representation and Quantification of Risky Situations},
  author = {Borgogno Mondino, Enrico},
  year = {2015},
  month = jul,
  journal = {Geomatics, Natural Hazards and Risk},
  volume = {6},
  number = {5-7},
  pages = {362--378},
  publisher = {Taylor \& Francis},
  issn = {1947-5705},
  doi = {10.1080/19475705.2014.927804},
  urldate = {2023-01-25},
  abstract = {Scientific applications dealing with natural hazards make wide use of digital geographical data and change detection techniques. If the attention is focused on changes affecting surfaces' geometry, multi-temporal aerial photogrammetry can represent an effective tool. In this case, the degree of spatial coherence between measurements at different times is an important issue to deal with. Reliability and accuracy of measured differences strictly depend on the strategy used during image processing. In this paper, a simultaneous multi-temporal aerial image bundle adjustment approach (MTBA) is compared against two more traditional strategies for aerial stereo-pair adjustment to map surface changes of the Belvedere Glacier (Italian north-western Alps) in the period 2001--2003. Two aerial stereo pairs (of 2001 and 2003) were used to generate the correspondent digital surface models. These were then compared to map glacier shape differences and calculate ablation and accumulation volumes. Results demonstrate that the proposed MTBA approach improves and maximizes accuracy and reliability of measured differences also when available reference data are low quality ones. Final uncertainty for both direct (surface height differences) and derived (volume changes) measurements were quantified and mapped.}
}

@article{borgognomondinoPreliminaryConsiderationsCosts2017,
  title = {Preliminary Considerations about Costs and Potential Market of Remote Sensing from {{UAV}} in the {{Italian}} Viticulture Context},
  author = {Borgogno Mondino, E. and Gajetti, M.},
  year = {2017},
  month = jan,
  journal = {European Journal of Remote Sensing},
  volume = {50},
  number = {1},
  pages = {310--319},
  publisher = {Taylor \& Francis},
  issn = {null},
  doi = {10.1080/22797254.2017.1328269},
  urldate = {2023-03-25},
  abstract = {UAVs have already demonstrated to be effective in many fields. Nevertheless, at the moment, it is not still clear the type and the value of benefits they can provide for remote sensing purposes in agriculture. In particular, in the Italian context, this technique has still to demonstrate that derivable information can improve ordinary crop management. Furthermore, it is not still clear if costs are consistent with the ones of the agricultural sector and if any actual benefit can be really obtained. Some basic questions have to be answered: (a) are costs consistent with sector incomes? and (b) which is the related economic/environmental value? In this work reference values for UAV costs and productivity are proposed. A cost simulating model, based on both technical and economic considerations, and parameterized in respect of the size of the imaged area is proposed. Different UAV company paradigms are considered demonstrating that sustainable costs can be obtained only by making remote sensing skills internal to company. A brief discussion is also given, concerning (a) UAV potential market in the Italian viticulture context and (b) expected minimal composition that a company, basing its business on this type of service, should have.},
  keywords = {Precision viticulture,UAV,UAV cost analysis,UAV potential market,UAV productivity}
}

@article{bosConceptsTerminologyPlant1995,
  title = {Concepts and {{Terminology}} on {{Plant}}/{{Pest Relationships}}: {{Toward Consensus}} in {{Plant Pathology}} and {{Crop Protection}}},
  shorttitle = {Concepts and {{Terminology}} on {{Plant}}/{{Pest Relationships}}},
  author = {Bos, L and Parlevliet, J E},
  year = {1995},
  journal = {Annual Review of Phytopathology},
  volume = {33},
  number = {1},
  pages = {69--102},
  doi = {10.1146/annurev.py.33.090195.000441},
  urldate = {2023-01-13},
  abstract = {In plant pathology, terminological confusion still reigns despite national attempts at standardization. Terminological agreements reached within the crop protection community in The Netherlands are elaborated here and presented as an endeavor toward international consensus. Much of the on-going terminological disconcert derives from differences in outlook between academically oriented biologists (including biologically trained pathologists) and pathologists working in and for agricultural institutions where disease and harm have anthropocentric connotations. The name crop protection science more realistically covers and marks the field dealt with by most plant pathologists, and adoption of the FAO-defined term pest to encompass all biotic factors that are harmful to plants and their products is advocated. The effect of pests on plants and the interrelationships between pests and plants in dependence upon the environment, topical in resistance breeding, are especially dealt with. A diagrammatic model is used to better describe these relationships and to define the terms that denote the phenomena and mechanisms involved.},
  pmid = {18288897}
}

@article{bravoEarlyDiseaseDetection2003,
  title = {Early {{Disease Detection}} in {{Wheat Fields}} Using {{Spectral Reflectance}}},
  author = {Bravo, C{\'e}dric and Moshou, Dimitrios and West, Jonathan and McCartney, Alastair and Ramon, Herman},
  year = {2003},
  month = feb,
  journal = {Biosystems Engineering},
  volume = {84},
  number = {2},
  pages = {137--145},
  issn = {1537-5110},
  doi = {10.1016/S1537-5110(02)00269-6},
  urldate = {2023-01-13},
  abstract = {The difference in spectral reflectance between healthy and diseased wheat plants infected with Puccinia striiformis (yellow rust) was investigated. In-field spectral images were taken with a spectrograph mounted at spray boom height. A normalisation method based on reflectance and illumination adjustments was applied. To consider the entire canopy reflection, a spatially moving average was introduced. A classification model based on quadratic discrimination was built on a selected group of wavebands obtained by stepwise variable selection. Through this method, confusion rates dropped from 12 to 4\% error classification, based on four different wavebands. These results are very encouraging for the development of a cost-effective optical device for recognising diseases, such as yellow rust, in the field in early spring.},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/VYDZQ8SH/S1537511002002696.html}
}

@article{bruggerImpactCompatibleIncompatible2018,
  title = {Impact of Compatible and Incompatible Barley---{{Blumeria}} Graminis f.Sp. Hordei Interactions on Chlorophyll Fluorescence Parameters},
  author = {Brugger, Anna and Kuska, Matheus Thomas and Mahlein, Anne-Katrin},
  year = {2018},
  month = apr,
  journal = {Journal of Plant Diseases and Protection},
  volume = {125},
  number = {2},
  pages = {177--186},
  issn = {1861-3837},
  doi = {10.1007/s41348-017-0129-1},
  urldate = {2023-01-13},
  abstract = {Interactions between different barley genotypes and the fungal pathogen Blumeria graminis f.sp. hordei (Bgh) have a specific impact on the crop physiology. Within the context of plant resistance phenotyping, it is relevant to investigate early host--pathogen interactions to avoid the crop infestation. Analyzing different parameters of the photosynthesis apparatus gives in-depth information of the plant's health status and can be used for a spatial and temporal assessment of interaction types during plant--pathogen infestation. In the present study, experiments were performed with a near-isogenic line of barley cv. Ingrid WT (susceptible), mlo3 (papilla-based resistance) as well as a near-isogenic line of cv. Pallas, containing the Mla1 (hypersensitive response-based resistance) gene. After inoculation with Bgh isolate K1, the leaves were measured daily using chlorophyll fluorescence imaging. Inoculated, susceptible wild-type leaves showed a reduced effective quantum yield of the photosystem II ({$\Phi$}PSII) already 1 day after inoculation. In accordance with the quantum yield reduction, the non-photochemical quenching (NPQ) increased, indicating thermal dissipation of excess energy. The changes of {$\Phi$}PSII and NPQ represent modifications of the leaf metabolism to aid the fungal nutrition uptake, which is influenced by Bgh. By analyzing these parameters, it was also possible to indicate resistance reactions of mlo3 and Mla1 barley genotypes against Bgh. During papilla formation in mlo3 leaves, {$\Phi$}PSII revealed the lowest values. In contrast, inoculated Mla1 leaves showed the lowest NPQ. The present study proofs that chlorophyll fluorescence imaging is a valuable tool for investigating early plant--pathogen interaction noninvasively. Furthermore, this phytopathology study uses chlorophyll fluorescence imaging, chlorophyll extraction and microscopic observations to characterize the interaction response of different genotypes to an Bgh infection.},
  langid = {english},
  keywords = {Blumeria graminis f.sp. hordei,Chlorophyll fluorescence imaging,Hordeum vulgare,Host-pathogen interaction,Phenotyping}
}

@article{bumbacaSupportingScreeningNew2024,
  title = {Supporting {{Screening}} of {{New Plant Protection Products}} through a {{Multispectral Photogrammetric Approach Integrated}} with {{AI}}},
  author = {Bumbaca, Samuele and {Borgogno-Mondino}, Enrico},
  year = {2024},
  month = feb,
  journal = {Agronomy},
  volume = {14},
  number = {2},
  pages = {306},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2073-4395},
  doi = {10.3390/agronomy14020306},
  urldate = {2024-02-08},
  abstract = {This work was aimed at developing a prototype system based on multispectral digital photogrammetry to support tests required by international regulations for new Plant Protection Products (PPPs). In particular, the goal was to provide a system addressing the challenges of a new PPP evaluation with a higher degree of objectivity with respect to the current one, which relies on expert evaluations. The system uses Digital Photogrammetry, which is applied to multispectral acquisitions and Artificial Intelligence (AI). The goal of this paper is also to simplify the present screening process, moving it towards more objective and quantitative scores about phytotoxicity. The implementation of an opportunely trained AI model for phytotoxicity prediction aims to convert ordinary human visual observations, which are presently provided with a discrete scale (forbidding a variance analysis), into a continuous variable. The technical design addresses the need for a reduced dataset for training the AI model and relating discrete observations, as usually performed, to some proxy variables derived from the photogrammetric multispectral 3D model. To achieve this task, an appropriate photogrammetric multispectral system was designed. The system operates in multi-nadiral-view mode over a bench within a greenhouse exploiting an active system for lighting providing uniform and diffuse illumination. The whole system is intended to reduce the environmental variability of acquisitions tending to a standard situation. The methodology combines advanced image processing, image radiometric calibration, and machine learning techniques to predict the General Phytotoxicity percentage index (PHYGEN), a crucial measure of phytotoxicity. Results show that the system can generate reliable estimates of PHYGEN, compliant with existing accuracy standards (even from previous PPPs symptom severity models), using limited training datasets. The proposed solution addressing this challenge is the adoption of the Logistic Function with LASSO model regularization that has been shown to overcome the limitations of a small sample size (typical of new PPP trials). Additionally, it provides the estimate of a numerical continuous index (a percentage), which makes it possible to tackle the objectivity problem related to human visual evaluation that is presently based on an ordinal discrete scale. In our opinion, the proposed prototype system could have significant potential in improving the screening process for new PPPs. In fact, it works specifically for new PPPs screening and, despite this, it has an accuracy consistent with the one ordinarily accepted for human visual approaches. Additionally, it provides a higher degree of objectivity and repeatability.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {computer vision,diagnostic,digitalization,machine learning,plant protection product}
}

@article{burkartAngularDependencyHyperspectral2015,
  title = {Angular {{Dependency}} of {{Hyperspectral Measurements}} over {{Wheat Characterized}} by a {{Novel UAV Based Goniometer}}},
  author = {Burkart, Andreas and Aasen, Helge and Alonso, Luis and Menz, Gunter and Bareth, Georg and Rascher, Uwe},
  year = {2015},
  month = jan,
  journal = {Remote Sensing},
  volume = {7},
  number = {1},
  pages = {725--746},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2072-4292},
  doi = {10.3390/rs70100725},
  urldate = {2023-01-13},
  abstract = {In this study we present a hyperspectral flying goniometer system, based on a rotary-wing unmanned aerial vehicle (UAV) equipped with a spectrometer mounted on an active gimbal. We show that this approach may be used to collect multiangular hyperspectral data over vegetated environments. The pointing and positioning accuracy are assessed using structure from motion and vary from {$\sigma$} = 1{$^\circ$} to 8{$^\circ$} in pointing and {$\sigma$} = 0.7 to 0.8 m in positioning. We use a wheat dataset to investigate the influence of angular effects on the NDVI, TCARI and REIP vegetation indices. Angular effects caused significant variations on the indices: NDVI = 0.83--0.95; TCARI = 0.04--0.116; REIP = 729--735 nm. Our analysis highlights the necessity to consider angular effects in optical sensors when observing vegetation. We compare the measurements of the UAV goniometer to the angular modules of the SCOPE radiative transfer model. Model and measurements are in high accordance  (r2 = 0.88) in the infrared region at angles close to nadir; in contrast the comparison show discrepancies at low tilt angles (r2 = 0.25). This study demonstrates that the UAV goniometer is a promising approach for the fast and flexible assessment of angular effects.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {bidirectional reflectance distribution function (BRDF),goniometer,hyperspectral,unmanned aerial vehicle (UAV),vegetation,vegetation indices}
}

@article{caiReviewSemisupervisedClustering2023,
  title = {A Review on Semi-Supervised Clustering},
  author = {Cai, Jianghui and Hao, Jing and Yang, Haifeng and Zhao, Xujun and Yang, Yuqing},
  year = {2023},
  month = jun,
  journal = {Information Sciences},
  volume = {632},
  pages = {164--200},
  issn = {0020-0255},
  doi = {10.1016/j.ins.2023.02.088},
  urldate = {2025-01-13},
  abstract = {Semi-supervised clustering (SSC), a technique integrating semi-supervised learning and clustering analysis, incorporates the given prior information (e.g., class labels and pairwise constraints) into clustering to guide the clustering process and improve the performance. In recent years, a large number of valuable works have emerged, focusing on theoretical research and application in different fields. In this paper, a detailed review of SSC is provided from a new perspective. Firstly, all SSC studies are organized as partition-based SSC, hierarchical-based SSC, density-based SSC, graph-based SSC, neural network-based SSC, Nonnegative Matrix Factorization-based SSC and random subspace technique-based SSC. Thus, the semi-supervised researches can be in-depth discussed in each clustering idea. Secondly, the general overviews are detailed in each category respectively, including the performance, the suitable scenarios and the way to add supervising information. Thirdly, the recent successful applications of SSC are summarized according to different backgrounds such as medical, biological, business, journalism, financial and so on. Based on this, some application caveats and development trends of SSC are particularly given in the end. This comprehensive review and analysis of SSC can provide an overall outline, the scope of research topics, and a relative complete analysis of existing SSC methods for researchers.},
  keywords = {Constraints K-means,Constraints spectral clustering,NMF-based semi-supervised clustering,Random subspace-based semi-supervised clustering,Semi-supervised clustering,Semi-supervised fuzzy clustering},
  file = {/home/samuelebumbaca/Zotero/storage/2K44ETN5/S0020025523002840.html}
}

@book{caludeRainbowComputerScience2011,
  title = {Rainbow of {{Computer Science}}},
  editor = {Calude, Cristian S. and Rozenberg, Grzegorz and Salomaa, Arto},
  year = {2011},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {6570},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-19391-0},
  urldate = {2022-11-24},
  isbn = {978-3-642-19390-3 978-3-642-19391-0},
  langid = {english}
}

@misc{CameraCalibrationOpenCV,
  title = {Camera Calibration {{With OpenCV}} --- {{OpenCV}} 3.0.0-Dev Documentation},
  urldate = {2022-09-15},
  howpublished = {https://docs.opencv.org/3.0-beta/doc/tutorials/calib3d/camera\_calibration/camera\_calibration.html},
  file = {/home/samuelebumbaca/Zotero/storage/EIZA4XKP/camera_calibration.html}
}

@misc{cameraMAPIRCameraReflectance,
  title = {{{MAPIR Camera Reflectance Calibration Ground Target Package}} ({{V2}})},
  author = {CAMERA, {\relax MAPIR}},
  journal = {MAPIR CAMERA},
  urldate = {2022-09-15},
  abstract = {This package contains~4~ground targets that each have known reflectance curves. The target material~is composed of a felt-like~material mounted to a plastic substrate. It~can be~captured~from any angle with your~camera thanks to~similar total~and diffuse reflection properties. To use this target, before each flight tak},
  howpublished = {https://www.mapir.camera/products/mapir-camera-reflectance-calibration-ground-target-package-v2},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/64C9ABR3/mapir-camera-reflectance-calibration-ground-target-package-v2.html}
}

@misc{cameraMAPIRCameraReflectancea,
  title = {{{MAPIR Camera Reflectance Calibration Ground Target Package}} ({{V2}})},
  author = {CAMERA, {\relax MAPIR}},
  journal = {MAPIR CAMERA},
  urldate = {2022-09-05},
  abstract = {This package contains~4~ground targets that each have known reflectance curves. The target material~is composed of a felt-like~material mounted to a plastic substrate. It~can be~captured~from any angle with your~camera thanks to~similar total~and diffuse reflection properties. To use this target, before each flight tak},
  howpublished = {https://www.mapir.camera/products/mapir-camera-reflectance-calibration-ground-target-package-v2},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/7IPFRRIV/MAPIR_Camera_Reflectance_Calibration_Ground_Target_Package_Data_V2 (2).xlsx;/home/samuelebumbaca/Zotero/storage/GSJ4JRVQ/mapir-camera-reflectance-calibration-ground-target-package-v2.html}
}

@article{candiagoEvaluatingMultispectralImages2015,
  title = {Evaluating {{Multispectral Images}} and {{Vegetation Indices}} for {{Precision Farming Applications}} from {{UAV Images}}},
  author = {Candiago, Sebastian and Remondino, Fabio and De Giglio, Michaela and Dubbini, Marco and Gattelli, Mario},
  year = {2015},
  month = apr,
  journal = {Remote Sensing},
  volume = {7},
  number = {4},
  pages = {4026--4047},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2072-4292},
  doi = {10.3390/rs70404026},
  urldate = {2023-01-13},
  abstract = {Unmanned Aerial Vehicles (UAV)-based remote sensing offers great possibilities to acquire in a fast and easy way field data for precision agriculture applications. This field of study is rapidly increasing due to the benefits and advantages for farm resources management, particularly for studying crop health. This paper reports some experiences related to the analysis of cultivations (vineyards and tomatoes) with Tetracam multispectral data. The Tetracam camera was mounted on a multi-rotor hexacopter. The multispectral data were processed with a photogrammetric pipeline to create triband orthoimages of the surveyed sites. Those orthoimages were employed to extract some Vegetation Indices (VI) such as the Normalized Difference Vegetation Index (NDVI), the Green Normalized Difference Vegetation Index (GNDVI), and the Soil Adjusted Vegetation Index (SAVI), examining the vegetation vigor for each crop. The paper demonstrates the great potential of high-resolution UAV data and photogrammetric techniques applied in the agriculture framework to collect multispectral images and evaluate different VI, suggesting that these instruments represent a fast, reliable, and  cost-effective resource in crop assessment for precision farming applications.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {agriculture,crops,multispectral,photogrammetry,unmanned aerial vehicles,vegetation,vegetation indices}
}

@article{carellaIntegratedTentativeRemotesensing2022,
  title = {An Integrated, Tentative Remote-Sensing Approach Based on {{NDVI}} Entropy to Model Canine Distemper Virus in Wildlife and to Prompt Science-Based Management Policies},
  author = {Carella, Emanuele and Orusa, Tommaso and Viani, Annalisa and Meloni, Daniela and {Borgogno-Mondino}, Enrico and Orusa, Riccardo},
  year = {2022},
  journal = {Animals},
  volume = {12},
  number = {8},
  pages = {1049}
}

@article{carterLeafOpticalProperties2001,
  title = {Leaf Optical Properties in Higher Plants: Linking Spectral Characteristics to Stress and Chlorophyll Concentration},
  shorttitle = {Leaf Optical Properties in Higher Plants},
  author = {Carter, Gregory A. and Knapp, Alan K.},
  year = {2001},
  journal = {American Journal of Botany},
  volume = {88},
  number = {4},
  pages = {677--684},
  issn = {1537-2197},
  doi = {10.2307/2657068},
  urldate = {2023-12-17},
  abstract = {A number of studies have linked responses in leaf spectral reflectance, transmittance, or absorptance to physiological stress. A variety of stressors including dehydration, flooding, freezing, ozone, herbicides, competition, disease, insects, and deficiencies in ectomycorrhizal development and N fertilization have been imposed on species ranging from grasses to conifers and deciduous trees. In all cases, the maximum difference in reflectance within the 400--850 nm wavelength range between control and stressed states occurred as a reflectance increase at wavelengths near 700 nm. In studies that included transmittance and absorptance as well as reflectance, maximum differences occurred as increases and decreases, respectively, near 700 nm. This common optical response to stress could be simulated closely by varying the chlorophyll concentration of model leaves (fiberglass filter pads) and by the natural variability in leaf chlorophyll concentrations in senescent leaves of five species. The optical response to stress near 700 nm, as well as corresponding changes in reflectance that occur in the green--yellow spectrum, can be explained by the general tendency of stress to reduce leaf chlorophyll concentration.},
  copyright = {{\copyright} 2001 Botanical Society of America},
  langid = {english},
  keywords = {absorptance,chlorophyll,leaf optics,light,reflectance,stress,transmittance},
  file = {/home/samuelebumbaca/Zotero/storage/24S6D35Q/2657068.html}
}

@article{carterLeafOpticalProperties2001a,
  title = {Leaf Optical Properties in Higher Plants: Linking Spectral Characteristics to Stress and Chlorophyll Concentration},
  shorttitle = {Leaf Optical Properties in Higher Plants},
  author = {Carter, Gregory A. and Knapp, Alan K.},
  year = {2001},
  journal = {American Journal of Botany},
  volume = {88},
  number = {4},
  pages = {677--684},
  issn = {1537-2197},
  doi = {10.2307/2657068},
  urldate = {2023-01-13},
  abstract = {A number of studies have linked responses in leaf spectral reflectance, transmittance, or absorptance to physiological stress. A variety of stressors including dehydration, flooding, freezing, ozone, herbicides, competition, disease, insects, and deficiencies in ectomycorrhizal development and N fertilization have been imposed on species ranging from grasses to conifers and deciduous trees. In all cases, the maximum difference in reflectance within the 400--850 nm wavelength range between control and stressed states occurred as a reflectance increase at wavelengths near 700 nm. In studies that included transmittance and absorptance as well as reflectance, maximum differences occurred as increases and decreases, respectively, near 700 nm. This common optical response to stress could be simulated closely by varying the chlorophyll concentration of model leaves (fiberglass filter pads) and by the natural variability in leaf chlorophyll concentrations in senescent leaves of five species. The optical response to stress near 700 nm, as well as corresponding changes in reflectance that occur in the green--yellow spectrum, can be explained by the general tendency of stress to reduce leaf chlorophyll concentration.},
  copyright = {{\copyright} 2001 Botanical Society of America},
  langid = {english},
  keywords = {absorptance,chlorophyll,leaf optics,light,reflectance,stress,transmittance}
}

@article{carterResponsesLeafSpectral1993,
  title = {Responses of {{Leaf Spectral Reflectance}} to {{Plant Stress}}},
  author = {Carter, Gregory A.},
  year = {1993},
  journal = {American Journal of Botany},
  volume = {80},
  number = {3},
  pages = {239--243},
  issn = {1537-2197},
  doi = {10.1002/j.1537-2197.1993.tb13796.x},
  urldate = {2023-03-24},
  abstract = {Leaf spectral reflectances were measured to determine whether leaf reflectance responses to plant stress may differ according to the agent of stress and species. As a result of decreased absorption by pigments, reflectance at visible wavelengths increased consistently in stressed leaves for eight stress agents and among six vascular plant species. Visible reflectance was most sensitive to stress in the 535--640-nm and 685--700-nm wavelength ranges. A sensitivity minimum occurred consistently near 670 nm. Infrared reflectance was comparatively unresponsive to stress, but increased at 1,400--2,500 nm with severe leaf dehydration and the accompanying decreased absorption by water. Thus, visible rather than infrared reflectance was the most reliable indicator of plant stress. Visible reflectance responses to stress were spectrally similar among agents of stress and species.},
  copyright = {{\copyright} 1993 Botanical Society of America},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/2LDWY6TA/j.1537-2197.1993.tb13796.html}
}

@article{castillo-martinezColorIndexBased2020,
  title = {Color Index Based Thresholding Method for Background and Foreground Segmentation of Plant Images},
  author = {{Castillo-Mart{\'i}nez}, Miguel {\'A}. and {Gallegos-Funes}, Francisco J. and {Carvajal-G{\'a}mez}, Blanca E. and {Urriolagoitia-Sosa}, Guillermo and {Rosales-Silva}, Alberto J.},
  year = {2020},
  month = nov,
  journal = {Computers and Electronics in Agriculture},
  volume = {178},
  pages = {105783},
  issn = {0168-1699},
  doi = {10.1016/j.compag.2020.105783},
  urldate = {2022-12-05},
  abstract = {In this paper, the color index based thresholding method for background and foreground segmentation of plant images is presented. The proposed method is implemented with color index approach, for this purpose two color indexes are modified to provide better information about the green color of the plants. Two fixed threshold methods are proposed for the color indexes to discriminate between foreground (green plant) and background (soil). Three versions of the proposed method are presented, these are applied in plant images with controlled conditions and crop images with real environmental conditions. Experimental results demonstrate that the proposed method outperforms other algorithms used as comparative in plant images obtaining a segmentation error of 6.62~{\textpm}~5.85\% and a classification ratio of 1.93~{\textpm}~0.05. Also, the proposed method provides better segmentation results in comparison with other well-known state-of-art algorithms in different crop images. Finally, the proposed method does not require of complex calculus and their implementations are straightforward on any device.},
  langid = {english},
  keywords = {Color index,Green plants,Segmentation,Threshold method},
  file = {/home/samuelebumbaca/Zotero/storage/J8XIGRJ9/S0168169919306398.html}
}

@misc{chadebecDataAugmentationHigh2022,
  title = {Data Augmentation in High Dimensional Low Sample Size Setting Using a Geometry-Based Variational Autoencoder},
  author = {Chadebec, Cl{\'e}ment and {Thibeau-Sutre}, Elina and Burgos, Ninon and Allassonni{\`e}re, St{\'e}phanie},
  year = {2022},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  urldate = {2025-01-05},
  abstract = {Data Augmentation with Variational Autoencoders (TPAMI)},
  copyright = {Apache-2.0}
}

@inproceedings{chadebecDataAugmentationVariational2021,
  title = {Data {{Augmentation}} with {{Variational Autoencoders}} and {{Manifold Sampling}}},
  booktitle = {Deep {{Generative Models}}, and {{Data Augmentation}}, {{Labelling}}, and {{Imperfections}}},
  author = {Chadebec, Cl{\'e}ment and Allassonni{\`e}re, St{\'e}phanie},
  editor = {Engelhardt, Sandy and Oksuz, Ilkay and Zhu, Dajiang and Yuan, Yixuan and Mukhopadhyay, Anirban and Heller, Nicholas and Huang, Sharon Xiaolei and Nguyen, Hien and Sznitman, Raphael and Xue, Yuan},
  year = {2021},
  pages = {184--192},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-88210-5_17},
  abstract = {We propose a new efficient way to sample from a Variational Autoencoder in the challenging low sample size setting (A code is available at https://github.com/clementchadebec/Data\_Augmentation\_with\_VAE-DALI). This method reveals particularly well suited to perform data augmentation in such a low data regime and is validated across various standard and real-life data sets. In particular, this scheme allows to greatly improve classification results on the OASIS database where balanced accuracy jumps from 80.7\% for a classifier trained with the raw data to 88.6\% when trained only with the synthetic data generated by our method. Such results were also observed on 3 standard data sets and with other classifiers.},
  isbn = {978-3-030-88210-5},
  langid = {english},
  keywords = {Data augmentation,Latent space modelling,VAE}
}

@article{chaerleImagingTechniquesEarly2000,
  title = {Imaging Techniques and the Early Detection of Plant Stress},
  author = {Chaerle, Laury and Straeten, Dominique Van Der},
  year = {2000},
  month = nov,
  journal = {Trends in Plant Science},
  volume = {5},
  number = {11},
  pages = {495--501},
  publisher = {Elsevier},
  issn = {1360-1385},
  doi = {10.1016/S1360-1385(00)01781-7},
  urldate = {2023-01-13},
  langid = {english},
  pmid = {11077259}
}

@article{chaudhurySkeletonizationPlantPoint2020,
  title = {Skeletonization of {{Plant Point Cloud Data Using Stochastic Optimization Framework}}},
  author = {Chaudhury, Ayan and Godin, Christophe},
  year = {2020},
  month = jun,
  journal = {Frontiers in Plant Science},
  volume = {11},
  pages = {773},
  issn = {1664-462X},
  doi = {10.3389/fpls.2020.00773},
  urldate = {2021-12-18}
}

@article{chebroluRegistrationSpatiotemporalPoint2021,
  title = {Registration of Spatio-Temporal Point Clouds of Plants for Phenotyping},
  author = {Chebrolu, Nived and Magistri, Federico and L{\"a}be, Thomas and Stachniss, Cyrill},
  editor = {Agudo, Antonio},
  year = {2021},
  month = feb,
  journal = {PLOS ONE},
  volume = {16},
  number = {2},
  pages = {e0247243},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0247243},
  urldate = {2021-12-18},
  abstract = {Plant phenotyping is a central task in crop science and plant breeding. It involves measuring plant traits to describe the anatomy and physiology of plants and is used for deriving traits and evaluating plant performance. Traditional methods for phenotyping are often time-consuming operations involving substantial manual labor. The availability of 3D sensor data of plants obtained from laser scanners or modern depth cameras offers the potential to automate several of these phenotyping tasks. This automation can scale up the phenotyping measurements and evaluations that have to be performed to a larger number of plant samples and at a finer spatial and temporal resolution. In this paper, we investigate the problem of registering 3D point clouds of the plants over time and space. This means that we determine correspondences between point clouds of plants taken at different points in time and register them using a new, non-rigid registration approach. This approach has the potential to form the backbone for phenotyping applications aimed at tracking the traits of plants over time. The registration task involves finding data associations between measurements taken at different times while the plants grow and change their appearance, allowing 3D models taken at different points in time to be compared with each other. Registering plants over time is challenging due to its anisotropic growth, changing topology, and non-rigid motion in between the time of the measurements. Thus, we propose a novel approach that first extracts a compact representation of the plant in the form of a skeleton that encodes both topology and semantic information, and then use this skeletal structure to determine correspondences over time and drive the registration process. Through this approach, we can tackle the data association problem for the time-series point cloud data of plants effectively. We tested our approach on different datasets acquired over time and successfully registered the 3D plant point clouds recorded with a laser scanner. We demonstrate that our method allows for developing systems for automated temporal plant-trait analysis by tracking plant traits at an organ level.},
  langid = {english}
}

@article{cheneUseDepthCamera2012,
  title = {On the Use of Depth Camera for {{3D}} Phenotyping of Entire Plants},
  author = {Ch{\'e}n{\'e}, Yann and Rousseau, David and Lucidarme, Philippe and Bertheloot, Jessica and Caffier, Val{\'e}rie and Morel, Philippe and Belin, {\'E}tienne and {Chapeau-Blondeau}, Fran{\c c}ois},
  year = {2012},
  month = mar,
  journal = {Computers and Electronics in Agriculture},
  volume = {82},
  pages = {122--127},
  issn = {01681699},
  doi = {10.1016/j.compag.2011.12.007},
  urldate = {2023-03-24},
  abstract = {In this article, we assess the potential of depth imaging systems for 3D measurements in the context of plant phenotyping. We propose an original algorithm to segment depth images of plant from a single topview. Various applications of biological interest involving for illustration rosebush, yucca and apple tree are then presented to demonstrate the practical interest of such imaging systems. In addition, the depth camera used here is very low cost and low weight. The present results therefore open interesting perspectives in the direction of high-throughput phenotyping in controlled environment or in field conditions. {\'O} 2012 Elsevier B.V. All rights reserved.},
  langid = {english}
}

@misc{chenGridMaskDataAugmentation2024,
  title = {{{GridMask Data Augmentation}}},
  author = {Chen, Pengguang and Liu, Shu and Zhao, Hengshuang and Wang, Xingquan and Jia, Jiaya},
  year = {2024},
  month = feb,
  number = {arXiv:2001.04086},
  eprint = {2001.04086},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2001.04086},
  urldate = {2025-01-07},
  abstract = {We propose a novel data augmentation method `GridMask' in this paper. It utilizes information removal to achieve state-of-the-art results in a variety of computer vision tasks. We analyze the requirement of information dropping. Then we show limitation of existing information dropping algorithms and propose our structured method, which is simple and yet very effective. It is based on the deletion of regions of the input image. Our extensive experiments show that our method outperforms the latest AutoAugment, which is way more computationally expensive due to the use of reinforcement learning to find the best policies. On the ImageNet dataset for recognition, COCO2017 object detection, and on Cityscapes dataset for semantic segmentation, our method all notably improves performance over baselines. The extensive experiments manifest the effectiveness and generality of the new method.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/samuelebumbaca/Zotero/storage/HR8TXRAZ/2001.html}
}

@article{chiangEffectsRaterBias2016,
  title = {Effects of Rater Bias and Assessment Method on Disease Severity Estimation with Regard to Hypothesis Testing},
  author = {Chiang, K. S. and Bock, C. H. and El Jarroudi, M. and Delfosse, P. and Lee, I. H. and Liu, H. I.},
  year = {2016},
  journal = {Plant Pathology},
  volume = {65},
  number = {4},
  pages = {523--535},
  issn = {1365-3059},
  doi = {10.1111/ppa.12435},
  urldate = {2023-09-12},
  abstract = {The effects of bias (over- and underestimates) in estimates of disease severity on hypothesis testing using different assessment methods was explored. Nearest percentage estimates (NPE), the Horsfall--Barratt (H-B) scale, and two linear category scales (10\% increments, with and without additional grades at low severity) were compared using simulation modelling to assess effects of bias. Type I and type II error rates were used to compare two treatment differences. The power of the H-B scale and the 10\% scale were least for correctly testing a hypothesis compared with the other methods, and the effects of rater bias on type II errors were greater over specific severity ranges. Apart from NPEs, the amended 10\% category scale was most often superior to other methods at all severities tested for reducing the risk of type II errors. It should thus be a preferred method for raters who must use a category scale for disease assessments. Rater bias and assessment method had little effect on type I error rates. The power of the hypothesis test using unbiased estimates was most often greater compared with biased estimates, regardless of assessment method. An unanticipated observation was the greater impact of rater bias compared with assessment method on type II errors. Knowledge of the effects of rater bias and scale type on hypothesis testing can be used to improve accuracy and reliability of disease severity estimates, and can provide a logical framework for improving aids to estimate severity visually, including standard area diagrams and rater training software.},
  copyright = {{\copyright} 2015 British Society for Plant Pathology},
  langid = {english},
  keywords = {phytopathometry,plant disease quantification,rating scales},
  file = {/home/samuelebumbaca/Zotero/storage/M756UVLC/ppa.html}
}

@article{chiangUnderstandingRamificationsQuantitative2022,
  title = {Understanding the Ramifications of Quantitative Ordinal Scales on Accuracy of Estimates of Disease Severity and Data Analysis in Plant Pathology},
  author = {Chiang, Kuo-Szu and Bock, Clive H.},
  year = {2022},
  month = feb,
  journal = {Tropical Plant Pathology},
  volume = {47},
  number = {1},
  pages = {58--73},
  issn = {1983-2052},
  doi = {10.1007/s40858-021-00446-0},
  urldate = {2023-09-12},
  abstract = {The severity of plant diseases, traditionally defined as the proportion of the plant tissue exhibiting symptoms, is a key quantitative variable to know for many diseases but is prone to error. Plant pathologists face many situations in which the measurement by nearest percent estimates (NPEs) of disease severity is time-consuming or impractical. Moreover, rater NPEs of disease severity are notoriously variable. Therefore, NPEs of disease may be of questionable value if severity cannot be determined accurately and reliably. In such situations, researchers have often used a quantitative ordinal scale of measurement---often alleging the time saved, and the ease with which the scale can be learned. Because quantitative ordinal disease scales lack the resolution of the 0 to 100\% scale, they are inherently less accurate. We contend that scale design and structure have ramifications for the resulting analysis of data from the ordinal scale data. To minimize inaccuracy and ensure that there is equivalent statistical power when using quantitative ordinal scale data, design of the scales can be optimized for use in the discipline of plant pathology. In this review, we focus on the nature of quantitative ordinal scales used in plant disease assessment. Subsequently, their application and effects will be discussed. Finally, we will review how to optimize quantitative ordinal scales design to allow sufficient accuracy of estimation while maximizing power for hypothesis testing.},
  langid = {english},
  keywords = {Calculation of the interval range,Nearest percent estimates,Plant disease assessment,Scale design}
}

@article{CHLOROPHYLLMETERSPAD502Plus,
  title = {{{CHLOROPHYLL METER SPAD-502Plus}}},
  pages = {4},
  langid = {english}
}

@article{choiIterativeKClosestPoint2020,
  title = {Iterative {{K-Closest Point Algorithms}} for {{Colored Point Cloud Registration}}},
  author = {Choi, Ouk and Park, Min-Gyu and Hwang, Youngbae},
  year = {2020},
  month = sep,
  journal = {Sensors},
  volume = {20},
  number = {18},
  pages = {5331},
  issn = {1424-8220},
  doi = {10.3390/s20185331},
  urldate = {2021-12-19},
  abstract = {We present two algorithms for aligning two colored point clouds. The two algorithms are designed to minimize a probabilistic cost based on the color-supported soft matching of points in a point cloud to their K-closest points in the other point cloud. The first algorithm, like prior iterative closest point algorithms, refines the pose parameters to minimize the cost. Assuming that the point clouds are obtained from RGB-depth images, our second algorithm regards the measured depth values as variables and minimizes the cost to obtain refined depth values. Experiments with our synthetic dataset show that our pose refinement algorithm gives better results compared to the existing algorithms. Our depth refinement algorithm is shown to achieve more accurate alignments from the outputs of the pose refinement step. Our algorithms are applied to a real-world dataset, providing accurate and visually improved results.},
  langid = {english}
}

@article{chuHyperspectralImagingShallow2022,
  title = {Hyperspectral Imaging with Shallow Convolutional Neural Networks ({{SCNN}}) Predicts the Early Herbicide Stress in Wheat Cultivars},
  author = {Chu, Hangjian and Zhang, Chu and Wang, Mengcen and Gouda, Mostafa and Wei, Xinhua and He, Yong and Liu, Yufei},
  year = {2022},
  month = jan,
  journal = {Journal of Hazardous Materials},
  volume = {421},
  pages = {126706},
  issn = {0304-3894},
  doi = {10.1016/j.jhazmat.2021.126706},
  urldate = {2023-12-17},
  abstract = {The toxicity impacts of herbicides on crop, animals, and human are big problems global wide. The rapid and non-invasive ways for assessing herbicide-responsible effects on crop growth regarding types and levels still remain unexplored. In this study, visible/near infrared hyperspectral imaging (Vis/NIR HSI) coupled with SCNN was used to reveal the different characteristics in the spectral reflectance of 2 varieties of wheat seedling leaves that were subjected to 4 stress levels of 3 herbicide types during 4 stress durations and make early herbicide stress prediction. The first-order derivative results showed the spectral reflectance exhibited obvious differences at 518--531~nm, 637--675~nm and the red-edge. A SCNN model with attention mechanism (SCNN-ATT) was proposed for herbicide type and level classification of different stress durations. Further, a SCNN-based feature selection model (SCNN-FS) was proposed to screen out the characteristic wavelengths. The proposed methods achieved 96\% accuracy of herbicide type classification and around 80\% accuracy of stress level classification for both wheat varieties after 48~h. Overall, this study illustrated the potential of using Vis/NIR HSI to rapidly distinguish different herbicide types and serial levels in wheat at an early stage, which held great value for developing on-line herbicide stress recognizing methods in the field.},
  keywords = {Crops,Deep learning,Herbicide toxicity,Hyperspectral technology,Prediction model},
  file = {/home/samuelebumbaca/Zotero/storage/XJTU4CZJ/S030438942101671X.html}
}

@misc{ClarkeAdvancesGeographic,
  title = {Clarke: {{Advances}} in Geographic Information Systems - {{Google Scholar}}},
  urldate = {2023-01-13},
  howpublished = {https://scholar.google.com/scholar\_lookup?hl=en\&volume=10\&publication\_year=1986\&pages=175-84\&journal=\%00null\%00\&issue=3\%E2\%80\%934\&issn=\%00null\%00\&author=KC+Clarke\&title=Advances+in+geographic+information+systems\&pmid=\%00empty\%00\&doi=\%00empty\%00}
}

@article{curranRemoteSensingFoliar1989,
  title = {Remote Sensing of Foliar Chemistry},
  author = {Curran, Paul J},
  year = {1989},
  month = dec,
  journal = {Remote Sensing of Environment},
  volume = {30},
  number = {3},
  pages = {271--278},
  issn = {0034-4257},
  doi = {10.1016/0034-4257(89)90069-2},
  urldate = {2023-01-13},
  abstract = {Remotely sensed data are being used to estimate foliar chemical content as a result of our need for the information and our increasing ability to understand and measure foliar spectra. This paper reviews how stepwise multiple regression and deconvolution have been used to extract chemical information from foliar spectra, and concludes that both methods are useful, but neither is ideal. It is recommended that the focus of research be modeling in the long term and experimentation in the short term. Long-term research should increase our understanding of the interaction between radiation and foliar chemistry so that the focus of research can move from leaf model to canopy model to field experiment. Short-term research should aim to design experiments in which remotely sensed data are used to generate unambiguous and accurate estimates of foliar chemical content.},
  langid = {english}
}

@article{daleyTopographyPhotosyntheticActivity1989,
  title = {Topography of {{Photosynthetic Activity}} of {{Leaves Obtained}} from {{Video Images}} of {{Chlorophyll Fluorescence}} 1},
  author = {Daley, Paul F. and Raschke, Klaus and Ball, J. Timothy and Berry, Joseph A.},
  year = {1989},
  month = aug,
  journal = {Plant Physiology},
  volume = {90},
  number = {4},
  pages = {1233--1238},
  issn = {0032-0889},
  doi = {10.1104/pp.90.4.1233},
  urldate = {2022-01-13},
  abstract = {The distribution of photosynthetic activity over the area of a leaf and its change with time was determined (at low partial pressure of O2) by recording images of chlorophyll fluorescence during saturating light flashes. Simultaneously, the gas exchange was being measured. Reductions of local fluorescence intensity quantitatively displayed the extent of nonphotochemical quenching; quench coefficients, q ~N, were computed pixel by pixel. Because rates of photosynthetic electron transport are positively correlated with (1 - q ~N), computed images of (1 - q ~N) represented topographies of photosynthetic activity. Following application of abscisic acid to the heterobaric leaves of Xanthium strumarium L., clearly delineated regions varying in nonphotochemical quenching appeared that coincided with areoles formed by minor veins and indicated stomatal closure in groups.}
}

@article{darkoPhotosynthesisArtificialLight2014,
  title = {Photosynthesis under Artificial Light: The Shift in Primary and Secondary Metabolism},
  shorttitle = {Photosynthesis under Artificial Light},
  author = {Darko, Eva and Heydarizadeh, Parisa and Schoefs, Beno{\^i}t and Sabzalian, Mohammad R.},
  year = {2014},
  month = apr,
  journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  volume = {369},
  number = {1640},
  pages = {20130243},
  issn = {0962-8436, 1471-2970},
  doi = {10.1098/rstb.2013.0243},
  urldate = {2021-12-18},
  abstract = {Providing an adequate quantity and quality of food for the escalating human population under changing climatic conditions is currently a great challenge. In outdoor cultures, sunlight provides energy (through photosynthesis) for photosynthetic organisms. They also use light quality to sense and respond to their environment. To increase the production capacity, controlled growing systems using artificial lighting have been taken into consideration. Recent development of light-emitting diode (LED) technologies presents an enormous potential for improving plant growth and making systems more sustainable. This review uses selected examples to show how LED can mimic natural light to ensure the growth and development of photosynthetic organisms, and how changes in intensity and wavelength can manipulate the plant metabolism with the aim to produce functionalized foods.},
  langid = {english}
}

@article{deeryProximalRemoteSensing2014,
  title = {Proximal {{Remote Sensing Buggies}} and {{Potential Applications}} for {{Field-Based Phenotyping}}},
  author = {Deery, David and {Jimenez-Berni}, Jose and Jones, Hamlyn and Sirault, Xavier and Furbank, Robert},
  year = {2014},
  month = sep,
  journal = {Agronomy},
  volume = {4},
  number = {3},
  pages = {349--379},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2073-4395},
  doi = {10.3390/agronomy4030349},
  urldate = {2023-01-13},
  abstract = {The achievements made in genomic technology in recent decades are yet to be matched by fast and accurate crop phenotyping methods. Such crop phenotyping methods are required for crop improvement efforts to meet expected demand for food and fibre in the future. This review evaluates the role of proximal remote sensing buggies for field-based phenotyping with a particular focus on the application of currently available sensor technology for large-scale field phenotyping. To illustrate the potential for the development of high throughput phenotyping techniques, a case study is presented with sample data sets obtained from a ground-based proximal remote sensing buggy mounted with the following sensors: LiDAR, RGB camera, thermal infra-red camera and imaging spectroradiometer. The development of such techniques for routine deployment in commercial-scale breeding and pre-breeding operations will require a multidisciplinary approach to leverage the recent technological advances realised in computer science, image analysis, proximal remote sensing and robotics.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {chlorophyll fluorescence,data processing,field experiments,hyperspectral,image analysis,LiDAR,RGB camera,thermal imaging,time of flight,wheat}
}

@article{deeryProximalRemoteSensing2014a,
  title = {Proximal {{Remote Sensing Buggies}} and {{Potential Applications}} for {{Field-Based Phenotyping}}},
  author = {Deery, David and {Jimenez-Berni}, Jose and Jones, Hamlyn and Sirault, Xavier and Furbank, Robert},
  year = {2014},
  month = sep,
  journal = {Agronomy},
  volume = {4},
  number = {3},
  pages = {349--379},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2073-4395},
  doi = {10.3390/agronomy4030349},
  urldate = {2023-01-13},
  abstract = {The achievements made in genomic technology in recent decades are yet to be matched by fast and accurate crop phenotyping methods. Such crop phenotyping methods are required for crop improvement efforts to meet expected demand for food and fibre in the future. This review evaluates the role of proximal remote sensing buggies for field-based phenotyping with a particular focus on the application of currently available sensor technology for large-scale field phenotyping. To illustrate the potential for the development of high throughput phenotyping techniques, a case study is presented with sample data sets obtained from a ground-based proximal remote sensing buggy mounted with the following sensors: LiDAR, RGB camera, thermal infra-red camera and imaging spectroradiometer. The development of such techniques for routine deployment in commercial-scale breeding and pre-breeding operations will require a multidisciplinary approach to leverage the recent technological advances realised in computer science, image analysis, proximal remote sensing and robotics.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {chlorophyll fluorescence,data processing,field experiments,hyperspectral,image analysis,LiDAR,RGB camera,thermal imaging,time of flight,wheat}
}

@article{deliaTreestructuredMarkovRandom2003,
  title = {A Tree-Structured {{Markov}} Random Field Model for Bayesian Image Segmentation},
  author = {D'Elia, C. and Poggi, G. and Scarpa, G.},
  year = {2003},
  month = oct,
  journal = {IEEE Transactions on Image Processing},
  volume = {12},
  number = {10},
  pages = {1259--1273},
  issn = {1057-7149},
  doi = {10.1109/TIP.2003.817257},
  urldate = {2021-12-19},
  langid = {english}
}

@article{delponteStandardAreaDiagrams2017,
  title = {Standard {{Area Diagrams}} for {{Aiding Severity Estimation}}: {{Scientometrics}}, {{Pathosystems}}, and {{Methodological Trends}} in the {{Last}} 25 {{Years}}},
  shorttitle = {Standard {{Area Diagrams}} for {{Aiding Severity Estimation}}},
  author = {Del Ponte, Emerson M. and Pethybridge, Sarah J. and Bock, Clive H. and Michereff, Sami J. and Machado, Franklin J. and Spolti, Pi{\'e}rri},
  year = {2017},
  month = oct,
  journal = {Phytopathology{\textregistered}},
  volume = {107},
  number = {10},
  pages = {1161--1174},
  publisher = {Scientific Societies},
  issn = {0031-949X},
  doi = {10.1094/PHYTO-02-17-0069-FI},
  urldate = {2023-09-01},
  abstract = {Standard area diagrams (SAD) have long been used as a tool to aid the estimation of plant disease severity, an essential variable in phytopathometry. Formal validation of SAD was not considered prior to the early 1990s, when considerable effort began to be invested developing SAD and assessing their value for improving accuracy of estimates of disease severity in many pathosystems. Peer-reviewed literature post-1990 was identified, selected, and cataloged in bibliographic software for further scrutiny and extraction of scientometric, pathosystem-related, and methodological-related data. In total, 105 studies (127 SAD) were found and authored by 327 researchers from 10 countries, mainly from Brazil. The six most prolific authors published at least seven studies. The scientific impact of a SAD article, based on annual citations after publication year, was affected by disease significance, the journal's impact factor, and methodological innovation. The reviewed SAD encompassed 48 crops and 103 unique diseases across a range of plant organs. Severity was quantified largely by image analysis software such as QUANT, APS-Assess, or a LI-COR leaf area meter. The most typical SAD comprised five to eight black-and-white drawings of leaf diagrams, with severity increasing nonlinearly. However, there was a trend toward using true-color photographs or stylized representations in a range of color combinations and more linear (equally spaced) increments of severity. A two-step SAD validation approach was used in 78 of 105 studies for which linear regression was the preferred method but a trend toward using Lin's correlation concordance analysis and hypothesis tests to detect the effect of SAD on accuracy was apparent. Reliability measures, when obtained, mainly considered variation among rather than within raters. The implications of the findings and knowledge gaps are discussed. A list of best practices for designing and implementing SAD and a website called SADBank for hosting SAD research data are proposed.}
}

@article{demarinisSupportingProPoorReforms2021,
  title = {Supporting {{Pro-Poor Reforms}} of {{Agricultural Systems}} in {{Eastern DRC}} ({{Africa}}) with {{Remotely Sensed Data}}: {{A Possible Contribution}} of {{Spatial Entropy}} to {{Interpret Land Management Practices}}},
  author = {De Marinis, Pietro and De Petris, Samuele and Sarvia, Filippo and Manfron, Giacinto and Momo, Evelyn Joan and Orusa, Tommaso and Corvino, Gianmarco and Sali, Guido and Borgogno, Enrico Mondino},
  year = {2021},
  journal = {Land},
  volume = {10},
  number = {12},
  pages = {1368}
}

@misc{dengAnomalyDetectionReverse2022,
  title = {Anomaly {{Detection}} via {{Reverse Distillation}} from {{One-Class Embedding}}},
  author = {Deng, Hanqiu and Li, Xingyu},
  year = {2022},
  month = mar,
  number = {arXiv:2201.10703},
  eprint = {2201.10703},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2201.10703},
  urldate = {2025-01-05},
  abstract = {Knowledge distillation (KD) achieves promising results on the challenging problem of unsupervised anomaly detection (AD).The representation discrepancy of anomalies in the teacher-student (T-S) model provides essential evidence for AD. However, using similar or identical architectures to build the teacher and student models in previous studies hinders the diversity of anomalous representations. To tackle this problem, we propose a novel T-S model consisting of a teacher encoder and a student decoder and introduce a simple yet effective "reverse distillation" paradigm accordingly. Instead of receiving raw images directly, the student network takes teacher model's one-class embedding as input and targets to restore the teacher's multiscale representations. Inherently, knowledge distillation in this study starts from abstract, high-level presentations to low-level features. In addition, we introduce a trainable one-class bottleneck embedding (OCBE) module in our T-S model. The obtained compact embedding effectively preserves essential information on normal patterns, but abandons anomaly perturbations. Extensive experimentation on AD and one-class novelty detection benchmarks shows that our method surpasses SOTA performance, demonstrating our proposed approach's effectiveness and generalizability.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/samuelebumbaca/Zotero/storage/AU7YRNTV/2201.html}
}

@article{depetrisRPASbasedPhotogrammetrySupport2020,
  title = {{{RPAS-based}} Photogrammetry to Support Tree Stability Assessment: {{Longing}} for Precision Arboriculture},
  shorttitle = {{{RPAS-based}} Photogrammetry to Support Tree Stability Assessment},
  author = {De Petris, Samuele and Sarvia, Filippo and {Borgogno-Mondino}, Enrico},
  year = {2020},
  month = nov,
  journal = {Urban Forestry \& Urban Greening},
  volume = {55},
  pages = {126862},
  issn = {1618-8667},
  doi = {10.1016/j.ufug.2020.126862},
  urldate = {2023-01-25},
  abstract = {Tree stability evaluation is an important issue with great practical implications. In the recent years, tree potential to cause harm has been increasing in consequence of climate change effects, mainly related to windstorms and tree diseases that represent the main tree failure causes. A tree owner has a duty of safety, imposed by civil and penal laws; consequently, he must operate an appropriate tree management to avoid foreseeable injuries or harms. A relevant problem arises when tree monitoring concern wide areas (extensive contexts), like natural park or urban forest; in these situations a variety of management factors have to be taken into account: the spatial size of the monitored areas; the great heterogeneity of trees vegetative conditions; the relevant number of trees; the balance between environmental protection and safe use of the area; the conspicuous cost of controls and technical interventions. With these premises an efficient planning tool is mandatory to manage this complex resource. Geomatics can support these requirements by integrating different techniques like survey, spatialization and modelling of territorial/environmental variables. In this work authors propose a new approach, hereinafter called ``Precision Arboriculture'' (PA), for tree management, fitting extensive contexts requirements. The proposed workflow is mainly based on RPAS photogrammetry technique and is specifically aimed at (i) accurately estimating single tree parameters; (ii) developing a robust algorithm to assess tree stability with the aim of reducing costs by better addressing ground controls through a spatially based management tool. This technology proved to generate estimates of the main dendrometric parameters with accuracies consistent (sometime higher) than the one ordinary required in the arboricultural context. Nevertheless, some ground data are however needed to calibrate models and testing accuracy of estimates. The proposed methodology proved to be able to generate an easy to use tool (Tree Safety Factor map) for better address ground controls aimed at testing tree stability and reducing the correlated hazard. Safety Factor map enhances critical trees addressing mitigation actions like tree removal, pruning, static bracing, limitations of people transit under potential tree fall area. The adoption of a quantitative index permits to better balance costs and benefits in a more objective way, improving economic efficiency of urban forestry and natural park policies. The method is configuring a new approach in arboricultural field involving new technologies, like RPAS photogrammetric survey and skills moving towards a ``Precision Arboriculture'' concept.},
  langid = {english},
  keywords = {CHM,Single tree parameters,Static integrated assessment,Tree stability index},
  file = {/home/samuelebumbaca/Zotero/storage/ZLA4YSD7/S1618866720306798.html}
}

@article{DesignAnalysisEfficacy2012,
  title = {Design and Analysis of Efficacy Evaluation Trials},
  year = {2012},
  month = dec,
  journal = {EPPO Bulletin},
  volume = {42},
  number = {3},
  pages = {367--381},
  issn = {02508052},
  doi = {10.1111/epp.2610},
  urldate = {2023-01-03},
  langid = {english}
}

@article{DesignAnalysisEfficacy2012a,
  title = {Design and Analysis of Efficacy Evaluation Trials},
  year = {2012},
  month = dec,
  journal = {EPPO Bulletin},
  volume = {42},
  number = {3},
  pages = {367--381},
  issn = {02508052},
  doi = {10.1111/epp.2610},
  urldate = {2023-01-03},
  langid = {english}
}

@article{DesignAnalysisEfficacy2012b,
  title = {Design and Analysis of Efficacy Evaluation Trials},
  year = {2012},
  month = dec,
  journal = {EPPO Bulletin},
  volume = {42},
  number = {3},
  pages = {367--381},
  issn = {02508052},
  doi = {10.1111/epp.2610},
  urldate = {2023-05-03},
  langid = {english}
}

@misc{DevelopmentSpectralIndices,
  title = {Development of Spectral Indices for Detecting and Identifying Plant Diseases - {{ScienceDirect}}},
  urldate = {2023-01-13},
  howpublished = {https://www.sciencedirect.com/science/article/abs/pii/S0034425712003793},
  file = {/home/samuelebumbaca/Zotero/storage/CN7U3CQI/S0034425712003793.html}
}

@article{dewolfDiseaseCycleApproach2007,
  title = {Disease {{Cycle Approach}} to {{Plant Disease Prediction}}},
  author = {De Wolf, Erick D. and Isard, Scott A.},
  year = {2007},
  journal = {Annual Review of Phytopathology},
  volume = {45},
  number = {1},
  pages = {203--220},
  doi = {10.1146/annurev.phyto.44.070505.143329},
  urldate = {2023-01-13},
  abstract = {AbstractPlant disease cycles represent pathogen biology as a series of interconnected stages of development including dormancy, reproduction, dispersal, and pathogenesis. The progression through these stages is determined by a continuous sequence of interactions among host, pathogen, and environment. The stages of the disease cycle form the basis of many plant disease prediction models. The relationship of temperature and moisture to disease development and pathogen reproduction serve as the basis for most contemporary plant disease prediction systems. Pathogen dormancy and inoculum dispersal are considered less frequently. We found extensive research efforts evaluating the performance of prediction models as part of operation disease management systems. These efforts appear to be greater than just a few decades ago, and include novel applications of Bayesian decision theory. Advances in information technology have stimulated innovations in model application. This trend must accelerate to provide the disease management strategies needed to maintain global food supplies.},
  pmid = {17408356},
  keywords = {Bayesian decision theory,disease warning,epidemiology,forecasting,modeling,pest management}
}

@book{dexaerdeStatisticalHandbookAgricultural2016,
  title = {A {{Statistical Handbook}} for {{Agricultural Field Trials Specialists}}},
  author = {{d'Exaerde}, G.K.},
  year = {2016},
  publisher = {Gylling Data Management},
  isbn = {978-0-9977002-1-3}
}

@article{dimyatiComparisonSeveralUAVBased2023,
  title = {A {{Comparison}} of {{Several UAV-Based Multispectral Imageries}} in {{Monitoring Rice Paddy}} ({{A Case Study}} in {{Paddy Fields}} in {{Tottori Prefecture}}, {{Japan}})},
  author = {Dimyati, Muhammad and Supriatna, Supriatna and Nagasawa, Ryota and Pamungkas, Fajar Dwi and Pramayuda, Rizki},
  year = {2023},
  month = jan,
  journal = {ISPRS International Journal of Geo-Information},
  volume = {12},
  number = {36},
  pages = {36},
  publisher = {MDPI AG},
  issn = {2220-9964},
  doi = {10.3390/ijgi12020036},
  urldate = {2023-03-29},
  abstract = {DOAJ is a unique and extensive index of diverse open access journals from around the world, driven by a growing community, committed to ensuring quality content is freely available online for everyone.},
  langid = {english}
}

@article{dimyatiComparisonSeveralUAVBased2023a,
  title = {A {{Comparison}} of {{Several UAV-Based Multispectral Imageries}} in {{Monitoring Rice Paddy}} ({{A Case Study}} in {{Paddy Fields}} in {{Tottori Prefecture}}, {{Japan}})},
  author = {Dimyati, Muhammad and Supriatna, Supriatna and Nagasawa, Ryota and Pamungkas, Fajar Dwi and Pramayuda, Rizki},
  year = {2023},
  month = feb,
  journal = {ISPRS International Journal of Geo-Information},
  volume = {12},
  number = {2},
  pages = {36},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2220-9964},
  doi = {10.3390/ijgi12020036},
  urldate = {2023-03-29},
  abstract = {In recent years, unmanned aerial vehicles (UAVs) have been actively applied in the agricultural sector. Several UAVs equipped with multispectral cameras have become available on the consumer market. Multispectral data are informative and practical for evaluating the greenness and growth status of vegetation as well as agricultural crops. The precise monitoring of rice paddy, especially in the Asian region, is crucial for optimizing profitability, sustainability, and protection of agro-ecological services. This paper reports and discusses our findings from experiments conducted to test four different commercially available multispectral cameras (Micesense RedEdge-M, Sentera Single NDVI, Mapir Survey3, and Bizworks Yubaflex), which can be mounted on a UAV in monitoring rice paddy. The survey has conducted in the typical paddy field area located in the alluvial plain in Tottori Prefecture, Japan. Six different vegetation indices (NDVI, BNDVI, GNDVI, VARI, NDRE and MCARI) captured by UAVs were also compared and evaluated monitoring contribution at three different rice cropping phases. The results showed that the spatial distribution of NDVI collected by each camera is almost similar in paddy fields, but the absolute values of NDVI differed significantly from each other. Among them, the Sentera camera showed the most reasonable NDVI values of each growing phase, indicating 0.49 in the early reproductive phase, 0.62 in the late reproductive stage, and 0.38 in the ripening phase. On the other hand, compared to the most commonly used NDVI, VARI which can be calculated from only visible RGB bands, can be used as an easy and effective index for rice paddy monitoring.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {multispectral camera,normalized differences vegetation index,rice paddy monitoring,unmanned aerial vehicle,visible atmospherically resistant index}
}

@article{dingEstimationSPADValue2020,
  title = {Estimation of {{SPAD}} Value in Tomato Leaves by Multispectral Images},
  author = {Ding, Yongjun and Zhang, Jingjing},
  year = {2020},
  month = sep,
  journal = {Journal of Physics: Conference Series},
  volume = {1634},
  number = {1},
  pages = {012128},
  publisher = {IOP Publishing},
  issn = {1742-6596},
  doi = {10.1088/1742-6596/1634/1/012128},
  abstract = {To improve the prediction accuracy of tomato chlorophyll content based on multispectral images, three preprocessing methods that can weaken illumination influence, i.e., self-adaptive gamma correction, multiscale Retinex and reflectance reconstruction, are compared and analyzed, and corresponding estimation models for the tomato Soil-Plant Analysis Development (SPAD) value are established. The correction coefficients are set according to the deviations between the grayscale values of the pixels in the highlighted and shaded areas and the average grayscale values in the area of uniform illumination to realize the self-adaptive gamma correction. The SPAD estimation model is constructed by the corrected image, with input parameters of nir, RVIb,g, RVIg,nir, RVIr,nir, NDVIr,g, and NDVIb,r, and the Rc2 and Rv2 of the model are 0.87 and 0.8, respectively. The original image is convolved with three different Gaussian functions to obtain a multiscale Retinex corrected image, and the SPAD estimation model is constructed. The input parameters are b, RVIr,g, RVIr,nir, RVIg,b, RVIg,nir, RVIb,nir, and NDVIr,g, and the Rc2 and Rv2 of the model are 0.91 and 0.84, respectively. The accuracy of the above two models depends on the selection of the corrected gamma value and the convolution kernel, and improper selections could seriously affect the accuracy of the model. For the SPAD value estimation model based on the reflectance reconstruction, its input parameters are nir, RVIg,nir, RVIr,g, NDVIg,b, NDVIr,nir, and NDVIb,r, and the Rc2 and Rv2 of the model are 0.90 and 0.88, respectively. The preprocessing procedure is simple, and the universality is high, making it suitable for the application of the digital field management of the crop.}
}

@article{dingPredictionSPADValue2015,
  title = {{[Prediction of SPAD value in oilseed rape leaves using hyperspectral imaging technique]}},
  author = {Ding, Xi-bin and Liu, Fei and Zhang, Chu and He, Yong},
  year = {2015},
  month = feb,
  journal = {Guang Pu Xue Yu Guang Pu Fen Xi = Guang Pu},
  volume = {35},
  number = {2},
  pages = {486--491},
  issn = {1000-0593},
  abstract = {In the present work, prediction models of SPAD value (Soil and Plant Analyzer Development, often used as a parameter to indicate chlorophyll content) in oilseed rape leaves were successfully built using hyperspectral imaging technique. The hy perspectral images of 160 oilseed rape leaf samples in the spectral range of 380-1030 nm were acquired. Average spectrum was extracted from the region of interest (ROI) of each sample. We chose spectral data in the spectral range of 500-900 nm for analysis. Using Monte Carlo partial least squares(MC-PLS) algorithm, 13 samples were identified as outliers and eliminated. Based on the spectral information and measured SPAD values of the rest 147 samples, several estimation models have been built based on different parameters using different algorithms for comparison, including: (1) a SPAD value estimation model based on partial least squares(PLS) in the whole wavelength region of 500-900 nm; (2) a SPAD value estimation model based on successive projections algorithmcombined with PLS(SPA-PLS); (3) 4 kind of simple experience SPAD value estimation models in which red edge position was used as an argument; (4) 4 kind of simple experience SPAD value estimation models in which three vegetation indexes R710/R760, (R750-R705)/(R750-R705) and R860/(R550 x R708), which all have been proved to have a good relevance with chlorophyll content, were used as an argument respectively; (5) a SPAD value estimation model based on PLS using the 3 vegetation indexes mentioned above. The results indicate that the optimal prediction performance is achieved by PLS model in the whole wavelength region of 500-900 nm, which has a correlation coefficient(r(p)) of 0.8339 and a root mean squares error of predicted (RMSEP) of 1.52. The SPA-PLS model can provide avery close prediction result while the calibration computation has been significantly reduced and the calibration speed has been accelerated sharply. For simple experience models based on red edge parameters and vegetation indexes, although there is a slight gap between theprediction performance and that of the PLS model in the whole wavelength region of 500-900 nm, they also have their own unique advantages which should be thought highly of: these models are much simpler and thus the calibration computation is reduced significantly, they can perform an important function under circumstances in which increasing modeling speed and reducing calibration computation operand are more important than improving the prediction accuracy, such as the development of portable devices.},
  langid = {chi},
  pmid = {25970918},
  keywords = {Algorithms,Brassica rapa,Chlorophyll,Least-Squares Analysis,Models Theoretical,Plant Leaves,Spectrum Analysis}
}

@article{dongGenerativeConvNetFoundation2024,
  title = {Generative {{ConvNet Foundation Model With Sparse Modeling}} and {{Low-Frequency Reconstruction}} for {{Remote Sensing Image Interpretation}}},
  author = {Dong, Zhe and Gu, Yanfeng and Liu, Tianzhu},
  year = {2024},
  journal = {IEEE Transactions on Geoscience and Remote Sensing},
  volume = {62},
  pages = {1--16},
  issn = {1558-0644},
  doi = {10.1109/TGRS.2023.3348479},
  urldate = {2025-01-05},
  abstract = {Foundation models offer a highly versatile and precise solution for intelligent interpretation of remote sensing images, thus greatly facilitating various remote sensing applications. Nevertheless, conventional remote sensing foundational models based on generative transformers neglect the consideration of multiscale features and frequency information, limiting their potential for dense prediction tasks in remote sensing scenarios. In this article, we make the first attempt to propose a generative convolutional neural network (ConvNet) foundation model tailored for remote sensing scenarios, which comprises two key components: First, a large dataset named GeoSense, containing approximately nine million diverse remote sensing images, is constructed to enhance the robustness and generalization of the foundation model during the pretraining phase. Second, a sparse modeling and low-frequency reconstruction (SMLFR) framework is designed for self-supervised representation learning of the ConvNet foundation model. Specifically, a sparse modeling strategy is proposed in masked image modeling (MIM), which allows ConvNet to process variable-length sequences by treating unmasked patches as voxels and sparsifying the encoder. In addition, a low-frequency reconstruction target is designed to guide the model's attention toward essential ground object features in remote sensing images, while mitigating unnecessary detail interference. To evaluate the general performance of our proposed foundation model, comprehensive experiments have been carried out on five datasets across three downstream tasks. Experimental results demonstrate that our method consistently achieves state-of-the-art performance across all the benchmark datasets and downstream tasks. The code and pretrained models will be available at https://github.com/HIT-SIRS/SMLFR.},
  keywords = {Computational modeling,Convolutional neural network (ConvNet),Data models,foundation model,Image reconstruction,remote sensing,Remote sensing,self-supervised pretraining,Sensors,Task analysis,Transformers},
  file = {/home/samuelebumbaca/Zotero/storage/7AG9RNIX/10378718.html}
}

@article{dudduHighThroughputUAVImageBased2019,
  title = {High-{{Throughput UAV Image-Based Method Is More Precise Than Manual Rating}} of {{Herbicide Tolerance}}},
  author = {Duddu, Hema S. N. and Johnson, Eric N. and Willenborg, Christian J. and Shirtliffe, Steven J.},
  year = {2019},
  month = sep,
  journal = {Plant Phenomics},
  volume = {2019},
  pages = {1--9},
  issn = {2643-6515},
  doi = {10.34133/2019/6036453},
  urldate = {2022-01-28},
  abstract = {The traditional visual rating system is labor-intensive, time-consuming, and prone to human error. Unmanned aerial vehicle (UAV) imagery-based vegetation indices (VI) have potential applications in high-throughput plant phenotyping. The study objective is to determine if UAV imagery provides accurate and consistent estimations of crop injury from herbicide application and its potential as an alternative to visual ratings. The study was conducted at the Kernen Crop Research Farm, University of Saskatchewan in 2016 and 2017. Fababean (                Vicia faba                L.) crop tolerance to nine herbicide tank mixtures was evaluated with 2 rates distributed in a randomized complete block design (RCBD) with 4 blocks. The trial was imaged using a multispectral camera with a ground sample distance (GSD) of 1.2\,cm, one week after the treatment application. Visual ratings of growth reduction and physiological chlorosis were recorded simultaneously with imaging. The optimized soil-adjusted vegetation index (OSAVI) was calculated from the thresholded orthomosaics. The UAV-based vegetation index (OSAVI) produced more precise results compared to visual ratings for both years. The coefficient of variation (CV) of OSAVI was {\textasciitilde}1\% when compared to 18-43\% for the visual ratings. Furthermore, Tukey's honestly significance difference (HSD) test yielded a more precise mean separation for the UAV-based vegetation index than visual ratings. The significant correlations between OSAVI and the visual ratings from the study suggest that undesirable variability associated with visual assessments can be minimized with the UAV-based approach. UAV-based imagery methods had greater precision than the visual-based ratings for crop herbicide damage. These methods have the potential to replace visual ratings and aid in screening crops for herbicide tolerance.},
  langid = {english}
}

@article{dutagaciROSEXAnnotatedData2020,
  title = {{{ROSE-X}}: An Annotated Data Set for Evaluation of {{3D}} Plant Organ Segmentation Methods},
  shorttitle = {{{ROSE-X}}},
  author = {Dutagaci, Helin and Rasti, Pejman and Galopin, Gilles and Rousseau, David},
  year = {2020},
  month = dec,
  journal = {Plant Methods},
  volume = {16},
  number = {1},
  pages = {28},
  issn = {1746-4811},
  doi = {10.1186/s13007-020-00573-w},
  urldate = {2021-12-18},
  abstract = {Abstract                              Background                The production and availability of annotated data sets are indispensable for training and evaluation of automatic phenotyping methods. The need for complete 3D models of real plants with organ-level labeling is even more pronounced due to the advances in 3D vision-based phenotyping techniques and the difficulty of full annotation of the intricate 3D plant structure.                                            Results                We introduce the ROSE-X data set of 11 annotated 3D models of real rosebush plants acquired through X-ray tomography and presented both in volumetric form and as point clouds. The annotation is performed manually to provide ground truth data in the form of organ labels for the voxels corresponding to the plant shoot. This data set is constructed to serve both as training data for supervised learning methods performing organ-level segmentation and as a benchmark to evaluate their performance. The rosebush models in the data set are of high quality and complex architecture with organs frequently touching each other posing a challenge for the current plant organ segmentation methods. We report leaf/stem segmentation results obtained using four baseline methods. The best performance is achieved by the volumetric approach where local features are trained with a random forest classifier, giving Intersection of Union (IoU) values of 97.93\% and 86.23\% for leaf and stem classes, respectively.                                            Conclusion                We provided an annotated 3D data set of 11 rosebush plants for training and evaluation of organ segmentation methods. We also reported leaf/stem segmentation results of baseline methods, which are open to improvement. The data set, together with the baseline results, has the potential of becoming a significant resource for future studies on automatic plant phenotyping.},
  langid = {english}
}

@misc{eppoDigitalTechnologyEfficacy,
  title = {Digital {{Technology}} and {{Efficacy Evaluation}} of {{Plant Protection Products}}},
  author = {EPPO, 2022-06-27/29},
  urldate = {2023-09-07},
  abstract = {EPPO},
  howpublished = {https://www.eppo.int/MEETINGS/2022},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/2AIV2ADN/wk_digital_technology_ppp.html}
}

@misc{eppoDigitalTechnologyEfficacy2022,
  title = {Digital {{Technology}} and {{Efficacy Evaluation}} of {{Plant Protection Products}}},
  shorttitle = {Digital {{Technology}} and {{Efficacy Evaluation}} of {{Plant Protection Products}}},
  author = {EPPO, 2022-06-27/29},
  year = {2022-06-27/0029},
  urldate = {2022-11-07},
  abstract = {The EPPO Workshop on adoption of digital technology for data generation for the efficacy evaluation of plant protection products was organized in collaboration with the Netherlands Food and Consumer Product Safety Authority (NVWA). Thanks are due to our Dutch hosts, in particular Ms Jilesen, for organizing the venue and logistics. Participants greatly appreciated the interesting technical visit to Eurofins experimental station in Elst, where they were welcomed by the Director of Eurofins, Mr Flier. The use of different digital technologies in efficacy trials was demonstrated there thanks to contribution of teams from six different companies. The EPPO Secretariat would like to express their gratitude to the Organizing Committee, Working Group Chairs, and Rapporteurs who helped in structuring this workshop and assisted with finalizing the conclusions. Thanks, are also due to the speakers for their informative presentations and all those attending for their active participation and contribution to the outcomes of the Workshop. The Workshop was organized upon request from EPPO Member Countries which identified the need to critically discuss how the digital technologies used in efficacy trials can be validated and accepted within Good Experimental Practice (GEP) systems and by regulators in the future.   General background At the Workshop the focus was on sharing experience on the use of digital technology in PPP efficacy evaluation, identifying how digital technologies can support existing methods for specific assessment types and discussing knowledge gaps. The participants discussed how digital technologies can be validated, calibrated and verified, as well as what further work or guidance may be needed. The Workshop also focussed on possible work EPPO could do to assist their member countries, including updating of existing, or preparation of new EPPO Standards. The use of digital technologies in the application of plant protection products was outside of the Workshop's scope.   The Workshop provided an excellent opportunity to share experiences on the topic. A total of 72 participants, from 17 EPPO countries were present at the meeting. Presentations Mr Horn (EPPO Director General) welcomed participants and explained the objectives of the Workshop. The opening lectures (click on the links to see the presentations -- PDF) illustrated the current state of developments of digital technologies, their use in practice and potential possibilities for the future. GEP Managers and representatives of GEP units shared their experiences with using digital technologies and on implementing EPPO PP1 Standards while using digital tools. Representatives of plant protection products industry and the digital technology providers presented their experience with the use of digital technology and the potential for use in efficacy trials.     Opening	  Welcome address and objectives of the Workshop	Nico Horn (EPPO) Developments of digital technologies: current state and potential possibilities for the future	  Novel sensing and machine learning techniques for in field disease detection	Gerrit Polder, WUR Plant Research Wageningen (NL) How can we learn from plant breeders? Update on use of digital technologies in plant breeding	Francois Tardieu, INRAE (FR) The integration of digital technologies into biological assessment approaches to enhance data quality and delivery	Rosie Bryson, BASF (DE) GEP managers experience   Experience of Digital Technology in GEP Trials in the UK	Tony Fisher (GB) Digital technologies in GEP Units	Anna Papamichail (GR)   Key studies GEP units - Experiences to share on making use of digital technologies so far and on following EPPO PP1 Standards while using digital tools Cirillo, next generation digital plant pest phenotyping	Peter Korsten, Botany (NL) How can simple RGB pictures be used for counting plant emergence	Martin Gejl, Agrolab (DK) Key studies Plant protection products industry and Digital technology providers Using digital tools to assess R\&D trials - disease recognition at leaf level Ramon Navarra Mestre, BASF (DE) Digital Phenotyping: using sensor-based technologies for measuring crop responses Aline Nink, Bayer CropScience (DE) From images to data: the path of automated techniques for digital trial evaluations	 Valentino Bosco, Corteva (IT) Development of a smartphone/tablet app for cereal stand counts Frank Meier-Runge, Syngenta (DE) Improving traceability, transparency, and precision of assessments for biological dossiers with digital technology Alexis Comar, Hiphen (FR)   Working groups Participants were divided into four Working Groups to discuss the use of digital technologies in efficacy evaluation. Three groups focused on different groups of plant protection products, considering the specificities for efficacy trials of herbicides, fungicides and insecticides, and the fourth group discussed use of digital technologies in the framework of GEP systems. In the final plenary session moderated by Mr Kudsk (DK), the rapporteur of each group summarized the conclusions of their group for all the Workshop participants.     Conclusions and recommendations Based on those outcomes of the Working Groups, the general conclusions and recommendations were elaborated during the plenary session and are summarized as follows. At the moment there is no need to revise EPPO specific Standards concerning digital technologies as the Standards don't specify how the data is obtained. Revision may be needed in the future if digital technologies are used to generate additional parameters. Validation of digital technologies is crucial. A glossary of technical terms is needed, e.g. to clarify the meaning of the terms `calibration', `verification' and `validation'. The raw trial data is the outputs of the assessments, not the images or data files. Calibration, verification and validation is primarily a responsibility of the GEP system. A new Standard or alternatively an addendum to EPPO PP1/181 describing procedures for calibration, verification and validation of digital technologies is urgently needed. Bringing GEP managers together could promote harmonization of the use of digital technologies. Industry may consider sharing a common data set for validation.},
  howpublished = {https://www.eppo.int/MEETINGS/2022\_meetings/https\%3A\%2F\%2Fwww.eppo.int\%2FMEETINGS\%2F2022\_meetings\%2Fwk\_digital\_technology\_ppp},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/3W2FWBCW/wk_digital_technology_ppp.html}
}

@misc{EPPOGlobalDatabase,
  title = {{{EPPO Global Database}}},
  shorttitle = {{{EPPO}} (2022) {{EPPO Global Database}} (Available Online).},
  urldate = {2022-10-28},
  howpublished = {https://gd.eppo.int/},
  file = {/home/samuelebumbaca/Zotero/storage/YJ2SVG9R/gd.eppo.int.html}
}

@article{eppoPP11352014,
  title = {{{PP}} 1/135 (4) {{Phytotoxicity}} Assessment},
  author = {{EPPO}},
  year = {2014},
  journal = {EPPO Bulletin},
  volume = {44},
  number = {3},
  pages = {265--273},
  issn = {1365-2338},
  doi = {10.1111/epp.12134},
  urldate = {2023-09-01},
  abstract = {Specific scope This Standard provides detailed advice on assessment of the phytotoxicity of plant protection products to crops or plant products including propagating material and is intended for use in association with EPPO Standards of series PP 1 (Efficacy evaluation of plant protection products, especially of herbicides and plant growth regulators). Specific approval and amendment First approved in 1987--09. First revision approved in 1997--09. Second revision approved in 2006--09. (Table corrected in 2011--04.) Third revision approved in 2014--09.},
  copyright = {{\copyright} 2014 OEPP/EPPO},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/ZHWNSNHY/epp.html}
}

@article{ESRIShapefileTechnical,
  title = {{{ESRI Shapefile Technical Description}}},
  langid = {english}
}

@article{fangReviewCropCanopy2015,
  title = {{[Review of Crop Canopy Spectral Information Detection Technology and Methods]}},
  author = {Fang, Xiao-rong and Gao, Jun-feng and Xie, Chuan-qi and Zhu, Feng-le and Huang, Ling-xia and He, Yong},
  year = {2015},
  month = jul,
  journal = {Guang Pu Xue Yu Guang Pu Fen Xi = Guang Pu},
  volume = {35},
  number = {7},
  pages = {1949--1955},
  issn = {1000-0593},
  abstract = {Compared with the traditional chemical methods and the subjective visual ways for measuring plant physiology information indicators, the assessments of crop canopy information through spectral radiometer are more simple, rapid and accurate. The applications of different types of spectral radiometer, especially for international general used Cropscan multispectral radiometer, for predicting crop canopy leaf area index under different growth stage, biomass, nitrogen, chlorophyll and yield, and monitoring plant diseases and insect pests were summarized based on crop group information acquisition methods in recent years. The varity of vegetation indices (VIs) were concluded after comparing regression coefficients of related models among different crops. In general, the correlation coefficients of mathematical models were high and it can realize the crop detection of various kinds of physiological information. Besides, the combination of multispectral radiometer and other sensors can provide useful information to evaluate the status of crops growth, which is very important in practice.},
  langid = {chi},
  pmid = {26717758},
  keywords = {Biomass,Chlorophyll,Crops Agricultural,Environmental Monitoring,Models Theoretical,Nitrogen,Plant Diseases,Plant Leaves,Spectrum Analysis}
}

@inproceedings{FASTAPPROXIMATENEAREST2009,
  title = {{{FAST APPROXIMATE NEAREST NEIGHBORS WITH AUTOMATIC ALGORITHM CONFIGURATION}}:},
  shorttitle = {{{FAST APPROXIMATE NEAREST NEIGHBORS WITH AUTOMATIC ALGORITHM CONFIGURATION}}},
  booktitle = {Proceedings of the {{Fourth International Conference}} on {{Computer Vision Theory}} and {{Applications}}},
  year = {2009},
  pages = {331--340},
  publisher = {{SciTePress - Science and and Technology Publications}},
  address = {Lisboa, Portugal},
  doi = {10.5220/0001787803310340},
  urldate = {2022-11-25},
  isbn = {978-989-8111-69-2},
  langid = {english}
}

@article{felzenszwalbEfficientGraphBasedImage2004,
  title = {Efficient {{Graph-Based Image Segmentation}}},
  author = {Felzenszwalb, Pedro F. and Huttenlocher, Daniel P.},
  year = {2004},
  month = sep,
  journal = {International Journal of Computer Vision},
  volume = {59},
  number = {2},
  pages = {167--181},
  issn = {0920-5691},
  doi = {10.1023/B:VISI.0000022288.19776.77},
  urldate = {2022-12-02},
  abstract = {This paper addresses the problem of segmenting an image into regions. We define a predicate for measuring the evidence for a boundary between two regions using a graph-based representation of the image. We then develop an efficient segmentation algorithm based on this predicate, and show that although this algorithm makes greedy decisions it produces segmentations that satisfy global properties. We apply the algorithm to image segmentation using two different kinds of local neighborhoods in constructing the graph, and illustrate the results with both real and synthetic images. The algorithm runs in time nearly linear in the number of graph edges and is also fast in practice. An important characteristic of the method is its ability to preserve detail in low-variability image regions while ignoring detail in high-variability regions.},
  langid = {english}
}

@article{fitzpatrickPredictingErrorRigidbody1998,
  title = {Predicting Error in Rigid-Body Point-Based Registration},
  author = {Fitzpatrick, J.M. and West, J.B. and Maurer, C.R.},
  year = {1998},
  month = oct,
  journal = {IEEE Transactions on Medical Imaging},
  volume = {17},
  number = {5},
  pages = {694--702},
  issn = {02780062},
  doi = {10.1109/42.736021},
  urldate = {2021-12-19}
}

@article{friedmanRegularizationPathsGeneralized2010,
  title = {Regularization {{Paths}} for {{Generalized Linear Models}} via {{Coordinate Descent}}},
  author = {Friedman, Jerome H. and Hastie, Trevor and Tibshirani, Rob},
  year = {2010},
  month = feb,
  journal = {Journal of Statistical Software},
  volume = {33},
  pages = {1--22},
  issn = {1548-7660},
  doi = {10.18637/jss.v033.i01},
  urldate = {2025-03-16},
  abstract = {We develop fast algorithms for estimation of generalized linear models with convex penalties. The models include linear regression, two-class logistic regression, and multi- nomial regression problems while the penalties include {$\ell$}1 (the lasso), {$\ell$}2 (ridge regression) and mixtures of the two (the elastic net). The algorithms use cyclical coordinate descent, computed along a regularization path. The methods can handle large problems and can also deal efficiently with sparse features. In comparative timings we find that the new algorithms are considerably faster than competing methods.},
  copyright = {Copyright (c) 2009 Jerome H. Friedman, Trevor Hastie, Rob Tibshirani},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/WIRL35LD/Friedman et al. - 2010 - Regularization Paths for Generalized Linear Models via Coordinate Descent.pdf}
}

@misc{FrontiersHighThroughput,
  title = {Frontiers {\textbar} {{High Throughput In}} Vivo {{Analysis}} of {{Plant Leaf Chemical Properties Using Hyperspectral Imaging}}},
  urldate = {2023-01-13},
  howpublished = {https://www.frontiersin.org/articles/10.3389/fpls.2017.01348/full},
  file = {/home/samuelebumbaca/Zotero/storage/HHNXT9XA/full.html}
}

@article{fuentesImprovingAccuracyTomato2021,
  title = {Improving {{Accuracy}} of {{Tomato Plant Disease Diagnosis Based}} on {{Deep Learning With Explicit Control}} of {{Hidden Classes}}},
  author = {Fuentes, Alvaro and Yoon, Sook and Lee, Mun Haeng and Park, Dong Sun},
  year = {2021},
  month = dec,
  journal = {Frontiers in Plant Science},
  volume = {12},
  publisher = {Frontiers Media S.A.},
  issn = {1664-462X},
  doi = {10.3389/fpls.2021.682230},
  urldate = {2023-09-01},
  abstract = {Recognizing plant diseases is a major challenge in agriculture, and recent works based on deep learning have shown high efficiency in addressing problems...},
  langid = {english}
}

@inproceedings{gallianiMassivelyParallelMultiview2015,
  title = {Massively {{Parallel Multiview Stereopsis}} by {{Surface Normal Diffusion}}},
  booktitle = {2015 {{IEEE International Conference}} on {{Computer Vision}} ({{ICCV}})},
  author = {Galliani, Silvano and Lasinger, Katrin and Schindler, Konrad},
  year = {2015},
  month = dec,
  pages = {873--881},
  publisher = {IEEE},
  address = {Santiago, Chile},
  doi = {10.1109/ICCV.2015.106},
  urldate = {2022-11-24},
  abstract = {We present a new, massively parallel method for highquality multiview matching. Our work builds on the Patchmatch idea: starting from randomly generated 3D planes in scene space, the best-fitting planes are iteratively propagated and refined to obtain a 3D depth and normal field per view, such that a robust photo-consistency measure over all images is maximized. Our main novelties are on the one hand to formulate Patchmatch in scene space, which makes it possible to aggregate image similarity across multiple views and obtain more accurate depth maps. And on the other hand a modified, diffusion-like propagation scheme that can be massively parallelized and delivers dense multiview correspondence over ten 1.9-Megapixel images in 3 seconds, on a consumer-grade GPU. Our method uses a slanted support window and thus has no fronto-parallel bias; it is completely local and parallel, such that computation time scales linearly with image size, and inversely proportional to the number of parallel threads. Furthermore, it has low memory footprint (four values per pixel, independent of the depth range). It therefore scales exceptionally well and can handle multiple large images at high depth resolution. Experiments on the DTU and Middlebury multiview datasets as well as oblique aerial images show that our method achieves very competitive results with high accuracy and completeness, across a range of different scenarios.},
  isbn = {978-1-4673-8391-2},
  langid = {english}
}

@article{gamonAssessingLeafPigment1999,
  title = {Assessing Leaf Pigment Content and Activity with a Reflectometer},
  author = {Gamon, J. A. and Surfus, J. S.},
  year = {1999},
  month = jul,
  journal = {The New Phytologist},
  volume = {143},
  number = {1},
  pages = {105--117},
  publisher = {Cambridge University Press},
  issn = {1469-8137, 0028-646X},
  doi = {10.1046/j.1469-8137.1999.00424.x},
  urldate = {2023-01-13},
  abstract = {This study explored reflectance indices sampled with a `leaf reflectometer' as measures of pigment content for  leaves of contrasting light history, developmental stage and functional type (herbaceous annual versus  sclerophyllous evergreen). We employed three reflectance indices: a modified normalized difference vegetation  index (NDVI), an index of chlorophyll content; the red/green reflectance ratio (RRED[ratio   ]RGREEN), an index of  anthocyanin content; and the change in photochemical reflectance index upon dark--light conversions ({$\Delta$}PRI), an  index of xanthophyll cycle pigment activity. In Helianthus annuus (sunflower), xanthophyll cycle pigment amounts  were linearly related to growth light environment; leaves in full sun contained approximately twice the amount  of xanthophyll cycle pigments as leaves in deep shade, and at midday a larger proportion of these pigments were  in the photoprotective, de-epoxidized forms relative to shade leaves. Reflectance indices also revealed contrasting  patterns of pigment development in leaves of contrasting structural types (annual versus evergreen). In H. annuus  sun leaves, there was a remarkably rapid increase in amounts of both chlorophyll and xanthophyll cycle pigments  along a leaf developmental sequence. This pattern contrasted with that of Quercus agrifolia (coast live oak, a  sclerophyllous evergreen), which exhibited a gradual development of both chlorophyll and xanthophyll cycle  pigments along with a pronounced peak of anthocyanin pigment content in newly expanding leaves. These  temporal patterns of pigment development in Q. agrifolia leaves suggest that anthocyanins and xanthophyll cycle  pigments serve complementary photoprotective roles during early leaf development. The results illustrate the use  of reflectance indices for distinguishing divergent patterns of pigment activity in leaves of contrasting light history  and functional type.},
  langid = {english},
  keywords = {anthocyanins,chlorophyll,leaf development,leaf pigments,leaf reflectometer,photoprotection,reflectance indices,xanthophyll cycle}
}

@article{gamonNarrowwavebandSpectralIndex1992,
  title = {A Narrow-Waveband Spectral Index That Tracks Diurnal Changes in Photosynthetic Efficiency},
  author = {Gamon, J. A. and Pe{\~n}uelas, J. and Field, C. B.},
  year = {1992},
  month = jul,
  journal = {Remote Sensing of Environment},
  volume = {41},
  number = {1},
  pages = {35--44},
  issn = {0034-4257},
  doi = {10.1016/0034-4257(92)90059-S},
  urldate = {2023-11-09},
  abstract = {We present a new ``physiological reflectance index'' (PRI) isolated from narrow waveband spectral measurements of sunflower canopies. This index correlates with the epoxidation state of the xanthophyll cycle pigments and with the efficiency of photosynthesis in control and nitrogen stress canopies, but not in water stress canopies undergoing midday wilting. It is analogous in formulation to the broadband normalized difference vegetation index (NDVI) and uses reflectance at 531 nm and at a reference wavelength to minimize complications associated with diurnal sun angle changes. In conjunction with other methods, this index may lead to improved remote and ground-based estimates of canopy photosynthetic function.},
  file = {/home/samuelebumbaca/Zotero/storage/5AZQS3D4/003442579290059S.html}
}

@article{garbowMINPACK1SubroutineLibrary1984,
  title = {{{MINPACK-1}}, {{Subroutine Library}} for {{Nonlinear Equation System}}},
  author = {Garbow, Burton S.},
  year = {1984},
  month = apr,
  address = {Nuclear Energy Agency of the OECD (NEA)},
  abstract = {1 - Description of problem or function: MINPACK1 is a package of FORTRAN subprograms for the numerical solution of systems of non- linear equations and nonlinear least-squares problems The individual programs are: Identification/Description: - CHKDER: Check gradients for consistency with functions, - DOGLEG: Determine combination of Gauss-Newton and gradient directions, - DPMPAR: Provide double precision machine parameters, - ENORM: Calculate Euclidean norm of vector, - FDJAC1: Calculate difference approximation to Jacobian (nonlinear equations), - FDJAC2: Calculate difference approximation to Jacobian (least squares), - HYBRD: Solve system of nonlinear equations (approximate Jacobian), - HYBRD1: Easy-to-use driver for HYBRD, - HYBRJ: Solve system of nonlinear equations (analytic Jacobian), - HYBRJ1: Easy-to-use driver for HYBRJ, - LMDER: Solve nonlinear least squares problem (analytic Jacobian), - LMDER1: Easy-to-use driver for LMDER, - LMDIF: Solve nonlinear least squares problem (approximate Jacobian), - LMDIF1: Easy-to-use driver for LMDIF, - LMPAR: Determine Levenberg-Marquardt parameter - LMSTR: Solve nonlinear least squares problem (analytic Jacobian, storage conserving), - LMSTR1: Easy-to-use driver for LMSTR, - QFORM: Accumulate orthogonal matrix from QR factorization QRFAC Compute QR factorization of rectangular matrix, - QRSOLV: Complete solution of least squares problem, - RWUPDT: Update QR factorization after row addition, - R1MPYQ: Apply orthogonal transformations from QR factorization, - R1UPDT: Update QR factorization after rank-1 addition, - SPMPAR: Provide single precision machine parameters 4 Method of solution - MINPACK1 uses the modified Powell hybrid method and the Levenberg-Marquardt algorithm}
}

@article{gatesSpectralPropertiesPlants1965,
  title = {Spectral {{Properties}} of {{Plants}}},
  author = {Gates, David M. and Keegan, Harry J. and Schleter, John C. and Weidner, Victor R.},
  year = {1965},
  month = jan,
  journal = {Applied Optics},
  volume = {4},
  number = {1},
  pages = {11--20},
  publisher = {Optica Publishing Group},
  issn = {2155-3165},
  doi = {10.1364/AO.4.000011},
  urldate = {2023-01-13},
  abstract = {The spectral properties of plant leaves and stems have been obtained for ultraviolet, visible, and infrared frequencies. The spectral reflectance, transmittance, and absorptance for certain plants is given. The mechanism by which radiant energy interacts with a leaf is discussed, including the presence of plant pigments. Examples are given concerning the amount of absorbed solar radiation for clear sky and overcast conditions. The spectral properties of desert plants are compared with those of more mesic plants. The evolution of the spectral properties of plant leaves during the early growing season is given as well as the colorimetric behavior during the autumn.},
  copyright = {{\copyright} 1965 Optical Society of America},
  langid = {english},
  keywords = {Energy transfer,Infrared radiation,Solar energy,Solar radiation,Spectral properties,Visible light}
}

@article{ghahremaniDeepSegmentationPoint2021,
  title = {Deep {{Segmentation}} of {{Point Clouds}} of {{Wheat}}},
  author = {Ghahremani, Morteza and Williams, Kevin and Corke, Fiona M. K. and Tiddeman, Bernard and Liu, Yonghuai and Doonan, John H.},
  year = {2021},
  month = mar,
  journal = {Frontiers in Plant Science},
  volume = {12},
  pages = {608732},
  issn = {1664-462X},
  doi = {10.3389/fpls.2021.608732},
  urldate = {2021-12-18},
  abstract = {The 3D analysis of plants has become increasingly effective in modeling the relative structure of organs and other traits of interest. In this paper, we introduce a novel pattern-based deep neural network, Pattern-Net, for segmentation of point clouds of wheat. This study is the first to segment the point clouds of wheat into defined organs and to analyse their traits directly in 3D space. Point clouds have no regular grid and thus their segmentation is challenging. Pattern-Net creates a dynamic link among neighbors to seek stable patterns from a 3D point set across several levels of abstraction using the K-nearest neighbor algorithm. To this end, different layers are connected to each other to create complex patterns from the simple ones, strengthen dynamic link propagation, alleviate the vanishing-gradient problem, encourage link reuse and substantially reduce the number of parameters. The proposed deep network is capable of analysing and decomposing unstructured complex point clouds into semantically meaningful parts. Experiments on a wheat dataset verify the effectiveness of our approach for segmentation of wheat in 3D space.}
}

@article{ghosalExplainableDeepMachine2018,
  title = {An Explainable Deep Machine Vision Framework for Plant Stress Phenotyping},
  author = {Ghosal, Sambuddha and Blystone, David and Singh, Asheesh K. and Ganapathysubramanian, Baskar and Singh, Arti and Sarkar, Soumik},
  year = {2018},
  month = may,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {115},
  number = {18},
  pages = {4613--4618},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.1716999115},
  urldate = {2023-09-01},
  abstract = {Current approaches for accurate identification, classification, and quantification of biotic and abiotic stresses in crop research and production are predominantly visual and require specialized training. However, such techniques are hindered by subjectivity resulting from inter- and intrarater cognitive variability. This translates to erroneous decisions and a significant waste of resources. Here, we demonstrate a machine learning framework's ability to identify and classify a diverse set of foliar stresses in soybean [Glycine max (L.) Merr.] with remarkable accuracy. We also present an explanation mechanism, using the top-K high-resolution feature maps that isolate the visual symptoms used to make predictions. This unsupervised identification of visual symptoms provides a quantitative measure of stress severity, allowing for identification (type of foliar stress), classification (low, medium, or high stress), and quantification (stress severity) in a single framework without detailed symptom annotation by experts. We reliably identified and classified several biotic (bacterial and fungal diseases) and abiotic (chemical injury and nutrient deficiency) stresses by learning from over 25,000 images. The learned model is robust to input image perturbations, demonstrating viability for high-throughput deployment. We also noticed that the learned model appears to be agnostic to species, seemingly demonstrating an ability of transfer learning. The availability of an explainable model that can consistently, rapidly, and accurately identify and quantify foliar stresses would have significant implications in scientific research, plant breeding, and crop production. The trained model could be deployed in mobile platforms (e.g., unmanned air vehicles and automated ground scouts) for rapid, large-scale scouting or as a mobile application for real-time detection of stress by farmers and researchers.}
}

@article{ghosalExplainableDeepMachine2018a,
  title = {An Explainable Deep Machine Vision Framework for Plant Stress Phenotyping},
  author = {Ghosal, Sambuddha and Blystone, David and Singh, Asheesh K. and Ganapathysubramanian, Baskar and Singh, Arti and Sarkar, Soumik},
  year = {2018},
  month = may,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {115},
  number = {18},
  pages = {4613--4618},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.1716999115},
  urldate = {2023-08-31},
  abstract = {Current approaches for accurate identification, classification, and quantification of biotic and abiotic stresses in crop research and production are predominantly visual and require specialized training. However, such techniques are hindered by subjectivity resulting from inter- and intrarater cognitive variability. This translates to erroneous decisions and a significant waste of resources. Here, we demonstrate a machine learning framework's ability to identify and classify a diverse set of foliar stresses in soybean [Glycine max (L.) Merr.] with remarkable accuracy. We also present an explanation mechanism, using the top-K high-resolution feature maps that isolate the visual symptoms used to make predictions. This unsupervised identification of visual symptoms provides a quantitative measure of stress severity, allowing for identification (type of foliar stress), classification (low, medium, or high stress), and quantification (stress severity) in a single framework without detailed symptom annotation by experts. We reliably identified and classified several biotic (bacterial and fungal diseases) and abiotic (chemical injury and nutrient deficiency) stresses by learning from over 25,000 images. The learned model is robust to input image perturbations, demonstrating viability for high-throughput deployment. We also noticed that the learned model appears to be agnostic to species, seemingly demonstrating an ability of transfer learning. The availability of an explainable model that can consistently, rapidly, and accurately identify and quantify foliar stresses would have significant implications in scientific research, plant breeding, and crop production. The trained model could be deployed in mobile platforms (e.g., unmanned air vehicles and automated ground scouts) for rapid, large-scale scouting or as a mobile application for real-time detection of stress by farmers and researchers.}
}

@book{gibbsThreeDimensionalReconstructionPlant2015,
  title = {Three-{{Dimensional Reconstruction}} of {{Plant Shoots}} from {{Multiple Images}} Using an {{Active Vision System}}},
  author = {Gibbs, Jonathon and Pound, Michael and French, Andrew and Wells, Darren and Pridmore, Tony and Murchie, Erik},
  year = {2015},
  month = oct,
  abstract = {The reconstruction of 3D models of plant shoots is a challenging problem central to the emerging discipline of plant phenomics -- the quantitative measurement of plant structure and function. Current approaches are, however, often limited by the use of static cameras. We propose an automated active phenotyping cell to reconstruct plant shoots from multiple images using a turntable capable of rotating 360 degrees and camera mounted robot arm. To overcome the problem of static camera positions we develop an algorithm capable of analysing the environment and determining viewpoints from which to capture initial images suitable for use by a structure from motion technique.}
}

@article{gitelsonOpticalPropertiesNondestructive2001,
  title = {Optical {{Properties}} and {{Nondestructive Estimation}} of {{Anthocyanin Content}} in {{Plant Leaves}}{\P}},
  author = {Gitelson, Anatoly A. and Merzlyak, Mark N. and Chivkunova, Olga B.},
  year = {2001},
  journal = {Photochemistry and Photobiology},
  volume = {74},
  number = {1},
  pages = {38--45},
  issn = {1751-1097},
  doi = {10.1562/0031-8655(2001)0740038OPANEO2.0.CO2},
  urldate = {2023-03-24},
  abstract = {Absorption and reflectance spectra of maple (Acer platanoides), cotoneaster (Cotoneaster alaunica), dogwood (Cornus alba) and pelargonium (Pelargonium zonale) leaves with a wide range of pigment content and composition were studied in visible and near-infrared spectra in order to reveal specific anthocyanin (Anth) spectral features in leaves. Comparing absorption spectra of Anth-containing and Anth-free leaves with the same chlorophyll (Chl) content, absorption spectra of Anth in leaves were derived. The main spectral feature of Anth absorption in vivo was a peak around 550 nm; the peak magnitude was closely related to Anth content. A quantitative nondestructive technique was developed to subtract Chl contribution to reflectance in this spectral region and retrieve Anth content from reflectance over a wide range of pigment content and composition. Anth reflectance index in the form ARI = (R550)-1- (R700)-1, where (R550)-1 and (R700)-1 are inverse reflectances at 550 and 700 nm, respectively, allowed an accurate estimation of Anth accumulation, even in minute amounts, in intact senescing and stressed leaves.},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/23QTXUT3/0031-8655(2001)0740038OPANEO2.0.html}
}

@article{gitelsonThreebandModelNoninvasive2006,
  title = {Three-Band Model for Noninvasive Estimation of Chlorophyll, Carotenoids, and Anthocyanin Contents in Higher Plant Leaves},
  author = {Gitelson, Anatoly A. and Keydan, Galina P. and Merzlyak, Mark N.},
  year = {2006},
  journal = {Geophysical Research Letters},
  volume = {33},
  number = {11},
  issn = {1944-8007},
  doi = {10.1029/2006GL026457},
  urldate = {2023-01-13},
  abstract = {Leaf pigment content and composition provide important information about plant physiological status. Reflectance measurements offer a rapid, nondestructive technique to estimate pigment content. This paper describes a recently developed three-band conceptual model capable of remotely estimating total of chlorophylls, carotenoids and anthocyanins contents in leaves from many tree and crop species. We tuned the spectral regions used in the model in accord with pigment of interest and the optical characteristics of the leaves studied, and showed that the developed technique allowed accurate estimation of total chlorophylls, carotenoids and anthocyanins, explaining more than 91\%, 70\% and 93\% of pigment variation, respectively. This new technique shows a great potential for noninvasive tracking of the physiological status of vegetation and the impact of environmental changes.},
  langid = {english}
}

@misc{GitHubEriklindernorenPyTorchGAN,
  title = {{{GitHub}} - Eriklindernoren/{{PyTorch-GAN}}: {{PyTorch}} Implementations of {{Generative Adversarial Networks}}.},
  urldate = {2025-01-13},
  howpublished = {https://github.com/eriklindernoren/PyTorch-GAN/tree/master?tab=readme-ov-file\#auxiliary-classifier-gan},
  file = {/home/samuelebumbaca/Zotero/storage/8TQYWCAG/master.html}
}

@article{glasbeyAnalysisHistogramBasedThresholding1993,
  title = {An {{Analysis}} of {{Histogram-Based Thresholding Algorithms}}},
  author = {Glasbey, C. A.},
  year = {1993},
  month = nov,
  journal = {CVGIP: Graphical Models and Image Processing},
  volume = {55},
  number = {6},
  pages = {532--537},
  issn = {1049-9652},
  doi = {10.1006/cgip.1993.1040},
  urldate = {2023-01-25},
  abstract = {Eleven histogram-based global thresholding algorithms are presented in a common notational framework. Relationships among them are identified from 654 mixtures of two Gaussian distributions, plus effects of mixed pixels. The iterated version of Kittler and Illingworth{$\prime$}s minimum error algorithm (Pattern Recognition, 19, 1986, 41-47) is found to be best.},
  langid = {english}
}

@incollection{gomarascaElementsPhotogrammetry2009,
  title = {Elements of {{Photogrammetry}}},
  booktitle = {Basics of {{Geomatics}}},
  author = {Gomarasca, Mario A.},
  editor = {Gomarasca, Mario A.},
  year = {2009},
  pages = {79--121},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-1-4020-9014-1_3},
  urldate = {2022-11-25},
  abstract = {Photogrammetry is a technique that allows the measurement of an object without touching it. Measurement can be performed in two and three dimensions (2D and 3D) exploiting both photograms (analogical images) acquired by traditional photogrammetric cameras and digital imagery. Although photogrammetry was born for architectural survey, it can be considered the first remote sensing technology based on the acquisition of objects' geometric properties from photographic images. Nowadays it is widely used in topographic aerial survey and mapping, and for military purposes.},
  isbn = {978-1-4020-9014-1},
  langid = {english},
  keywords = {Bundle Adjustment,Flight Plan,Ground Control Point,Photo Camera,Stereoscopic Vision}
}

@article{gomarascaSENTINELAPPLICATIONSAGRICULTURE2019,
  title = {{{SENTINEL FOR APPLICATIONS IN AGRICULTURE}}},
  author = {Gomarasca, M. A. and Tornato, A. and Spizzichino, D. and Valentini, E. and Taramelli, A. and Satalino, G. and Vincini, M. and Boschetti, M. and Colombo, R. and Rossi, L. and Borgogno Mondino, E. and Perotti, L. and Alberto, W. and Villa, F.},
  year = {2019},
  month = jul,
  journal = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  volume = {XLII-3/W6},
  pages = {91--98},
  issn = {2194-9034},
  doi = {10.5194/isprs-archives-XLII-3-W6-91-2019},
  urldate = {2022-11-10},
  abstract = {The European Union and the European Space Agency (EU/ESA) have promoted since 1998 (Baveno Manifesto*) the GMES Programme (Global Monitoring for Environment and Security), nowadays called Copernicus (www.copernicus.eu). In the agriculture domain, the use of Copernicus Sentinel imagery and its services are providing several new opportunities. The knowledge of fundamentals of Earth Observation/Geographic Information EO/GI, namely Geomatics, for the development of innovative strategies for professional skills adequacy and capacity building, supporting Copernicus user uptake, becomes mandatory (Gomarasca, 2009). The target is to help bridging gaps between supply and demand of education and training for geospatial sector (www.eo4geo.eu). The innovative and strategical novelties are the complete free access to Sentinel time series imagery and digital image processing software ``Sentinel toolboxes'' such as SNAP (Sentinel Application Platform) for different environments (Windows, Mac, Unix). The paper introduce topics as crop mapping and monitoring, biophysical parameters, phenology and yield estimations, through several concluded or ongoing international projects such as: ERMES -FP7 (http://www.ermes-fp7space.eu/it/homepage/, Busetto et al. 2017) and SATURNO (https://www.progettosaturno.it/, Nutini et al., 2018) devoted to the regional agricultural monitoring. As conclusion, SNAP software for image processing of Sentinel data was demonstrated and tested together with Earth Engine software for specific vertical agriculture applications. The topics reported in this paper have been part of the Summer School `Sentinel for Applications in Agriculture' supported by the Copernicus programme, several scientific associations (AIT, ASITA, EARSeL - European Association of Remote Sensing Laboratories), the European Erasmus+ project EO4GEO, University Departments and Geo-Information Companies.},
  langid = {english}
}

@article{gomesApplicationsComputerVision2012,
  title = {Applications of Computer Vision Techniques in the Agriculture and Food Industry: A Review},
  shorttitle = {Applications of Computer Vision Techniques in the Agriculture and Food Industry},
  author = {Gomes, Juliana and Leta, Fabiana},
  year = {2012},
  month = dec,
  journal = {European Food Research \& Technology},
  volume = {235},
  number = {6},
  pages = {989--1000},
  publisher = {Springer Nature},
  issn = {14382377},
  doi = {10.1007/s00217-012-1844-2},
  urldate = {2022-11-06},
  abstract = {Over the last decades, parallel to technological development, there has been a great increase in the use of visual inspection systems. These systems have been widely implemented, particularly in the stage of inspection of product quality, as a means of replacing manual inspection conducted by humans. Much research has been published proposing the use of such tools in the processes of sorting and classification of food products. This paper presents a review of the main publications in the last ten years with respect to new technologies and to the wide application of systems of visual inspection in the sectors of precision farming and in the food industry.},
  keywords = {AGRICULTURAL industries,Computational vision,COMPUTER vision,Food,Food industry,FOOD industry,Image analysis,INSPECTION & review,Precision farming,PRECISION farming,TECHNOLOGICAL innovations,Visual inspection}
}

@article{gomesCOMPARINGSINGLESENSORCAMERA2021,
  title = {{{COMPARING A SINGLE-SENSOR CAMERA WITH A MULTISENSOR CAMERA FOR MONITORING COFFEE CROP USING UNMANNED AERIAL VEHICLES}}},
  author = {Gomes, Amanda P. A. and de Queiroz, Daniel M. and Valente, Domingos S. M. and Pinto, Francisco de A. de C. and Rosas, Jorge T. F.},
  year = {2021},
  month = feb,
  journal = {Engenharia Agr{\'i}cola},
  volume = {41},
  number = {1},
  pages = {87--97},
  issn = {1809-4430, 0100-6916},
  doi = {10.1590/1809-4430-eng.agric.v41n1p87-97/2021},
  urldate = {2022-09-17},
  abstract = {There exist two options for digital cameras that can capture the near-infrared (NIR) band. Conventional red--green--blue (RGB, visible bands) cameras with a single sensor provide NIR band visibility based on the removal of the internal NIR-blocking filter. Alternatively, multisensor cameras exist that have a specific sensor for each band. The modified RGB cameras are of a lower price. In this context, the objective of this study was to compare the performance of a modified RGB camera with that of a multisensor camera for obtaining the normalized difference vegetation index (NDVI) in an area with coffee cultivations. A multispectral camera with five sensors and another camera with only one sensor were used. The NDVI of the coffee field was also measured using the GreenSeeker handheld NDVI sensor manufactured by Trimble. The images were calibrated radiometrically based on the targets in shades of gray made of napa, and the NDVI was calculated after image calibration. The calibration curves showed a high coefficient of determination. The NDVI value obtained with the calibrated images from the cameras showed a significant correlation with the values obtained by the GreenSeeker NDVI sensor, making it possible to obtain the variability pattern of the vegetation index. However, the NDVI obtained using the multisensor camera was closer to the NDVI obtained by the GreenSeeker NDVI sensor.},
  langid = {english}
}

@article{gomesCOMPARINGSINGLESENSORCAMERA2021a,
  title = {{{COMPARING A SINGLE-SENSOR CAMERA WITH A MULTISENSOR CAMERA FOR MONITORING COFFEE CROP USING UNMANNED AERIAL VEHICLES}}},
  author = {Gomes, Amanda P. A. and de Queiroz, Daniel M. and Valente, Domingos S. M. and Pinto, Francisco de A. de C. and Rosas, Jorge T. F.},
  year = {2021},
  month = mar,
  journal = {Engenharia Agr{\'i}cola},
  volume = {41},
  pages = {87--97},
  publisher = {Associa{\c c}{\~a}o Brasileira de Engenharia Agr{\'i}cola},
  issn = {0100-6916, 1809-4430},
  doi = {10.1590/1809-4430-Eng.Agric.v41n1p87-97/2021},
  urldate = {2023-03-29},
  abstract = {ABSTRACT There exist two options for digital cameras that can capture the near-infrared (NIR) band. Conventional red--green--blue (RGB, visible bands) cameras with a single sensor provide NIR band visibility based on the removal of the internal NIR-blocking filter. Alternatively, multisensor cameras exist that have a specific sensor for each band. The modified RGB cameras are of a lower price. In this context, the objective of this study was to compare the performance of a modified RGB camera with that of a multisensor camera for obtaining the normalized difference vegetation index (NDVI) in an area with coffee cultivations. A multispectral camera with five sensors and another camera with only one sensor were used. The NDVI of the coffee field was also measured using the GreenSeeker handheld NDVI sensor manufactured by Trimble. The images were calibrated radiometrically based on the targets in shades of gray made of napa, and the NDVI was calculated after image calibration. The calibration curves showed a high coefficient of determination. The NDVI value obtained with the calibrated images from the cameras showed a significant correlation with the values obtained by the GreenSeeker NDVI sensor, making it possible to obtain the variability pattern of the vegetation index. However, the NDVI obtained using the multisensor camera was closer to the NDVI obtained by the GreenSeeker NDVI sensor.},
  langid = {english},
  keywords = {modified RGB camera,precision agriculture,radiometric calibration,UAV}
}

@article{gomez-zamanilloDamageAssessmentSoybean2023,
  title = {Damage Assessment of Soybean and Redroot Amaranth Plants in Greenhouse through Biomass Estimation and Deep Learning-Based Symptom Classification},
  author = {{G{\'o}mez-Zamanillo}, Laura and {Bereciartua-P{\'e}rez}, Arantza and Pic{\'o}n, Artzai and Parra, Liliana and Oldenbuerger, Marian and {Navarra-Mestre}, Ram{\'o}n and Klukas, Christian and Eggers, Till and Echazarra, Jone},
  year = {2023},
  month = oct,
  journal = {Smart Agricultural Technology},
  volume = {5},
  pages = {100243},
  issn = {2772-3755},
  doi = {10.1016/j.atech.2023.100243},
  urldate = {2023-08-31},
  abstract = {Greenhouse plant assessment is key part in the process of developing and testing new herbicides as it serves to analyze the response of the species to those different products and doses in a controlled way. With that purpose, trials are carried out in greenhouse where the damage in the treated plants is daily assessed. This assessment of every pot is often performed in comparison with an untreated reference pot, also named as control pot. This assessment is currently done pot by pot through a time-consuming process which consists of visual assessments done by experts in the field. Digital tools to reduce time and to endow the experts with more objective and repetitive methods for establishing the damage in the plants are required. A novel solution based on image processing and deep learning techniques is proposed to estimate the damage in the plants in different growing stages in the greenhouse. Different damage types and in different stages are produced in plants and images of them are acquired to create a dataset. The available annotation is the damage estimation value provided by the experts. The proposed methodology tries to emulate the way the experts estimate the damage over the plants through a two-step procedure. First, the biomass reduction of the assessed plant compared to the corresponding control plant is calculated, and secondly, the possible disease symptoms in the plant are detected. The first part is done using classical image processing techniques and the second part relies on a deep learning based multi-label classification model for symptom classification. The algorithm has been tested over two species: Glycine max (soybean) and Amaranthus retroflexus (redroot amaranth). An R2 of 0.87 and 0.89 respectively is obtained for the damage estimation. The method improves the performance of the current manual process in terms of efficiency and objectivity.},
  keywords = {Convolutional neural network (CNN),Deep learning,Greenhouse,Image processing,Multi-label classification,Plant damage estimation},
  file = {/home/samuelebumbaca/Zotero/storage/6WXQW4U8/S2772375523000734.html}
}

@article{gradyRandomWalksImage2006,
  title = {Random {{Walks}} for {{Image Segmentation}}},
  author = {Grady, L.},
  year = {2006},
  month = nov,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {28},
  number = {11},
  pages = {1768--1783},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2006.233},
  abstract = {A novel method is proposed for performing multilabel, interactive image segmentation. Given a small number of pixels with user-defined (or predefined) labels, one can analytically and quickly determine the probability that a random walker starting at each unlabeled pixel will first reach one of the prelabeled pixels. By assigning each pixel to the label for which the greatest probability is calculated, a high-quality image segmentation may be obtained. Theoretical properties of this algorithm are developed along with the corresponding connections to discrete potential theory and electrical circuits. This algorithm is formulated in discrete space (i.e., on a graph) using combinatorial analogues of standard operators and principles from continuous potential theory, allowing it to be applied in arbitrary dimension on arbitrary graphs},
  keywords = {boundary completion.,Circuits,combinatorial Dirichlet problem,Electric potential,graph cuts,graph theory,Graph theory,harmonic functions,Image segmentation,interactive segmentation,Iterative algorithms,Laplace equation,Laplace equations,Pixel,Probability,random walks,Sparse matrices,Symmetric matrices},
  file = {/home/samuelebumbaca/Zotero/storage/K47FXIFB/1704833.html}
}

@article{gresselTechnicalManualParasitic2002,
  title = {A {{Technical Manual}} for {{Parasitic Weed Research}} and {{Extension}}: {{Edited}} by {{J}}. {{Kroschel}}, {{Kluwer}}, {{Dordrecht}}, 2001, 256 Pp. and 18 Color Plates, {{ISBN-0-7923-6880-0}} ({{Price}}: {{EUR}} 130, {{US}}\$ 113, {{GB}} 79; Hard Cover Only)},
  shorttitle = {A {{Technical Manual}} for {{Parasitic Weed Research}} and {{Extension}}},
  author = {Gressel, Jonathan},
  year = {2002},
  month = feb,
  journal = {Plant Science},
  volume = {162},
  number = {2},
  pages = {325--326},
  issn = {0168-9452},
  doi = {10.1016/S0168-9452(01)00544-1},
  urldate = {2022-11-10},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/S83K7FFE/S0168945201005441.html}
}

@inproceedings{griwodzAliceVisionMeshroomOpensource2021,
  title = {{{AliceVision Meshroom}}: {{An}} Open-Source {{3D}} Reconstruction Pipeline},
  shorttitle = {{{AliceVision Meshroom}}},
  booktitle = {12th {{ACM Multimedia Systems Conference}} ({{MMSys}} 2021)},
  author = {Griwodz, Carsten and Gasparini, Simone and Calvet, Lilian and Gurdjos, Pierre and Castan, Fabien and Maujean, Benoit and Lanthony, Yann and de Lillo, Gregoire},
  year = {2021},
  month = sep,
  pages = {241},
  publisher = {ACM: Association for Computing Machinery},
  doi = {10.1145/3458305.3478443},
  urldate = {2023-03-24},
  abstract = {This paper introduces the Meshroom software and its underlying 3D computer vision framework AliceVision. This solution provides a photogrammetry pipeline to reconstruct 3D scenes from a set of unordered images. It also features other pipelines for fusing multi-bracketing low dynamic range images into high dynamic range, stitching multiple images into a panorama and estimating the motion of a moving camera. Meshroom's nodal architecture allows the user to customize the different pipelines to adjust them to their domain specific needs. The user can interactively add other processing nodes to modify a pipeline, export intermediate data},
  langid = {english}
}

@misc{gronneIntroductionEmbeddingClustering2022,
  title = {Introduction to {{Embedding}}, {{Clustering}}, and {{Similarity}}},
  author = {Gr{\o}nne, Mathias},
  year = {2022},
  month = oct,
  journal = {Medium},
  urldate = {2025-01-05},
  abstract = {Introduction to key elements of ML and Autoencoders: Embedding, Clustering, and Similarity.},
  howpublished = {https://towardsdatascience.com/introduction-to-embedding-clustering-and-similarity-11dd80b00061},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/IAHTL8W4/introduction-to-embedding-clustering-and-similarity-11dd80b00061.html}
}

@article{gumGuideExpressionUncertainty,
  title = {Guide to the Expression of Uncertainty in Measurement - {{Part}} 6: {{Developing}} and Using Measurement Models},
  author = {Gum, Jcgm},
  langid = {english}
}

@article{guoIlluminationInvariantSegmentation2013,
  title = {Illumination Invariant Segmentation of Vegetation for Time Series Wheat Images Based on Decision Tree Model},
  author = {Guo, Wei and Rage, Uday K. and Ninomiya, Seishi},
  year = {2013},
  month = aug,
  journal = {Computers and Electronics in Agriculture},
  volume = {96},
  pages = {58--66},
  issn = {0168-1699},
  doi = {10.1016/j.compag.2013.04.010},
  urldate = {2023-01-13},
  abstract = {Effective and efficient segmentation of vegetation from digital plant images is an actively studied topic in crop phenotyping. Many of the formerly proposed methods showed good performance in the extraction under controlled light conditions but it is still hard to properly extract only vegetation from RGB images taken under natural light condition where the images can contain shadowed and lighted parts with specularly reflected parts of plants. In this paper, we propose a robust method to extract vegetation from the plant images taken under natural light conditions using wheat images. The method is based on a machine learning process, decision tree and image noise reduction filters. We adopted the CART algorithm to create a decision tree in the training process and examined its performance using test images, comparing it with the performances of other methods such as ExG, ExG-ExR and Modified ExG which are widely used recently. The results showed that the accuracy of the vegetation extraction by the proposed method was significantly better than that of the other methods particularly for the images which include strongly shadowed and specularly reflected parts. The proposed method also has an advantage that the same model can be applied to different images without requiring a threshold adjustment for each image.},
  langid = {english},
  keywords = {Machine learning,Natural light condition,Non-thresholding,Specular reflection,Vegetation segmentation}
}

@article{haDeepConvolutionalNeural2017,
  title = {Deep Convolutional Neural Network for Classifying {{Fusarium}} Wilt of Radish from Unmanned Aerial Vehicles},
  author = {Ha, Jin Gwan and Moon, Hyeonjoon and Kwak, Jin Tae and Hassan, Syed Ibrahim and Dang, Minh and Lee, O. New and Park, Han Yong},
  year = {2017},
  month = dec,
  journal = {Journal of Applied Remote Sensing},
  volume = {11},
  number = {4},
  pages = {042621},
  publisher = {SPIE},
  issn = {1931-3195, 1931-3195},
  doi = {10.1117/1.JRS.11.042621},
  urldate = {2023-01-13},
  abstract = {Recently, unmanned aerial vehicles (UAVs) have gained much attention. In particular, there is a growing interest in utilizing UAVs for agricultural applications such as crop monitoring and management. We propose a computerized system that is capable of detecting Fusarium wilt of radish with high accuracy. The system adopts computer vision and machine learning techniques, including deep learning, to process the images captured by UAVs at low altitudes and to identify the infected radish. The whole radish field is first segmented into three distinctive regions (radish, bare ground, and mulching film) via a softmax classifier and K-means clustering. Then, the identified radish regions are further classified into healthy radish and Fusarium wilt of radish using a deep convolutional neural network (CNN). In identifying radish, bare ground, and mulching film from a radish field, we achieved an accuracy of {$\geq$}97.4\%. In detecting Fusarium wilt of radish, the CNN obtained an accuracy of 93.3\%. It also outperformed the standard machine learning algorithm, obtaining 82.9\% accuracy. Therefore, UAVs equipped with computational techniques are promising tools for improving the quality and efficiency of agriculture today.}
}

@article{hajamEffectiveEnsembleConvolutional2023,
  title = {An {{Effective Ensemble Convolutional Learning Model}} with {{Fine-Tuning}} for {{Medicinal Plant Leaf Identification}}},
  author = {Hajam, Mohd Asif and Arif, Tasleem and Khanday, Akib Mohi Ud Din and Neshat, Mehdi},
  year = {2023},
  month = nov,
  journal = {Information},
  volume = {14},
  number = {11},
  pages = {618},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2078-2489},
  doi = {10.3390/info14110618},
  urldate = {2024-01-25},
  abstract = {Accurate and efficient medicinal plant image classification is of utmost importance as these plants produce a wide variety of bioactive compounds that offer therapeutic benefits. With a long history of medicinal plant usage, different parts of plants, such as flowers, leaves, and roots, have been recognized for their medicinal properties and are used for plant identification. However, leaf images are extensively used due to their convenient accessibility and are a major source of information. In recent years, transfer learning and fine-tuning, which use pre-trained deep convolutional networks to extract pertinent features, have emerged as an extremely effective approach for image-identification problems. This study leveraged the power by three-component deep convolutional neural networks, namely VGG16, VGG19, and DenseNet201, to derive features from the input images of the medicinal plant dataset, containing leaf images of 30 classes. The models were compared and ensembled to make four hybrid models to enhance the predictive performance by utilizing the averaging and weighted averaging strategies. Quantitative experiments were carried out to evaluate the models on the Mendeley Medicinal Leaf Dataset. The resultant ensemble of VGG19+DensNet201 with fine-tuning showcased an enhanced capability in identifying medicinal plant images with an improvement of 7.43\% and 5.8\% compared with VGG19 and VGG16. Furthermore, VGG19+DensNet201 can outperform its standalone counterparts by achieving an accuracy of 99.12\% on the test set. A thorough assessment with metrics such as accuracy, recall, precision, and the F1-score firmly established the effectiveness of the ensemble strategy.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {ensemble convolutional learning,fine-tuning,medicinal plant identification,multiclass classification,transfer learning}
}

@article{hamdaneComparisonProximalRemote2022,
  title = {Comparison of {{Proximal Remote Sensing Devices}} of {{Vegetable Crops}} to {{Determine}} the {{Role}} of {{Grafting}} in {{Plant Resistance}} to {{Meloidogyne}} Incognita},
  author = {Hamdane, Yassine and {Gracia-Romero}, Adrian and Buchaillot, Maria Luisa and {Sanchez-Bragado}, Rut and Fullana, Aida Magdalena and Sorribas, Francisco Javier and Araus, Jos{\'e} Luis and Kefauver, Shawn C.},
  year = {2022},
  month = apr,
  journal = {Agronomy},
  volume = {12},
  number = {5},
  pages = {1098},
  issn = {2073-4395},
  doi = {10.3390/agronomy12051098},
  urldate = {2022-09-19},
  abstract = {Proximal remote sensing devices are novel tools that enable the study of plant health status through the measurement of specific characteristics, including the color or spectrum of light reflected or transmitted by the leaves or the canopy. The aim of this study is to compare the RGB and multispectral data collected during five years (2016--2020) of four fruiting vegetables (melon, tomato, eggplant, and peppers) with trial treatments of non-grafted and grafted onto resistant rootstocks cultivated in a Meloidogyne incognita (a root-knot nematode) infested soil in a greenhouse. The proximal remote sensing of plant health status data collected was divided into three levels. Firstly, leaf level pigments were measured using two different handheld sensors (SPAD and Dualex). Secondly, canopy vigor and biomass were assessed using vegetation indices derived from RGB images and the Normalized Difference Vegetation Index (NDVI) measured with a portable spectroradiometer (Greenseeker). Third, we assessed plant level water stress, as a consequence of the root damage by nematodes, using stomatal conductance measured with a porometer and indirectly using plant temperature with an infrared thermometer, and also the stable carbon isotope composition of leaf dry matter.. It was found that the interaction between treatments and crops (ANOVA) was statistically different for only four of seventeen parameters: flavonoid (p {$<$} 0.05), NBI (p {$<$} 0.05), NDVI (p {$<$} 0.05) and the RGB CSI (Crop Senescence Index) (p {$<$} 0.05). Concerning the effect of treatments across all crops, differences existed only in two parameters, which were flavonoid (p {$<$} 0.05) and CSI (p {$<$} 0.001). Grafted plants contained fewer flavonoids (x{\textasciimacron} = 1.37) and showed lower CSI (x{\textasciimacron} = 11.65) than non-grafted plants (x{\textasciimacron} = 1.98 and x{\textasciimacron} = 17.28, respectively, p {$<$} 0.05 and p {$<$} 0.05) when combining all five years and four crops. We conclude that the grafted plants were less stressed and more protected against nematode attack. Leaf flavonoids content and the CSI index were robust indicators of root-knot nematode impacts across multiple crop types.},
  langid = {english}
}

@article{hansenMultispectralRadiometrySource1992,
  title = {Multispectral Radiometry {{A}} Source of Additional Data in Field Fungicide Trials},
  author = {Hansen, {\relax JG} and J{\o}rgensen, {\relax LN} and Simonsen, J},
  year = {1992},
  journal = {Statens Planteavlsfors{\o}g},
  pages = {39}
}

@book{hartleyMultipleViewGeometry2004,
  title = {Multiple {{View Geometry}} in {{Computer Vision}}},
  author = {Hartley, Richard and Zisserman, Andrew},
  year = {2004},
  edition = {2},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9780511811685},
  urldate = {2023-03-23},
  abstract = {A basic problem in computer vision is to understand the structure of a real world scene given several images of it. Techniques for solving this problem are taken from projective geometry and photogrammetry. Here, the authors cover the geometric principles and their algebraic representation in terms of camera projection matrices, the fundamental matrix and the trifocal tensor. The theory and methods of computation of these entities are discussed with real examples, as is their use in the reconstruction of scenes from multiple images. The new edition features an extended introduction covering the key ideas in the book (which itself has been updated with additional examples and appendices) and significant new results which have appeared since the first edition. Comprehensive background material is provided, so readers familiar with linear algebra and basic numerical methods can understand the projective geometry and estimation algorithms presented, and implement the algorithms directly from the book.},
  isbn = {978-0-521-54051-3},
  file = {/home/samuelebumbaca/Zotero/storage/FVTPY22J/0B6F289C78B2B23F596CAA76D3D43F7A.html}
}

@misc{HarvestMasterJuniper,
  title = {Harvest {{Master}} by {{Juniper Systems}}},
  urldate = {2022-09-19},
  howpublished = {https://www.harvestmaster.com/},
  file = {/home/samuelebumbaca/Zotero/storage/N77UMA5J/www.harvestmaster.com.html}
}

@article{hasanbelliuInformationTheoreticShape2014,
  title = {Information {{Theoretic Shape Matching}}},
  author = {Hasanbelliu, Erion and Giraldo, Luis Sanchez and Principe, Jose C.},
  year = {2014},
  month = dec,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {36},
  number = {12},
  pages = {2436--2451},
  issn = {0162-8828, 2160-9292},
  doi = {10.1109/TPAMI.2014.2324585},
  urldate = {2021-12-19}
}

@book{hastieElementsStatisticalLearning2009,
  title = {The {{Elements}} of {{Statistical Learning}}},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year = {2009},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {Springer},
  address = {New York, NY},
  doi = {10.1007/978-0-387-84858-7},
  urldate = {2025-03-16},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-0-387-84857-0 978-0-387-84858-7},
  keywords = {Averaging,Boosting,classification,clustering,data mining,machine learning,Projection pursuit,Random Forest,supervised learning,Support Vector Machine,unsupervised learning}
}

@inproceedings{heExemplarbasedCRFMultiinstance2014,
  title = {An {{Exemplar-based CRF}} for {{Multi-instance Object Segmentation}}},
  booktitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {He, Xuming and Gould, Stephen},
  year = {2014},
  pages = {296--303},
  urldate = {2023-01-13}
}

@article{hillnhutterRemoteSensingDetect2011,
  title = {Remote Sensing to Detect Plant Stress Induced by {{Heterodera}} Schachtii and {{Rhizoctonia}} Solani in Sugar Beet Fields},
  author = {Hillnh{\"u}tter, C. and Mahlein, A. -K. and Sikora, R. A. and Oerke, E. -C.},
  year = {2011},
  month = apr,
  journal = {Field Crops Research},
  volume = {122},
  number = {1},
  pages = {70--77},
  issn = {0378-4290},
  doi = {10.1016/j.fcr.2011.02.007},
  urldate = {2023-01-13},
  abstract = {The characteristically clustered occurrence and low level of mobility of Heterodera schachtii and Rhizoctonia solani in the soil and the induction of stress symptoms in the sugar beet canopy make them ideal targets for site-specific arrangements with precision agriculture tools. A field site infested with H. schachtii and R. solani was investigated in 2009 with near-range and aerial hyperspectral sensors during the growing season. At 31 sample points ground truth data for incidence and severity of the two organisms were collected and geo-referenced. Spectral vegetation indices computed from reflectance measurements obtained from two flight campaigns (AISA, 17th of June; HyMap, 28th of August) and the near-range spectroradiometers were significantly correlated (P{$<$}0.01) with symptoms caused by the nematode or Rhizoctonia crown and root rot. A supervised classification with Spectral Angle Mapper of leaf symptoms induced by the organisms resulted in a classification accuracy of 72 and 64\% for the AISA and HyMap data, respectively. The results demonstrated that remote sensing in combination with geographic information system technologies can be used effectively for the detection and mapping of symptoms caused by beet cyst nematode and Rhizoctonia crown and root rot.},
  langid = {english},
  keywords = {Hyperspectral,Nematode,Soil-borne pathogens,Supervised classification,Vegetation indices}
}

@inproceedings{hirschmullerAccurateEfficientStereo2005,
  title = {Accurate and Efficient Stereo Processing by Semi-Global Matching and Mutual Information},
  booktitle = {2005 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}}'05)},
  author = {Hirschmuller, H.},
  year = {2005},
  month = jun,
  volume = {2},
  pages = {807-814 vol. 2},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2005.56},
  abstract = {This paper considers the objectives of accurate stereo matching, especially at object boundaries, robustness against recording or illumination changes and efficiency of the calculation. These objectives lead to the proposed semi-global matching method that performs pixelwise matching based on mutual information and the approximation of a global smoothness constraint. Occlusions are detected and disparities determined with sub-pixel accuracy. Additionally, an extension for multi-baseline stereo images is presented. There are two novel contributions. Firstly, a hierarchical calculation of mutual information based matching is shown, which is almost as fast as intensity based matching. Secondly, an approximation of a global cost calculation is proposed that can be performed in a time that is linear to the number of pixels and disparities. The implementation requires just 1 second on typical images.},
  keywords = {Belief propagation,Costs,Geometry,Image reconstruction,Lighting,Mutual information,Pixel,Reflection,Robustness,Stereo vision},
  file = {/home/samuelebumbaca/Zotero/storage/9CIE4QMZ/1467526.html}
}

@article{hirschmullerStereoProcessingSemiglobal2008,
  title = {Stereo {{Processing}} by {{Semiglobal Matching}} and {{Mutual Information}}},
  author = {Hirschmuller, H.},
  year = {2008},
  month = feb,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {30},
  number = {2},
  pages = {328--341},
  issn = {0162-8828},
  doi = {10.1109/TPAMI.2007.1166},
  urldate = {2022-11-24},
  abstract = {This paper describes the Semi-Global Matching (SGM) stereo method. It uses a pixelwise, Mutual Information based matching cost for compensating radiometric differences of input images. Pixelwise matching is supported by a smoothness constraint that is usually expressed as a global cost function. SGM performs a fast approximation by pathwise optimizations from all directions. The discussion also addresses occlusion detection, subpixel refinement and multi-baseline matching. Additionally, postprocessing steps for removing outliers, recovering from specific problems of structured environments and the interpolation of gaps are presented. Finally, strategies for processing almost arbitrarily large images and fusion of disparity images using orthographic projection are proposed.},
  langid = {english}
}

@article{hughesOpenAccessRepository,
  title = {An Open Access Repository of Images on Plant Health to Enable the Development of Mobile Disease Diagnostics},
  author = {Hughes, David P and Salath{\'e}, Marcel},
  abstract = {Human society needs to increase food production by an estimated 70\% by 2050 to feed an expected population size that is predicted to be over 9 billion people. Currently, infectious diseases reduce the potential yield by an average of 40\% with many farmers in the developing world experiencing yield losses as high as 100\%. The widespread distribution of smartphones among crop growers around the world with an expected 5 billion smartphones by 2020 offers the potential of turning the smartphone into a valuable tool for diverse communities growing food. One potential application is the development of mobile disease diagnostics through machine learning and crowdsourcing. Here we announce the release of over 50,000 expertly curated images on healthy and infected leaves of crops plants through the existing online platform PlantVillage. We describe both the data and the platform. These data are the beginning of an on-going, crowdsourcing effort to enable computer vision approaches to help solve the problem of yield losses in crop plants due to infectious diseases.},
  langid = {english}
}

@article{huizingaPCAbasedGroupwiseImage2016,
  title = {{{PCA-based}} Groupwise Image Registration for Quantitative {{MRI}}},
  author = {Huizinga, W. and Poot, D.H.J. and Guyader, J.-M. and Klaassen, R. and Coolen, B.F. and {van Kranenburg}, M. and {van Geuns}, R.J.M. and Uitterdijk, A. and Polfliet, M. and Vandemeulebroucke, J. and Leemans, A. and Niessen, W.J. and Klein, S.},
  year = {2016},
  month = apr,
  journal = {Medical Image Analysis},
  volume = {29},
  pages = {65--78},
  issn = {13618415},
  doi = {10.1016/j.media.2015.12.004},
  urldate = {2021-12-19},
  langid = {english}
}

@misc{HyperspectralRemoteSensing,
  title = {Hyperspectral Remote Sensing of Plant Pigments {\textbar} {{Journal}} of {{Experimental Botany}} {\textbar} {{Oxford Academic}}},
  urldate = {2023-01-13},
  howpublished = {https://academic.oup.com/jxb/article/58/4/855/424429}
}

@misc{HyperspectralRemoteSensinga,
  title = {Hyperspectral Remote Sensing of Plant Pigments {\textbar} {{Journal}} of {{Experimental Botany}} {\textbar} {{Oxford Academic}}},
  urldate = {2023-01-13},
  howpublished = {https://academic.oup.com/jxb/article/58/4/855/424429}
}

@misc{INISRepositorySearch,
  title = {{{INIS Repository Search}} - {{Citation}}},
  urldate = {2023-03-10},
  howpublished = {https://inis.iaea.org/search/citationdownload.aspx},
  file = {/home/samuelebumbaca/Zotero/storage/I37FITUG/citationdownload.html}
}

@article{InterpretationStructureMotion1979,
  title = {The Interpretation of Structure from Motion},
  year = {1979},
  month = jan,
  journal = {Proceedings of the Royal Society of London. Series B. Biological Sciences},
  volume = {203},
  number = {1153},
  pages = {405--426},
  issn = {0080-4649, 2053-9193},
  doi = {10.1098/rspb.1979.0006},
  urldate = {2022-01-31},
  abstract = {The interpretation of structure from motion is examined from a computional point of view. The question addressed is how the three dimen\-sional structure and motion of objects can be inferred from the two dimensional transformations of their projected images when no three dimensional information is conveyed by the individual projections. The following scheme is proposed: (i) divide the image into groups of four elements each; (ii) test each group for a rigid interpretation; (iii) combine the results obtained in (ii). It is shown that this scheme will correctly decompose scenes containing arbitrary rigid objects in motion, recovering their three dimensional structure and motion. The analysis is based primarily on the 'structure from motion' theorem which states that the structure of four non-coplanar points is recoverable from three orthographic projections. The interpretation scheme is extended to cover perspective projections, and its psychological relevance is discussed.},
  langid = {english}
}

@article{jacquemoudPROSPECTModelLeaf1990,
  title = {{{PROSPECT}}: {{A}} Model of Leaf Optical Properties Spectra},
  shorttitle = {{{PROSPECT}}},
  author = {Jacquemoud, S. and Baret, F.},
  year = {1990},
  month = nov,
  journal = {Remote Sensing of Environment},
  volume = {34},
  number = {2},
  pages = {75--91},
  issn = {0034-4257},
  doi = {10.1016/0034-4257(90)90100-Z},
  urldate = {2023-01-13},
  abstract = {PROSPECT is a radiative transfer model based of Allen's generalized ``plate model'' that represents the optical properties of plant leaves from 400 nm to 2500 nm. Scattering is described by a spectral refractive index (n) and a parameter characterizing the leaf mesophyll structure (N). Absorption is modeled using pigment concentration (Ca+b), water content (Cw), and the corresponding specific spectral absorption coefficients (Ka+b and Kw). The parameters n, Ka+b, and Kw have been fitted using experimental data corresponding to a wide range of plant types and status. PROSPECT has been tested successfully on independent data sets. Its inversion allows one to reconstruct, with reasonable accuracy, leaf reflectance, and transmittance features in the 400--2500 nm range by adjusting the three input variables N, Ca+b, and Cw.},
  langid = {english}
}

@article{jamesAssessmentPlantDiseases1974,
  title = {Assessment of {{Plant Diseases}} and {{Losses}}},
  author = {James, W C},
  year = {1974},
  journal = {Annual Review of Phytopathology},
  volume = {12},
  number = {1},
  pages = {27--48},
  doi = {10.1146/annurev.py.12.090174.000331},
  urldate = {2023-01-13}
}

@book{jamesIntroductionStatisticalLearning2023,
  title = {An {{Introduction}} to {{Statistical Learning}}: With {{Applications}} in {{Python}}},
  shorttitle = {An {{Introduction}} to {{Statistical Learning}}},
  author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert and Taylor, Jonathan},
  year = {2023},
  series = {Springer {{Texts}} in {{Statistics}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-38747-0},
  urldate = {2025-03-16},
  copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
  isbn = {978-3-031-38746-3 978-3-031-38747-0},
  langid = {english},
  keywords = {data mining,inference,Python,Python software,statistical learning,supervised learning,unsupervsied learning}
}

@article{jayEstimatingLeafChlorophyll2017,
  title = {Estimating Leaf Chlorophyll Content in Sugar Beet Canopies Using Millimeter- to Centimeter-Scale Reflectance Imagery},
  author = {Jay, Sylvain and Gorretta, Nathalie and Morel, Julien and Maupas, Fabienne and Bendoula, Ryad and Rabatel, Gilles and Dutartre, Dan and Comar, Alexis and Baret, Fr{\'e}d{\'e}ric},
  year = {2017},
  month = sep,
  journal = {Remote Sensing of Environment},
  volume = {198},
  pages = {173--186},
  issn = {0034-4257},
  doi = {10.1016/j.rse.2017.06.008},
  urldate = {2023-01-13},
  abstract = {Accurate estimation of leaf chlorophyll content (Cab) from remote sensing is of tremendous significance to monitor the physiological status of vegetation or to estimate primary production. Many vegetation indices (VIs) have been developed to retrieve Cab at the canopy level from meter- to decameter-scale reflectance observations. However, most of these VIs may be affected by the possible confounding influence of canopy structure. The objective of this study is to develop methods for Cab estimation using millimeter to centimeter spatial resolution reflectance imagery acquired at the field level. Hyperspectral images were acquired over sugar beet canopies from a ground-based platform in the 400--1000nm range, concurrently to Cab, green fraction (GF), green area index (GAI) ground measurements. The original image spatial resolution was successively degraded from 1mm to 35cm, resulting in eleven sets of hyperspectral images. Vegetation and soil pixels were discriminated, and for each spatial resolution, measured Cab values were related to various VIs computed over four sets of reflectance spectra extracted from the images (soil and vegetation pixels, only vegetation pixels, 50\% darkest and brightest vegetation pixels). The selected VIs included some classical VIs from the literature as well as optimal combinations of spectral bands, including simple ratio (SR), modified normalized difference (mND) and structure insensitive pigment index (SIPI). In the case of mND and SIPI, the use of a blue reference band instead of the classical near-infrared one was also investigated. For the eleven spatial resolutions, the four pixel selections and the five VI formats, similar band combinations are obtained when optimizing VI performances: the main bands of interest are generally located in the blue, red, red-edge and near-infrared domains. Overall, mNDblue[728,850] defined as (R440-R728)/(R440+R850) and computed over the brightest green pixels obtains the best correlations with Cab for spatial resolutions finer than 8.8cm with a root mean square error of prediction better than 2.6{$\mu$}g/cm2. Conversely, mNDblue[728,850] poorly correlates with variations in GF and GAI, thus reducing the risk of deriving non-causal relationships with Cab that would actually be due to the covariance between Cab and these canopy structure variables. As mNDblue[728,850] can be calculated from most current multispectral sensors, it is therefore a promising VI to retrieve Cab from millimeter- to centimeter-scale reflectance imagery.},
  langid = {english},
  keywords = {Leaf chlorophyll content,Millimeter to centimeter spatial resolutions,mND,Reflectance imagery,Vegetation index}
}

@article{jayPhysicallybasedModelRetrieving2016,
  title = {A Physically-Based Model for Retrieving Foliar Biochemistry and Leaf Orientation Using Close-Range Imaging Spectroscopy},
  author = {Jay, Sylvain and Bendoula, Ryad and Hadoux, Xavier and F{\'e}ret, Jean-Baptiste and Gorretta, Nathalie},
  year = {2016},
  month = may,
  journal = {Remote Sensing of Environment},
  volume = {177},
  pages = {220--236},
  issn = {0034-4257},
  doi = {10.1016/j.rse.2016.02.029},
  urldate = {2023-01-13},
  abstract = {Radiative transfer models have long been used to characterize the foliar content at the leaf and canopy levels. However, they still do not apply well to close-range imaging spectroscopy, especially because directional effects are usually not taken into account. For this purpose, we introduce a physical approach to describe and simulate the variation in leaf reflectance observed at this scale. Two parameters are thus introduced to represent (1) specular reflection at the leaf surface and (2) local leaf orientation. The model, called COSINE (ClOse-range Spectral ImagiNg of lEaves), can be coupled with a directional--hemispherical reflectance model of leaf optical properties to relate the measured reflectance to the foliar content. In this study, we show that, when combining COSINE with the PROSPECT model, the overall PROCOSINE model allows for a robust submillimeter retrieval of foliar content based on numerical inversion and pseudo-bidirectional reflectance factor hyperspectral measurements. The relevance of the added parameters is first shown through a sensitivity analysis performed in the visible and near-infrared (VNIR) and shortwave infrared (SWIR) ranges. PROCOSINE is then validated based on VNIR and SWIR hyperspectral images of various leaf species exhibiting different surface properties. Introducing these two parameters within the inversion allows us to obtain accurate maps of PROSPECT parameters, e.g., the chlorophyll content in the VNIR range, and the equivalent water thickness and leaf mass per area in the SWIR range. Through the estimation of light incident angle, the PROCOSINE inversion also provides information on leaf orientation, which is a critical parameter in vegetation remote sensing.},
  langid = {english},
  keywords = {Close-range,COSINE,Hyperspectral,Imaging spectroscopy,Leaf optical properties,Pigment retrieval,PROCOSINE,PROSPECT,Radiative transfer,Vegetation}
}

@article{jayPhysicallybasedModelRetrieving2016a,
  title = {A Physically-Based Model for Retrieving Foliar Biochemistry and Leaf Orientation Using Close-Range Imaging Spectroscopy},
  author = {Jay, Sylvain and Bendoula, Ryad and Hadoux, Xavier and F{\'e}ret, Jean-Baptiste and Gorretta, Nathalie},
  year = {2016},
  month = may,
  journal = {Remote Sensing of Environment},
  volume = {177},
  pages = {220--236},
  issn = {0034-4257},
  doi = {10.1016/j.rse.2016.02.029},
  urldate = {2023-01-13},
  abstract = {Radiative transfer models have long been used to characterize the foliar content at the leaf and canopy levels. However, they still do not apply well to close-range imaging spectroscopy, especially because directional effects are usually not taken into account. For this purpose, we introduce a physical approach to describe and simulate the variation in leaf reflectance observed at this scale. Two parameters are thus introduced to represent (1) specular reflection at the leaf surface and (2) local leaf orientation. The model, called COSINE (ClOse-range Spectral ImagiNg of lEaves), can be coupled with a directional--hemispherical reflectance model of leaf optical properties to relate the measured reflectance to the foliar content. In this study, we show that, when combining COSINE with the PROSPECT model, the overall PROCOSINE model allows for a robust submillimeter retrieval of foliar content based on numerical inversion and pseudo-bidirectional reflectance factor hyperspectral measurements. The relevance of the added parameters is first shown through a sensitivity analysis performed in the visible and near-infrared (VNIR) and shortwave infrared (SWIR) ranges. PROCOSINE is then validated based on VNIR and SWIR hyperspectral images of various leaf species exhibiting different surface properties. Introducing these two parameters within the inversion allows us to obtain accurate maps of PROSPECT parameters, e.g., the chlorophyll content in the VNIR range, and the equivalent water thickness and leaf mass per area in the SWIR range. Through the estimation of light incident angle, the PROCOSINE inversion also provides information on leaf orientation, which is a critical parameter in vegetation remote sensing.},
  langid = {english},
  keywords = {Close-range,COSINE,Hyperspectral,Imaging spectroscopy,Leaf optical properties,Pigment retrieval,PROCOSINE,PROSPECT,Radiative transfer,Vegetation},
  file = {/home/samuelebumbaca/Zotero/storage/U4PV5VIP/S0034425716300566.html}
}

@article{jiangResearchAccuracyStability2015,
  title = {{[Research on Accuracy and Stability of Inversing Vegetation Chlorophyll Content by Spectral Index Method]}},
  author = {Jiang, Hai-ling and Yang, Hang and Chen, Xiao-ping and Wang, Shu-dong and Li, Xue-ke and Liu, Kai and Cen, Yi},
  year = {2015},
  month = apr,
  journal = {Guang Pu Xue Yu Guang Pu Fen Xi = Guang Pu},
  volume = {35},
  number = {4},
  pages = {975--981},
  issn = {1000-0593},
  abstract = {Spectral index method was widely applied to the inversion of crop chlorophyll content. In the present study, PSR3500 spectrometer and SPAD-502 chlorophyll fluorometer were used to acquire the spectrum and relative chlorophyll content (SPAD value) of winter wheat leaves on May 2nd 2013 when it was at the jointing stage of winter wheat. Then the measured spectra were resampled to simulate TM multispectral data and Hyperion hyperspectral data respectively, using the Gaussian spectral response function. We chose four typical spectral indices including normalized difference vegetation index (NDVD, triangle vegetation index (TVI), the ratio of modified transformed chlorophyll absorption ratio index (MCARI) to optimized soil adjusted vegetation index (OSAVI) (MCARI/OSAVI) and vegetation index based on universal pattern decomposition (VIUPD), which were constructed with the feature bands sensitive to the vegetation chlorophyll. After calculating these spectral indices based on the resampling TM and Hyperion data, the regression equation between spectral indices and chlorophyll content was established. For TM, the result indicates that VIUPD has the best correlation with chlorophyll (R2 = 0.819 7) followed by NDVI (R2 = 0.791 8), while MCARI/OSAVI and TVI also show a good correlation with R2 higher than 0.5. For the simulated Hyperion data, VIUPD again ranks first with R2 = 0.817 1, followed by MCARI/OSAVI (R2 = 0.658 6), while NDVI and TVI show very low values with R2 less than 0.2. It was demonstrated that VIUPD has the best accuracy and stability to estimate chlorophyll of winter wheat whether using simulated TM data or Hyperion data, which reaffirms that VIUPD is comparatively sensor independent. The chlorophyll estimation accuracy and stability of MCARI/OSAVI also works well, partly because OSAVI could reduce the influence of backgrounds. Two broadband spectral indices NDVI and TVI are weak for the chlorophyll estimation of simulated Hyperion data mainly because of their dependence on few bands and the strong influence of atmosphere, solar altitude, viewing angle of sensor, background and so on. In conclusion, the stability and consistency of chlorophyll estimation is equally important to the estimation accuracy by spectral index method. VIUPD introduced in the study has the best performance to estimate winter wheat chlorophyll, which illustrates its potential ability in the area of estimating vegetation biochemical parameters.},
  langid = {jpn},
  pmid = {26197586},
  keywords = {Chlorophyll,Plant Leaves,Soil,Spectrum Analysis,Triticum}
}

@article{jiangResearchAccuracyStability2015a,
  title = {{[Research on Accuracy and Stability of Inversing Vegetation Chlorophyll Content by Spectral Index Method]}},
  author = {Jiang, Hai-ling and Yang, Hang and Chen, Xiao-ping and Wang, Shu-dong and Li, Xue-ke and Liu, Kai and Cen, Yi},
  year = {2015},
  month = apr,
  journal = {Guang Pu Xue Yu Guang Pu Fen Xi = Guang Pu},
  volume = {35},
  number = {4},
  pages = {975--981},
  issn = {1000-0593},
  abstract = {Spectral index method was widely applied to the inversion of crop chlorophyll content. In the present study, PSR3500 spectrometer and SPAD-502 chlorophyll fluorometer were used to acquire the spectrum and relative chlorophyll content (SPAD value) of winter wheat leaves on May 2nd 2013 when it was at the jointing stage of winter wheat. Then the measured spectra were resampled to simulate TM multispectral data and Hyperion hyperspectral data respectively, using the Gaussian spectral response function. We chose four typical spectral indices including normalized difference vegetation index (NDVD, triangle vegetation index (TVI), the ratio of modified transformed chlorophyll absorption ratio index (MCARI) to optimized soil adjusted vegetation index (OSAVI) (MCARI/OSAVI) and vegetation index based on universal pattern decomposition (VIUPD), which were constructed with the feature bands sensitive to the vegetation chlorophyll. After calculating these spectral indices based on the resampling TM and Hyperion data, the regression equation between spectral indices and chlorophyll content was established. For TM, the result indicates that VIUPD has the best correlation with chlorophyll (R2 = 0.819 7) followed by NDVI (R2 = 0.791 8), while MCARI/OSAVI and TVI also show a good correlation with R2 higher than 0.5. For the simulated Hyperion data, VIUPD again ranks first with R2 = 0.817 1, followed by MCARI/OSAVI (R2 = 0.658 6), while NDVI and TVI show very low values with R2 less than 0.2. It was demonstrated that VIUPD has the best accuracy and stability to estimate chlorophyll of winter wheat whether using simulated TM data or Hyperion data, which reaffirms that VIUPD is comparatively sensor independent. The chlorophyll estimation accuracy and stability of MCARI/OSAVI also works well, partly because OSAVI could reduce the influence of backgrounds. Two broadband spectral indices NDVI and TVI are weak for the chlorophyll estimation of simulated Hyperion data mainly because of their dependence on few bands and the strong influence of atmosphere, solar altitude, viewing angle of sensor, background and so on. In conclusion, the stability and consistency of chlorophyll estimation is equally important to the estimation accuracy by spectral index method. VIUPD introduced in the study has the best performance to estimate winter wheat chlorophyll, which illustrates its potential ability in the area of estimating vegetation biochemical parameters.},
  langid = {jpn},
  pmid = {26197586},
  keywords = {Chlorophyll,Plant Leaves,Soil,Spectrum Analysis,Triticum}
}

@article{jinCornPlantSensing2009,
  title = {Corn Plant Sensing Using Real-Time Stereo Vision},
  author = {Jin, Jian and Tang, Lie},
  year = {2009},
  journal = {Journal of Field Robotics},
  volume = {26},
  number = {6-7},
  pages = {591--608},
  issn = {1556-4967},
  doi = {10.1002/rob.20293},
  urldate = {2023-01-13},
  abstract = {Though some two-dimensional (2D) machine vision--based systems for early-growth-stage corn plant sensing exist, some of their shortcomings are difficult to overcome. The greatest challenge comes from separating individual corn plants with overlapped plant canopies. With 2D machine vision, variation in outdoor lighting conditions and weeds in the background also pose difficulties in corn plant identification. Adding the depth dimension has the potential to improve the performance of such a sensing system. A new corn plant sensing system using a real-time stereo vision system was investigated in this research. Top-view depth images of corn plant canopy were acquired. By processing the depth images, the algorithm effectively updated the plant skeleton structures and finally recognized individual corn plants and detected their center positions. The stereo vision system was tested over corn plants of V2--V3 growth stages in both laboratory and field conditions. Experimental results showed that the stereo vision system was capable of detecting both separated and overlapped corn plants. During the field test, 96.7\% of the corn plants were correctly detected, and plant center positions were estimated with maximum distance errors of 5 and 1 cm for 74.6\% and 62.3\% of detections, respectively. {\copyright} 2009 Wiley Periodicals, Inc.},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/8PT7KKFF/rob.html}
}

@article{juGLCCGeneralFramework2023,
  title = {{{GLCC}}: {{A General Framework}} for {{Graph-Level Clustering}}},
  shorttitle = {{{GLCC}}},
  author = {Ju, Wei and Gu, Yiyang and Chen, Binqi and Sun, Gongbo and Qin, Yifang and Liu, Xingyuming and Luo, Xiao and Zhang, Ming},
  year = {2023},
  month = jun,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {37},
  number = {4},
  pages = {4391--4399},
  issn = {2374-3468},
  doi = {10.1609/aaai.v37i4.25559},
  urldate = {2025-01-13},
  abstract = {This paper studies the problem of graph-level clustering, which is a novel yet challenging task. This problem is critical in a variety of real-world applications such as protein clustering and genome analysis in bioinformatics. Recent years have witnessed the success of deep clustering coupled with graph neural networks (GNNs). However, existing methods focus on clustering among nodes given a single graph, while exploring clustering on multiple graphs is still under-explored. In this paper, we propose a general graph-level clustering framework named Graph-Level Contrastive Clustering (GLCC) given multiple graphs. Specifically, GLCC first constructs an adaptive affinity graph to explore instance- and cluster-level contrastive learning (CL). Instance-level CL leverages graph Laplacian based contrastive loss to learn clustering-friendly representations while cluster-level CL captures discriminative cluster representations incorporating neighbor information of each sample. Moreover, we utilize neighbor-aware pseudo-labels to reward the optimization of representation learning. The two steps can be alternatively trained to collaborate and benefit each other. Experiments on a range of well-known datasets demonstrate the superiority of our proposed GLCC over competitive baselines.},
  copyright = {Copyright (c) 2023 Association for the Advancement of Artificial Intelligence},
  langid = {english},
  keywords = {ML: Clustering}
}

@book{kaehlerLearningOpenCV32016,
  title = {Learning {{OpenCV}} 3: {{Computer Vision}} in {{C}}++ with the {{OpenCV Library}}},
  shorttitle = {Learning {{OpenCV}} 3},
  author = {Kaehler, Adrian and Bradski, Gary},
  year = {2016},
  month = dec,
  publisher = {"O'Reilly Media, Inc."},
  abstract = {Get started in the rapidly expanding field of computer vision with this practical guide. Written by Adrian Kaehler and Gary Bradski, creator of the open source OpenCV library, this book provides a thorough introduction for developers, academics, roboticists, and hobbyists. You'll learn what it takes to build applications that enable computers to "see" and make decisions based on that data.With over 500 functions that span many areas in vision, OpenCV is used for commercial applications such as security, medical imaging, pattern and face recognition, robotics, and factory product inspection. This book gives you a firm grounding in computer vision and OpenCV for building simple or sophisticated vision applications. Hands-on exercises in each chapter help you apply what you've learned.This volume covers the entire library, in its modern C++ implementation, including machine learning tools for computer vision.Learn OpenCV data types, array types, and array operationsCapture and store still and video images with HighGUITransform images to stretch, shrink, warp, remap, and repairExplore pattern recognition, including face detectionTrack objects and motion through the visual fieldReconstruct 3D images from stereo visionDiscover basic and advanced machine learning techniques in OpenCV},
  googlebooks = {LPm3DQAAQBAJ},
  isbn = {978-1-4919-3796-9},
  langid = {english},
  keywords = {Computers / Artificial Intelligence / Computer Vision & Pattern Recognition,Computers / Languages / C,Technology & Engineering / Robotics}
}

@article{kalyoncuGeometricLeafClassification2015,
  title = {Geometric Leaf Classification},
  author = {Kalyoncu, Cem and Toygar, {\"O}nsen},
  year = {2015},
  month = apr,
  journal = {Computer Vision and Image Understanding},
  volume = {133},
  pages = {102--109},
  issn = {1077-3142},
  doi = {10.1016/j.cviu.2014.11.001},
  urldate = {2023-01-13},
  abstract = {In this paper, we propose a novel method including segmentation, a combination of new and well-known feature extraction and classification methods to classify plant leaves. The aim of the proposed features is to distinguish leaf margins, which cannot be distinguished using commonly used geometric features. Additionally, Linear Discriminant Classifier is used for classification, therefore using features that are noisy for some leaf types does not reduce the performance of the system. The proposed system outperforms the well-known geometric methods that are used for leaf classification.},
  langid = {english},
  keywords = {Geometric features,Leaf classification,Linear Discriminant Classifier,Multi-scale distance matrix}
}

@inproceedings{katafuchiImagebasedPlantDisease2021,
  title = {Image-Based {{Plant Disease Diagnosis}} with {{Unsupervised Anomaly Detection}} Based on {{Reconstructability}} of {{Colors}}:},
  shorttitle = {Image-Based {{Plant Disease Diagnosis}} with {{Unsupervised Anomaly Detection}} Based on {{Reconstructability}} of {{Colors}}},
  booktitle = {Proceedings of the {{International Conference}} on {{Image Processing}} and {{Vision Engineering}}},
  author = {Katafuchi, Ryoya and Tokunaga, Terumasa},
  year = {2021},
  pages = {112--120},
  publisher = {{SCITEPRESS - Science and Technology Publications}},
  address = {Online Streaming, --- Select a Country ---},
  doi = {10.5220/0010463201120120},
  urldate = {2024-07-23},
  abstract = {This paper proposes an unsupervised anomaly detection technique for image-based plant disease diagnosis. The construction of large and publicly available datasets containing labeled images of healthy and diseased crop plants led to growing interest in computer vision techniques for automatic plant disease diagnosis. Although supervised image classifiers based on deep learning can be a powerful tool for plant disease diagnosis, they require a huge amount of labeled data. The data mining technique of anomaly detection includes unsupervised approaches that do not require rare samples for training classifiers. We propose an unsupervised anomaly detection technique for image-based plant disease diagnosis that is based on the reconstructability of colors; a deep encoder-decoder network trained to reconstruct the colors of healthy plant images should fail to reconstruct colors of symptomatic regions. Our proposed method includes a new image-based framework for plant disease detection that utilizes a conditional adversarial network called pix2pix and a new anomaly score based on CIEDE2000 color difference. Experiments with PlantVillage dataset demonstrated the superiority of our proposed method compared to an existing anomaly detector at identifying diseased crop images in terms of accuracy, interpretability and computational efficiency.},
  isbn = {978-989-758-511-1},
  langid = {english}
}

@article{kaurImageFusionTechniques2021,
  title = {Image {{Fusion Techniques}}: {{A Survey}}},
  shorttitle = {Image {{Fusion Techniques}}},
  author = {Kaur, Harpreet and Koundal, Deepika and Kadyan, Virender},
  year = {2021},
  month = dec,
  journal = {Archives of Computational Methods in Engineering},
  volume = {28},
  number = {7},
  pages = {4425--4447},
  issn = {1134-3060, 1886-1784},
  doi = {10.1007/s11831-021-09540-7},
  urldate = {2021-12-19},
  langid = {english}
}

@article{kawataStatisticallyHarmonizedAlignmentClassification2007,
  title = {A {{Statistically Harmonized Alignment-Classification}} in {{Image Space Enables Accurate}} and {{Robust Alignment}} of {{Noisy Images}} in {{Single Particle Analysis}}},
  author = {Kawata, M. and Sato, C.},
  year = {2007},
  month = jun,
  journal = {Journal of Electron Microscopy},
  volume = {56},
  number = {3},
  pages = {83--92},
  issn = {0022-0744, 1477-9986},
  doi = {10.1093/jmicro/dfm010},
  urldate = {2021-12-19},
  langid = {english}
}

@article{kerrImmediateIrrigationImproves2019,
  title = {Immediate {{Irrigation Improves Turfgrass Safety}} to {{Postemergence Herbicides}}},
  author = {Kerr, Robert Andrew and McCarty, Lambert B. and Brown, Philip J. and Harris, James and McElroy, J. Scott},
  year = {2019},
  month = feb,
  journal = {HortScience},
  volume = {54},
  number = {2},
  pages = {353--356},
  issn = {0018-5345, 2327-9834},
  doi = {10.21273/HORTSCI13571-18},
  urldate = {2022-09-20},
  abstract = {Summer annual grassy weeds such as goosegrass (               Eleusine indica               L. Gaertn.) continue to be problematic to control selectively with postemergence (POST) herbicides within turfgrass stands. In recent years, reduced performance by certain herbicides (e.g., foramsulfuron), cancellation of goosegrass-specific herbicides (e.g., diclofop-methyl), and cancellation and/or severe use reductions of other herbicides [e.g., monosodium methanearsonate (MSMA)] have limited the options for satisfactory control and maintenance of an acceptable ({$\leq$}30\% visual turfgrass injury) turfgrass quality. Currently available herbicides (e.g., topramezone and metribuzin) with goosegrass activity typically injure warm-season turfgrass species. The objectives of this research were to evaluate both `Tifway 419' bermudagrass [               Cynodon dactylon               (L.) Pers. {\texttimes}               Cynodon transvaalensis               Burtt-Davy] injury after treatment with POST herbicides, and to determine whether irrigating immediately after application reduces turfgrass injury. Treatments were control ({\textpm} irrigation); topramezone (Pylex 2.8C; {\textpm} irrigation); carfentrazone + 2,4-D + dicamba + 2-(2-methyl-4-chlorophenoxy) propionic acid (MCPP) (Speedzone 2.2L; {\textpm} irrigation); carfentrazone + 2,4-D + dicamba + MCPP in combination with topramezone ({\textpm} irrigation); metribuzin (Sencor 75DF; {\textpm} irrigation); mesotrione (Tenacity 4L; {\textpm} irrigation); simazine 4L ({\textpm}irrigation); and mesotrione + simazine ({\textpm} irrigation). Irrigated treatments were applied immediately with a hand hose precalibrated to apply 0.6 cm or 0.25 inch ({$\approx$}6.3 L). Visual turfgrass injury for combined herbicide treatments for the irrigated plots was 6\% 4 days after treatment (DAT), 12\% 1 week after treatment (WAT), 17\% 2 WAT, and 6\% 4 WAT, whereas nonirrigated plots had turfgrass injury of 14\% at 4 DAT, 31\% 1 WAT, 35\% 2 WAT, and 12\% 4 WAT. Irrigated pots had normalized differences vegetative indices (NDVI) ratings of 0.769 at 4 DAT, 0.644 at 1 WAT, 0.612 at 2 WAT, and 0.621 at 4 WAT, whereas nonirrigated plots had the lowest (least green) turfgrass NDVI ratings of 0.734 at 4 DAT, 0.599 at 1 WAT, 0.528 at 2 WAT, and 0.596 at 4 WAT. These experiments suggest turfgrass injury could be alleviated by immediately incorporating herbicides through irrigation.}
}

@incollection{kerstingFeedingWorldBig2016,
  title = {Feeding the {{World}} with {{Big Data}}: {{Uncovering Spectral Characteristics}} and {{Dynamics}} of {{Stressed Plants}}},
  shorttitle = {Feeding the {{World}} with {{Big Data}}},
  booktitle = {Computational {{Sustainability}}},
  author = {Kersting, Kristian and Bauckhage, Christian and Wahabzada, Mirwaes and Mahlein, Anne-Kathrin and Steiner, Ulrike and Oerke, Erich-Christian and R{\"o}mer, Christoph and Pl{\"u}mer, Lutz},
  editor = {L{\"a}ssig, J{\"o}rg and Kersting, Kristian and Morik, Katharina},
  year = {2016},
  series = {Studies in {{Computational Intelligence}}},
  pages = {99--120},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-31858-5_6},
  urldate = {2023-01-13},
  abstract = {Modern communication, sensing, and actuator technologies as well as methods from signal processing, pattern recognition, and data mining are increasingly applied in agriculture, ultimately helping to meet the challenge of ``How to feed a hungry world?'' Developments such as increased mobility, wireless networks, new environmental sensors, robots, and the computational cloud put the vision of a sustainable agriculture for anybody, anytime, and anywhere within reach. Unfortunately, data-driven agriculture also presents unique computational problems in scale and interpretability: (1) Data is gathered often at massive scale, and (2) researchers and experts of complementary skills have to cooperate in order to develop models and tools for data intensive discovery that yield easy-to-interpret insights for users that are not necessarily trained computer scientists. On the problem of mining hyperspectral images to uncover spectral characteristic and dynamics of drought stressed plants, we showcase that both challenges can be met and that big data mining can---and should---play a key role for feeding the world, while enriching and transforming data mining.},
  isbn = {978-3-319-31858-5},
  langid = {english},
  keywords = {Drought Level,Drought Stress,Drought Stress Level,Euclidean Embedding,Precision Farming}
}

@article{kienbaumDeepCobPreciseHighthroughput2021,
  title = {{{DeepCob}}: Precise and High-Throughput Analysis of Maize Cob Geometry Using Deep Learning with an Application in Genebank Phenomics},
  shorttitle = {{{DeepCob}}},
  author = {Kienbaum, Lydia and Correa Abondano, Miguel and Blas, Raul and Schmid, Karl},
  year = {2021},
  month = dec,
  journal = {Plant Methods},
  volume = {17},
  number = {1},
  pages = {91},
  issn = {1746-4811},
  doi = {10.1186/s13007-021-00787-6},
  urldate = {2021-12-18},
  abstract = {Abstract                              Background                Maize cobs are an important component of crop yield that exhibit a high diversity in size, shape and color in native landraces and modern varieties. Various phenotyping approaches were developed to measure maize cob parameters in a high throughput fashion. More recently, deep learning methods like convolutional neural networks (CNNs) became available and were shown to be highly useful for high-throughput plant phenotyping. We aimed at comparing classical image segmentation with deep learning methods for maize cob image segmentation and phenotyping using a large image dataset of native maize landrace diversity from Peru.                                            Results                                  Comparison of three image analysis methods showed that a Mask R-CNN trained on a diverse set of maize cob images was highly superior to classical image analysis using the Felzenszwalb-Huttenlocher algorithm and a Window-based CNN due to its robustness to image quality and object segmentation accuracy (                                                            \$\$r=0.99\$\$                                                                        r                          =                          0.99                                                                                                      ). We integrated Mask R-CNN into a high-throughput pipeline to segment both maize cobs and rulers in images and perform an automated quantitative analysis of eight phenotypic traits, including diameter, length, ellipticity, asymmetry, aspect ratio and average values of red, green and blue color channels for cob color. Statistical analysis identified key training parameters for efficient iterative model updating. We also show that a small number of 10--20 images is sufficient to update the initial Mask R-CNN model to process new types of cob images. To demonstrate an application of the pipeline we analyzed phenotypic variation in 19,867 maize cobs extracted from 3449 images of 2484 accessions from the maize genebank of Peru to identify phenotypically homogeneous and heterogeneous genebank accessions using multivariate clustering.                                                            Conclusions                Single Mask R-CNN model and associated analysis pipeline are widely applicable tools for maize cob phenotyping in contexts like genebank phenomics or plant breeding.},
  langid = {english}
}

@article{kierdorfLeavesEstimationOccluded2022,
  title = {Behind the {{Leaves}}: {{Estimation}} of {{Occluded Grapevine Berries With Conditional Generative Adversarial Networks}}},
  shorttitle = {Behind the {{Leaves}}},
  author = {Kierdorf, Jana and Weber, Immanuel and Kicherer, Anna and Zabawa, Laura and Drees, Lukas and Roscher, Ribana},
  year = {2022},
  month = mar,
  journal = {Frontiers in Artificial Intelligence},
  volume = {5},
  publisher = {Frontiers},
  issn = {2624-8212},
  doi = {10.3389/frai.2022.830026},
  urldate = {2025-01-06},
  abstract = {{$<$}p{$>$}The need for accurate yield estimates for viticulture is becoming more important due to increasing competition in the wine market worldwide. One of the most promising methods to estimate the harvest is berry counting, as it can be approached non-destructively, and its process can be automated. In this article, we present a method that addresses the challenge of occluded berries with leaves to obtain a more accurate estimate of the number of berries that will enable a better estimate of the harvest. We use generative adversarial networks, a deep learning-based approach that generates a highly probable scenario behind the leaves exploiting learned patterns from images with non-occluded berries. Our experiments show that the estimate of the number of berries after applying our method is closer to the manually counted reference. In contrast to applying a factor to the berry count, our approach better adapts to local conditions by directly involving the appearance of the visible berries. Furthermore, we show that our approach can identify which areas in the image should be changed by adding new berries without explicitly requiring information about hidden areas.{$<$}/p{$>$}},
  langid = {english},
  keywords = {deep learning,Domain transfer,Generative Adversarial Networks,grape generation,machine   learning,yield counting}
}

@article{kimHierarchicalAlignmentBreast2012,
  title = {Hierarchical Alignment of Breast {{DCE}}-{{MR}} Images by Groupwise Registration and Robust Feature Matching},
  author = {Kim, Minjeong and Wu, Guorong and Shen, Dinggang},
  year = {2012},
  month = jan,
  journal = {Medical Physics},
  volume = {39},
  number = {1},
  pages = {353--366},
  issn = {0094-2405, 2473-4209},
  doi = {10.1118/1.3665705},
  urldate = {2021-12-19},
  langid = {english}
}

@article{kirchgessnerETHFieldPhenotyping2016,
  title = {The {{ETH}} Field Phenotyping Platform {{FIP}}: A Cable-Suspended Multi-Sensor System},
  shorttitle = {The {{ETH}} Field Phenotyping Platform {{FIP}}},
  author = {Kirchgessner, Norbert and Liebisch, Frank and Yu, Kang and Pfeifer, Johannes and Friedli, Michael and Hund, Andreas and Walter, Achim and Kirchgessner, Norbert and Liebisch, Frank and Yu, Kang and Pfeifer, Johannes and Friedli, Michael and Hund, Andreas and Walter, Achim},
  year = {2016},
  month = oct,
  journal = {Functional Plant Biology},
  volume = {44},
  number = {1},
  pages = {154--168},
  publisher = {CSIRO PUBLISHING},
  issn = {1445-4416, 1445-4416},
  doi = {10.1071/FP16165},
  urldate = {2023-01-13},
  abstract = {Crop phenotyping is a major bottleneck in current plant research. Field-based high-throughput phenotyping platforms are an important prerequisite to advance crop breeding. We developed a cable-suspended field phenotyping platform covering an area of {\textasciitilde}1 ha. The system operates from 2 to 5 m above the canopy, enabling a high image resolution. It can carry payloads of up to 12 kg and can be operated under adverse weather conditions. This ensures regular measurements throughout the growing period even during cold, windy and moist conditions. Multiple sensors capture the reflectance spectrum, temperature, height or architecture of the canopy. Monitoring from early development to maturity at high temporal resolution allows the determination of dynamic traits and their correlation to environmental conditions throughout the entire season. We demonstrate the capabilities of the system with respect to monitoring canopy cover, canopy height and traits related to thermal and multi-spectral imaging by selected examples from winter wheat, maize and soybean. The system is discussed in the context of other, recently established field phenotyping approaches; such as ground-operating or aerial vehicles, which impose traffic on the field or require a higher distance to the canopy.},
  langid = {english}
}

@article{kotwalAgriculturalPlantDiseases2023,
  title = {Agricultural Plant Diseases Identification: {{From}} Traditional Approach to Deep Learning},
  shorttitle = {Agricultural Plant Diseases Identification},
  author = {Kotwal, Jameer and Kashyap, Dr. Ramgopal and Pathan, Dr. Shafi},
  year = {2023},
  month = jan,
  journal = {Materials Today: Proceedings},
  series = {3rd {{International Congress}} on {{Mechanical}} and {{Systems Engineering}} ({{CAMSE}} 2022)},
  volume = {80},
  pages = {344--356},
  issn = {2214-7853},
  doi = {10.1016/j.matpr.2023.02.370},
  urldate = {2023-09-01},
  abstract = {Plant disease computerization in agriculture areas an important for every country, as the population rate increases the demand for food supply also increases. Today, the significant adaption of modern techniques and tools increases the accuracy of detection the plant disease. Identifying plant diseases in an early stage can reduce their spread. Early identifying is a beginning stage to fight against disease spreading. For plenty of years, researchers have researched how to tackle the common disease effects amongst humans, animals, and plants. However, there are still many gaps are remaining to identify and explore. In recent years, there have been many researchers using Deep Learning (DL) and Transfer Learning (TL) technologies to detect agricultural diseases based on Machine Learning (ML) algorithms that were developed with the development of Artificial Intelligence (AI) technology. Many, DL architectures are carried out together with numerous diverse visualization strategies to perceive and label the features of plant diseases. Our take a look at additionally makes a specialty of how ML strategies had been moved from conventional ML to DL and additionally numerous overall performance metrics (F1-score, sensitivity, accuracy, etc) are used for the assessment of the architecture/strategies. Some challenges are figure out while identifying the plant disease detection.},
  keywords = {Convolution neural network (CNN),Deep learning,Plant diseases},
  file = {/home/samuelebumbaca/Zotero/storage/JWWRV32M/S2214785323009343.html}
}

@book{krausPhotogrammetryGeometryImages2011,
  title = {Photogrammetry: {{Geometry}} from {{Images}} and {{Laser Scans}}},
  shorttitle = {Photogrammetry},
  author = {Kraus, Karl},
  year = {2011},
  month = oct,
  journal = {Photogrammetry},
  publisher = {De Gruyter},
  doi = {10.1515/9783110892871},
  urldate = {2023-01-25},
  abstract = {This textbook deals with the basics and methods of photogrammetry and laser scanning which are used to determine the form and location of objects, with measurements provided by sensors placed in air planes as well as on terrestrial platforms. Many examples and exercises with solutions are included. Photogrammetry, Laserscanning.},
  isbn = {978-3-11-089287-1},
  langid = {english},
  keywords = {Cartography,Geodesy,Geology,Geophysics}
}

@article{kurugolluColorImageSegmentation2001,
  title = {Color Image Segmentation Using Histogram Multithresholding and Fusion},
  author = {Kurugollu, F and Sankur, B and Harmanci, A. E},
  year = {2001},
  month = nov,
  journal = {Image and Vision Computing},
  volume = {19},
  number = {13},
  pages = {915--928},
  issn = {0262-8856},
  doi = {10.1016/S0262-8856(01)00052-X},
  urldate = {2023-01-13},
  abstract = {A novel method for multiband image segmentation has been proposed. The method is based on segmentation of subsets of bands using multithresholding followed by the fusion of the resulting segmentation ``channels''. For color images the band subsets are chosen as the RB, RG and BG pairs, whose two-dimensional histograms are processed via a peak-picking algorithm to effect multithresholding. The segmentation maps are first fused by running a label concordance algorithm and then smoothed by a spatial--chromatic majority filter. It is shown that for multiband images, multithresholding subsets of bands followed by a fusion stage results in improved performance and running time.},
  langid = {english},
  keywords = {Fusion,Image segmentation,Multithresholding}
}

@article{lamprinouGroupwiseImageAlignment2020,
  title = {Groupwise {{Image Alignment}} via {{Self Quotient Images}}},
  author = {Lamprinou, Nefeli and Nikolikos, Nikolaos and Psarakis, Emmanouil Z.},
  year = {2020},
  month = apr,
  journal = {Sensors},
  volume = {20},
  number = {8},
  pages = {2325},
  issn = {1424-8220},
  doi = {10.3390/s20082325},
  urldate = {2021-12-19},
  abstract = {Compared with pairwise registration, the groupwise one is capable of handling a large-scale population of images simultaneously in an unbiased way. In this work we improve upon the state-of-the-art pixel-level, Least-Squares (LS)-based groupwise image registration methods. Specifically, the registration technique is properly adapted by the use of Self Quotient Images (SQI) in order to become capable for solving the groupwise registration of photometrically distorted, partially occluded as well as unimodal and multimodal images. Moreover, the proposed groupwise technique is linear to the cardinality of the image set and thus it can be used for the successful solution of the problem on large image sets with low complexity. From the application of the proposed technique on a series of experiments for the groupwise registration of photometrically and geometrically distorted, partially occluded faces as well as unimodal and multimodal magnetic resonance image sets and its comparison with the Lucas--Kanade Entropy (LKE) algorithm, the obtained results look very promising, in terms of alignment quality, using as figures of merit the mean Peak Signal to Noise Ratio ( m P S N R ) and mean Structural Similarity ( m S S I M ), and computational cost.},
  langid = {english}
}

@book{latiniLessicoNuvoleParole2021,
  title = {Lessico e Nuvole: Le Parole Del Cambiamento Climatico},
  author = {Latini, Gianni and Bagliani, Marco and Orusa, Tommaso},
  year = {2021},
  publisher = {Youcanprint}
}

@article{lauComparingLinkingMachine2022,
  title = {Comparing and Linking Machine Learning and Semi-Mechanistic Models for the Predictability of Endemic Measles Dynamics},
  author = {Lau, Max S. Y. and Becker, Alex and Madden, Wyatt and Waller, Lance A. and Metcalf, C. Jessica E. and Grenfell, Bryan T.},
  year = {2022},
  month = sep,
  journal = {PLOS Computational Biology},
  volume = {18},
  number = {9},
  pages = {e1010251},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1010251},
  urldate = {2023-03-24},
  abstract = {Measles is one the best-documented and most-mechanistically-studied non-linear infectious disease dynamical systems. However, systematic investigation into the comparative performance of traditional mechanistic models and machine learning approaches in forecasting the transmission dynamics of this pathogen are still rare. Here, we compare one of the most widely used semi-mechanistic models for measles (TSIR) with a commonly used machine learning approach (LASSO), comparing performance and limits in predicting short to long term outbreak trajectories and seasonality for both regular and less regular measles outbreaks in England and Wales (E\&W) and the United States. First, our results indicate that the proposed LASSO model can efficiently use data from multiple major cities and achieve similar short-to-medium term forecasting performance to semi-mechanistic models for E\&W epidemics. Second, interestingly, the LASSO model also captures annual to biennial bifurcation of measles epidemics in E\&W caused by susceptible response to the late 1940s baby boom. LASSO may also outperform TSIR for predicting less-regular dynamics such as those observed in major cities in US between 1932--45. Although both approaches capture short-term forecasts, accuracy suffers for both methods as we attempt longer-term predictions in highly irregular, post-vaccination outbreaks in E\&W. Finally, we illustrate that the LASSO model can both qualitatively and quantitatively reconstruct mechanistic assumptions, notably susceptible dynamics, in the TSIR model. Our results characterize the limits of predictability of infectious disease dynamics for strongly immunizing pathogens with both mechanistic and machine learning models, and identify connections between these two approaches.},
  langid = {english},
  keywords = {Cities,Disease dynamics,Dynamical systems,Epidemiology,Forecasting,Machine learning,Measles,Vaccination and immunization}
}

@article{lazarTaizZeigerPlant2003,
  title = {Taiz, {{L}}. and {{Zeiger}}, {{E}}. {{Plant}} Physiology. 3rd Edn.},
  author = {Lazar, T.},
  year = {2003},
  month = may,
  journal = {Annals of Botany},
  volume = {91},
  number = {6},
  pages = {750--751},
  issn = {03057364, 10958290},
  doi = {10.1093/aob/mcg079},
  urldate = {2023-01-10},
  langid = {english}
}

@article{lemaireUniversalBroadLeaf2004,
  title = {Towards Universal Broad Leaf Chlorophyll Indices Using {{PROSPECT}} Simulated Database and Hyperspectral Reflectance Measurements},
  author = {{le Maire}, G. and Fran{\c c}ois, C. and Dufr{\^e}ne, E.},
  year = {2004},
  month = jan,
  journal = {Remote Sensing of Environment},
  volume = {89},
  number = {1},
  pages = {1--28},
  issn = {0034-4257},
  doi = {10.1016/j.rse.2003.09.004},
  urldate = {2023-01-13},
  abstract = {Fifty-three leaves were randomly sampled on different deciduous tree species, representing a wide range of chlorophyll contents, tree ages, and leaf structural features. Their reflectance was measured between 400 and 800 nm with a 1-nm step, and their chlorophyll content determined by extraction. A larger simulated database (11,583 spectra) was built using the PROSPECT model, in order to test, calibrate, and obtain universal indices, i.e., indices applicable to a wide range of species and leaf structure. To our knowledge, almost all leaf chlorophyll indices published in the literature since 1973 have been tested on both databases. Fourteen canonical types of indices (published ones and new ones) were identified, and their wavelengths calibrated on the simulated database as well as on the experimental database to determine the best wavelengths and, hence, the best performances in chlorophyll estimation for each index types. These indices go from simple reflectance ratios to more sophisticated indices using reflectance first derivatives (using the Savitzky and Golay method). We also tested other nondestructive methods to obtain total chlorophyll concentration: SPAD (Minolta Camera, Osaka, Japan) and neural networks. The validity of the actual PROSPECT model is challenged by our results: Important discordances are found when the indices are calculated with PROSPECT compared to experimental data, especially for some indices and wavelengths. The discordance is even greater when the indices are determined with PROSPECT and applied on the experimental database. A new calibration of PROSPECT is therefore necessary for any study aiming at using simulated spectra to determine or to calibrate indices. The ``peak jump'' and the multiple-peak feature observed on the first derivative of the reflectances (e.g., in the Red-Edge Inflection Point [REIP] index) has been investigated. It was shown that chlorophyll absorption alone can explain this feature. The peak jump disqualifies the REIP to be a valuable chlorophyll index. A simple modified difference ratio gave the best results among all published indices (cross-validated RMSE=2.1 {$\mu$}g/cm2 on the experimental database). After calibration on the experimental database, modified Simple Ratio (mSR) and modified Normalized Difference (mND) indices gave the best performances (RMSECV=1.8 {$\mu$}g/cm2 on the experimental database). The new Double Difference (DD) index, although not the best on the experimental database (RMSECV=2.9 {$\mu$}g/cm2), has the best results on the larger simulated database (RMSE=3.7 {$\mu$}g/cm2) and is expected to give good results on larger experimental databases. The best reflectance-based indices give better performances than the current commercial nondestructive device SPAD (RMSECV=4.5 {$\mu$}g/cm2). In this leaf-level study, the best indices are very near from each other, so that complex methods are useless: REIP-like, neural networks, and derivative-based indices are not necessary and give worst results than simpler properly chosen indices. These conclusions will certainly be different for a canopy-level study, where the derivative-based indices may perform significantly better than the other ones.},
  langid = {english},
  keywords = {Hyperspectral reflectance measurements,PROSPECT,Universal broad leaf chlorophyll indices}
}

@article{lemesTriangularGreennessIndex2022,
  title = {Triangular {{Greenness Index}} to {{Evaluate}} the {{Effects}} of {{Dicamba}} in {{Soybean}}},
  author = {Lemes, Ernane Miranda and Coelho, L{\'i}sias and de Andrade, Samuel Lacerda and Oliveira, Aline dos Santos and Marques, Matheus Gregorio and do Nascimento, Felipe Mauro Assis and da Cunha, Jo{\~a}o Paulo Arantes Rodrigues},
  year = {2022},
  month = sep,
  journal = {AgriEngineering},
  volume = {4},
  number = {3},
  pages = {758--769},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2624-7402},
  doi = {10.3390/agriengineering4030049},
  urldate = {2023-03-24},
  abstract = {Significant losses in agricultural production are due to abiotic stresses, such as herbicide phytotoxicity. Dicamba (diglycolamine salt) is a herbicide used for post-emergent control of broadleaf weeds. It has a possibility to vapor-spread into neighboring fields causing damage to other crops. However, not every stress can be easily identified. Therefore, remote sensing has the potential as a new tool in early injury detection. This study evaluated the effects of simulated dicamba drift on the occurrence of phytotoxicity in soybeans (Glycine max). Soybean was assessed in seven dicamba doses (0, 0.056, 0.56, 5.6, 11.2, 28, 112 g ha-1) for changes in plant injury (scale of notes), spectral aspects (triangular greenness index (TGI), and shoot dry mass. The plants were photographed using a digital camera positioned at 1.2 m above the planting media level. The results indicate a positive effect of low dicamba doses (0.56 and 0.056 g a.e. ha-1) on TGI canopy distinction and shoot dry mass. Soybean TGI canopy distinction and the injury scale estimated at 45 days after sowing, and the soybean shoot dry mass observed at 99 days after sowing, presented significant and moderate Pearson's r coefficient of correlations (r = -0.609 and 0.625), indicating TGI as a valid and practical spectral index for plant dicamba-injured evaluations.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {herbicide phytotoxicity,image analysis,plant analysis,soybean,weed management}
}

@article{li3DImagingGreenhouse2017,
  title = {{{3D Imaging}} of {{Greenhouse Plants}} with an {{Inexpensive Binocular Stereo Vision System}}},
  author = {Li, Dawei and Xu, Lihong and Tang, Xue-song and Sun, Shaoyuan and Cai, Xin and Zhang, Peng},
  year = {2017},
  month = may,
  journal = {Remote Sensing},
  volume = {9},
  number = {5},
  pages = {508},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2072-4292},
  doi = {10.3390/rs9050508},
  urldate = {2022-09-25},
  abstract = {Nowadays, 3D imaging of plants not only contributes to monitoring and managing plant growth, but is also becoming an essential part of high-throughput plant phenotyping. In this paper, an inexpensive (less than 70 USD) and portable platform with binocular stereo vision is established, which can be controlled by a laptop. In the stereo matching step, an efficient cost calculating measure---AD-Census---is integrated with the adaptive support-weight (ASW) approach to improve the ASW's performance on real plant images. In the quantitative assessment, our stereo algorithm reaches an average error rate of 6.63\% on the Middlebury datasets, which is lower than the error rates of the original ASW approach and several other popular algorithms. The imaging experiments using the proposed stereo system are carried out in three different environments including an indoor lab, an open field with grass, and a multi-span glass greenhouse. Six types of greenhouse plants are used in experiments; half of them are ornamentals and the others are greenhouse crops. The imaging accuracy of the proposed method at different baseline settings is investigated, and the results show that the optimal length of the baseline (distance between the two cameras of the stereo system) is around 80 mm for reaching a good trade-off between the depth accuracy and the mismatch rate for a plant that is placed within 1 m of the cameras. Error analysis from both theoretical and experimental sides show that for an object that is approximately 800 mm away from the stereo platform, the measured depth error of a single point is no higher than 5 mm, which is tolerable considering the dimensions of greenhouse plants. By applying disparity refinement, the proposed methodology generates dense and accurate point clouds of crops in different environments including an indoor lab, an outdoor field, and a greenhouse. Our approach also shows invariance against changing illumination in a real greenhouse, as well as the capability of recovering 3D surfaces of highlighted leaf regions. The method not only works on a binocular stereo system, but is also potentially applicable to a SFM-MVS (structure-from-motion and multiple-view stereo) system or any multi-view imaging system that uses stereo matching.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {3D imaging,greenhouse plants,point cloud,remote sensing,stereo matching},
  file = {/home/samuelebumbaca/Zotero/storage/FV2Q2Q6R/htm.html}
}

@article{liaoAssessmentChlorophyllContent2014,
  title = {{[Assessment of chlorophyll content using a new vegetation index based on multi-angular hyperspectral image data]}},
  author = {Liao, Qin-hong and Zhang, Dong-yan and Wang, Ji-hua and Yang, Gui-jun and Yang, Hao and Coburn, Craig and Wong, Zhijie and Wang, Da-cheng},
  year = {2014},
  month = jun,
  journal = {Guang Pu Xue Yu Guang Pu Fen Xi = Guang Pu},
  volume = {34},
  number = {6},
  pages = {1599--1604},
  issn = {1000-0593},
  abstract = {The fast estimation of chlorophyll content is significant for understanding the crops growth, monitoring the disease and insect, and assessing the yield of crops. This study gets the hyperspectral imagery data by using a self-developed multi-angular acquisition system during the different maize growth period, the reflectance of maize canopy was extracted accurately from the hyperspectral images under different view angles in the principal plane. The hot-dark-spot index (HDS) of red waveband was calculated through the analysis of simulated values by ACRM model and measured values, then this index was used to modify the vegetation index (TCARI), thus a new vegetation index (HD-TCARI) based on the multi-angular observation was proposed. Finally, the multi-angular hyperspectral imagery data was used to validate the vegetation indexes. The result showed that HD-TCARI could effectively reduce the LAI effects on the assessment of chlorophyll content. When the chlorophyll content was greater than 30 {$\mu$}g x cm(-2), the correlation (R2) between HD-TCARI and LAI was only 26.88\%-28.72\%. In addition, the HD-TCARI could resist the saturation of vegetation index during the assessment of high chlorophyll content. When the LAI varled from 1 to 6, the linear relation between HD-TCARI and chlorophyll content could be improved by 9\% compared with TCARI. The ground validation of HD-TCARI by multi-angular hyperspectral image showed that the linear relation between HD-TCARI and chlorophyll content (R2 = 66.74\%) was better than the TCARI (R2 = 39.92\%), which indicated that HD-TCARI has good potentials for estimating the chlorophyll content.},
  langid = {chi},
  pmid = {25358171},
  keywords = {Chlorophyll,Crops Agricultural,Models Theoretical,Plant Leaves,Spectrum Analysis,Zea mays}
}

@article{liaoFastAlgorithmMultilevel,
  title = {A {{Fast Algorithm}} for {{Multilevel Thresholding}}},
  author = {Liao, Ping-Sung and Chen, Tse-Sheng and Chung, Pau-Choo},
  pages = {15},
  langid = {english}
}

@article{liebischRemoteAerialPhenotyping2015,
  title = {Remote, Aerial Phenotyping of Maize Traits with a Mobile Multi-Sensor Approach},
  author = {Liebisch, Frank and Kirchgessner, Norbert and Schneider, David and Walter, Achim and Hund, Andreas},
  year = {2015},
  month = feb,
  journal = {Plant Methods},
  volume = {11},
  number = {1},
  pages = {9},
  issn = {1746-4811},
  doi = {10.1186/s13007-015-0048-8},
  urldate = {2023-01-13},
  abstract = {Field-based high throughput phenotyping is a bottleneck for crop breeding research. We present a novel method for repeated remote phenotyping of maize genotypes using the Zeppelin NT aircraft as an experimental sensor platform. The system has the advantage of a low altitude and cruising speed compared to many drones or airplanes, thus enhancing image resolution while reducing blurring effects. Additionally there was no restriction in sensor weight. Using the platform, red, green and blue colour space (RGB), normalized difference vegetation index (NDVI) and thermal images were acquired throughout the growing season and compared with traits measured on the ground. Ground control points were used to co-register the images and to overlay them with a plot map.},
  keywords = {Aerial phenotyping,Image analysis,NDVI,Near infrared imaging,Remote sensing,Thermal imaging,Zea mays}
}

@article{liHighthroughputPhenotypingAnalysis2021,
  title = {High-Throughput Phenotyping Analysis of Maize at the Seedling Stage Using End-to-End Segmentation Network},
  author = {Li, Yinglun and Wen, Weiliang and Guo, Xinyu and Yu, Zetao and Gu, Shenghao and Yan, Haipeng and Zhao, Chunjiang},
  editor = {Bianconi, Francesco},
  year = {2021},
  month = jan,
  journal = {PLOS ONE},
  volume = {16},
  number = {1},
  pages = {e0241528},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0241528},
  urldate = {2021-12-18},
  abstract = {Image processing technologies are available for high-throughput acquisition and analysis of phenotypes for crop populations, which is of great significance for crop growth monitoring, evaluation of seedling condition, and cultivation management. However, existing methods rely on empirical segmentation thresholds, thus can have insufficient accuracy of extracted phenotypes. Taking maize as an example crop, we propose a phenotype extraction approach from top-view images at the seedling stage. An end-to-end segmentation network, named PlantU-net, which uses a small amount of training data, was explored to realize automatic segmentation of top-view images of a maize population at the seedling stage. Morphological and color related phenotypes were automatic extracted, including maize shoot coverage, circumscribed radius, aspect ratio, and plant azimuth plane angle. The results show that the approach can segment the shoots at the seedling stage from top-view images, obtained either from the UAV or tractor-based high-throughput phenotyping platform. The average segmentation accuracy, recall rate, and F1 score are 0.96, 0.98, and 0.97, respectively. The extracted phenotypes, including maize shoot coverage, circumscribed radius, aspect ratio, and plant azimuth plane angle, are highly correlated with manual measurements (R                2                = 0.96--0.99). This approach requires less training data and thus has better expansibility. It provides practical means for high-throughput phenotyping analysis of early growth stage crop populations.},
  langid = {english}
}

@article{liHighThroughputPlantPhenotyping2021,
  title = {High-{{Throughput Plant Phenotyping Platform}} ({{HT3P}}) as a {{Novel Tool}} for {{Estimating Agronomic Traits From}} the {{Lab}} to the {{Field}}},
  author = {Li, Daoliang and Quan, Chaoqun and Song, Zhaoyang and Li, Xiang and Yu, Guanghui and Li, Cheng and Muhammad, Akhter},
  year = {2021},
  month = jan,
  journal = {Frontiers in Bioengineering and Biotechnology},
  volume = {8},
  pages = {623705},
  issn = {2296-4185},
  doi = {10.3389/fbioe.2020.623705},
  urldate = {2021-12-18},
  abstract = {Food scarcity, population growth, and global climate change have propelled crop yield growth driven by high-throughput phenotyping into the era of big data. However, access to large-scale phenotypic data has now become a critical barrier that phenomics urgently must overcome. Fortunately, the high-throughput plant phenotyping platform (HT3P), employing advanced sensors and data collection systems, can take full advantage of non-destructive and high-throughput methods to monitor, quantify, and evaluate specific phenotypes for large-scale agricultural experiments, and it can effectively perform phenotypic tasks that traditional phenotyping could not do. In this way, HT3Ps are novel and powerful tools, for which various commercial, customized, and even self-developed ones have been recently introduced in rising numbers. Here, we review these HT3Ps in nearly 7 years from greenhouses and growth chambers to the field, and from ground-based proximal phenotyping to aerial large-scale remote sensing. Platform configurations, novelties, operating modes, current developments, as well the strengths and weaknesses of diverse types of HT3Ps are thoroughly and clearly described. Then, miscellaneous combinations of HT3Ps for comparative validation and comprehensive analysis are systematically present, for the first time. Finally, we consider current phenotypic challenges and provide fresh perspectives on future development trends of HT3Ps. This review aims to provide ideas, thoughts, and insights for the optimal selection, exploitation, and utilization of HT3Ps, and thereby pave the way to break through current phenotyping bottlenecks in botany.}
}

@article{liIterativeAlgorithmMinimum1998,
  title = {An Iterative Algorithm for Minimum Cross Entropy Thresholding},
  author = {Li, C. H. and Tam, P. K. S.},
  year = {1998},
  month = jun,
  journal = {Pattern Recognition Letters},
  volume = {19},
  number = {8},
  pages = {771--776},
  issn = {0167-8655},
  doi = {10.1016/S0167-8655(98)00057-9},
  urldate = {2023-01-25},
  abstract = {A fast iterative method is derived for minimum cross entropy thresholding using a one-point iteration scheme. Simulations performed using synthetic generated histograms and a real image show the speed advantage and the accuracy of the iterated version.},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/5TTGIRDU/S0167865598000579.html}
}

@article{liIterativeAlgorithmMinimum1998a,
  title = {An Iterative Algorithm for Minimum Cross Entropy Thresholding},
  author = {Li, C. H. and Tam, P. K. S.},
  year = {1998},
  month = jun,
  journal = {Pattern Recognition Letters},
  volume = {19},
  number = {8},
  pages = {771--776},
  issn = {0167-8655},
  doi = {10.1016/S0167-8655(98)00057-9},
  urldate = {2023-01-25},
  abstract = {A fast iterative method is derived for minimum cross entropy thresholding using a one-point iteration scheme. Simulations performed using synthetic generated histograms and a real image show the speed advantage and the accuracy of the iterated version.},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/FFQ9K7VT/S0167865598000579.html}
}

@article{lillesaeterSpectralReflectancePartly1982,
  title = {Spectral Reflectance of Partly Transmitting Leaves: {{Laboratory}} Measurements and Mathematical Modeling},
  shorttitle = {Spectral Reflectance of Partly Transmitting Leaves},
  author = {Lillesaeter, O.},
  year = {1982},
  month = jul,
  journal = {Remote Sensing of Environment},
  volume = {12},
  number = {3},
  pages = {247--254},
  issn = {0034-4257},
  doi = {10.1016/0034-4257(82)90057-8},
  urldate = {2023-01-13},
  abstract = {Previous work related to remote sensing of natural sceneries has shown that the near infrared signature of a plant canopy is a combined function of leaf optical properties, canopy geometry, and soil reflectance. This paper deals with the problems involved in spectrophotometric measurements of leaves that are partly transmitting and partly reflecting, and thus influenced by the sample background provided by the measuring instrument. A mathematical model requiring only single-leaf spectral reflectance data as input is developed for prediction of multiple-leaf reflectance. The validity of the model appears to be adequate for any number of stacked leaves, when leaf-to-leaf variations caused by differences in water content and pigmentation are considered.},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/S52NEKA4/0034425782900578.html}
}

@article{liMinimumCrossEntropy1993,
  title = {Minimum Cross Entropy Thresholding},
  author = {Li, C. H. and Lee, C. K.},
  year = {1993},
  month = apr,
  journal = {Pattern Recognition},
  volume = {26},
  number = {4},
  pages = {617--625},
  issn = {0031-3203},
  doi = {10.1016/0031-3203(93)90115-D},
  urldate = {2023-01-25},
  abstract = {The threshold selection problem is solved by minimizing the cross entropy between the image and its segmented version. The cross entropy is formulated in a pixel-to-pixel basis between the two images and a computationally attractive algorithm employing the histogram is developed. Without making a priori assumptions about the population distribution, this method provides an unbiased estimate of a binarized version of the image in an information theoretic sense.},
  langid = {english},
  keywords = {Image segmentation,Maximum entropy method,Minimum cross entropy,Thresholding},
  file = {/home/samuelebumbaca/Zotero/storage/6DRXH6VX/003132039390115D.html}
}

@misc{linder-norenEriklindernorenPyTorchGAN2025,
  title = {Eriklindernoren/{{PyTorch-GAN}}},
  author = {{Linder-Nor{\'e}n}, Erik},
  year = {2025},
  month = jan,
  urldate = {2025-01-05},
  abstract = {PyTorch implementations of Generative Adversarial Networks.},
  copyright = {MIT}
}

@article{liRobustPointSet2020,
  title = {Robust {{Point Set Registration Using Signature Quadratic Form Distance}}},
  author = {Li, Liang and Yang, Ming and Wang, Chunxiang and Wang, Bing},
  year = {2020},
  month = may,
  journal = {IEEE Transactions on Cybernetics},
  volume = {50},
  number = {5},
  pages = {2097--2109},
  issn = {2168-2267, 2168-2275},
  doi = {10.1109/TCYB.2018.2845745},
  urldate = {2021-12-19}
}

@article{liuIndustry40Agriculture2021,
  title = {From {{Industry}} 4.0 to {{Agriculture}} 4.0: {{Current Status}}, {{Enabling Technologies}}, and {{Research Challenges}}},
  shorttitle = {From {{Industry}} 4.0 to {{Agriculture}} 4.0},
  author = {Liu, Ye and Ma, Xiaoyuan and Shu, Lei and Hancke, Gerhard Petrus and {Abu-Mahfouz}, Adnan M.},
  year = {2021},
  month = jun,
  journal = {IEEE Transactions on Industrial Informatics},
  volume = {17},
  number = {6},
  pages = {4322--4334},
  issn = {1941-0050},
  doi = {10.1109/TII.2020.3003910},
  abstract = {The three previous industrial revolutions profoundly transformed agriculture industry from indigenous farming to mechanized farming and recent precision agriculture. Industrial farming paradigm greatly improves productivity, but a number of challenges have gradually emerged, which have exacerbated in recent years. Industry 4.0 is expected to reshape the agriculture industry once again and promote the fourth agricultural revolution. In this article, first, we review the current status of industrial agriculture along with lessons learned from industrialized agricultural production patterns, industrialized agricultural production processes, and the industrialized agri-food supply chain. Furthermore, five emerging technologies, namely the Internet of Things, robotics, artificial intelligence, big data analytics, and blockchain, toward Agriculture 4.0 are discussed. Specifically, we focus on the key applications of these emerging technologies in the agricultural sector and corresponding research challenges. This article aims to open up new research opportunities for readers, particularly industrial practitioners.},
  keywords = {Agriculture,Agriculture 4.0,Animals,industrial agriculture,Industry 4.0,precision agriculture,Productivity,Soil,Supply chains},
  file = {/home/samuelebumbaca/Zotero/storage/A5LDPB3H/9122412.html}
}

@article{longClassificationWheatDiseases2023,
  title = {Classification of Wheat Diseases Using Deep Learning Networks with Field and Glasshouse Images},
  author = {Long, Megan and Hartley, Matthew and Morris, Richard J. and Brown, James K. M.},
  year = {2023},
  journal = {Plant Pathology},
  volume = {72},
  number = {3},
  pages = {536--547},
  issn = {1365-3059},
  doi = {10.1111/ppa.13684},
  urldate = {2023-09-01},
  abstract = {Crop diseases can cause major yield losses, so the ability to detect and identify them in their early stages is important for disease control. Deep learning methods have shown promise in classifying multiple diseases; however, many studies do not use datasets that represent real field conditions, necessitating either further image processing or reducing their applicability. In this paper, we present a dataset of wheat images taken in real growth situations, including both field and glasshouse conditions, with five categories: healthy plants and four foliar diseases, yellow rust, brown rust, powdery mildew and Septoria leaf blotch. This dataset was used to train a deep learning model. The resulting model, named CerealConv, reached a 97.05\% classification accuracy. When tested against trained pathologists on a subset of images from the larger dataset, the model delivered an accuracy score 2\% higher than the best-performing pathologist. Image masks were used to show that the model was using the correct information to drive its classifications. These results show that deep learning networks are a viable tool for disease detection and classification in the field, and disease quantification is a logical next step.},
  langid = {english},
  keywords = {brown rust,convolutional neural network (CNN),deep learning,septoria,wheat,yellow rust},
  file = {/home/samuelebumbaca/Zotero/storage/INZPQAM6/ppa.html}
}

@article{lottesEffectiveVisionbasedClassification2017,
  title = {Effective {{Vision-based Classification}} for {{Separating Sugar Beets}} and {{Weeds}} for {{Precision Farming}}},
  author = {Lottes, Philipp and H{\"o}rferlin, Markus and Sander, Slawomir and Stachniss, Cyrill},
  year = {2017},
  journal = {Journal of Field Robotics},
  volume = {34},
  number = {6},
  pages = {1160--1178},
  issn = {1556-4967},
  doi = {10.1002/rob.21675},
  urldate = {2023-01-13},
  abstract = {The use of robots in precision farming has the potential to reduce the reliance on herbicides and pesticides through selectively spraying individual plants or through manual weed removal. A prerequisite for that is the ability of the robot to separate and identify the value crops and the weeds in the field. Based on the output of the robot's perception system, it can trigger the actuators for spraying or removal. In this paper, we address the problem of detecting sugar beet plants as well as weeds using a camera installed on a mobile field robot. We propose a system that performs vegetation detection, local as well as object-based feature extraction, random forest classification, and smoothing through a Markov random field to obtain an accurate estimate of crops and weeds. We implemented and thoroughly evaluated our system using a real farm robot in different sugar beet fields, and we illustrate that our approach allows for accurately identifying weeds in a field.},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/QZSNJMFY/rob.html}
}

@article{loweDistinctiveImageFeatures2004,
  title = {Distinctive {{Image Features}} from {{Scale-Invariant Keypoints}}},
  author = {Lowe, David G.},
  year = {2004},
  month = nov,
  journal = {International Journal of Computer Vision},
  volume = {60},
  number = {2},
  pages = {91--110},
  issn = {0920-5691},
  doi = {10.1023/B:VISI.0000029664.99615.94},
  urldate = {2022-11-24},
  abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
  langid = {english}
}

@article{loweHyperspectralImageAnalysis2017,
  title = {Hyperspectral Image Analysis Techniques for the Detection and Classification of the Early Onset of Plant Disease and Stress},
  author = {Lowe, Amy and Harrison, Nicola and French, Andrew P.},
  year = {2017},
  month = oct,
  journal = {Plant Methods},
  volume = {13},
  number = {1},
  pages = {80},
  issn = {1746-4811},
  doi = {10.1186/s13007-017-0233-z},
  urldate = {2023-01-13},
  abstract = {This review explores how imaging techniques are being developed with a focus on deployment for crop monitoring methods. Imaging applications are discussed in relation to both field and glasshouse-based plants, and techniques are sectioned into `healthy and diseased plant classification' with an emphasis on classification accuracy, early detection of stress, and disease severity. A central focus of the review is the use of hyperspectral imaging and how this is being utilised to find additional information about plant health, and the ability to predict onset of disease. A summary of techniques used to detect biotic and abiotic stress in plants is presented, including the level of accuracy associated with each method.},
  langid = {english},
  keywords = {Early detection of stress,Hyperspectral image analysis,Hyperspectral imaging,Image analysis techniques,Plant disease and stress,Vegetation Indices}
}

@inproceedings{loweObjectRecognitionLocal1999,
  title = {Object Recognition from Local Scale-Invariant Features},
  booktitle = {Proceedings of the {{Seventh IEEE International Conference}} on {{Computer Vision}}},
  author = {Lowe, D.G.},
  year = {1999},
  pages = {1150-1157 vol.2},
  publisher = {IEEE},
  address = {Kerkyra, Greece},
  doi = {10.1109/ICCV.1999.790410},
  urldate = {2024-01-23},
  abstract = {An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest-neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low-residual least-squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially-occluded images with a computation time of under 2 seconds.},
  isbn = {978-0-7695-0164-2},
  langid = {english}
}

@article{luRoboticPlatformCorn2017,
  title = {A {{Robotic Platform}} for {{Corn Seedling Morphological Traits Characterization}}},
  author = {Lu, Hang and Tang, Lie and Whitham, Steven A. and Mei, Yu},
  year = {2017},
  month = sep,
  journal = {Sensors},
  volume = {17},
  number = {9},
  pages = {2082},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1424-8220},
  doi = {10.3390/s17092082},
  urldate = {2025-01-05},
  abstract = {Crop breeding plays an important role in modern agriculture, improving plant performance, and increasing yield. Identifying the genes that are responsible for beneficial traits greatly facilitates plant breeding efforts for increasing crop production. However, associating genes and their functions with agronomic traits requires researchers to observe, measure, record, and analyze phenotypes of large numbers of plants, a repetitive and error-prone job if performed manually. An automated seedling phenotyping system aimed at replacing manual measurement, reducing sampling time, and increasing the allowable work time is thus highly valuable. Toward this goal, we developed an automated corn seedling phenotyping platform based on a time-of-flight of light (ToF) camera and an industrial robot arm. A ToF camera is mounted on the end effector of the robot arm. The arm positions the ToF camera at different viewpoints for acquiring 3D point cloud data. A camera-to-arm transformation matrix was calculated using a hand-eye calibration procedure and applied to transfer different viewpoints into an arm-based coordinate frame. Point cloud data filters were developed to remove the noise in the background and in the merged seedling point clouds. A 3D-to-2D projection and an x-axis pixel density distribution method were used to segment the stem and leaves. Finally, separated leaves were fitted with 3D curves for morphological traits characterization. This platform was tested on a sample of 60 corn plants at their early growth stages with between two to five leaves. The error ratios of the stem height and leave length measurements are 13.7\% and 13.1\%, respectively, demonstrating the feasibility of this robotic system for automated corn seedling phenotyping.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {3D reconstruction,corn breeding,plant phenotyping,point cloud,robot arm,ToF camera}
}

@article{maeda-gutierrezComparisonConvolutionalNeural2020,
  title = {Comparison of {{Convolutional Neural Network Architectures}} for {{Classification}} of {{Tomato Plant Diseases}}},
  author = {{Maeda-Guti{\'e}rrez}, Valeria and {Galv{\'a}n-Tejada}, Carlos E. and {Zanella-Calzada}, Laura A. and {Celaya-Padilla}, Jos{\'e} M. and {Galv{\'a}n-Tejada}, Jorge I. and {Gamboa-Rosales}, Hamurabi and {Luna-Garc{\'i}a}, Huizilopoztli and {Magallanes-Quintanar}, Rafael and Guerrero M{\'e}ndez, Carlos A. and {Olvera-Olvera}, Carlos A.},
  year = {2020},
  month = jan,
  journal = {Applied Sciences},
  volume = {10},
  number = {4},
  pages = {1245},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-3417},
  doi = {10.3390/app10041245},
  urldate = {2023-11-27},
  abstract = {Tomato plants are highly affected by diverse diseases. A timely and accurate diagnosis plays an important role to prevent the quality of crops. Recently, deep learning (DL), specifically convolutional neural networks (CNNs), have achieved extraordinary results in many applications, including the classification of plant diseases. This work focused on fine-tuning based on the comparison of the state-of-the-art architectures: AlexNet, GoogleNet, Inception V3, Residual Network (ResNet) 18, and ResNet 50. An evaluation of the comparison was finally performed. The dataset used for the experiments is contained by nine different classes of tomato diseases and a healthy class from PlantVillage. The models were evaluated through a multiclass statistical analysis based on accuracy, precision, sensitivity, specificity, F-Score, area under the curve (AUC), and receiving operating characteristic (ROC) curve. The results present significant values obtained by the GoogleNet technique, with 99.72\% of AUC and 99.12\% of sensitivity. It is possible to conclude that this significantly success rate makes the GoogleNet model a useful tool for farmers in helping to identify and protect tomatoes from the diseases mentioned.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {classification,convolutional neural networks,deep learning,tomato plant diseases}
}

@article{mahleinDevelopmentSpectralIndices2013,
  title = {Development of Spectral Indices for Detecting and Identifying Plant Diseases},
  author = {Mahlein, A. -K. and Rumpf, T. and Welke, P. and Dehne, H. -W. and Pl{\"u}mer, L. and Steiner, U. and Oerke, E. -C.},
  year = {2013},
  month = jan,
  journal = {Remote Sensing of Environment},
  volume = {128},
  pages = {21--30},
  issn = {0034-4257},
  doi = {10.1016/j.rse.2012.09.019},
  urldate = {2023-01-13},
  abstract = {Spectral vegetation indices (SVIs) have been shown to be useful for an indirect detection of plant diseases. However, these indices have not been evaluated to detect or to differentiate between plant diseases on crop plants. The aim of this study was to develop specific spectral disease indices (SDIs) for the detection of diseases in crops. Sugar beet plants and the three leaf diseases Cercospora leaf spot, sugar beet rust and powdery mildew were used as model system. Hyperspectral signatures of healthy and diseased sugar beet leaves were assessed with a non-imaging spectroradiometer at different developing stages and disease severities of pathogens. Significant and most relevant wavelengths and two band normalized differences from 450 to 950nm, describing the impact of a disease on sugar beet leaves were extracted from the data-set using the RELIEF-F algorithm. To develop hyperspectral indices for the detection of sugar beet diseases the best weighted combination of a single wavelength and a normalized wavelength difference was exhaustively searched testing all possible combinations. The optimized disease indices were tested for their ability to detect and to classify healthy and diseased sugar beet leaves. With a high accuracy and sensitivity healthy sugar beet leaves and leaves, infected with Cercospora leaf spot, sugar beet rust and powdery mildew were classified (balanced classification accuracy: 89\%, 92\%, 87\%, 85\%, respectively). Spectral disease indices were also successfully applied on hyperspectral imaging data and on non-imaging data from a sugar beet field. Specific disease indices will improve disease detection, identification and monitoring in precision agriculture applications.},
  langid = {english},
  keywords = {Band selection,Hyperspectral reflectance,leaf spot,Plant diseases,Powdery mildew,Precision crop protection,Spectral disease indices,Sugar beet,Sugar beet rust}
}

@article{mahleinDevelopmentSpectralIndices2013a,
  title = {Development of Spectral Indices for Detecting and Identifying Plant Diseases},
  author = {Mahlein, A. -K. and Rumpf, T. and Welke, P. and Dehne, H. -W. and Pl{\"u}mer, L. and Steiner, U. and Oerke, E. -C.},
  year = {2013},
  month = jan,
  journal = {Remote Sensing of Environment},
  volume = {128},
  pages = {21--30},
  issn = {0034-4257},
  doi = {10.1016/j.rse.2012.09.019},
  urldate = {2023-01-13},
  abstract = {Spectral vegetation indices (SVIs) have been shown to be useful for an indirect detection of plant diseases. However, these indices have not been evaluated to detect or to differentiate between plant diseases on crop plants. The aim of this study was to develop specific spectral disease indices (SDIs) for the detection of diseases in crops. Sugar beet plants and the three leaf diseases Cercospora leaf spot, sugar beet rust and powdery mildew were used as model system. Hyperspectral signatures of healthy and diseased sugar beet leaves were assessed with a non-imaging spectroradiometer at different developing stages and disease severities of pathogens. Significant and most relevant wavelengths and two band normalized differences from 450 to 950nm, describing the impact of a disease on sugar beet leaves were extracted from the data-set using the RELIEF-F algorithm. To develop hyperspectral indices for the detection of sugar beet diseases the best weighted combination of a single wavelength and a normalized wavelength difference was exhaustively searched testing all possible combinations. The optimized disease indices were tested for their ability to detect and to classify healthy and diseased sugar beet leaves. With a high accuracy and sensitivity healthy sugar beet leaves and leaves, infected with Cercospora leaf spot, sugar beet rust and powdery mildew were classified (balanced classification accuracy: 89\%, 92\%, 87\%, 85\%, respectively). Spectral disease indices were also successfully applied on hyperspectral imaging data and on non-imaging data from a sugar beet field. Specific disease indices will improve disease detection, identification and monitoring in precision agriculture applications.},
  langid = {english},
  keywords = {Band selection,Hyperspectral reflectance,leaf spot,Plant diseases,Powdery mildew,Precision crop protection,Spectral disease indices,Sugar beet,Sugar beet rust}
}

@article{mahleinHyperspectralSensorsImaging2018,
  title = {Hyperspectral {{Sensors}} and {{Imaging Technologies}} in {{Phytopathology}}: {{State}} of the {{Art}}},
  shorttitle = {Hyperspectral {{Sensors}} and {{Imaging Technologies}} in {{Phytopathology}}},
  author = {Mahlein, A.-K. and Kuska, M.T. and Behmann, J. and Polder, G. and Walter, A.},
  year = {2018},
  journal = {Annual Review of Phytopathology},
  volume = {56},
  number = {1},
  pages = {535--558},
  doi = {10.1146/annurev-phyto-080417-050100},
  urldate = {2023-01-13},
  abstract = {Plant disease detection represents a tremendous challenge for research and practical applications. Visual assessment by human raters is time-consuming, expensive, and error prone. Disease rating and plant protection need new and innovative techniques to address forthcoming challenges and trends in agricultural production that require more precision than ever before. Within this context, hyperspectral sensors and imaging techniques---intrinsically tied to efficient data analysis approaches---have shown an enormous potential to provide new insights into plant-pathogen interactions and for the detection of plant diseases. This article provides an overview of hyperspectral sensors and imaging technologies for assessing compatible and incompatible plant-pathogen interactions. Within the progress of digital technologies, the vision, which is increasingly discussed in the society and industry, includes smart and intuitive solutions for assessing plant features in plant phenotyping or for making decisions on plant protection measures in the context of precision agriculture.},
  pmid = {30149790},
  keywords = {digital technologies,machine learning,noninvasive,phenotyping,plant disease detection,precision agriculture}
}

@article{mahleinPlantDiseaseDetection2016,
  title = {Plant {{Disease Detection}} by {{Imaging Sensors}} -- {{Parallels}} and {{Specific Demands}} for {{Precision Agriculture}} and {{Plant Phenotyping}}},
  author = {Mahlein, Anne-Katrin},
  year = {2016},
  month = feb,
  journal = {Plant Disease},
  volume = {100},
  number = {2},
  pages = {241--251},
  publisher = {Scientific Societies},
  issn = {0191-2917},
  doi = {10.1094/PDIS-03-15-0340-FE},
  urldate = {2023-01-13},
  abstract = {Early and accurate detection and diagnosis of plant diseases are key factors in plant production and the reduction of both qualitative and quantitative losses in crop yield. Optical techniques, such as RGB imaging, multi- and hyperspectral sensors, thermography, or chlorophyll fluorescence, have proven their potential in automated, objective, and reproducible detection systems for the identification and quantification of plant diseases at early time points in epidemics. Recently, 3D scanning has also been added as an optical analysis that supplies additional information on crop plant vitality. Different platforms from proximal to remote sensing are available for multiscale monitoring of single crop organs or entire fields. Accurate and reliable detection of diseases is facilitated by highly sophisticated and innovative methods of data analysis that lead to new insights derived from sensor data for complex plant-pathogen systems. Nondestructive, sensor-based methods support and expand upon visual and/or molecular approaches to plant disease assessment. The most relevant areas of application of sensor-based analyses are precision agriculture and plant phenotyping.}
}

@misc{MAIAS2Sentinel,
  title = {{{MAIA S2 Versus Sentinel}} 2: {{Spectral Issues}} and {{Their Effects}} in the {{Precision Farming Context}}},
  shorttitle = {{{MAIA S2 Versus Sentinel}} 2},
  journal = {springerprofessional.de},
  urldate = {2023-03-24},
  abstract = {Precision agriculture involves the integration of new technologies including Geographic Information Systems (GIS), Global Navigation Satellites Systems (GNSS) and Remote Sensing (RS) platforms and sensors to allow farmers to maximize the {\dots}},
  howpublished = {https://www.springerprofessional.de/en/maia-s2-versus-sentinel-2-spectral-issues-and-their-effects-in-t/19653452},
  langid = {english}
}

@misc{MAPIR_Survey3_Camera_Datasheet_Englishpdf,
  title = {{{MAPIR}}\_{{Survey3}}\_{{Camera}}\_{{Datasheet}}\_{{English}}.Pdf},
  journal = {Google Docs},
  urldate = {2022-09-20},
  howpublished = {www.mapir.camera},
  file = {/home/samuelebumbaca/Zotero/storage/R6T3R7NZ/view.html}
}

@inproceedings{martinDatabaseHumanSegmented2001,
  title = {A Database of Human Segmented Natural Images and Its Application to Evaluating Segmentation Algorithms and Measuring Ecological Statistics},
  booktitle = {Proceedings {{Eighth IEEE International Conference}} on {{Computer Vision}}. {{ICCV}} 2001},
  author = {Martin, D. and Fowlkes, C. and Tal, D. and Malik, J.},
  year = {2001},
  month = jul,
  volume = {2},
  pages = {416-423 vol.2},
  doi = {10.1109/ICCV.2001.937655},
  abstract = {This paper presents a database containing 'ground truth' segmentations produced by humans for images of a wide variety of natural scenes. We define an error measure which quantifies the consistency between segmentations of differing granularities and find that different human segmentations of the same image are highly consistent. Use of this dataset is demonstrated in two applications: (1) evaluating the performance of segmentation algorithms and (2) measuring probability distributions associated with Gestalt grouping factors as well as statistics of image region properties.},
  keywords = {Application software,Computer errors,Electric variables measurement,Humans,Image databases,Image recognition,Image segmentation,Layout,Statistics,Testing},
  file = {/home/samuelebumbaca/Zotero/storage/HZYTETC7/937655.html}
}

@article{martinLearningDetectNatural2004,
  title = {Learning to Detect Natural Image Boundaries Using Local Brightness, Color, and Texture Cues},
  author = {Martin, D.R. and Fowlkes, C.C. and Malik, J.},
  year = {2004},
  month = may,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {26},
  number = {5},
  pages = {530--549},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2004.1273918},
  abstract = {The goal of this work is to accurately detect and localize boundaries in natural scenes using local image measurements. We formulate features that respond to characteristic changes in brightness, color, and texture associated with natural boundaries. In order to combine the information from these features in an optimal way, we train a classifier using human labeled images as ground truth. The output of this classifier provides the posterior probability of a boundary at each image location and orientation. We present precision-recall curves showing that the resulting detector significantly outperforms existing approaches. Our two main results are 1) that cue combination can be performed adequately with a simple linear model and 2) that a proper, explicit treatment of texture is required to detect boundaries in natural images.},
  keywords = {Brightness,Data mining,Detectors,Feature extraction,Humans,Image edge detection,Image segmentation,Layout,Pixel,Supervised learning}
}

@inproceedings{maSkeletonExtraction3D2003,
  title = {Skeleton Extraction of {{3D}} Objects with Radial Basis Functions},
  booktitle = {2003 {{Shape Modeling International}}.},
  author = {Ma, Wan-Chun and Wu, Fu-Che and Ouhyoung, Ming},
  year = {2003},
  pages = {207--215},
  publisher = {IEEE},
  urldate = {2024-06-10}
}

@article{mcdonaldHumanVsMachine2022,
  title = {Human vs. {{Machine}}, the {{Eyes Have It}}. {{Assessment}} of {{Stemphylium Leaf Blight}} on {{Onion Using Aerial Photographs}} from an {{NIR Camera}}},
  author = {McDonald, Mary Ruth and Tayviah, Cyril Selasi and Gossen, Bruce D.},
  year = {2022},
  journal = {Remote Sensing},
  volume = {14},
  number = {2},
  issn = {2072-4292},
  doi = {10.3390/rs14020293},
  abstract = {Aerial surveillance could be a useful tool for early detection and quantification of plant diseases, however, there are often confounding effects of other types of plant stress. Stemphylium leaf blight (SLB), caused by the fungus Stemphylium vesicarium, is a damaging foliar disease of onion. Studies were conducted to determine if near-infrared photographic images could be used to accurately assess SLB severity in onion research trials in the Holland Marsh in Ontario, Canada. The site was selected for its uniform soil and level topography. Aerial photographs were taken in 2015 and 2016 using an Xnite-Canon SX230NDVI with a near-infrared filter, mounted on a modified Cine Star\&mdash;8 MK Heavy Lift RTF octocopter UAV. Images were taken at 15\&ndash;20 m above the ground, providing an average of 0.5 cm/pixel and a field of view of 15 \&times; 20 m. Photography and ground assessments of disease were carried out on the same day. NDVI (normalized difference vegetation index), green NDVI, chlorophyll index and plant senescence reflective index (PSRI) were calculated from the images. There were differences in SLB incidence and severity in the field plots and differences in the vegetative indices among the treatments, but there were no correlations between disease assessments and any of the indices.}
}

@inproceedings{meiBuildingAccurateStereo2011,
  title = {On Building an Accurate Stereo Matching System on Graphics Hardware},
  booktitle = {2011 {{IEEE International Conference}} on {{Computer Vision Workshops}} ({{ICCV Workshops}})},
  author = {Mei, Xing and Sun, Xun and Zhou, Mingcai and Jiao, Shaohui and Wang, Haitao and Zhang, Xiaopeng},
  year = {2011},
  month = nov,
  pages = {467--474},
  doi = {10.1109/ICCVW.2011.6130280},
  abstract = {This paper presents a GPU-based stereo matching system with good performance in both accuracy and speed. The matching cost volume is initialized with an AD-Census measure, aggregated in dynamic cross-based regions, and updated in a scanline optimization framework to produce the disparity results. Various errors in the disparity results are effectively handled in a multi-step refinement process. Each stage of the system is designed with parallelism considerations such that the computations can be accelerated with CUDA implementations. Experimental results demonstrate the accuracy and the efficiency of the system: currently it is the top performer in the Middlebury benchmark, and the results are achieved on GPU within 0.1 seconds. We also provide extra examples on stereo video sequences and discuss the limitations of the system.},
  keywords = {Accuracy,Graphics processing unit,Image color analysis,Image edge detection,Interpolation,Reliability,Stereo vision},
  file = {/home/samuelebumbaca/Zotero/storage/6LK2BTPX/6130280.html}
}

@inproceedings{merrellRealTimeVisibilityBasedFusion2007,
  title = {Real-{{Time Visibility-Based Fusion}} of {{Depth Maps}}},
  booktitle = {2007 {{IEEE}} 11th {{International Conference}} on {{Computer Vision}}},
  author = {Merrell, Paul and Akbarzadeh, Amir and Wang, Liang and Mordohai, Philippos and Frahm, Jan-Michael and Yang, Ruigang and Nister, David and Pollefeys, Marc},
  year = {2007},
  pages = {1--8},
  publisher = {IEEE},
  address = {Rio de Janeiro, Brazil},
  doi = {10.1109/ICCV.2007.4408984},
  urldate = {2022-11-24},
  abstract = {We present a viewpoint-based approach for the quick fusion of multiple stereo depth maps. Our method selects depth estimates for each pixel that minimize violations of visibility constraints and thus remove errors and inconsistencies from the depth maps to produce a consistent surface. We advocate a two-stage process in which the first stage generates potentially noisy, overlapping depth maps from a set of calibrated images and the second stage fuses these depth maps to obtain an integrated surface with higher accuracy, suppressed noise, and reduced redundancy. We show that by dividing the processing into two stages we are able to achieve a very high throughput because we are able to use a computationally cheap stereo algorithm and because this architecture is amenable to hardwareaccelerated (GPU) implementations. A rigorous formulation based on the notion of stability of a depth estimate is presented first. It aims to determine the validity of a depth estimate by rendering multiple depth maps into the reference view as well as rendering the reference depth map into the other views in order to detect occlusions and freespace violations. We also present an approximate alternative formulation that selects and validates only one hypothesis based on confidence. Both formulations enable us to perform video-based reconstruction at up to 25 frames per second. We show results on the Multi-View Stereo Evaluation benchmark datasets and several outdoors video sequences. Extensive quantitative analysis is performed using an accurately surveyed model of a real building as ground truth.},
  isbn = {978-1-4244-1630-1},
  langid = {english}
}

@article{merzlyakLightAbsorptionAnthocyanins2008,
  title = {Light Absorption by Anthocyanins in Juvenile, Stressed, and Senescing Leaves},
  author = {Merzlyak, Mark N. and Chivkunova, Olga B. and Solovchenko, Alexei E. and Naqvi, K. Razi},
  year = {2008},
  month = oct,
  journal = {Journal of Experimental Botany},
  volume = {59},
  number = {14},
  pages = {3903--3911},
  issn = {0022-0957},
  doi = {10.1093/jxb/ern230},
  urldate = {2023-01-13},
  abstract = {The optical properties of leaves from five species, Norway maple (Acer platanoides L.), cotoneaster (Cotoneaster alaunica Golite), hazel (Corylus avellana L.), Siberian dogwood (Cornus alba L.), and Virginia creeper (Parthenocissus quinquefolia (L.) Planch.), differing in pigment composition and at different stages of ontogenesis, were studied. Anthocyanin absorption maxima in vivo, as estimated with spectrophotometry of intact anthocyanic versus acyanic leaves and microspectrophotometry of vacuoles in the leaf cross-sections, were found between 537 nm and 542 nm, showing a red shift of 5--20 nm compared with the corresponding maxima in acidic water--methanol extracts. In non-senescent leaves, strong anthocyanin absorption was found between 500 nm and 600 nm (with a 70--80 nm apparent bandwidth). By and large, absorption by anthocyanin in leaves followed a modified form of the Lambert--Beer law, showing a linear trend up to a content of nearly 50 nmol cm-2, and permitting thereby a non-invasive determination of anthocyanin content. The apparent specific absorption coefficients of anthocyanins at 550 nm showed no substantial dependence on the species. Anthocyanin contribution to total light absorption at 550 nm was followed in maple leaves in the course of autumn senescence. Photoprotection by vacuolar anthocyanins is discussed with special regard to their distribution within a leaf; radiation screening by anthocyanins predominantly localized in the epidermal cells in A. platanoides and C. avellana leaves was also evaluated.}
}

@article{mewesSpectralRequirementsAirborne2011,
  title = {Spectral Requirements on Airborne Hyperspectral Remote Sensing Data for Wheat Disease Detection},
  author = {Mewes, Thorsten and Franke, Jonas and Menz, Gunter},
  year = {2011},
  month = dec,
  journal = {Precision Agriculture},
  volume = {12},
  number = {6},
  pages = {795--812},
  issn = {1573-1618},
  doi = {10.1007/s11119-011-9222-9},
  urldate = {2023-01-13},
  abstract = {Remote sensing approaches are of increasing importance for agricultural applications, particularly for the support of selective agricultural measures that increase the productivity of crop stands. In contrast to multi-spectral image data, hyperspectral data has been shown to be highly suitable for the detection of crop growth anomalies, since they allow a detailed examination of stress-dependent changes in certain spectral ranges. However, the entire spectrum covered by hyperspectral data is probably not needed for discrimination between healthy and stressed plants. To define an optimal sensor-based system or a data product designed for crop stress detection, it is necessary to know which spectral wavelengths are significantly affected by stress factors and which spectral resolution is needed. In this study, a single airborne hyperspectral HyMap dataset was analyzed for its potential to detect plant stress symptoms in wheat stands induced by a pathogen infection. The Bhattacharyya distance (BD) with a forward feature search strategy was used to select relevant bands for the differentiation between healthy and fungal infected stands. Two classification algorithms, i.e. spectral angle mapper (SAM) and support vector machines (SVM) were used to classify the data covering an experimental field. Thus, the original dataset as well as datasets reduced to several band combinations as selected by the feature selection approach were classified. To analyze the influence of the spectral resolution on the detection accuracy, the original dataset was additionally stepwise spectrally resampled and a feature selection was carried out on each step. It is demonstrated that just a few phenomenon-specific spectral features are sufficient to detect wheat stands infected with powdery mildew. With original spectral resolution of HyMap, the highest classification accuracy could be obtained by using only 13 spectral bands with a Kappa coefficient of 0.59 in comparison to Kappa 0.57 using all spectral bands of the HyMap sensor. The results demonstrate that even a few hyperspectral bands as well as bands with lower spectral resolution still allow an adequate detection of fungal infections in wheat. By focusing on a few relevant bands, the detection accuracy could be enhanced and thus more reliable information could be extracted which may be helpful in agricultural practice.},
  langid = {english},
  keywords = {Bhattacharyya distance,Crop stress,Data reduction,Feature selection,Hyperspectral data,Spectral angle mapper,Spectral resolution,Support vector machines}
}

@article{mezarisStillImageObjective,
  title = {Still {{Image Objective Segmentation Evaluation}} Using {{Ground Truth}}},
  author = {Mezaris, V and Kompatsiaris, I and Strintzis, M G},
  abstract = {In this paper, an objective segmentation evaluation metric suitable for the evaluation of still image segmentation results is proposed. The proposed metric is based on the spatial accuracy approach, originally proposed for the evaluation of foreground/backgroung segmentation masks generated from video sequences. This approach is extended to still image segmentation evaluation, where both the estimated segmentation masks and the ground truth mask typically contain multiple regions. The proposed method takes into account, using a single metric, not only the accuracy of the boundary localization of the created segments but also the under-segmentation and over-segmentation effects, which can hinder the performance of any segmentation algorithm and decrease the usability of the segmentation results in content-based applications. Several experiments have shown the potential of this approach.},
  langid = {english}
}

@article{miaoLabel3DMaizeToolkit3D2021,
  title = {{{Label3DMaize}}: Toolkit for {{3D}} Point Cloud Data Annotation of Maize Shoots},
  shorttitle = {{{Label3DMaize}}},
  author = {Miao, Teng and Wen, Weiliang and Li, Yinglun and Wu, Sheng and Zhu, Chao and Guo, Xinyu},
  year = {2021},
  month = may,
  journal = {GigaScience},
  volume = {10},
  number = {5},
  pages = {giab031},
  issn = {2047-217X},
  doi = {10.1093/gigascience/giab031},
  urldate = {2021-12-18},
  abstract = {Abstract                              Background                The 3D point cloud is the most direct and effective data form for studying plant structure and morphology. In point cloud studies, the point cloud segmentation of individual plants to organs directly determines the accuracy of organ-level phenotype estimation and the reliability of the 3D plant reconstruction. However, highly accurate, automatic, and robust point cloud segmentation approaches for plants are unavailable. Thus, the high-throughput segmentation of many shoots is challenging. Although deep learning can feasibly solve this issue, software tools for 3D point cloud annotation to construct the training dataset are lacking.                                            Results                We propose a top-to-down point cloud segmentation algorithm using optimal transportation distance for maize shoots. We apply our point cloud annotation toolkit for maize shoots, Label3DMaize, to achieve semi-automatic point cloud segmentation and annotation of maize shoots at different growth stages, through a series of operations, including stem segmentation, coarse segmentation, fine segmentation, and sample-based segmentation. The toolkit takes {$\sim$}4--10 minutes to segment a maize shoot and consumes 10--20\% of the total time if only coarse segmentation is required. Fine segmentation is more detailed than coarse segmentation, especially at the organ connection regions. The accuracy of coarse segmentation can reach 97.2\% that of fine segmentation.                                            Conclusion                Label3DMaize integrates point cloud segmentation algorithms and manual interactive operations, realizing semi-automatic point cloud segmentation of maize shoots at different growth stages. The toolkit provides a practical data annotation tool for further online segmentation research based on deep learning and is expected to promote automatic point cloud processing of various plants.},
  langid = {english}
}

@article{millerPlantDiseaseDiagnostic2009,
  title = {Plant {{Disease Diagnostic Capabilities}} and {{Networks}}},
  author = {Miller, Sally A. and Beed, Fen D. and Harmon, Carrie Lapaire},
  year = {2009},
  month = sep,
  journal = {Annual Review of Phytopathology},
  volume = {47},
  number = {1},
  pages = {15--38},
  issn = {0066-4286, 1545-2107},
  doi = {10.1146/annurev-phyto-080508-081743},
  urldate = {2023-01-13},
  abstract = {Emerging, re-emerging and endemic plant pathogens continue to challege our ability to safeguard plant health worldwide. Further, globalization, climate change, increased human mobility, and pathogen and vector evolution have combined to increase the spread of invasive plant pathogens. Early and accurate diagnoses and pathogen surveillance on local, regional, and global scales are necessary to predict outbreaks and allow time for development and application of mitigation strategies. Plant disease diagnostic networks have developed worldwide to address the problems of efficient and effective disease diagnosis and pathogen detection, engendering cooperation of institutions and experts within countries and across national borders. Networking maximizes impact in the face of shrinking government investments in agriculture and diminishing human resource capacity in diagnostics and applied pathology. New technologies promise to improve the speed and accuracy of disease diagnostics and pathogen detection. Widespread adoption of standard operating procedures and diagnostic laboratory accreditation serve to build trust and confidence among institutions. Case studies of national, regional, and international diagnostic networks are presented.},
  langid = {english}
}

@article{minerviniImagebasedPlantPhenotyping2014,
  title = {Image-Based Plant Phenotyping with Incremental Learning and Active Contours},
  author = {Minervini, Massimo and Abdelsamea, Mohammed M. and Tsaftaris, Sotirios A.},
  year = {2014},
  month = sep,
  journal = {Ecological Informatics},
  series = {Special {{Issue}} on {{Multimedia}} in {{Ecology}} and {{Environment}}},
  volume = {23},
  pages = {35--48},
  issn = {1574-9541},
  doi = {10.1016/j.ecoinf.2013.07.004},
  urldate = {2023-01-13},
  abstract = {Plant phenotyping investigates how a plant's genome, interacting with the environment, affects the observable traits of a plant (phenome). It is becoming increasingly important in our quest towards efficient and sustainable agriculture. While sequencing the genome is becoming increasingly efficient, acquiring phenotype information has remained largely of low throughput. Current solutions for automated image-based plant phenotyping, rely either on semi-automated or manual analysis of the imaging data, or on expensive and proprietary software which accompanies costly hardware infrastructure. While some attempts have been made to create software applications that enable the analysis of such images in an automated fashion, most solutions are tailored to particular acquisition scenarios and restrictions on experimental design. In this paper we propose and test, a method for the segmentation and the automated analysis of time-lapse plant images from phenotyping experiments in a general laboratory setting, that can adapt to scene variability. The method involves minimal user interaction, necessary to establish the statistical experiments that may follow. At every time instance (i.e., a digital photograph), it segments the plants in images that contain many specimens of the same species. For accurate plant segmentation we propose a vector valued level set formulation that incorporates features of color intensity, local texture, and prior knowledge. Prior knowledge is incorporated using a plant appearance model implemented with Gaussian mixture models, which utilizes incrementally information from previously segmented instances. The proposed approach is tested on Arabidopsis plant images acquired with a static camera capturing many subjects at the same time. Our validation with ground truth segmentations and comparisons with state-of-the-art methods in the literature shows that the proposed method is able to handle images with complicated and changing background in an automated fashion. An accuracy of 96.7\% (dice similarity coefficient) was observed, which was higher than other methods used for comparison. While here it was tested on a single plant species, the fact that we do not employ shape driven models and we do not rely on fully supervised classification (trained on a large dataset) increases the ease of deployment of the proposed solution for the study of different plant species in a variety of laboratory settings. Our solution will be accompanied by an easy to use graphical user interface and, to facilitate adoption, we will make the software available to the scientific community.},
  langid = {english},
  keywords = {Active contour model,Agriculture,Gaussian mixture model,Machine learning,Phenotyping,Plant segmentation}
}

@article{minkSensorbasedEvaluationMaize2020,
  title = {Sensor-Based Evaluation of Maize ({{Zea}} Mays) and Weed Response to Post-Emergence Herbicide Applications of {{Isoxaflutole}} and {{Cyprosulfamide}} Applied as Crop Seed Treatment or Herbicide Mixing Partner},
  author = {Mink, Robin and Linn, Alexander Ingo and Santel, Hans-Joachim and Gerhards, Roland},
  year = {2020},
  journal = {Pest Management Science},
  volume = {76},
  number = {5},
  pages = {1856--1865},
  issn = {1526-4998},
  doi = {10.1002/ps.5715},
  urldate = {2023-03-24},
  abstract = {BACKGROUND Some maize post-emergence herbicides obtain their crop/weed selectivity only through the use of chemical crop safeners. Safeners improve the tolerance of maize to herbicidal active ingredients. In order to investigate the crop response to safener (cyprosulfamide) spray application and seed treatment, greenhouse and field trials were conducted on three maize development stages (2-, 4-, and 6-leaf stage). Visual estimations on crop vitality were compared to ground-based and airborne hyperspectral and multispectral sensors. RESULTS The reduction of cyprosulfamide by 88\% when applied as seed treatment did not significantly reduce maize biomass yields at the field. The crop deterioration in both trials was stronger in the cyprosulfamide seed treatments compared to the spray applications but was found to be transient in the field trial. The hyperspectral sensor and multispectral camera data correlated with R2 = 0.84 (CropSpec Vegetation Index) and R2 = 0.64 (Green Normalized Difference Vegetation Index). CONCLUSION The sensor-based collection of crop responses to treatments enables early, quantifiable and auditor-independent assessments. In particular, the airborne multispectral imagery assessment of field experiments provides more detailed and comprehensive information than visually collected data. {\copyright} 2019 The Authors. Pest Management Science published by John Wiley \& Sons Ltd on behalf of Society of Chemical Industry.},
  langid = {english},
  keywords = {crop stress measurement,remote sensing,sensor fusion,spectral indices,spectrometer,UAV multispectral imagery,weed management},
  file = {/home/samuelebumbaca/Zotero/storage/AIZ44UKB/ps.html}
}

@article{mirandaDetectionAnomalousGrapevine2022,
  title = {Detection of {{Anomalous Grapevine Berries Using Variational Autoencoders}}},
  author = {Miranda, Miro and Zabawa, Laura and Kicherer, Anna and Strothmann, Laurenz and Rascher, Uwe and Roscher, Ribana},
  year = {2022},
  month = jun,
  journal = {Frontiers in Plant Science},
  volume = {13},
  pages = {729097},
  issn = {1664-462X},
  doi = {10.3389/fpls.2022.729097},
  urldate = {2025-01-05},
  abstract = {Grapevine is one of the economically most important quality crops. The monitoring of the plant performance during the growth period is, therefore, important to ensure a high quality end-product. This includes the observation, detection, and respective reduction of unhealthy berries (physically damaged, or diseased). At harvest, it is not necessary to know the exact cause of the damage, but rather if the damage is apparent or not. Since a manual screening and selection before harvest is time-consuming and expensive, we propose an automatic, image-based machine learning approach, which can lead observers directly to anomalous areas without the need to monitor every plant manually. Specifically, we train a fully convolutional variational autoencoder with a feature perceptual loss on images with healthy berries only and consider image areas with deviations from this model as damaged berries. We use heatmaps which visualize the results of the trained neural network and, therefore, support the decision making for farmers. We compare our method against a convolutional autoencoder that was successfully applied to a similar task and show that our approach outperforms it.},
  pmcid = {PMC9198582},
  pmid = {35720600}
}

@article{mirikSatelliteRemoteSensing2011,
  title = {Satellite {{Remote Sensing}} of {{Wheat Infected}} by {{Wheat}} Streak Mosaic Virus},
  author = {Mirik, M. and Jones, D. C. and Price, J. A. and Workneh, F. and Ansley, R. J. and Rush, C. M.},
  year = {2011},
  month = jan,
  journal = {Plant Disease},
  volume = {95},
  number = {1},
  pages = {4--12},
  publisher = {Scientific Societies},
  issn = {0191-2917},
  doi = {10.1094/PDIS-04-10-0256},
  urldate = {2023-01-13},
  abstract = {The prevalence of wheat streak mosaic, caused by Wheat streak mosaic virus, was assessed using Landsat 5 Thematic Mapper (TM) images in two counties of the Texas Panhandle during the 2005--2006 and 2007--2008 crop years. In both crop years, wheat streak mosaic was widely distributed in the counties studied. Healthy and diseased wheat were separated on the images using the maximum likelihood classifier. The overall classification accuracies were between 89.47 and 99.07\% for disease detection when compared to ``ground truth'' field observations. Omission errors (i.e., pixels incorrectly excluded from a particular class and assigned to other classes) varied between 0 and 12.50\%. Commission errors (i.e., pixels incorrectly assigned to a particular class that actually belong to other classes) ranged from 0 to 23.81\%. There were substantial differences between planted wheat acreage reported by the United States Department of Agriculture-National Agricultural Statistics Service (USDA-NASS) and that detected by image analyses. However, harvested wheat acreage reported by USDA-NASS and that detected by image classifications were closely matched. These results indicate that the TM image can be used to accurately detect and quantify incidence of wheat streak mosaic over large areas. This method appears to be one of the best currently available for identification and mapping disease incidence over large and remote areas by offering a repeatable, inexpensive, and synoptic strategy during the course of a growing season.}
}

@misc{MiSTreeMistree13,
  title = {{{MiSTree}} --- Mistree 1.3 Documentation},
  urldate = {2024-06-10},
  howpublished = {https://mistree.readthedocs.io/en/latest/\#installation},
  file = {/home/samuelebumbaca/Zotero/storage/DMRXPKCJ/latest.html}
}

@article{moulonPositionnementRobustePrecis,
  title = {{Positionnement robuste et pr{\'e}cis de r{\'e}seaux d'images}},
  author = {Moulon, Pierre},
  pages = {193},
  langid = {french}
}

@phdthesis{moulonPositionnementRobustePrecis2014,
  title = {Positionnement Robuste et Pr{\'e}cis de R{\'e}seaux d'images},
  author = {Moulon, Pierre},
  year = {2014},
  school = {Universit{\'e} Paris-Est}
}

@article{moulonPositionnementRobustePrecisa,
  title = {{Positionnement robuste et pr{\'e}cis de r{\'e}seaux d'images}},
  author = {Moulon, Pierre},
  pages = {193},
  langid = {french}
}

@misc{mukherjeeClusterGANLatentSpace2019,
  title = {{{ClusterGAN}} : {{Latent Space Clustering}} in {{Generative Adversarial Networks}}},
  shorttitle = {{{ClusterGAN}}},
  author = {Mukherjee, Sudipto and Asnani, Himanshu and Lin, Eugene and Kannan, Sreeram},
  year = {2019},
  month = jan,
  number = {arXiv:1809.03627},
  eprint = {1809.03627},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1809.03627},
  urldate = {2025-01-13},
  abstract = {Generative Adversarial networks (GANs) have obtained remarkable success in many unsupervised learning tasks and unarguably, clustering is an important unsupervised learning problem. While one can potentially exploit the latent-space back-projection in GANs to cluster, we demonstrate that the cluster structure is not retained in the GAN latent space. In this paper, we propose ClusterGAN as a new mechanism for clustering using GANs. By sampling latent variables from a mixture of one-hot encoded variables and continuous latent variables, coupled with an inverse network (which projects the data to the latent space) trained jointly with a clustering specific loss, we are able to achieve clustering in the latent space. Our results show a remarkable phenomenon that GANs can preserve latent space interpolation across categories, even though the discriminator is never exposed to such vectors. We compare our results with various clustering baselines and demonstrate superior performance on both synthetic and real datasets.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/samuelebumbaca/Zotero/storage/ITR7W5L6/1809.html}
}

@misc{mukherjeeClusterGANLatentSpace2019a,
  title = {{{ClusterGAN}} : {{Latent Space Clustering}} in {{Generative Adversarial Networks}}},
  shorttitle = {{{ClusterGAN}}},
  author = {Mukherjee, Sudipto and Asnani, Himanshu and Lin, Eugene and Kannan, Sreeram},
  year = {2019},
  month = jan,
  number = {arXiv:1809.03627},
  eprint = {1809.03627},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1809.03627},
  urldate = {2025-01-13},
  abstract = {Generative Adversarial networks (GANs) have obtained remarkable success in many unsupervised learning tasks and unarguably, clustering is an important unsupervised learning problem. While one can potentially exploit the latent-space back-projection in GANs to cluster, we demonstrate that the cluster structure is not retained in the GAN latent space. In this paper, we propose ClusterGAN as a new mechanism for clustering using GANs. By sampling latent variables from a mixture of one-hot encoded variables and continuous latent variables, coupled with an inverse network (which projects the data to the latent space) trained jointly with a clustering specific loss, we are able to achieve clustering in the latent space. Our results show a remarkable phenomenon that GANs can preserve latent space interpolation across categories, even though the discriminator is never exposed to such vectors. We compare our results with various clustering baselines and demonstrate superior performance on both synthetic and real datasets.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/samuelebumbaca/Zotero/storage/JZ4FBCK6/1809.html}
}

@article{myronenkoPointSetRegistration2010,
  title = {Point {{Set Registration}}: {{Coherent Point Drift}}},
  shorttitle = {Point {{Set Registration}}},
  author = {Myronenko, Andriy and {Xubo Song}},
  year = {2010},
  month = dec,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {32},
  number = {12},
  pages = {2262--2275},
  issn = {0162-8828},
  doi = {10.1109/TPAMI.2010.46},
  urldate = {2021-12-19}
}

@misc{nagarAutomatedSeedQuality2021,
  title = {Automated {{Seed Quality Testing System}} Using {{GAN}} \& {{Active Learning}}},
  author = {Nagar, Sandeep and Pani, Prateek and Nair, Raj and Varma, Girish},
  year = {2021},
  month = oct,
  number = {arXiv:2110.00777},
  eprint = {2110.00777},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2110.00777},
  urldate = {2025-01-05},
  abstract = {Quality assessment of agricultural produce is a crucial step in minimizing food stock wastage. However, this is currently done manually and often requires expert supervision, especially in smaller seeds like corn. We propose a novel computer vision-based system for automating this process. We build a novel seed image acquisition setup, which captures both the top and bottom views. Dataset collection for this problem has challenges of data annotation costs/time and class imbalance. We address these challenges by i.) using a Conditional Generative Adversarial Network (CGAN) to generate real-looking images for the classes with lesser images and ii.) annotate a large dataset with minimal expert human intervention by using a Batch Active Learning (BAL) based annotation tool. We benchmark different image classification models on the dataset obtained. We are able to get accuracies of up to 91.6\% for testing the physical purity of seed samples.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Hardware Architecture},
  file = {/home/samuelebumbaca/Zotero/storage/4XT7JNAC/2110.html}
}

@article{nawazRobustDeepLearning2022,
  title = {A Robust Deep Learning Approach for Tomato Plant Leaf Disease Localization and Classification},
  author = {Nawaz, Marriam and Nazir, Tahira and Javed, Ali and Masood, Momina and Rashid, Junaid and Kim, Jungeun and Hussain, Amir},
  year = {2022},
  month = nov,
  journal = {Scientific Reports},
  volume = {12},
  number = {1},
  pages = {18568},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-022-21498-5},
  urldate = {2023-09-01},
  abstract = {Tomato plants' disease detection and classification at the earliest stage can save the farmers from expensive crop sprays and can assist in increasing the food quantity. Although, extensive work has been presented by the researcher for the tomato plant disease classification, however, the timely localization and identification of various tomato leaf diseases is a complex job as a consequence of the huge similarity among the healthy and affected portion of plant leaves. Furthermore, the low contrast information between the background and foreground of the suspected sample has further complicated the plant leaf disease detection process. To deal with the aforementioned challenges, we have presented a robust deep learning (DL)-based approach namely ResNet-34-based Faster-RCNN for tomato plant leaf disease classification. The proposed method includes three basic steps. Firstly, we generate the annotations of the suspected images to specify the region of interest (RoI). In the next step, we have introduced ResNet-34 along with Convolutional Block Attention Module (CBAM) as a feature extractor module of Faster-RCNN to extract the deep key points. Finally, the calculated features are utilized for the Faster-RCNN model training to locate and categorize the numerous tomato plant leaf anomalies. We tested the presented work on an accessible standard database, the PlantVillage Kaggle dataset. More specifically, we have obtained the mAP and accuracy values of 0.981, and 99.97\% respectively along with the test time of 0.23~s. Both qualitative and quantitative results confirm that the presented solution is robust to the detection of plant leaf disease and can replace the manual systems. Moreover, the proposed method shows a low-cost solution to tomato leaf disease classification which is robust to several image transformations like the variations in the size, color, and orientation of the leaf diseased portion. Furthermore, the framework can locate the affected plant leaves under the occurrence of blurring, noise, chrominance, and brightness variations. We have confirmed through the reported results that our approach is robust to several tomato leaf diseases classification under the varying image capturing conditions. In the future, we plan to extend our approach to apply it to other parts of plants as well.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Diseases,Mathematics and computing,Plant sciences}
}

@article{neillUseCropSensing2011,
  title = {Use of Crop Sensing Technology in Crop Protection Research},
  author = {Neill, {\relax DE} and Follas, {\relax GB}},
  year = {2011},
  journal = {New Zealand Plant Protection},
  volume = {64},
  pages = {287--287}
}

@inproceedings{nguyenPlantPhenotypingUsing2016,
  title = {Plant Phenotyping Using Multi-View Stereo Vision with Structured Lights},
  booktitle = {Autonomous {{Air}} and {{Ground Sensing Systems}} for {{Agricultural Optimization}} and {{Phenotyping}}},
  author = {Nguyen, Thuy Tuong and Slaughter, David C. and Maloof, Julin N. and Sinha, Neelima},
  year = {2016},
  month = may,
  volume = {9866},
  pages = {22--30},
  publisher = {SPIE},
  doi = {10.1117/12.2229513},
  urldate = {2022-11-10},
  abstract = {A multi-view stereo vision system for true 3D reconstruction, modeling and phenotyping of plants was created that successfully resolves many of the shortcomings of traditional camera-based 3D plant phenotyping systems. This novel system incorporates several features including: computer algorithms, including camera calibration, excessive-green based plant segmentation, semi-global stereo block matching, disparity bilateral filtering, 3D point cloud processing, and 3D feature extraction, and hardware consisting of a hemispherical superstructure designed to hold five stereo pairs of cameras and a custom designed structured light pattern illumination system. This system is nondestructive and can extract 3D features of whole plants modeled from multiple pairs of stereo images taken at different view angles. The study characterizes the systems phenotyping performance for 3D plant features: plant height, total leaf area, and total leaf shading area. For plants having specified leaf spacing and size, the algorithms used in our system yielded satisfactory experimental results and demonstrated the ability to study plant development where the same plants were repeatedly imaged and phenotyped over the time.},
  file = {/home/samuelebumbaca/Zotero/storage/T8MJB229/12.2229513.html}
}

@article{nieuwenhuisSpatiallyVaryingColor2013,
  title = {Spatially {{Varying Color Distributions}} for {{Interactive Multilabel Segmentation}}},
  author = {Nieuwenhuis, Claudia and Cremers, Daniel},
  year = {2013},
  month = may,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {35},
  number = {5},
  pages = {1234--1247},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2012.183},
  abstract = {We propose a method for interactive multilabel segmentation which explicitly takes into account the spatial variation of color distributions. To this end, we estimate a joint distribution over color and spatial location using a generalized Parzen density estimator applied to each user scribble. In this way, we obtain a likelihood for observing certain color values at a spatial coordinate. This likelihood is then incorporated in a Bayesian MAP estimation approach to multiregion segmentation which in turn is optimized using recently developed convex relaxation techniques. These guarantee global optimality for the two-region case (foreground/background) and solutions of bounded optimality for the multiregion case. We show results on the GrabCut benchmark, the recently published Graz benchmark, and on the Berkeley segmentation database which exceed previous approaches such as GrabCut [32], the Random Walker [15], Santner's approach [35], TV-Seg [39], and interactive graph cuts [4] in accuracy. Our results demonstrate that taking into account the spatial variation of color models leads to drastic improvements for interactive image segmentation.},
  keywords = {Bayesian methods,color distribution,convex optimization,Image color analysis,Image segmentation,Joints,Kernel,Motion segmentation,Probability distribution,spatially varying}
}

@article{nikithLeafDiseaseDetection2023,
  title = {Leaf {{Disease Detection}} and {{Classification}}},
  author = {Nikith, B. V. and Keerthan, N. K. S. and Praneeth, M. S. and Amrita, Dr. T},
  year = {2023},
  month = jan,
  journal = {Procedia Computer Science},
  series = {International {{Conference}} on {{Machine Learning}} and {{Data Engineering}}},
  volume = {218},
  pages = {291--300},
  issn = {1877-0509},
  doi = {10.1016/j.procs.2023.01.011},
  urldate = {2023-12-17},
  abstract = {The notion of smart farming is gaining traction in the agricultural industry these days, and it makes use of sensors and a variety of machine learning based technologies. According to recent surveys, 56 percent of the agricultural industry is facing significant losses because of diseases developing on plant leaves. It's critical to keep track of the disease's spread and enhance agricultural yields. To prevent the disease from spreading, we must first recognize it on time and prevent it. As a result, we may solve this problem by putting in place some algorithms for detecting sickness on leaves. This paper presents a comparative analysis between support vector machines (SVM) model, K-Nearest Neighbor (KNN) model and convolution neural network (CNN) model. The three different models are presented and examined in this research, and they can detect eight different leaf diseases. The CNN model has achieved an accuracy of 96 percent when trained with the images of soyabean leaf disease dataset, outperforms the KNN and SVM models, which have accuracy of 64 percent and 76 percent, respectively},
  keywords = {CNN,HOG,kernels,KNN,SVM},
  file = {/home/samuelebumbaca/Zotero/storage/SD95BKG2/S187705092300011X.html}
}

@article{nikouBayesianFrameworkImage2010,
  title = {A {{Bayesian Framework}} for {{Image Segmentation With Spatially Varying Mixtures}}},
  author = {Nikou, Christophoros and Likas, Aristidis C and Galatsanos, Nikolaos P},
  year = {2010},
  month = sep,
  journal = {IEEE Transactions on Image Processing},
  volume = {19},
  number = {9},
  pages = {2278--2289},
  issn = {1057-7149, 1941-0042},
  doi = {10.1109/TIP.2010.2047903},
  urldate = {2021-12-19}
}

@inproceedings{nisterScalableRecognitionVocabulary2006,
  title = {Scalable {{Recognition}} with a {{Vocabulary Tree}}},
  booktitle = {2006 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}}'06)},
  author = {Nister, D. and Stewenius, H.},
  year = {2006},
  month = jun,
  volume = {2},
  pages = {2161--2168},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2006.264},
  abstract = {A recognition scheme that scales efficiently to a large number of objects is presented. The efficiency and quality is exhibited in a live demonstration that recognizes CD-covers from a database of 40000 images of popular music CD's. The scheme builds upon popular techniques of indexing descriptors extracted from local regions, and is robust to background clutter and occlusion. The local region descriptors are hierarchically quantized in a vocabulary tree. The vocabulary tree allows a larger and more discriminatory vocabulary to be used efficiently, which we show experimentally leads to a dramatic improvement in retrieval quality. The most significant property of the scheme is that the tree directly defines the quantization. The quantization and the indexing are therefore fully integrated, essentially being one and the same. The recognition quality is evaluated through retrieval on a database with ground truth, showing the power of the vocabulary tree approach, going as high as 1 million images.},
  keywords = {Computer vision,Frequency,Image databases,Image recognition,Indexing,Quantization,Robustness,Spatial databases,Visualization,Vocabulary},
  file = {/home/samuelebumbaca/Zotero/storage/CI87PER9/1641018.html}
}

@article{novakRectificationDigitalImagery1992,
  title = {Rectification of {{Digital Imagery}}},
  author = {Novak, Kurt},
  year = {1992},
  journal = {PHOTOGRAMMETRIC ENGINEERING},
  pages = {6},
  abstract = {Different methods can be applied to generate digital orthophotos. Three commonly used approaches are analyzed and compared in this paper. They can be applied to rectify both digitized aerial photographs and satellite scenes. These methods are polynomial, projective, and differential rectifications. The first two are defined by analytical transformations between image and orthophoto without considering the geometry and orientation of the camera. They are approximate solutions. The last one models the physical reality of the imaging process by means of the collinearity equations and corrects for relief displacements. For eliminating distortions of the camera system, additional parameters were included. This proves to be necessary when images are directly taken by video cameras. All three methods were implemented on a workstation and were tested with digitized aerial photographs and video images. By overlaying GIS data over the digital orthophoto, the quality of the rectification is checked. To determine the planimetric accuracy of the results, the coordinates of targets were measured in a digital orthophoto and compared to known map coordinates.},
  langid = {english}
}

@article{nutterDiseaseAssessmentConcepts2006,
  title = {Disease {{Assessment Concepts}} and the {{Advancements Made}} in {{Improving}} the {{Accuracy}} and {{Precision}} of {{Plant Disease Data}}},
  author = {Nutter, Forrest W. and Esker, Paul D. and Netto, Rosalee A. Coelho},
  year = {2006},
  month = may,
  journal = {European Journal of Plant Pathology},
  volume = {115},
  number = {1},
  pages = {95--103},
  issn = {1573-8469},
  doi = {10.1007/s10658-005-1230-z},
  urldate = {2023-01-13},
  abstract = {New concepts in phytopathometry continue to emerge, such as the evolution of the concept of pathogen intensity versus the well-established concept of disease intensity. The concept of pathogen severity, defined as the quantitative measurement of the amount of pathogen per sampling unit has also emerged in response to the now commonplace development of quantitative molecular detection tools. Although the concept of disease severity, i.e., the amount of disease per sampling unit, is a well-established concept, the accuracy and precision of visual estimates of disease severity is often questioned. This article will review disease assessment concepts, as well as the methods and assessment aides currently available to improve the accuracy and precision of visually-based disease severity data. The accuracy and precision of visual disease severity assessments can be improved by quantitatively measuring and comparing the accuracy and precision of rates and/or assessment methods using linear regression, by using computer-based disease assessment training programmes, and by developing and using diagrammatic keys (standard area diagrams).},
  langid = {english},
  keywords = {phytopathometry}
}

@article{nutterImprovingAccuracyPrecision1995,
  title = {Improving the Accuracy and Precision of Disease Assessments: Selection of Methods and Use of Computer-Aided Training Programs},
  shorttitle = {Improving the Accuracy and Precision of Disease Assessments},
  author = {Nutter, Forrest W. and Schultz, Patricia M.},
  year = {1995},
  month = jun,
  journal = {Canadian Journal of Plant Pathology},
  volume = {17},
  number = {2},
  pages = {174--184},
  publisher = {Taylor \& Francis},
  issn = {0706-0661},
  doi = {10.1080/07060669509500709},
  urldate = {2023-01-13}
}

@article{obertiSelectiveSprayingGrapevines2016,
  title = {Selective Spraying of Grapevines for Disease Control Using a Modular Agricultural Robot},
  author = {Oberti, Roberto and Marchi, Massimo and Tirelli, Paolo and Calcante, Aldo and Iriti, Marcello and Tona, Emanuele and Ho{\v c}evar, Marko and Baur, Joerg and Pfaff, Julian and Sch{\"u}tz, Christoph and Ulbrich, Heinz},
  year = {2016},
  month = jun,
  journal = {Biosystems Engineering},
  series = {Special {{Issue}}: {{Advances}} in {{Robotic Agriculture}} for {{Crops}}},
  volume = {146},
  pages = {203--215},
  issn = {1537-5110},
  doi = {10.1016/j.biosystemseng.2015.12.004},
  urldate = {2023-01-13},
  abstract = {Due to their recognised role in causing environmental pressures, the need to reduce production costs and public concerns over the healthfulness of fresh products and food, reducing pesticide use in agriculture is a major objective. In current farming practice, pesticides are typically applied uniformly across fields, despite many pests and diseases exhibiting uneven spatial distributions and evolving around discrete foci. This is the fundamental rationale for implementing the selective targeting of pesticide applications such that pesticides are deposited only where and when they are needed and at the correct dose. This approach is explored using the example of powdery mildew on grape vines controlled by means of a modular agricultural robot developed within the EU-project CROPS. The CROPS manipulator was configured to six degrees of freedom and equipped with a new precision-spraying end-effector with an integrated disease-sensing system based on R-G-NIR multispectral imaging. The robotic system was tested on four different replicates of grapevine canopy plots (5~m in length~{\texttimes}~1.8~m in height) prepared in a greenhouse setup by aligning potted plants exhibiting different levels of disease. The results indicate that the robot was able to automatically detect and spray from 85\% to 100\% of the diseased area within the canopy and to reduce the pesticide use from 65\% to 85\% when compared to a conventional homogeneous spraying of the canopy. This work, to the best of our knowledge, is the first using a totally automatic selective system for spraying of diseases in specialty crops.},
  langid = {english},
  keywords = {Agricultural robot,Automation,Crop protection,Disease sensing,Precision spraying}
}

@article{oerkeHyperspectralPhenotypingReaction2016,
  title = {Hyperspectral Phenotyping of the Reaction of Grapevine Genotypes to {{{\emph{Plasmopara}}}}{\emph{ Viticola}}},
  author = {Oerke, Erich-Christian and Herzog, Katja and Toepfer, Reinhard},
  year = {2016},
  month = oct,
  journal = {Journal of Experimental Botany},
  volume = {67},
  number = {18},
  pages = {5529--5543},
  issn = {0022-0957, 1460-2431},
  doi = {10.1093/jxb/erw318},
  urldate = {2021-12-22},
  langid = {english}
}

@article{omasaImageAnalysisChlorophyll1987,
  title = {Image {{Analysis}} of {{Chlorophyll Fluorescence Transients}} for {{Diagnosing}} the {{Photosynthetic System}} of {{Attached Leaves}}},
  author = {Omasa, Kenji and Shimazaki, Ken-Ichiro and Aiga, Ichiro and Larcher, Walter and Onoe, Morio},
  year = {1987},
  month = jul,
  journal = {Plant Physiology},
  volume = {84},
  number = {3},
  pages = {748--752},
  issn = {0032-0889},
  doi = {10.1104/pp.84.3.748},
  abstract = {A new image instrumentation system for quantitative analysis of the rapid change in intensity of chlorophyll fluorescence during dark-light transition (CFI, chlorophyll fluorescence induction), which is a sensitive indicator of the various reactions of photosynthesis, was developed and its performance was evaluated. This system made it possible to resolve CFI at any small leaf area (about 1 square millimeter) of a whole leaf when the plant was illuminated by blue-green light at more than 50 micromoles photons per square meter per second. In order to test the usefulness of this system, we applied it to analyze the effect of SO2 on photosynthetic apparatus in attached sunflower leaves. Dynamic CFI imaging over the whole single leaf, where there was no visible injury, indicated not only the local changes in photosynthetic activity but also the site of inhibition in photosynthetic electron transport system in chloroplasts. The new instrumentation system will be useful for the analytical diagnosis of various stress-actions on plants in situ.}
}

@misc{OpenCVCameraCalibration,
  title = {{{OpenCV}}: {{Camera Calibration}}},
  urldate = {2023-03-25},
  howpublished = {https://docs.opencv.org/4.x/dc/dbb/tutorial\_py\_calibration.html},
  file = {/home/samuelebumbaca/Zotero/storage/AKUA67N8/tutorial_py_calibration.html}
}

@misc{OpenCVDocumentationIndex,
  title = {{{OpenCV}} Documentation Index},
  urldate = {2023-03-24},
  howpublished = {https://docs.opencv.org/},
  file = {/home/samuelebumbaca/Zotero/storage/ZQWW6K7W/docs.opencv.org.html}
}

@article{orusaExploringShorttermClimate2021,
  title = {Exploring {{Short-term}} Climate Change Effects on Rangelands and Broad-Leaved Forests by Free Satellite Data in {{Aosta Valley}} ({{Northwest Italy}})},
  author = {Orusa, Tommaso and Borgogno Mondino, Enrico},
  year = {2021},
  journal = {Climate},
  volume = {9},
  number = {3},
  pages = {47}
}

@article{orusaGeomaticsEOData2020,
  title = {Geomatics and {{EO}} Data to Support Wildlife Diseases Assessment at Landscape Level: {{A}} Pilot Experience to Map Infectious Keratoconjunctivitis in Chamois and Phenological Trends in {{Aosta Valley}} ({{NW Italy}})},
  author = {Orusa, Tommaso and Orusa, Riccardo and Viani, Annalisa and Carella, Emanuele and Borgogno Mondino, Enrico},
  year = {2020},
  journal = {Remote Sensing},
  volume = {12},
  number = {21},
  pages = {3542}
}

@article{orusaGoogleEarthEngine2023,
  title = {A {{Google Earth Engine Algorithm}} to {{Map Phenological Metrics}} in {{Mountain Areas Worldwide}} with {{Landsat Collection}} and {{Sentinel-2}}},
  author = {Orusa, Tommaso and Viani, Annalisa and Cammareri, Duke and Borgogno Mondino, Enrico},
  year = {2023},
  journal = {Geomatics},
  volume = {3},
  number = {1},
  pages = {221--238}
}

@inproceedings{orusaLandsat8Thermal2019,
  title = {Landsat 8 Thermal Data to Support Urban Management and Planning in the Climate Change Era: {{A}} Case Study in {{Torino}} Area, {{NW Italy}}},
  booktitle = {Remote {{Sensing Technologies}} and {{Applications}} in {{Urban Environments IV}}},
  author = {Orusa, {\relax TOMMASO} and Mondino, E Borgogno},
  year = {2019},
  volume = {11157},
  pages = {133--149},
  publisher = {SPIE}
}

@article{orusaPossibleLandCover2022,
  title = {A {{Possible Land Cover EAGLE Approach}} to {{Overcome Remote Sensing Limitations}} in the {{Alps Based}} on {{Sentinel-1}} and {{Sentinel-2}}: {{The Case}} of {{Aosta Valley}} ({{NW Italy}})},
  author = {Orusa, Tommaso and Cammareri, Duke and Borgogno Mondino, Enrico},
  year = {2022},
  journal = {Remote Sensing},
  volume = {15},
  number = {1},
  pages = {178}
}

@article{orusaRiskAssessmentRising2023,
  title = {Risk {{Assessment}} of {{Rising Temperatures Using Landsat}} 4--9 {{LST Time Series}} and {{Meta}}{\textregistered} {{Population Dataset}}: {{An Application}} in {{Aosta Valley}}, {{NW Italy}}},
  author = {Orusa, Tommaso and Viani, Annalisa and Moyo, Boineelo and Cammareri, Duke and {Borgogno-Mondino}, Enrico},
  year = {2023},
  journal = {Remote Sensing},
  volume = {15},
  number = {9},
  pages = {2348},
  publisher = {Multidisciplinary Digital Publishing Institute}
}

@article{orusaRiskAssessmentRising2023a,
  title = {Risk {{Assessment}} of {{Rising Temperatures Using Landsat}} 4--9 {{LST Time Series}} and {{Meta}}{\textregistered} {{Population Dataset}}: {{An Application}} in {{Aosta Valley}}, {{NW Italy}}},
  author = {Orusa, Tommaso and Viani, Annalisa and Moyo, Boineelo and Cammareri, Duke and {Borgogno-Mondino}, Enrico},
  year = {2023},
  journal = {Remote Sensing},
  volume = {15},
  number = {9},
  pages = {2348},
  publisher = {Multidisciplinary Digital Publishing Institute}
}

@article{orusaRiskAssessmentRising2023b,
  title = {Risk {{Assessment}} of {{Rising Temperatures Using Landsat}} 4--9 {{LST Time Series}} and {{Meta}}{\textregistered} {{Population Dataset}}: {{An Application}} in {{Aosta Valley}}, {{NW Italy}}},
  author = {Orusa, Tommaso and Viani, Annalisa and Moyo, Boineelo and Cammareri, Duke and {Borgogno-Mondino}, Enrico},
  year = {2023},
  journal = {Remote Sensing},
  volume = {15},
  number = {9},
  pages = {2348},
  publisher = {Multidisciplinary Digital Publishing Institute}
}

@article{orusaRiskAssessmentRising2023c,
  title = {Risk {{Assessment}} of {{Rising Temperatures Using Landsat}} 4--9 {{LST Time Series}} and {{Meta}}{\textregistered} {{Population Dataset}}: {{An Application}} in {{Aosta Valley}}, {{NW Italy}}},
  author = {Orusa, Tommaso and Viani, Annalisa and Moyo, Boineelo and Cammareri, Duke and {Borgogno-Mondino}, Enrico},
  year = {2023},
  journal = {Remote Sensing},
  volume = {15},
  number = {9},
  pages = {2348},
  publisher = {Multidisciplinary Digital Publishing Institute}
}

@article{orusaScalableEarthObservation2022,
  title = {A {{Scalable Earth Observation Service}} to {{Map Land Cover}} in {{Geomorphological Complex Areas}} beyond the {{Dynamic World}}: {{An Application}} in {{Aosta Valley}} ({{NW Italy}})},
  author = {Orusa, Tommaso and Cammareri, Duke and Borgogno Mondino, Enrico},
  year = {2022},
  journal = {Applied Sciences},
  volume = {13},
  number = {1},
  pages = {390}
}

@article{oteroAnatomySIFTMethod2014,
  title = {Anatomy of the {{SIFT Method}}},
  author = {Otero, Ives Rey and Delbracio, Mauricio},
  year = {2014},
  month = dec,
  journal = {Image Processing On Line},
  volume = {4},
  pages = {370--396},
  issn = {2105-1232},
  doi = {10.5201/ipol.2014.82},
  urldate = {2022-11-24},
  abstract = {This article presents a detailed description and implementation of the Scale Invariant Feature Transform (SIFT), a popular image matching algorithm. This work contributes to a detailed dissection of SIFT's complex chain of transformations and to a careful presentation of each of its design parameters. A companion online demonstration allows the reader to use SIFT and individually set each parameter to analyze its impact on the algorithm results.},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/2ATQY5YG/82.html}
}

@article{otsuThresholdSelectionMethod1979,
  title = {A {{Threshold Selection Method}} from {{Gray-Level Histograms}}},
  author = {Otsu, Nobuyuki},
  year = {1979},
  month = jan,
  journal = {IEEE Transactions on Systems, Man, and Cybernetics},
  volume = {9},
  number = {1},
  pages = {62--66},
  issn = {0018-9472, 2168-2909},
  doi = {10.1109/TSMC.1979.4310076},
  urldate = {2023-12-21}
}

@article{owenEvaluationApplicationTimings2013,
  title = {{Evaluation of Application Timings of Warrant Herbicide for Soybean Phytotoxicity}},
  author = {Owen, Michael D. and Franzenburg, Damian D. and Grossnickle, Dean M. and Lux, James F.},
  year = {2013},
  month = jan,
  journal = {Iowa State University Research and Demonstration Farms Progress Reports},
  volume = {2012},
  number = {1},
  publisher = {Iowa State University Digital Press},
  urldate = {2023-12-17},
  abstract = {{$<$}p{$>$}Warrant herbicide is an encapsulated formulation of acetochlor herbicide and labeled for postemergence use in soybean. This study was designed to evaluate crop safety from various Warrant treatments and application timings including early preplant, preemergence, and postemergence. Early preplant and preemergence applications of Warrant are currently not labeled for use in soybean.{$<$}/p{$>$}},
  langid = {None}
}

@inproceedings{panichevUnetBasedConvolutional2019,
  title = {U-Net Based Convolutional Neural Network for Skeleton Extraction},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition Workshops}}},
  author = {Panichev, Oleg and Voloshyna, Alona},
  year = {2019},
  pages = {0--0},
  urldate = {2024-06-10}
}

@inproceedings{pape3DHistogramBasedSegmentation2015,
  title = {3-{{D Histogram-Based Segmentation}} and {{Leaf Detection}} for {{Rosette Plants}}},
  booktitle = {Computer {{Vision}} - {{ECCV}} 2014 {{Workshops}}},
  author = {Pape, Jean-Michel and Klukas, Christian},
  editor = {Agapito, Lourdes and Bronstein, Michael M. and Rother, Carsten},
  year = {2015},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {61--74},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-16220-1_5},
  abstract = {Recognition and segmentation of plant organs like leaves is one of the major challenges in digital plant phenotyping. Here we present a 3-D histogram-based segmentation and recognition approach for top view images of rosette plants such as Arabidopsis thaliana and tobacco. Furthermore a euclidean-distance-map-based method for the detection of leaves and the corresponding plant leaf segmentation method were developed. An approach for the detection of optimal leaf split points for the separation of overlapping leaf segments was created. We tested and tuned our algorithms for the Leaf Segmentation Challenge (LSC). The results demonstrate that our method is robust and handles demanding imaging situations and different species with high accuracy.},
  isbn = {978-3-319-16220-1},
  langid = {english},
  keywords = {3-D Histogram thresholding,Euclidean distance map,Graph analysis,Leaf counting,Leaf segmentation}
}

@article{paulusMeasuringCrops3D2019,
  title = {Measuring Crops in {{3D}}: Using Geometry for Plant Phenotyping},
  shorttitle = {Measuring Crops in {{3D}}},
  author = {Paulus, Stefan},
  year = {2019},
  month = dec,
  journal = {Plant Methods},
  volume = {15},
  number = {1},
  pages = {103},
  issn = {1746-4811},
  doi = {10.1186/s13007-019-0490-0},
  urldate = {2021-12-18},
  langid = {english}
}

@article{pengRobustCPDAlgorithm2016,
  title = {Robust {{CPD Algorithm}} for {{Non-Rigid Point Set Registration Based}} on {{Structure Information}}},
  author = {Peng, Lei and Li, Guangyao and Xiao, Mang and Xie, Li},
  editor = {Yap, Pew-Thian},
  year = {2016},
  month = feb,
  journal = {PLOS ONE},
  volume = {11},
  number = {2},
  pages = {e0148483},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0148483},
  urldate = {2021-12-19},
  langid = {english}
}

@article{perez-harguindeguyNewHandbookStandardised2013,
  title = {New Handbook for Standardised Measurement of Plant Functional Traits Worldwide},
  author = {{P{\'e}rez-Harguindeguy}, N. and D{\'i}az, S. and Garnier, E. and Lavorel, S. and Poorter, H. and Jaureguiberry, P. and {Bret-Harte}, M. S. and Cornwell, W. K. and Craine, J. M. and Gurvich, D. E. and Urcelay, C. and Veneklaas, E. J. and Reich, P. B. and Poorter, L. and Wright, I. J. and Ray, P. and Enrico, L. and Pausas, J. G. and de Vos, A. C. and Buchmann, N. and Funes, G. and Qu{\'e}tier, F. and Hodgson, J. G. and Thompson, K. and Morgan, H. D. and ter Steege, H. and van der Heijden, M. G. A. and Sack, L. and Blonder, B. and Poschlod, P. and Vaieretti, M. V. and Conti, G. and Staver, A. C. and Aquino, S. and Cornelissen, J. H. C. and {P{\'e}rez-Harguindeguy}, N. and D{\'i}az, S. and Garnier, E. and Lavorel, S. and Poorter, H. and Jaureguiberry, P. and {Bret-Harte}, M. S. and Cornwell, W. K. and Craine, J. M. and Gurvich, D. E. and Urcelay, C. and Veneklaas, E. J. and Reich, P. B. and Poorter, L. and Wright, I. J. and Ray, P. and Enrico, L. and Pausas, J. G. and de Vos, A. C. and Buchmann, N. and Funes, G. and Qu{\'e}tier, F. and Hodgson, J. G. and Thompson, K. and Morgan, H. D. and ter Steege, H. and van der Heijden, M. G. A. and Sack, L. and Blonder, B. and Poschlod, P. and Vaieretti, M. V. and Conti, G. and Staver, A. C. and Aquino, S. and Cornelissen, J. H. C.},
  year = {2013},
  month = apr,
  journal = {Australian Journal of Botany},
  volume = {61},
  number = {3},
  pages = {167--234},
  issn = {1444-9862, 1444-9862},
  doi = {10.1071/BT12225},
  urldate = {2022-01-28},
  abstract = {Plant functional traits are the features (morphological, physiological, phenological) that represent ecological strategies and determine how plants respond to environmental factors, affect other trophic levels and influence ecosystem properties. Variation in plant functional traits, and trait syndromes, has proven useful for tackling many important ecological questions at a range of scales, giving rise to a demand for standardised ways to measure ecologically meaningful plant traits. This line of research has been among the most fruitful avenues for understanding ecological and evolutionary patterns and processes. It also has the potential both to build a predictive set of local, regional and global relationships between plants and environment and to quantify a wide range of natural and human-driven processes, including changes in biodiversity, the impacts of species invasions, alterations in biogeochemical processes and vegetation--atmosphere interactions. The importance of these topics dictates the urgent need for more and better data, and increases the value of standardised protocols for quantifying trait variation of different species, in particular for traits with power to predict plant- and ecosystem-level processes, and for traits that can be measured relatively easily. Updated and expanded from the widely used previous version, this handbook retains the focus on clearly presented, widely applicable, step-by-step recipes, with a minimum of text on theory, and not only includes updated methods for the traits previously covered, but also introduces many new protocols for further traits. This new handbook has a better balance between whole-plant traits, leaf traits, root and stem traits and regenerative traits, and puts particular emphasis on traits important for predicting species' effects on key ecosystem properties. We hope this new handbook becomes a standard companion in local and global efforts to learn about the responses and impacts of different plant species with respect to environmental changes in the present, past and future.},
  langid = {english}
}

@article{pertuzAnalysisFocusMeasure2013,
  title = {Analysis of Focus Measure Operators for Shape-from-Focus},
  author = {Pertuz, Said and Puig, Domenec and Garcia, Miguel Angel},
  year = {2013},
  journal = {Pattern Recognition},
  volume = {46},
  number = {5},
  pages = {1415--1432},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2012.11.011},
  abstract = {Shape-from-focus (SFF) has widely been studied in computer vision as a passive depth recovery and 3D reconstruction method. One of the main stages in SFF is the computation of the focus level for every pixel of an image by means of a focus measure operator. In this work, a methodology to compare the performance of different focus measure operators for shape-from-focus is presented and applied. The selected operators have been chosen from an extensive review of the state-of-the-art. The performance of the different operators has been assessed through experiments carried out under different conditions, such as image noise level, contrast, saturation and window size. Such performance is discussed in terms of the working principles of the analyzed operators.},
  keywords = {Autofocus,Defocus model,Focus measure,Shape from focus}
}

@article{petterInternationalStandardsDiagnosis2008,
  title = {International Standards for the Diagnosis of Regulated Pests},
  author = {Petter, Fran{\c c}oise and Roy, Anne Sophie and Smith, Ian},
  year = {2008},
  month = jul,
  journal = {European Journal of Plant Pathology},
  volume = {121},
  number = {3},
  pages = {331--337},
  issn = {1573-8469},
  doi = {10.1007/s10658-007-9248-z},
  abstract = {For the last 10~years, the European and Mediterranean Plant Protection Organization (EPPO) has run a European Panel on diagnostics, which has developed regional standards on diagnostic protocols. Nearly 80 such standards have now been approved, and are in active use in EPPO countries. In 2003, the Commission for Phytosanitary Measures (CPM) of FAO, in reviewing global needs for International Standards for Phytosanitary Measures (ISPMs), recognized that there is a strong interest in developing diagnostic protocols for all contracting parties to the International Plant Protection Convention (IPPC). Such protocols would support the harmonization of detection and identification procedures worldwide, contribute to greater transparency and comparability in the diagnostics for regulated pests, and assist in the resolution of disputes between trading partners. In addition, such protocols would be very useful in technical assistance programmes. In 2004, the CPM adopted a mechanism for rapid development of ISPMs in specific areas, particularly suitable for diagnostic protocols. A Technical Panel was accordingly established to develop protocols for specific pests and meets on an annual basis. A format for international diagnostic protocols was adopted in 2006 and a list of priority pests was established. In 2003, EPPO initiated a new programme on quality management and accreditation for plant pest laboratories and Standards are now also being developed in this area. In 2006, a survey of existing diagnostic capacities in EPPO member countries was undertaken and a database on diagnostic expertise was created.}
}

@article{PictureThresholdingUsing1978,
  title = {Picture {{Thresholding Using}} an {{Iterative Selection Method}}},
  year = {1978},
  month = aug,
  journal = {IEEE Transactions on Systems, Man, and Cybernetics},
  volume = {8},
  number = {8},
  pages = {630--632},
  issn = {2168-2909},
  doi = {10.1109/TSMC.1978.4310039},
  keywords = {Aircraft,Brightness,Histograms,Image analysis,Image converters,Image segmentation,Iterative methods,Layout,Physics computing,Sampling methods},
  file = {/home/samuelebumbaca/Zotero/storage/NF5EVJWU/stamp.html}
}

@article{pingRetrievalModelSubtle2010,
  title = {{[Retrieval model for subtle variation of contamination stressed maize chlorophyll using hyperspectral data]}},
  author = {Ping, Wang and Liu, Xiang-nanz and Huang, Fang},
  year = {2010},
  month = jan,
  journal = {Guang Pu Xue Yu Guang Pu Fen Xi = Guang Pu},
  volume = {30},
  number = {1},
  pages = {197--201},
  issn = {1000-0593},
  abstract = {Chlorophyll content is an important indicator of photosynthesis activity, stress and nutritional state. In the present paper, the hyperspectral data, foliar chlorophyll content and heavy metal contents in foliar and soil were measured for the maize growing in three natural fields. In most previous research, the contamination stress was controlled artificially in laboratory by adding chromium, zinc or copper pollutant etc. to the soil, and the pollutant concentration added was much higher than that in natural environment. The three sample fields were under different heavy mental contamination level, but all located at the Changchun region, Northeast China, where is called Golden Maize Belts in the world. After continuum removal (400-800 nm), ten spectral indices were computed including max absorption position, normalized reflectance at max absorption position, absorption depth, green peak, normalized reflectance at green peak, red edge, normalized reflectance at red edge, red peak, absorption width, and asymmetry degree. The physics meaning of the above indices and their correlation with maize foliar chlorophyll content were analyzed. It was found that there were close relationships between these indices and foliar chlorophyll content except max absorption position, green edge and asymmetry degree. Besides the asymmetry degree, five indices were selected in the stepwise multiple linear regression for estimating chlorophyll content and its determination coefficient (R2) is 0.7027. Furthermore, in order to measure the weak change information of foliar chlorophyll content under the contamination stress, the BP artificial neural network (ANN-BP) was used. Several ANN-BP models were built and tried with different structure, namely five nodes, seven nodes or ten nodes in input layer, one hidden layer or two hidden layer, and different nodes number in hidden layers. It was found that the highest accuracy of estimates was obtained by the model with two hidden layers, ten nodes in input layer, seven nodes in first hidden layer and 4 nodes in second hidden layer (R2 = 0.9758).},
  langid = {chi},
  pmid = {20302113},
  keywords = {Chlorophyll,Models Theoretical,Neural Networks Computer,Plant Leaves,Spectrum Analysis,Zea mays}
}

@article{pinterRemoteSensingCrop2003,
  title = {Remote {{Sensing}} for {{Crop Management}}},
  author = {Pinter, Paul J., {\relax Jr}. and Hatfield, Jerry L. and Schepers, James S. and Barnes, Edward M. and Moran, M. Susan and Daughtry, Craig S.T. and Upchurch, Dan R.},
  year = {2003},
  month = jun,
  journal = {Photogrammetric Engineering \& Remote Sensing},
  volume = {69},
  number = {6},
  pages = {647--664},
  doi = {10.14358/PERS.69.6.647},
  abstract = {Scientists with the Agricultural Research Service (ARS) and various government agencies and private institutions have provided a great deal of fundamental information relating spectral reflectance and thermal emittance properties of soils and crops to their agronomic and biophysical characteristics. This knowledge has facilitated the development and use of various remote sensing methods for non-destructive monitoring of plant growth and development and for the detection of many environmental stresses which limit plant productivity. Coupled with rapid advances in computing and positionlocating technologies, remote sensing from ground-, air-, and space-based platforms is now capable of providing detailed spatial and temporal information on plant response to their local environment that is needed for site specific agricultural management approaches. This manuscript, which emphasizes contributions by ARS researchers, reviews the biophysical basis of remote sensing; examines approaches that have been developed, refined, and tested for management of water, nutrients, and pests in agricultural crops; and assesses the role of remote sensing in yield prediction. It concludes with a discussion of challenges facing remote sensing in the future.}
}

@misc{PlantDetectionCounting,
  title = {Plant Detection and Counting from High-Resolution {{RGB}} Images Acquired from {{UAVs}}: Comparison between Deep-Learning and Handcrafted Methods with Application to Maize, Sugar Beet, and Sunflower Crops {\textbar} {{bioRxiv}}},
  urldate = {2022-09-25},
  howpublished = {https://www.biorxiv.org/content/10.1101/2021.04.27.441631v1.abstract},
  file = {/home/samuelebumbaca/Zotero/storage/FV55SUWS/2021.04.27.441631v1.html}
}

@misc{PlantDiseaseDetection,
  title = {Plant {{Disease Detection}} by {{Imaging Sensors}} -- {{Parallels}} and {{Specific Demands}} for {{Precision Agriculture}} and {{Plant Phenotyping}} {\textbar} {{Plant Disease}}},
  urldate = {2023-01-13},
  howpublished = {https://apsjournals.apsnet.org/doi/full/10.1094/PDIS-03-15-0340-FE}
}

@article{polakEvaluationMetricImage2009,
  title = {An Evaluation Metric for Image Segmentation of Multiple Objects},
  author = {Polak, Mark and Zhang, Hong and Pi, Minghong},
  year = {2009},
  month = jul,
  journal = {Image and Vision Computing},
  volume = {27},
  number = {8},
  pages = {1223--1227},
  issn = {0262-8856},
  doi = {10.1016/j.imavis.2008.09.008},
  urldate = {2023-01-13},
  abstract = {It is important to be able to evaluate the performance of image segmentation algorithms objectively. In this paper, we define a new error measure which quantifies the performance of an image segmentation algorithm for identifying multiple objects in an image. This error measure is based on object-by-object comparisons of a segmented image and a ground-truth (reference) image. It takes into account the size, shape, and position of each object. Compared to existing error measures, our proposed error measure works at the object level, and is sensitive to both over-segmentation and under-segmentation. Hence, it can serve as a useful tool for comparing image segmentation algorithms and for tuning the parameters of a segmentation algorithm.},
  langid = {english},
  keywords = {Error measure,Evaluation,Image segmentation},
  file = {/home/samuelebumbaca/Zotero/storage/9DJAFTPH/S0262885608001984.html}
}

@article{poorterArtGrowingPlants2012,
  title = {The Art of Growing Plants for Experimental Purposes: A Practical Guide for the Plant Biologist},
  shorttitle = {The Art of Growing Plants for Experimental Purposes},
  author = {Poorter, Hendrik and Fiorani, Fabio and Stitt, Mark and Schurr, Uli and Finck, Alex and Gibon, Yves and Usadel, Bj{\"o}rn and Munns, Rana and Atkin, Owen K. and Tardieu, Fran{\c c}ois and Pons, Thijs L. and Poorter, Hendrik and Fiorani, Fabio and Stitt, Mark and Schurr, Uli and Finck, Alex and Gibon, Yves and Usadel, Bj{\"o}rn and Munns, Rana and Atkin, Owen K. and Tardieu, Fran{\c c}ois and Pons, Thijs L.},
  year = {2012},
  month = jun,
  journal = {Functional Plant Biology},
  volume = {39},
  number = {11},
  pages = {821--838},
  issn = {1445-4416, 1445-4416},
  doi = {10.1071/FP12028},
  urldate = {2022-01-28},
  abstract = {Every year thousands of experiments are conducted using plants grown under more-or-less controlled environmental conditions. The aim of many such experiments is to compare the phenotype of different species or genotypes in a specific environment, or to study plant performance under a range of suboptimal conditions. Our paper aims to bring together the minimum knowledge necessary for a plant biologist to set up such experiments and apply the environmental conditions that are appropriate to answer the questions of interest. We first focus on the basic choices that have to be made with regard to the experimental setup (e.g. where are the plants grown; what rooting medium; what pot size). Second, we present practical considerations concerning the number of plants that have to be analysed considering the variability in plant material and the required precision. Third, we discuss eight of the most important environmental factors for plant growth (light quantity, light quality, CO2, nutrients, air humidity, water, temperature and salinity); what critical issues should be taken into account to ensure proper growth conditions in controlled environments and which specific aspects need attention if plants are challenged with a certain a-biotic stress factor. Finally, we propose a simple checklist that could be used for tracking and reporting experimental conditions.},
  langid = {english}
}

@article{poorterPotSizeMatters2012,
  title = {Pot Size Matters: A Meta-Analysis of the Effects of Rooting Volume on Plant Growth},
  shorttitle = {Pot Size Matters},
  author = {Poorter, Hendrik and B{\"u}hler, Jonas and van Dusschoten, Dagmar and Climent, Jos{\'e} and Postma, Johannes A. and Poorter, Hendrik and B{\"u}hler, Jonas and van Dusschoten, Dagmar and Climent, Jos{\'e} and Postma, Johannes A.},
  year = {2012},
  month = jun,
  journal = {Functional Plant Biology},
  volume = {39},
  number = {11},
  pages = {839--850},
  issn = {1445-4416, 1445-4416},
  doi = {10.1071/FP12049},
  urldate = {2022-01-28},
  abstract = {The majority of experiments in plant biology use plants grown in some kind of container or pot. We conducted a meta-analysis on 65 studies that analysed the effect of pot size on growth and underlying variables. On average, a doubling of the pot size increased biomass production by 43\%. Further analysis of pot size effects on the underlying components of growth suggests that reduced growth in smaller pots is caused mainly by a reduction in photosynthesis per unit leaf area, rather than by changes in leaf morphology or biomass allocation. The appropriate pot size will logically depend on the size of the plants growing in them. Based on various lines of evidence we suggest that an appropriate pot size is one in which the plant biomass does not exceed 1 g L--1. In current research practice {\textasciitilde}65\% of the experiments exceed that threshold. We suggest that researchers need to carefully consider the pot size in their experiments, as small pots may change experimental results and defy the purpose of the experiment.},
  langid = {english}
}

@article{PP11352014,
  title = {{{PP}} 1/135 (4) {{Phytotoxicity}} Assessment},
  year = {2014},
  month = dec,
  journal = {EPPO Bulletin},
  volume = {44},
  number = {3},
  pages = {265--273},
  issn = {02508052},
  doi = {10.1111/epp.12134},
  urldate = {2022-09-06},
  langid = {english}
}

@misc{PP11354Phytotoxicity,
  title = {{{PP1}}/135(4) - {{Phytotoxicity}} Assessment},
  annotation = {https://pp1.eppo.int/standards/PP1-135-4}
}

@article{PP11812022,
  title = {{{PP}} 1/181 (5) {{Conduct}} and Reporting of Efficacy Evaluation Trials, Including Good Experimental Practice},
  year = {2022},
  journal = {EPPO Bulletin},
  volume = {52},
  number = {1},
  pages = {4--16},
  issn = {1365-2338},
  doi = {10.1111/epp.12788},
  urldate = {2022-09-06},
  abstract = {Specific scope This Standard, intended for use in association with EPPO Standards PP 1 Efficacy evaluation of plant protection products, describes the conduct and reporting of efficacy evaluation trials. Specific approval and amendment First approved in 1992--09. First revision approved in 1996--09. Second revision approved in 2003--09. Revision mainly to reflect zonal assessment approved in 2012--09. Revision to reflect parameters for greenhouse and other protective structures in 2021--09.},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/NGFSYVDQ/epp.html}
}

@misc{PP11815Conduct,
  title = {{{PP1}}/181(5) - {{Conduct}} and Reporting of Efficacy Evaluation Trials, Including Good Experimental Practice},
  annotation = {https://pp1.eppo.int/standards/PP1-181-5}
}

@article{PP13192021,
  title = {{{PP}} 1/319 (1) {{General}} Principles for Efficacy Evaluation of Plant Protection Products with a Mode of Action as Plant Defence Inducers},
  year = {2021},
  month = apr,
  journal = {EPPO Bulletin},
  volume = {51},
  number = {1},
  pages = {5--9},
  issn = {0250-8052, 1365-2338},
  doi = {10.1111/epp.12692},
  urldate = {2022-09-06},
  langid = {english}
}

@misc{PrecisionAgricultureFood,
  title = {Precision {{Agriculture}} and {{Food Security}} {\textbar} {{Science}}},
  urldate = {2023-01-13},
  howpublished = {https://www.science.org/doi/abs/10.1126/science.1183899}
}

@misc{PRELIMINARYCONCERNSAGRONOMIC,
  title = {{PRELIMINARY CONCERNS ABOUT AGRONOMIC INTERPRETATION OF NDVI TIME SERIES FROM SENTINEL-2 DATA: PHENOLOGY AND THERMAL EFFICIENCY OF WINTER WHEAT IN PIEMONTE (NW ITALY) - ProQuest}},
  shorttitle = {{PRELIMINARY CONCERNS ABOUT AGRONOMIC INTERPRETATION OF NDVI TIME SERIES FROM SENTINEL-2 DATA}},
  urldate = {2023-03-24},
  abstract = {Explore millions of resources from scholarly journals, books, newspapers, videos and more, on the ProQuest Platform.},
  howpublished = {https://www.proquest.com/openview/38e36faf03bb6acef6bc3a5a6d3cfc0f/1?pq-origsite=gscholar\&cbl=2037674},
  langid = {italian},
  file = {/home/samuelebumbaca/Zotero/storage/7NB4A86U/1.html}
}

@article{prenticeGeneralizationProbitLogit1976,
  title = {A {{Generalization}} of the {{Probit}} and {{Logit Methods}} for {{Dose Response Curves}}},
  author = {Prentice, Ross L.},
  year = {1976},
  journal = {Biometrics},
  volume = {32},
  number = {4},
  eprint = {2529262},
  eprinttype = {jstor},
  pages = {761--768},
  publisher = {[Wiley, International Biometric Society]},
  issn = {0006-341X},
  doi = {10.2307/2529262},
  urldate = {2023-03-24},
  abstract = {The relationship between response probability and dosage in quantal response bioassay is modelled using a four parameter class. In addition to location and scale quantities the model includes two shape parameters that essentially index skewness and heaviness of tails of the dose-response curve. The class of models includes such special cases as the logistic, normal, extreme minimum value, extreme maximum value, double exponential, exponential and reflected exponential distribution functions. Score tests are derived for logistic and normal hypotheses and certain submodels are discussed for which the model fitting is computationally convenient. The data of Bliss [1935] illustrates the potential improvement over usual methods in the estimation of critical dose levels.}
}

@article{qianDevelopmentApplicationCrop2014,
  title = {Development and Application of Crop Monitoring System for Detecting Chlorophyll Content of Tomato Seedlings},
  author = {Qian, Wu and Hong, Sun and Minzan, Li and Wei, Yang},
  year = {2014},
  journal = {International Journal of Agricultural and Biological Engineering},
  volume = {7},
  number = {2},
  pages = {138--145},
  issn = {1934-6352},
  doi = {10.25165/ijabe.v7i2.1220},
  urldate = {2023-02-23},
  abstract = {A crop monitoring system was developed to nondestructively monitor the crop growth status in the field.  With a two channel multispectral camera with one lens, controlling platform, wireless remote control module and control software, the system was able to synchronously acquire visible image (red(R), green(G), blue(B): 400-700 nm) and near-infrared (NIR) image (760-1 000 nm).  The tomato seedlings multi-spectral images collection experiment in the greenhouse was conducted by using the developed system from the seeding stage to fruiting stage.  More than 240 couples of tomato seedlings pictures were acquired with the Soil and Plant Analyzer Development (SPAD) value measured at the same time.  The obtained images were available to process, and some vegetation indexes, such as normalized difference vegetation index (NDVI), ratio vegetation index (RVI) and normalized difference green index (NDGI), were calculated.  Considering the SPAD value and the correlation coefficient between SPAD and other parameters in different fertilization treatments, the multiple linear regressions (MLR) model for tomato seedlings chlorophyll content predication was built based on the average gray value in red, green, blue and NIR, vegetable indexes, NDVI, RVI and NDGI in the 33.3\% (N1), 66.6\% (N2), and 100\% (N3) nutrient levels during seeding stage and blossom and fruit stage.  The R2 of the model is 0.88.  The results revealed that the developed crop monitoring system provided a feasible tool to detect the growth status of tomato.  More filed experiments and multi-spectral image analysis will be investigated to evaluate the crop growth status in the near future. Keywords: multi-spectral image, crop growth status, image acquisition, 2-CCD sensor, precision agriculture DOI: 10.3965/j.ijabe.20140702.017 Citation: Wu Q, Sun H, Li M Z, Yang W.  Development and application of crop monitoring system for detecting chlorophyll content of tomato seedlings.  Int J Agric \& Biol Eng, 2014; 7(2): 138－145.},
  copyright = {Copyright (c)},
  langid = {english},
  keywords = {2-CCD sensor,crop growth status,image acquisition,multi-spectral image,precision agriculture}
}

@inproceedings{quanImagebasedPlantModeling2006,
  title = {Image-Based Plant Modeling},
  booktitle = {{{ACM SIGGRAPH}} 2006 {{Papers}}},
  author = {Quan, Long and Tan, Ping and Zeng, Gang and Yuan, Lu and Wang, Jingdong and Kang, Sing Bing},
  year = {2006},
  month = jul,
  series = {{{SIGGRAPH}} '06},
  pages = {599--604},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1179352.1141929},
  urldate = {2023-01-13},
  abstract = {In this paper, we propose a semi-automatic technique for modeling plants directly from images. Our image-based approach has the distinct advantage that the resulting model inherits the realistic shape and complexity of a real plant. We designed our modeling system to be interactive, automating the process of shape recovery while relying on the user to provide simple hints on segmentation. Segmentation is performed in both image and 3D spaces, allowing the user to easily visualize its effect immediately. Using the segmented image and 3D data, the geometry of each leaf is then automatically recovered from the multiple views by fitting a deformable leaf model. Our system also allows the user to easily reconstruct branches in a similar manner. We show realistic reconstructions of a variety of plants, and demonstrate examples of plant editing.},
  isbn = {978-1-59593-364-5},
  keywords = {image-based modeling,photography,plant modeling,tree modeling}
}

@article{raoSemanticPointCloud2021,
  title = {Semantic {{Point Cloud Segmentation Using Fast Deep Neural Network}} and {{DCRF}}},
  author = {Rao, Yunbo and Zhang, Menghan and Cheng, Zhanglin and Xue, Junmin and Pu, Jiansu and Wang, Zairong},
  year = {2021},
  month = apr,
  journal = {Sensors},
  volume = {21},
  number = {8},
  pages = {2731},
  issn = {1424-8220},
  doi = {10.3390/s21082731},
  urldate = {2021-12-18},
  abstract = {Accurate segmentation of entity categories is the critical step for 3D scene understanding. This paper presents a fast deep neural network model with Dense Conditional Random Field (DCRF) as a post-processing method, which can perform accurate semantic segmentation for 3D point cloud scene. On this basis, a compact but flexible framework is introduced for performing segmentation to the semantics of point clouds concurrently, contribute to more precise segmentation. Moreover, based on semantics labels, a novel DCRF model is elaborated to refine the result of segmentation. Besides, without any sacrifice to accuracy, we apply optimization to the original data of the point cloud, allowing the network to handle fewer data. In the experiment, our proposed method is conducted comprehensively through four evaluation indicators, proving the superiority of our method.},
  langid = {english}
}

@book{rcoreteamLanguageEnvironmentStatistical2017,
  title = {R: {{A Language}} and {{Environment}} for {{Statistical Computing}}},
  author = {{R Core Team}},
  year = {2017},
  publisher = {R Foundation for Statistical Computing},
  address = {Vienna, Austria}
}

@article{RegulationECNo,
  title = {Regulation ({{EC}}) {{No}}~1107/2009 of the {{European Parliament}} and of the {{Council}} of 21~{{October}} 2009 Concerning the Placing of Plant Protection Products on the Market and Repealing {{Council Directives}} 79/117/{{EEC}} and 91/414/{{EEC}}},
  pages = {50},
  langid = {english}
}

@article{renDeepClusteringComprehensive2024,
  title = {Deep {{Clustering}}: {{A Comprehensive Survey}}},
  shorttitle = {Deep {{Clustering}}},
  author = {Ren, Yazhou and Pu, Jingyu and Yang, Zhimeng and Xu, Jie and Li, Guofeng and Pu, Xiaorong and Yu, Philip S. and He, Lifang},
  year = {2024},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  pages = {1--21},
  issn = {2162-2388},
  doi = {10.1109/TNNLS.2024.3403155},
  urldate = {2025-01-13},
  abstract = {Cluster analysis plays an indispensable role in machine learning and data mining. Learning a good data representation is crucial for clustering algorithms. Recently, deep clustering (DC), which can learn clustering-friendly representations using deep neural networks (DNNs), has been broadly applied in a wide range of clustering tasks. Existing surveys for DC mainly focus on the single-view fields and the network architectures, ignoring the complex application scenarios of clustering. To address this issue, in this article, we provide a comprehensive survey for DC in views of data sources. With different data sources, we systematically distinguish the clustering methods in terms of methodology, prior knowledge, and architecture. Concretely, DC methods are introduced according to four categories, i.e., traditional single-view DC, semi-supervised DC, deep multiview clustering (MVC), and deep transfer clustering. Finally, we discuss the open challenges and potential future opportunities in different fields of DC.},
  keywords = {Clustering methods,Deep clustering (DC),Feature extraction,multiview clustering (MVC),Probability distribution,Representation learning,semi-supervised clustering,Surveys,Task analysis,transfer learning,Transfer learning},
  file = {/home/samuelebumbaca/Zotero/storage/GQ5D94H6/10585323.html}
}

@inproceedings{riemenschneiderHoughRegionsJoining2012,
  title = {Hough {{Regions}} for {{Joining Instance Localization}} and {{Segmentation}}},
  booktitle = {Computer {{Vision}} -- {{ECCV}} 2012},
  author = {Riemenschneider, Hayko and Sternig, Sabine and Donoser, Michael and Roth, Peter M. and Bischof, Horst},
  editor = {Fitzgibbon, Andrew and Lazebnik, Svetlana and Perona, Pietro and Sato, Yoichi and Schmid, Cordelia},
  year = {2012},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {258--271},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-33712-3_19},
  abstract = {Object detection and segmentation are two challenging tasks in computer vision, which are usually considered as independent steps. In this paper, we propose a framework which jointly optimizes for both tasks and implicitly provides detection hypotheses and corresponding segmentations. Our novel approach is attachable to any of the available generalized Hough voting methods. We introduce Hough Regions by formulating the problem of Hough space analysis as Bayesian labeling of a random field. This exploits provided classifier responses, object center votes and low-level cues like color consistency, which are combined into a global energy term. We further propose a greedy approach to solve this energy minimization problem providing a pixel-wise assignment to background or to a specific category instance. This way we bypass the parameter sensitive non-maximum suppression that is required in related methods. The experimental evaluation demonstrates that state-of-the-art detection and segmentation results are achieved and that our method is inherently able to handle overlapping instances and an increased range of articulations, aspect ratios and scales.},
  isbn = {978-3-642-33712-3},
  langid = {english},
  keywords = {Category Instance,Conditional Random Field,Object Detection,Object Instance,Seed Region}
}

@article{ritzResearchMethodsWeed2015,
  title = {Research {{Methods}} in {{Weed Science}}: {{Statistics}}},
  shorttitle = {Research {{Methods}} in {{Weed Science}}},
  author = {Ritz, Christian and Kniss, Andrew R. and Streibig, Jens C.},
  year = {2015},
  journal = {Weed Science},
  volume = {63},
  eprint = {26906697},
  eprinttype = {jstor},
  pages = {166--187},
  publisher = {[Cambridge University Press, Weed Science Society of America]},
  issn = {0043-1745},
  urldate = {2023-03-24}
}

@article{rongComputerVisionDetection2017,
  title = {Computer Vision Detection of Surface Defect on Oranges by Means of a Sliding Comparison Window Local Segmentation Algorithm},
  author = {Rong, Dian and Rao, Xiuqin and Ying, Yibin},
  year = {2017},
  month = may,
  journal = {Computers and Electronics in Agriculture},
  volume = {137},
  pages = {59--68},
  issn = {0168-1699},
  doi = {10.1016/j.compag.2017.02.027},
  urldate = {2023-09-01},
  abstract = {Automatic detection of defective oranges by computer vision system is not easy because of the uneven lightness distribution on the surface of oranges. It means that the methods onlydirectly using global segmentation provide unsatisfactory results when orange images present faint defect characters or inhomogeneous surface. The contrast between sound and defective regions can be used to produce more accurate segmentation results, which is more capable of detecting pixels lying around the defect boundary on orange surface based on the local segmentation method. In this paper, we study and propose a sliding comparison window local segmentation algorithm and also presents the detailed image processing procedure including removal of background pixels, image binarization using local segmentation, image subtraction, image morphological modification, removal of stem end pixels for detecting surface defect in an orange gray-level image. This method is an original contribution that allows successful segmentation of various types of surface defects (e.g., insect injury, wind scarring, thrips scarring, scale infestation, canker spot, dehiscent fruit, copper burn, phytotoxicity).The image segmentation algorithm was tested with 1191 samples of oranges. The proposed algorithm was able to correctly detect 97\% of the defective orange. Future work will be focused on whole surface and fast on-line inspection.},
  keywords = {Computer vision,Defect detection,Image local segmentation,Orange surface defect},
  file = {/home/samuelebumbaca/Zotero/storage/Y4J547D7/S0168169916305579.html}
}

@article{roseAccuracyAnalysisMultiView2015,
  title = {Accuracy {{Analysis}} of a {{Multi-View Stereo Approach}} for {{Phenotyping}} of {{Tomato Plants}} at the {{Organ Level}}},
  author = {Rose, Johann and Paulus, Stefan and Kuhlmann, Heiner},
  year = {2015},
  month = apr,
  journal = {Sensors},
  volume = {15},
  number = {5},
  pages = {9651--9665},
  issn = {1424-8220},
  doi = {10.3390/s150509651},
  urldate = {2022-10-21},
  langid = {english}
}

@article{rossiPerformancesEvaluationLowCost2020,
  title = {Performances {{Evaluation}} of a {{Low-Cost Platform}} for {{High-Resolution Plant Phenotyping}}},
  author = {Rossi, Riccardo and Leolini, Claudio and {Costafreda-Aumedes}, Sergi and Leolini, Luisa and Bindi, Marco and Zaldei, Alessandro and Moriondo, Marco},
  year = {2020},
  month = jan,
  journal = {Sensors},
  volume = {20},
  number = {11},
  pages = {3150},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1424-8220},
  doi = {10.3390/s20113150},
  urldate = {2025-03-16},
  abstract = {This study aims to test the performances of a low-cost and automatic phenotyping platform, consisting of a Red-Green-Blue (RGB) commercial camera scanning objects on rotating plates and the reconstruction of main plant phenotypic traits via the structure for motion approach (SfM). The precision of this platform was tested in relation to three-dimensional (3D) models generated from images of potted maize, tomato and olive tree, acquired at a different frequency (steps of 4{$^\circ$}, 8{$^\circ$} and 12{$^\circ$}) and quality (4.88, 6.52 and 9.77 {\textmu}m/pixel). Plant and organs heights, angles and areas were extracted from the 3D models generated for each combination of these factors. Coefficient of determination (R2), relative Root Mean Square Error (rRMSE) and Akaike Information Criterion (AIC) were used as goodness-of-fit indexes to compare the simulated to the observed data. The results indicated that while the best performances in reproducing plant traits were obtained using 90 images at 4.88 {\textmu}m/pixel (R2 = 0.81, rRMSE = 9.49\% and AIC = 35.78), this corresponded to an unviable processing time (from 2.46 h to 28.25 h for herbaceous plants and olive trees, respectively). Conversely, 30 images at 4.88 {\textmu}m/pixel resulted in a good compromise between a reliable reconstruction of considered traits (R2 = 0.72, rRMSE = 11.92\% and AIC = 42.59) and processing time (from 0.50 h to 2.05 h for herbaceous plants and olive trees, respectively). In any case, the results pointed out that this input combination may vary based on the trait under analysis, which can be more or less demanding in terms of input images and time according to the complexity of its shape (R2 = 0.83, rRSME = 10.15\% and AIC = 38.78). These findings highlight the reliability of the developed low-cost platform for plant phenotyping, further indicating the best combination of factors to speed up the acquisition and elaboration process, at the same time minimizing the bias between observed and simulated data.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {3D phenotyping,low-cost platform,plant imaging,structure for motion},
  file = {/home/samuelebumbaca/Zotero/storage/U86W27Z4/Rossi et al. - 2020 - Performances Evaluation of a Low-Cost Platform for High-Resolution Plant Phenotyping.pdf}
}

@inproceedings{rotherGrabCutInteractiveForeground2004,
  title = {"{{GrabCut}}": Interactive Foreground Extraction Using Iterated Graph Cuts},
  shorttitle = {"{{GrabCut}}"},
  booktitle = {{{ACM SIGGRAPH}} 2004 {{Papers}}},
  author = {Rother, Carsten and Kolmogorov, Vladimir and Blake, Andrew},
  year = {2004},
  month = aug,
  series = {{{SIGGRAPH}} '04},
  pages = {309--314},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1186562.1015720},
  urldate = {2022-12-12},
  abstract = {The problem of efficient, interactive foreground/background segmentation in still images is of great practical importance in image editing. Classical image segmentation tools use either texture (colour) information, e.g. Magic Wand, or edge (contrast) information, e.g. Intelligent Scissors. Recently, an approach based on optimization by graph-cut has been developed which successfully combines both types of information. In this paper we extend the graph-cut approach in three respects. First, we have developed a more powerful, iterative version of the optimisation. Secondly, the power of the iterative algorithm is used to simplify substantially the user interaction needed for a given quality of result. Thirdly, a robust algorithm for "border matting" has been developed to estimate simultaneously the alpha-matte around an object boundary and the colours of foreground pixels. We show that for moderately difficult examples the proposed method outperforms competitive tools.},
  isbn = {978-1-4503-7823-9},
  keywords = {Alpha Matting,Foreground extraction,Graph Cuts,Image Editing,Interactive Image Segmentation}
}

@article{rouseMONITORINGVEGETATIONSYSTEMS,
  title = {{{MONITORING VEGETATION SYSTEMS IN THE GREAT PLAINS WITH ERTS}}},
  author = {Rouse, W and Haas, R H},
  pages = {9},
  abstract = {The Great Plains Corridor rangeland project being conducted at Texas A\&M University utilizes natural vegetation systems as phenological indicators of seasonal development and climatic effects upon regional growth conditions. A method has been developed for quantitative measurement of vegetation conditions over broad regions using ERTS-1 MSS data. Radiance values recorded in ERTS-1 spectral bands 5 and 7, corrected for sun angle, are used to compute a band ratio parameter which is shown to be correlated with aboveground green biomass on rangelands.},
  langid = {english}
}

@inproceedings{rouseMonitoringVegetationSystems1974,
  title = {Monitoring Vegetation Systems in the {{Great Plains}} with {{ERTS}}},
  author = {Rouse, J. W. and Haas, R. H. and Schell, J. A. and Deering, D. W.},
  year = {1974},
  month = jan,
  urldate = {2024-02-08},
  abstract = {The Great Plains Corridor rangeland project utilizes natural vegetation systems as phenological indicators of seasonal development and climatic effects upon regional growth conditions. A method has been developed for quantitative measurement of vegetation conditions over broad regions using ERTS-1 MSS data. Radiance values recorded in ERTS-1 spectral bands 5 and 7, corrected for sun angle, are used to compute a band ratio parameter which is shown to be correlated with aboveground green biomass on rangelands.},
  keywords = {Geophysics},
  annotation = {NTRS Author Affiliations: Texas A\&M Univ.\\
NTRS Report/Patent Number: PAPER-A20\\
NTRS Document ID: 19740022614\\
NTRS Research Center: Legacy CDMS (CDMS)},
  file = {/home/samuelebumbaca/Zotero/storage/LHM4GRWT/19740022614.html}
}

@article{samueleMappingSARGeometric2021,
  title = {Mapping {{SAR}} Geometric Distortions and Their Stability along Time: A New Tool in {{Google Earth Engine}} Based on {{Sentinel-1}} Image Time Series},
  author = {Samuele, De Petris and Filippo, Sarvia and Orusa, Tommaso and Enrico, Borgogno-Mondino},
  year = {2021},
  journal = {International Journal of Remote Sensing},
  volume = {42},
  number = {23},
  pages = {9135--9154}
}

@article{sanjay-gopalBayesianPixelClassification1998,
  title = {Bayesian Pixel Classification Using Spatially Variant Finite Mixtures and the Generalized {{EM}} Algorithm},
  author = {{Sanjay-Gopal}, S. and Hebert, T.J.},
  year = {1998},
  month = jul,
  journal = {IEEE Transactions on Image Processing},
  volume = {7},
  number = {7},
  pages = {1014--1028},
  issn = {10577149},
  doi = {10.1109/83.701161},
  urldate = {2021-12-19}
}

@article{sankaranReviewAdvancedTechniques2010,
  title = {A Review of Advanced Techniques for Detecting Plant Diseases},
  author = {Sankaran, Sindhuja and Mishra, Ashish and Ehsani, Reza and Davis, Cristina},
  year = {2010},
  month = jun,
  journal = {Computers and Electronics in Agriculture},
  volume = {72},
  number = {1},
  pages = {1--13},
  issn = {0168-1699},
  doi = {10.1016/j.compag.2010.02.007},
  urldate = {2023-01-13},
  abstract = {Diseases in plants cause major production and economic losses in agricultural industry worldwide. Monitoring of health and detection of diseases in plants and trees is critical for sustainable agriculture. To the best of our knowledge, there is no sensor commercially available for real-time assessment of health conditions in trees. Currently, scouting is most widely used mechanism for monitoring stress in trees, which is an expensive, labor-intensive, and time-consuming process. Molecular techniques such as polymerase chain reaction are used for the identification of plant diseases that require detailed sampling and processing procedure. Early information on crop health and disease detection can facilitate the control of diseases through proper management strategies such as vector control through pesticide applications, fungicide applications, and disease-specific chemical applications; and can improve productivity. The present review recognizes the need for developing a rapid, cost-effective, and reliable health-monitoring sensor that would facilitate advancements in agriculture. It describes the currently used technologies that can be used for developing a ground-based sensor system to assist in monitoring health and diseases in plants under field conditions. These technologies include spectroscopic and imaging-based, and volatile profiling-based plant disease detection methods. The paper compares the benefits and limitations of these potential methods.},
  langid = {english},
  keywords = {GC-MS,Imaging techniques,Plant diseases,Spectroscopy,Volatile profiling}
}

@article{sankaranReviewAdvancedTechniques2010a,
  title = {A Review of Advanced Techniques for Detecting Plant Diseases},
  author = {Sankaran, Sindhuja and Mishra, Ashish and Ehsani, Reza and Davis, Cristina},
  year = {2010},
  month = jun,
  journal = {Computers and Electronics in Agriculture},
  volume = {72},
  number = {1},
  pages = {1--13},
  issn = {0168-1699},
  doi = {10.1016/j.compag.2010.02.007},
  urldate = {2023-01-13},
  abstract = {Diseases in plants cause major production and economic losses in agricultural industry worldwide. Monitoring of health and detection of diseases in plants and trees is critical for sustainable agriculture. To the best of our knowledge, there is no sensor commercially available for real-time assessment of health conditions in trees. Currently, scouting is most widely used mechanism for monitoring stress in trees, which is an expensive, labor-intensive, and time-consuming process. Molecular techniques such as polymerase chain reaction are used for the identification of plant diseases that require detailed sampling and processing procedure. Early information on crop health and disease detection can facilitate the control of diseases through proper management strategies such as vector control through pesticide applications, fungicide applications, and disease-specific chemical applications; and can improve productivity. The present review recognizes the need for developing a rapid, cost-effective, and reliable health-monitoring sensor that would facilitate advancements in agriculture. It describes the currently used technologies that can be used for developing a ground-based sensor system to assist in monitoring health and diseases in plants under field conditions. These technologies include spectroscopic and imaging-based, and volatile profiling-based plant disease detection methods. The paper compares the benefits and limitations of these potential methods.},
  langid = {english},
  keywords = {GC-MS,Imaging techniques,Plant diseases,Spectroscopy,Volatile profiling}
}

@inproceedings{sarviaMAIAS2Sentinel2021,
  title = {{{MAIA S2}} versus Sentinel 2: Spectral Issues and Their Effects in the Precision Farming Context},
  booktitle = {Computational {{Science}} and {{Its Applications}}--{{ICCSA}} 2021: 21st {{International Conference}}, {{Cagliari}}, {{Italy}}, {{September}} 13--16, 2021, {{Proceedings}}, {{Part VII}} 21},
  author = {Sarvia, Filippo and De Petris, Samuele and Orusa, Tommaso and {Borgogno-Mondino}, Enrico},
  year = {2021},
  pages = {63--77},
  publisher = {Springer}
}

@inproceedings{satoTEASARTreestructureExtraction2000,
  title = {{{TEASAR}}: Tree-Structure Extraction Algorithm for Accurate and Robust Skeletons},
  shorttitle = {{{TEASAR}}},
  booktitle = {Proceedings the {{Eighth Pacific Conference}} on {{Computer Graphics}} and {{Applications}}},
  author = {Sato, M. and Bitter, I. and Bender, M.A. and Kaufman, A.E. and Nakajima, M.},
  year = {2000},
  pages = {281--449},
  publisher = {IEEE Comput. Soc},
  address = {Hong Kong, China},
  doi = {10.1109/PCCGA.2000.883951},
  urldate = {2024-06-10},
  abstract = {We introduce the TEASAR algorithm which is a Treestructure Extraction Algorithm delivering Skeletons that are Accurate and Robust. Volumetric skeletons are needed for accurate measurements of length along branching and winding structures. Skeletons are also required in automatic virtual navigation, such as traveling through human organs (e.g., the colon) to control movement and orientation of the virtual caniera. We introduce a concise but general definition of a skeleton, and provide an algorithm thatfinds the skeleton accurately and rapidly. Our solution isfully automatic, whichfrees the userfrom having to engage in data preprocessing. Wepresent the accurate skeletons computed on a number of test datasets. The algorithm is eficient as denionstrated by the running times on a single 194 M H z MIPS RIOOOO CPU which were all belowfive minutes.},
  isbn = {978-0-7695-0868-9},
  langid = {english}
}

@inproceedings{schaeferExamplebasedSkeletonExtraction2007,
  title = {Example-Based Skeleton Extraction},
  booktitle = {Symposium on {{Geometry Processing}}},
  author = {Schaefer, Scott and Yuksel, Can},
  year = {2007},
  volume = {153},
  pages = {162},
  urldate = {2024-06-10}
}

@article{scharrLeafSegmentationPlant2016,
  title = {Leaf Segmentation in Plant Phenotyping: A Collation Study},
  shorttitle = {Leaf Segmentation in Plant Phenotyping},
  author = {Scharr, Hanno and Minervini, Massimo and French, Andrew P. and Klukas, Christian and Kramer, David M. and Liu, Xiaoming and Luengo, Imanol and Pape, Jean Michel and Polder, Gerrit and Vukadinovic, Danijela and Yin, Xi and Tsaftaris, Sotirios A.},
  year = {2016},
  journal = {Machine Vision Applications},
  volume = {27},
  number = {4},
  pages = {585--606},
  publisher = {Springer},
  issn = {0932-8092},
  doi = {10.1007/s00138-015-0737-3},
  urldate = {2023-09-07},
  langid = {english},
  file = {/home/samuelebumbaca/Zotero/storage/4Y5H5C34/leaf-segmentation-in-plant-phenotyping-a-collation-study.html}
}

@article{scharsteinTaxonomyEvaluationDense2002,
  title = {A {{Taxonomy}} and {{Evaluation}} of {{Dense Two-Frame Stereo Correspondence Algorithms}}},
  author = {Scharstein, Daniel and Szeliski, Richard},
  year = {2002},
  month = apr,
  journal = {International Journal of Computer Vision},
  volume = {47},
  number = {1},
  pages = {7--42},
  issn = {1573-1405},
  doi = {10.1023/A:1014573219977},
  urldate = {2022-11-24},
  abstract = {Stereo matching is one of the most active research areas in computer vision. While a large number of algorithms for stereo correspondence have been developed, relatively little work has been done on characterizing their performance. In this paper, we present a taxonomy of dense, two-frame stereo methods. Our taxonomy is designed to assess the different components and design decisions made in individual stereo algorithms. Using this taxonomy, we compare existing stereo methods and present experiments evaluating the performance of many different variants. In order to establish a common software platform and a collection of data sets for easy evaluation, we have designed a stand-alone, flexible C++ implementation that enables the evaluation of individual components and that can easily be extended to include new algorithms. We have also produced several new multi-frame stereo data sets with ground truth and are making both the code and data sets available on the Web. Finally, we include a comparative evaluation of a large set of today's best-performing stereo algorithms.},
  langid = {english},
  keywords = {evaluation of performance,stereo correspondence software,stereo matching survey}
}

@article{schiavonEffectsFungicidesCreeping2022,
  title = {Effects of Fungicides on Creeping Bentgrass Health and Rooting Characteristics under Abiotic Stress},
  author = {Schiavon, Marco and Petelewicz, Pawel and Orlinski, Pawel M. and Baird, James H.},
  year = {2022},
  month = jun,
  journal = {International Turfgrass Society Research Journal},
  volume = {14},
  number = {1},
  pages = {893--901},
  issn = {2573-1513, 2573-1513},
  doi = {10.1002/its2.11},
  urldate = {2022-09-20},
  langid = {english}
}

@misc{schleglUnsupervisedAnomalyDetection2017,
  title = {Unsupervised {{Anomaly Detection}} with {{Generative Adversarial Networks}} to {{Guide Marker Discovery}}},
  author = {Schlegl, Thomas and Seeb{\"o}ck, Philipp and Waldstein, Sebastian M. and {Schmidt-Erfurth}, Ursula and Langs, Georg},
  year = {2017},
  month = mar,
  number = {arXiv:1703.05921},
  eprint = {1703.05921},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-07-23},
  abstract = {Obtaining models that capture imaging markers relevant for disease progression and treatment monitoring is challenging. Models are typically based on large amounts of data with annotated examples of known markers aiming at automating detection. High annotation effort and the limitation to a vocabulary of known markers limit the power of such approaches. Here, we perform unsupervised learning to identify anomalies in imaging data as candidates for markers. We propose AnoGAN, a deep convolutional generative adversarial network to learn a manifold of normal anatomical variability, accompanying a novel anomaly scoring scheme based on the mapping from image space to a latent space. Applied to new data, the model labels anomalies, and scores image patches indicating their fit into the learned distribution. Results on optical coherence tomography images of the retina demonstrate that the approach correctly identifies anomalous images, such as images containing retinal fluid or hyperreflective foci.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning}
}

@article{schorDevelopmentRoboticDetection2017,
  title = {Development of a Robotic Detection System for Greenhouse Pepper Plant Diseases},
  author = {Schor, Noa and Berman, Sigal and Dombrovsky, Aviv and Elad, Yigal and Ignat, Timea and Bechar, Avital},
  year = {2017},
  month = jun,
  journal = {Precision Agriculture},
  volume = {18},
  number = {3},
  pages = {394--409},
  issn = {1573-1618},
  doi = {10.1007/s11119-017-9503-z},
  urldate = {2023-01-13},
  abstract = {Automation of disease detection and monitoring can facilitate targeted and timely disease control, which can lead to increased yield, improved crop quality and reduction in the quantity of applied pesticides. Further advantages are reduced production costs, reduced exposure to pesticides for farm workers and inspectors and increased sustainability. Symptoms are unique for each disease and crop, and each plant may suffer from multiple threats. Thus, a dedicated integrated disease-detection system and algorithms are required. The development of such a robotic detection system for two major threats of bell pepper plants: powdery mildew (PM) and Tomato spotted wilt virus (TSWV), is presented. Detection algorithms were developed based on principal component analysis using RGB and multispectral NIR-R-G sensors. High accuracy was obtained for pixel classification as diseased or healthy, for both diseases, using RGB imagery (PM: 95\%, TSWV: 90\%). NIR-R-G multispectral imagery yielded low classification accuracy (PM: 80\%, TSWV: 61\%). Accordingly, the final sensing apparatus was composed of a RGB sensor and a single-laser-beam distance sensor. A relatively fast cycle time (average 26.7~s per plant) operation cycle for detection of the two diseases was developed and tested. The cycle time was mainly influenced by sub-tasks requiring motion of the manipulator. Among these tasks, the most demanding were the determination of the required detection position and orientation. The time for task completion may be reduced by increasing the robotic work volume and by improving the algorithm for determining position and orientation.},
  langid = {english},
  keywords = {Disease detection,Multispectral imagery,Powdery mildew,RGB imagery,Tomato spotted wilt virus}
}

@article{schunckPheno4DSpatiotemporalDataset2021,
  title = {{{Pheno4D}}: {{A}} Spatio-Temporal Dataset of Maize and Tomato Plant Point Clouds for Phenotyping and Advanced Plant Analysis},
  shorttitle = {{{Pheno4D}}},
  author = {Schunck, David and Magistri, Federico and Rosu, Radu Alexandru and Corneli{\ss}en, Andr{\'e} and Chebrolu, Nived and Paulus, Stefan and L{\'e}on, Jens and Behnke, Sven and Stachniss, Cyrill and Kuhlmann, Heiner and Klingbeil, Lasse},
  editor = {Agudo, Antonio},
  year = {2021},
  month = aug,
  journal = {PLOS ONE},
  volume = {16},
  number = {8},
  pages = {e0256340},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0256340},
  urldate = {2021-12-18},
  abstract = {Understanding the growth and development of individual plants is of central importance in modern agriculture, crop breeding, and crop science. To this end, using 3D data for plant analysis has gained attention over the last years. High-resolution point clouds offer the potential to derive a variety of plant traits, such as plant height, biomass, as well as the number and size of relevant plant organs. Periodically scanning the plants even allows for performing spatio-temporal growth analysis. However, highly accurate 3D point clouds from plants recorded at different growth stages are rare, and acquiring this kind of data is costly. Besides, advanced plant analysis methods from machine learning require annotated training data and thus generate intense manual labor before being able to perform an analysis. To address these issues, we present with this dataset paper a multi-temporal dataset featuring high-resolution registered point clouds of maize and tomato plants, which we manually labeled for computer vision tasks, such as for instance segmentation and 3D reconstruction, providing approximately 260 million labeled 3D points. To highlight the usability of the data and to provide baselines for other researchers, we show a variety of applications ranging from point cloud segmentation to non-rigid registration and surface reconstruction. We believe that our dataset will help to develop new algorithms to advance the research for plant phenotyping, 3D reconstruction, non-rigid registration, and deep learning on raw point clouds. The dataset is freely accessible at                https://www.ipb.uni-bonn.de/data/pheno4d/                .},
  langid = {english}
}

@article{schunckPheno4DSpatiotemporalDataset2021a,
  title = {{{Pheno4D}}: {{A}} Spatio-Temporal Dataset of Maize and Tomato Plant Point Clouds for Phenotyping and Advanced Plant Analysis},
  shorttitle = {{{Pheno4D}}},
  author = {Schunck, David and Magistri, Federico and Rosu, Radu Alexandru and Corneli{\ss}en, Andr{\'e} and Chebrolu, Nived and Paulus, Stefan and L{\'e}on, Jens and Behnke, Sven and Stachniss, Cyrill and Kuhlmann, Heiner and Klingbeil, Lasse},
  editor = {Agudo, Antonio},
  year = {2021},
  month = aug,
  journal = {PLOS ONE},
  volume = {16},
  number = {8},
  pages = {e0256340},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0256340},
  urldate = {2021-12-18},
  abstract = {Understanding the growth and development of individual plants is of central importance in modern agriculture, crop breeding, and crop science. To this end, using 3D data for plant analysis has gained attention over the last years. High-resolution point clouds offer the potential to derive a variety of plant traits, such as plant height, biomass, as well as the number and size of relevant plant organs. Periodically scanning the plants even allows for performing spatio-temporal growth analysis. However, highly accurate 3D point clouds from plants recorded at different growth stages are rare, and acquiring this kind of data is costly. Besides, advanced plant analysis methods from machine learning require annotated training data and thus generate intense manual labor before being able to perform an analysis. To address these issues, we present with this dataset paper a multi-temporal dataset featuring high-resolution registered point clouds of maize and tomato plants, which we manually labeled for computer vision tasks, such as for instance segmentation and 3D reconstruction, providing approximately 260 million labeled 3D points. To highlight the usability of the data and to provide baselines for other researchers, we show a variety of applications ranging from point cloud segmentation to non-rigid registration and surface reconstruction. We believe that our dataset will help to develop new algorithms to advance the research for plant phenotyping, 3D reconstruction, non-rigid registration, and deep learning on raw point clouds. The dataset is freely accessible at                https://www.ipb.uni-bonn.de/data/pheno4d/                .},
  langid = {english}
}

@misc{SciELOBrazilCOMPARING,
  title = {{{SciELO}} - {{Brazil}} - {{COMPARING A SINGLE-SENSOR CAMERA WITH A MULTISENSOR CAMERA FOR MONITORING COFFEE CROP USING UNMANNED AERIAL VEHICLES COMPARING A SINGLE-SENSOR CAMERA WITH A MULTISENSOR CAMERA FOR MONITORING COFFEE CROP USING UNMANNED AERIAL VEHICLES}}},
  urldate = {2022-10-14},
  howpublished = {https://www.scielo.br/j/eagri/a/JL7zQzY3mRXdBvxv4YMWLMd/?lang=en},
  file = {/home/samuelebumbaca/Zotero/storage/AUEITVNN/JL7zQzY3mRXdBvxv4YMWLMd.html}
}

@misc{Scipyoptimizecurve_fitSciPyV193,
  title = {Scipy.Optimize.Curve\_fit --- {{SciPy}} v1.9.3 {{Manual}}},
  urldate = {2022-12-06},
  howpublished = {https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve\_fit.html},
  file = {/home/samuelebumbaca/Zotero/storage/9LC3WLBQ/scipy.optimize.curve_fit.html}
}

@article{seefeldtLogLogisticAnalysisHerbicide1995,
  title = {Log-{{Logistic Analysis}} of {{Herbicide Dose-Response Relationships}}},
  author = {Seefeldt, Steven S. and Jensen, Jens Erik and Fuerst, E. Patrick},
  year = {1995},
  journal = {Weed Technology},
  volume = {9},
  number = {2},
  eprint = {3987736},
  eprinttype = {jstor},
  pages = {218--227},
  publisher = {[Cambridge University Press, Weed Science Society of America]},
  issn = {0890-037X},
  urldate = {2023-03-24},
  abstract = {Dose-response studies are an important tool in weed science. The use of such studies has become especially prevalent following the widespread development of herbicide resistant weeds. In the past, analyses of dose-response studies have utilized various types of transformations and equations which can be validated with several statistical techniques. Most dose-response analysis methods 1) do not accurately describe data at the extremes of doses and 2) do not provide a proper statistical test for the difference(s) between two or more dose-response curves. Consequently, results of dose-response studies are analyzed and reported in a great variety of ways, and comparison of results among various researchers is not possible. The objective of this paper is to review the principles involved in dose-response research and explain the log-logistic analysis of herbicide dose-response relationships. In this paper the log-logistic model is illustrated using a nonlinear computer analysis of experimental data. The log-logistic model is an appropriate method for analyzing most dose-response studies. This model has been used widely and successfully in weed science for many years in Europe. The log-logistic model possesses several clear advantages over other analysis methods and the authors suggest that it should be widely adopted as a standard herbicide dose-response analysis method.}
}

@article{seeligAssessmentLeafWater2008,
  title = {The Assessment of Leaf Water Content Using Leaf Reflectance Ratios in the Visible, Near-, and Short-wave-infrared},
  author = {Seelig, H.-D. and Hoehn, A. and Stodieck, L. S. and Klaus, D. M. and Adams III, W. W. and Emery, W. J.},
  year = {2008},
  month = jul,
  journal = {International Journal of Remote Sensing},
  volume = {29},
  number = {13},
  pages = {3701--3713},
  publisher = {Taylor \& Francis},
  issn = {0143-1161},
  doi = {10.1080/01431160701772500},
  urldate = {2023-01-13},
  abstract = {The common features of spectral reflectance from vegetation foliage upon leaf dehydration are decreasing water absorption troughs in the near-infrared (NIR) and short-wave-infrared (SWIR). We studied which leaf water index in the NIR and SWIR is most suitable for the assessment of leaf water content and the detection of leaf dehydration from the laboratory standpoint. We also examined the influence of the thickness of leaves upon leaf water indices. All leaf water content indices examined exhibited basic correlations with the relative water content (RWC) of leaves, while the R 1300/R 1450 leaf water index also demonstrated a high signal strength and low variability (R 2{$>$}0.94). All examined leaf reflectance ratios could also be correlated with leaf thickness. The thickness of leaves, however, was not independent of leaf RWC but appeared to decrease substantially as a result of leaf dehydration.}
}

@article{sezginSurveyImageThresholding2004,
  title = {Survey over Image Thresholding Techniques and Quantitative Performance Evaluation},
  author = {Sezgin, Mehmet and Sankur, B{\"u}lent},
  year = {2004},
  month = jan,
  journal = {Journal of Electronic Imaging},
  volume = {13},
  number = {1},
  pages = {146--165},
  publisher = {SPIE},
  issn = {1017-9909, 1560-229X},
  doi = {10.1117/1.1631315},
  urldate = {2023-01-25},
  abstract = {The \emph{Journal of Electronic Imaging} (JEI), copublished bimonthly with the Society for Imaging Science and Technology, publishes peer-reviewed papers that cover research and applications in all areas of electronic imaging science and technology.}
}

@article{sezginSurveyImageThresholding2004a,
  title = {Survey over Image Thresholding Techniques and Quantitative Performance Evaluation},
  author = {Sezgin, Mehmet and Sankur, B{\"u}lent},
  year = {2004},
  month = jan,
  journal = {Journal of Electronic Imaging},
  volume = {13},
  number = {1},
  pages = {146--165},
  publisher = {SPIE},
  issn = {1017-9909, 1560-229X},
  doi = {10.1117/1.1631315},
  urldate = {2023-01-25},
  abstract = {The \emph{Journal of Electronic Imaging} (JEI), copublished bimonthly with the Society for Imaging Science and Technology, publishes peer-reviewed papers that cover research and applications in all areas of electronic imaging science and technology.}
}

@article{shenDeepskeletonLearningMultitask2017,
  title = {Deepskeleton: {{Learning}} Multi-Task Scale-Associated Deep Side Outputs for Object Skeleton Extraction in Natural Images},
  shorttitle = {Deepskeleton},
  author = {Shen, Wei and Zhao, Kai and Jiang, Yuan and Wang, Yan and Bai, Xiang and Yuille, Alan},
  year = {2017},
  journal = {IEEE Transactions on Image Processing},
  volume = {26},
  number = {11},
  pages = {5298--5311},
  publisher = {IEEE},
  urldate = {2024-06-10}
}

@inproceedings{shenObjectSkeletonExtraction2016,
  title = {Object Skeleton Extraction in Natural Images by Fusing Scale-Associated Deep Side Outputs},
  booktitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Shen, Wei and Zhao, Kai and Jiang, Yuan and Wang, Yan and Zhang, Zhijiang and Bai, Xiang},
  year = {2016},
  pages = {222--230},
  urldate = {2024-06-10}
}

@phdthesis{siImprovingQualityLiDAR2022,
  title = {Improving the {{Quality}} of {{LiDAR Point Cloud Data}} for {{Greenhouse Crop Monitoring}}},
  author = {Si, Gaoshoutong},
  year = {2022},
  urldate = {2022-09-25},
  langid = {english},
  school = {The Ohio State University},
  file = {/home/samuelebumbaca/Zotero/storage/S9AAPBP9/10.html}
}

@article{silvaComparativeAssessmentFeature2013,
  title = {Comparative Assessment of Feature Selection and Classification Techniques for Visual Inspection of Pot Plant Seedlings},
  author = {Silva, L. O. L. A. and Koga, M. L. and Cugnasca, C. E. and Costa, A. H. R.},
  year = {2013},
  month = sep,
  journal = {Computers and Electronics in Agriculture},
  volume = {97},
  pages = {47--55},
  issn = {0168-1699},
  doi = {10.1016/j.compag.2013.07.001},
  urldate = {2023-01-13},
  abstract = {Homogeneity plays an important role in ornamental plant and flower production. As assessing the quality of seedlings is an effective way of predicting plant growth performance, a vision system capable of performing this task is desirable. Yet, the optical sorting of agricultural products must find ways to incorporate knowledge from human experts into the computational solution. Our aim is evaluating feature selection techniques with respect to the performance of vision-based inspection and classification of pot plant seedlings. A large feature set was initially obtained from seedlings images and several subsets were generated with various features selection techniques. The performance of each subset was compared to some of the most popular classifiers in the literature: Naive Bayes, k-Nearest Neighbors, Logistic Regression, C4.5, Random Forest, Multilayer Perceptron as well as Partial Least Squares and Support Vector Machine Discriminant Analysis. The best classifier and subset configuration is presented; our results show that feature selection was indeed advantageous, generating accuracy gains of up to 7.4\%.},
  langid = {english},
  keywords = {Agricultural,Computer vision,Machine learning,Sorting},
  file = {/home/samuelebumbaca/Zotero/storage/KJFKVSCD/S0168169913001518.html}
}

@article{simkoPhenomicApproachesTools2017,
  title = {Phenomic {{Approaches}} and {{Tools}} for {{Phytopathologists}}},
  author = {Simko, Ivan and {Jimenez-Berni}, Jose A. and Sirault, Xavier R. R.},
  year = {2017},
  month = jan,
  journal = {Phytopathology{\textregistered}},
  volume = {107},
  number = {1},
  pages = {6--17},
  publisher = {Scientific Societies},
  issn = {0031-949X},
  doi = {10.1094/PHYTO-02-16-0082-RVW},
  urldate = {2023-01-13},
  abstract = {Plant phenomics approaches aim to measure traits such as growth, performance, and composition of plants using a suite of noninvasive technologies. The goal is to link phenotypic traits to the genetic information for particular genotypes, thus creating the bridge between the phenome and genome. Application of sensing technologies for detecting specific phenotypic reactions occurring during plant-pathogen interaction offers new opportunities for elucidating the physiological mechanisms that link pathogen infection and disease symptoms in the host, and also provides a faster approach in the selection of genetic material that is resistant to specific pathogens or strains. Appropriate phenomics methods and tools may also allow presymptomatic detection of disease-related changes in plants or to identify changes that are not visually apparent. This review focuses on the use of sensor-based phenomics tools in plant pathology such as those related to digital imaging, chlorophyll fluorescence imaging, spectral imaging, and thermal imaging. A brief introduction is provided for less used approaches like magnetic resonance, soft x-ray imaging, ultrasound, and detection of volatile compounds. We hope that this concise review will stimulate further development and use of tools for automatic, nondestructive, and high-throughput phenotyping of plant-pathogen interaction.}
}

@inproceedings{singhInDepthExplorationAnomaly2024,
  title = {An {{In-Depth Exploration}} of {{Anomaly Detection}}, {{Classification}}, and {{Localization}} with {{Deep Learning}}: {{A Comprehensive Overview}}},
  shorttitle = {An {{In-Depth Exploration}} of {{Anomaly Detection}}, {{Classification}}, and {{Localization}} with {{Deep Learning}}},
  booktitle = {Semantic {{Intelligence}}},
  author = {Singh, Kamred Udham and Kumar, Ankit and Kumar, Gaurav and Singh, Teekam and Choudhury, Tanupriya and Kotecha, Ketan},
  editor = {Jain, Sarika and Mihindukulasooriya, Nandana and Janev, Valentina and Shimizu, Cogan Matthew},
  year = {2024},
  pages = {115--125},
  publisher = {Springer Nature},
  address = {Singapore},
  doi = {10.1007/978-981-97-7356-5_10},
  abstract = {The ability to identify trends in the data when one set of data is deviating from another is called Data Mining. The development of anomalies has made it possible to identify and avoid malware, as well as several other unlawful practices. Traditional detection strategies have shown strong results However, as deep learning progresses, important findings have emerged over the past few years. In order to summarize existing and the most cutting-edge fraud and intrusion detection strategies, we address these issues depending on the existence of neural networks, from broad to shallower. This paper provides an analysis of the published techniques for anomaly detection, especially on the contribution of deep learning to detection. Methods were sorted according to the kind of DNN included in this study. These classes helped us to categorize the deep learners by how often they've been using, in data representation and for differentiating between various types of anomalies. In addition, deep neural networks in specific anomaly detection tasks presented incontrovertible proof of their effective implementation.},
  isbn = {978-981-97-7356-5},
  langid = {english}
}

@article{soaresEfficientSegmentationLeaves2013,
  title = {Efficient Segmentation of Leaves in Semi-Controlled Conditions},
  author = {Soares, Jo{\~a}o V. B. and Jacobs, David W.},
  year = {2013},
  month = nov,
  journal = {Machine Vision and Applications},
  volume = {24},
  number = {8},
  pages = {1623--1643},
  issn = {1432-1769},
  doi = {10.1007/s00138-013-0530-0},
  urldate = {2023-01-13},
  abstract = {We present a study on segmentation of leaf images restricted to semi-controlled conditions, in which leaves are photographed against a solid light-colored background. Such images can be used in practice for plant species identification, by analyzing the distinctive shapes of the leaves. We restrict our attention to segmentation in this semi-controlled condition, providing us with a more well-defined problem, which at the same time presents several challenges. The most important of these are: the variety of leaf shapes, inevitable presence of shadows and specularities, and the time constraints required by interactive species identification applications. We evaluate several popular segmentation algorithms on this task. Different datasets of leaf images are used, with manually segmented images serving as ground truth for quantitative comparisons. We observe that many of the methods are not immediately applicable: they are either too slow or would require that important modifications be introduced. We thus present extensions to our previously published segmentation method, which are able to improve its performance. The previous approach was based on pixel clustering in color space. Our extensions introduce a graph cut step and the use of a training set of manual segmentations in order to adjust important parameters of the method. The new method is fast enough for an interactive application, while producing state-of-the-art results.},
  langid = {english},
  keywords = {Electronic field guide,Expectation-Maximization,Graph cut,Image segmentation,Species identification}
}

@misc{SPAD502KONICAMINOLTA,
  title = {{{SPAD-502}} - {{KONICA MINOLTA Europe}}},
  urldate = {2022-09-19},
  howpublished = {https://www5.konicaminolta.eu/it/strumenti-di-misura/prodotti/misura-di-colore/articoli-non-piu-in-produzione/spad-502.html},
  file = {/home/samuelebumbaca/Zotero/storage/CKMFM2QE/spad-502.html}
}

@article{sphrrzybyWDaaytShkhS2019,
  title = {{ارزیابی وضعیت شاخص سبزینگی گوجه و خیار گلخانه{\null}ای با استفاده از حسگرهای غیرمخرب}},
  author = {س‍‍پهر, بهنام and محمدی منور, حسنی},
  year = {2019},
  month = mar,
  journal = {ماشین های کشاورزی},
  volume = {9},
  number = {1},
  doi = {10.22067/jam.v9i1.67383},
  urldate = {2022-09-18},
  langid = {persian}
}

@article{sphrrzybyWDaaytShkhS2019a,
  title = {{ارزیابی وضعیت شاخص سبزینگی گوجه و خیار گلخانه{\null}ای با استفاده از حسگرهای غیرمخرب}},
  author = {س‍‍پهر, بهنام and محمدی منور, حسنی},
  year = {2019},
  month = mar,
  journal = {ماشین های کشاورزی},
  volume = {9},
  number = {1},
  doi = {10.22067/jam.v9i1.67383},
  urldate = {2022-09-18},
  langid = {persian}
}

@article{stevensTheoryScalesMeasurement1946,
  title = {On the {{Theory}} of {{Scales}} of {{Measurement}}},
  author = {Stevens, S. S.},
  year = {1946},
  month = jun,
  journal = {Science},
  volume = {103},
  number = {2684},
  pages = {677--680},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.103.2684.677},
  urldate = {2023-11-13}
}

@article{stornDifferentialEvolutionSimple1997,
  title = {Differential {{Evolution}} -- {{A Simple}} and {{Efficient Heuristic}} for Global {{Optimization}} over {{Continuous Spaces}}},
  author = {Storn, Rainer and Price, Kenneth},
  year = {1997},
  month = dec,
  journal = {Journal of Global Optimization},
  volume = {11},
  number = {4},
  pages = {341--359},
  issn = {1573-2916},
  doi = {10.1023/A:1008202821328},
  urldate = {2025-03-16},
  abstract = {A new heuristic approach for minimizing possiblynonlinear and non-differentiable continuous spacefunctions is presented. By means of an extensivetestbed it is demonstrated that the new methodconverges faster and with more certainty than manyother acclaimed global optimization methods. The newmethod requires few control variables, is robust, easyto use, and lends itself very well to parallelcomputation.},
  langid = {english},
  keywords = {evolution strategy,genetic algorithm,global optimization,nonlinear optimization,Stochastic optimization},
  file = {/home/samuelebumbaca/Zotero/storage/K6XQ5SA9/Storn and Price - 1997 - Differential Evolution – A Simple and Efficient Heuristic for global Optimization over Continuous Sp.pdf}
}

@inproceedings{strechaCombinedDepthOutlier2006,
  title = {Combined {{Depth}} and {{Outlier Estimation}} in {{Multi-View Stereo}}},
  booktitle = {2006 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}}'06)},
  author = {Strecha, C. and Fransens, R. and Van Gool, L.},
  year = {2006},
  month = jun,
  volume = {2},
  pages = {2394--2401},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2006.78},
  abstract = {In this paper, we present a generative model based approach to solve the multi-view stereo problem. The input images are considered to be generated by either one of two processes: (i) an inlier process, which generates the pixels which are visible from the reference camera and which obey the constant brightness assumption, and (ii) an outlier process which generates all other pixels. Depth and visibility are jointly modelled as a hiddenMarkov Random Field, and the spatial correlations of both are explicitly accounted for. Inference is made tractable by an EM-algorithm, which alternates between estimation of visibility and depth, and optimisation of model parameters. We describe and compare two implementations of the E-step of the algorithm, which correspond to the Mean Field and Bethe approximations of the free energy. The approach is validated by experiments on challenging real-world scenes, of which two are contaminated by independently moving objects.},
  keywords = {Brightness,Cameras,Hidden Markov models,Inference algorithms,Kernel,Layout,Noise level,Pixel,Rendering (computer graphics),Stereo vision}
}

@article{streibigSensorbasedAssessmentHerbicide2014,
  title = {Sensor-Based Assessment of Herbicide Effects},
  author = {Streibig, J C and Rasmussen, J and And{\'u}jar, D and Andreasen, C and Berge, T W and Chachalis, D and Dittmann, T and Gerhards, R and Giselsson, T M and Hamouz, P and {Jaeger-Hansen}, C and Jensen, K and J{\o}rgensen, R N and Keller, M and Laursen, M and Midtiby, H S and Nielsen, J and M{\"u}ller, S and Nordmeyer, H and Peteinatos, G and Papadopoulos, A and Svensgaard, J and Weis, M and Christensen, S},
  year = {2014},
  journal = {Weed Research},
  volume = {54},
  number = {3},
  pages = {223--233},
  issn = {1365-3180},
  doi = {10.1111/wre.12079},
  urldate = {2022-11-10},
  abstract = {Non-destructive assessment of herbicide effects may be able to support integrated weed management. To test whether effects of herbicides on canopy variables could be detected by sensors, two crops were used as models and treated with herbicides at BBCH 20 using a logarithmic sprayer. Twelve days after spraying at BBCH 25 and 42 days after sowing, nine sensor systems scanned a spring barley and an oilseed rape field experiment sown at different densities and sprayed with increasing field rates of glyphosate and tribenuron-methyl. The objective was to compare ED50s for crops and weeds derived by the different sensors in relation to crop density and herbicides. Although sensors were not directly developed to detect herbicide symptoms, they all detected changes in canopy colours or height and crop density. Generally ED50s showed the same pattern in response to crop density within herbicide, but there were marked differences between barley and oilseed rape. We suggest that the results of comparing the various sensor outputs could become a stepping stone to future standardisation for the benefit of the research and development of sensors that will detect herbicide effect on crops and weeds, particularly at the most vulnerable stages of development of the canopy.},
  langid = {english},
  keywords = {barley,glyphosate,image analysis,logarithmic sprayer,oilseed rape,tribenuron-methyl},
  file = {/home/samuelebumbaca/Zotero/storage/CBMYDRU6/wre.html}
}

@article{streibigSensorbasedAssessmentHerbicide2014a,
  title = {Sensor-Based Assessment of Herbicide Effects},
  author = {Streibig, J C and Rasmussen, J and And{\'u}jar, D and Andreasen, C and Berge, T W and Chachalis, D and Dittmann, T and Gerhards, R and Giselsson, T M and Hamouz, P and {Jaeger-Hansen}, C and Jensen, K and J{\o}rgensen, R N and Keller, M and Laursen, M and Midtiby, H S and Nielsen, J and M{\"u}ller, S and Nordmeyer, H and Peteinatos, G and Papadopoulos, A and Svensgaard, J and Weis, M and Christensen, S},
  editor = {Kudsk, Per},
  year = {2014},
  month = jun,
  journal = {Weed Research},
  volume = {54},
  number = {3},
  pages = {223--233},
  issn = {00431737},
  doi = {10.1111/wre.12079},
  urldate = {2023-03-24},
  abstract = {Non-destructive assessment of herbicide effects may be able to support integrated weed management. To test whether effects of herbicides on canopy variables could be detected by sensors, two crops were used as models and treated with herbicides at BBCH 20 using a logarithmic sprayer. Twelve days after spraying at BBCH 25 and 42 days after sowing, nine sensor systems scanned a spring barley and an oilseed rape field experiment sown at different densities and sprayed with increasing field rates of glyphosate and tribenuron-methyl. The objective was to compare ED50s for crops and weeds derived by the different sensors in relation to crop density and herbicides. Although sensors were not directly developed to detect herbicide symptoms, they all detected changes in canopy colours or height and crop density. Generally ED50s showed the same pattern in response to crop density within herbicide, but there were marked differences between barley and oilseed rape. We suggest that the results of comparing the various sensor outputs could become a stepping stone to future standardisation for the benefit of the research and development of sensors that will detect herbicide effect on crops and weeds, particularly at the most vulnerable stages of development of the canopy.},
  langid = {english}
}

@misc{StudyPlantDisease,
  title = {The {{Study}} of {{Plant Disease Epidemics}} {\textbar} {{Epidemiology}}},
  urldate = {2023-01-31},
  howpublished = {https://apsjournals.apsnet.org/doi/book/10.1094/9780890545058},
  file = {/home/samuelebumbaca/Zotero/storage/YTZ7XWDB/9780890545058.html}
}

@article{sunDetectionCornChlorophyll2010,
  title = {{[Detection of corn chlorophyll content using canopy spectral reflectance]}},
  author = {Sun, Hong and Li, Min-zan and Zhang, Yan-e and Zhao, Yong and Wang, Hai-hua},
  year = {2010},
  month = sep,
  journal = {Guang Pu Xue Yu Guang Pu Fen Xi = Guang Pu},
  volume = {30},
  number = {9},
  pages = {2488--2492},
  issn = {1000-0593},
  abstract = {The canopy spectral reflectance and chlorophyll content of corn were measured and analyzed under different nitrogen treatments. The correlation between spectral reflectance and chlorophyll content was discussed based on different growth stages and different nitrogen levels. The results showed positive correlations under high and normal nitrogen treatment, while negative correlation under low nitrogen treatment. The relation between reflectance of normal fertilizer region and chlorophyll content was better than others, with r(Normal) {$>$} r(High) {$>$} r(Low). Normal fertilizer was the best condition to detect the corn chlorophyll content using spectral reflectance. Analysis of the relations at different growth stages showed that on the band of 400-1000 nm the absolute value of correlation coefficient increased and reached the maximum at shooting stage, it decreased until anthesis-silking stage, and then rebounded at milking stage. The positive correlations were found at shooting and milking stage, while negative correlations were found at seedling, trumpet and anthesis-silking stage. It was indicated that the sensitive stages to detect the chlorophyll content were shooting and trumpet stage with high absolute value of correlation coefficient above 0.6 around 550 nm. In order to detect the chlorophyll content of corn, 558, 667, 714 and 912 nm were selected to establish the MLR model and PLSR model. The results showed that PLSR was more capable of building chlorophyll content models reflecting correct relations among multi-variables compared with MLR. In the meanwhile, three wavelengths were selected (558, 667 and 714 nm) to build different vegetation indices such as GDVI, GRVI, GNDVI, DVI, RVI and NDVI. The correlation between DVI and chlorophyll con tent was better than others and DVI was used to establish binomial model and exponential model at shooting stage (R2 = 0.80) and trumpet stage (R2 = 0.66) respectively which was higher than PLSR It also provided a feasible method to detect chlorophyll content non-destructively.},
  langid = {chi},
  pmid = {21105424},
  keywords = {Chlorophyll,Fertilizers,Models Theoretical,Nitrogen,Plant Leaves,Spectrum Analysis,Zea mays}
}

@article{sunMeasurementMethodBased2019,
  title = {Measurement {{Method Based}} on {{Multispectral Three-Dimensional Imaging}} for the {{Chlorophyll Contents}} of {{Greenhouse Tomato Plants}}},
  author = {Sun, Guoxiang and Wang, Xiaochan and Sun, Ye and Ding, Yongqian and Lu, Wei},
  year = {2019},
  month = jan,
  journal = {Sensors},
  volume = {19},
  number = {15},
  pages = {3345},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1424-8220},
  doi = {10.3390/s19153345},
  urldate = {2023-02-23},
  abstract = {Nondestructive plant growth measurement is essential for researching plant growth and health. A nondestructive measurement system to retrieve plant information includes the measurement of morphological and physiological information, but most systems use two independent measurement systems for the two types of characteristics. In this study, a highly integrated, multispectral, three-dimensional (3D) nondestructive measurement system for greenhouse tomato plants was designed. The system used a Kinect sensor, an SOC710 hyperspectral imager, an electric rotary table, and other components. A heterogeneous sensing image registration technique based on the Fourier transform was proposed, which was used to register the SOC710 multispectral reflectance in the Kinect depth image coordinate system. Furthermore, a 3D multiview RGB-D image-reconstruction method based on the pose estimation and self-calibration of the Kinect sensor was developed to reconstruct a multispectral 3D point cloud model of the tomato plant. An experiment was conducted to measure plant canopy chlorophyll and the relative chlorophyll content was measured by the soil and plant analyzer development (SPAD) measurement model based on a 3D multispectral point cloud model and a single-view point cloud model and its performance was compared and analyzed. The results revealed that the measurement model established by using the characteristic variables from the multiview point cloud model was superior to the one established using the variables from the single-view point cloud model. Therefore, the multispectral 3D reconstruction approach is able to reconstruct the plant multispectral 3D point cloud model, which optimizes the traditional two-dimensional image-based SPAD measurement method and can obtain a precise and efficient high-throughput measurement of plant chlorophyll.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {chlorophyll,greenhouse tomato,multispectral,plant phenotypes,SPAD,three-dimensional reconstruction}
}

@article{suSkeletonExtractionTree2011,
  title = {Skeleton Extraction for Tree Models},
  author = {Su, Zhixun and Zhao, Yuandi and Zhao, Chunjiang and Guo, Xinyu and Li, Zhiyang},
  year = {2011},
  journal = {Mathematical and Computer Modelling},
  volume = {54},
  number = {3-4},
  pages = {1115--1120},
  publisher = {Elsevier},
  urldate = {2024-06-10},
  file = {/home/samuelebumbaca/Zotero/storage/S3BAJ7J7/S0895717710005340.html}
}

@inproceedings{tagliasacchiCurveSkeletonExtraction2009,
  title = {Curve Skeleton Extraction from Incomplete Point Cloud},
  booktitle = {{{ACM SIGGRAPH}} 2009 Papers},
  author = {Tagliasacchi, Andrea and Zhang, Hao and {Cohen-Or}, Daniel},
  year = {2009},
  month = jul,
  pages = {1--9},
  publisher = {ACM},
  address = {New Orleans Louisiana},
  doi = {10.1145/1576246.1531377},
  urldate = {2024-06-10},
  isbn = {978-1-60558-726-4},
  langid = {english}
}

@book{taizPlantPhysiologyDevelopment2015,
  title = {Plant Physiology and Development},
  author = {Taiz, Lincoln and Zeiger, Eduardo and M??ller, I. M and Murphy, Angus S and Taiz, Lincoln},
  year = {2015},
  isbn = {978-1-60535-353-1},
  langid = {english},
  annotation = {OCLC: 897091434}
}

@article{tamRegistration3DPoint2013,
  title = {Registration of {{3D Point Clouds}} and {{Meshes}}: {{A Survey}} from {{Rigid}} to {{Nonrigid}}},
  shorttitle = {Registration of {{3D Point Clouds}} and {{Meshes}}},
  author = {Tam, G. K. L. and {Zhi-Quan Cheng} and {Yu-Kun Lai} and Langbein, F. C. and {Yonghuai Liu} and Marshall, D. and Martin, R. R. and {Xian-Fang Sun} and Rosin, P. L.},
  year = {2013},
  month = jul,
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {19},
  number = {7},
  pages = {1199--1217},
  issn = {1077-2626},
  doi = {10.1109/TVCG.2012.310},
  urldate = {2021-12-19}
}

@article{tanTomatoLeafDiseases2021,
  title = {Tomato {{Leaf Diseases Classification Based}} on {{Leaf Images}}: {{A Comparison}} between {{Classical Machine Learning}} and {{Deep Learning Methods}}},
  shorttitle = {Tomato {{Leaf Diseases Classification Based}} on {{Leaf Images}}},
  author = {Tan, Lijuan and Lu, Jinzhu and Jiang, Huanyu},
  year = {2021},
  month = sep,
  journal = {AgriEngineering},
  volume = {3},
  number = {3},
  pages = {542--558},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2624-7402},
  doi = {10.3390/agriengineering3030035},
  urldate = {2023-11-27},
  abstract = {Tomato production can be greatly reduced due to various diseases, such as bacterial spot, early blight, and leaf mold. Rapid recognition and timely treatment of diseases can minimize tomato production loss. Nowadays, a large number of researchers (including different institutes, laboratories, and universities) have developed and examined various traditional machine learning (ML) and deep learning (DL) algorithms for plant disease classification. However, through pass survey analysis, we found that there are no studies comparing the classification performance of ML and DL for the tomato disease classification problem. The performance and outcomes of different traditional ML and DL (a subset of ML) methods may vary depending on the datasets used and the tasks to be solved. This study generally aimed to identify the most suitable ML/DL models for the PlantVillage tomato dataset and the tomato disease classification problem. For machine learning algorithm implementation, we used different methods to extract disease features manually. In our study, we extracted a total of 52 texture features using local binary pattern (LBP) and gray level co-occurrence matrix (GLCM) methods and 105 color features using color moment and color histogram methods. Among all the feature extraction methods, the COLOR+GLCM method obtained the best result. By comparing the different methods, we found that the metrics (accuracy, precision, recall, F1 score) of the tested deep learning networks (AlexNet, VGG16, ResNet34, EfficientNet-b0, and MobileNetV2) were all better than those of the measured machine learning algorithms (support vector machine (SVM), k-nearest neighbor (kNN), and random forest (RF)). Furthermore, we found that, for our dataset and classification task, among the tested ML/DL algorithms, the ResNet34 network obtained the best results, with accuracy of 99.7\%, precision of 99.6\%, recall of 99.7\%, and F1 score of 99.7\%.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {deep learning,disease classification,feature extraction,machine learning}
}

@article{taoEstablishmentCropGrowth2016,
  title = {{[Establishment of The Crop Growth and Nitrogen Nutrition State Model Using Spectral Parameters Canopy Cover]}},
  author = {Tao, Zhi-Qiang and Bagum, Shamim Ara and Ma, Wei and Zhou, Bao-yuan and Fu, Jin-dong and Cui, Ri-xian and Sun, Xue-fang and Zhao, Ming},
  year = {2016},
  month = jan,
  journal = {Guang Pu Xue Yu Guang Pu Fen Xi = Guang Pu},
  volume = {36},
  number = {1},
  pages = {231--236},
  issn = {1000-0593},
  abstract = {In order to explore a non-destructive monitoring technique, the use of digital photo pixels canopy cover (CC) diagnosis and prediction on maize growth and its nitrogen nutrition status. This study through maize canopy digital photo images on relationship between color index in the photo and the leaf area index (LAI), shoot dry matter weight (DM), leaf nitrogen content percentage (N\%). The test conducted in the Chinese Academy of Agricultural Science from 2012 to 2013, based on Maize canopy Visual Image Analysis System developed by Visual Basic Version 6.0, analyzed the correlation of CC, color indices, LAI, DM, N\% on maize varieties (Zhongdan909, ZD 909) under three nitrogen levels treatments, furthermore the indicators significantly correlated were fitted with modeling, The results showed that CC had a highly significant correlation with LAI (r = 0.93, p {$<$} 0.01), DM (r = 0. 94, p {$<$} 0.01), N\% (r = 0.82, p {$<$} 0.01). Estimating the model of LAI, DM and N\% by CC were all power function, and the equation respectively were y = 3.281 2x(0.763 9), y = 283.658 1x(0.553 6) and y = 3.064 5x(0.932 9); using independent data from modeling for model validation indicated that R2, RMSE and RE based on 1 : 1 line relationship between measured values and simulated values in the model of CC estimating LAI were 0.996, 0.035 and 1.46\%; R2, RMSE and RE in the model of CC estimating DM were 0.978, 5.408 g and 2.43\%; R2, RMSE and RE in the model of CC estimating N\% were 0.990, 0.054 and 2.62\%. In summary, the model can comparatively accurately estimate the LAI, DM and N\% by CC under different nitrogen levels at maize grain filling stage, indicating that it is feasible to apply digital camera on real-time undamaged rapid monitoring and prediction for maize growth conditions and its nitrogen nutrition status. This research finding is to be verified in the field experiment, and further analyze the applicability throughout the growing period in other maize varieties and different planting density.},
  langid = {chi},
  pmid = {27228773},
  keywords = {Models Theoretical,Nitrogen,Plant Leaves,Spectrum Analysis,Zea mays}
}

@article{tardieuPlantResponseEnvironmental2013,
  title = {Plant Response to Environmental Conditions: Assessing Potential Production, Water Demand, and Negative Effects of Water Deficit},
  shorttitle = {Plant Response to Environmental Conditions},
  author = {Tardieu, Francois},
  year = {2013},
  journal = {Frontiers in Physiology},
  volume = {4},
  issn = {1664-042X},
  urldate = {2022-01-28},
  abstract = {This paper reviews methods for analyzing plant performance and its genetic variability under a range of environmental conditions. Biomass accumulation is linked every day to available light in the photosynthetically active radiation (PAR) domain, multiplied by the proportion of light intercepted by plants and by the radiation use efficiency. Total biomass is cumulated over the duration of the considered phase (e.g., plant cycle or vegetative phase). These durations are essentially constant for a given genotype provided that time is corrected for temperature (thermal time). Several ways of expressing thermal time are reviewed. Two alternative equations are presented, based either on the effect of transpiration, or on yield components. Their comparative interests and drawbacks are discussed. The genetic variability of each term of considered equations affects yield under water deficit, via mechanisms at different scales of plant organization and time. The effect of any physiological mechanism on yield of stressed plants acts via one of these terms, although the link is not always straightforward. Finally, I propose practical ways to compare the productivity of genotypes in field environments, and a ``minimum dataset'' of environmental data and traits that should be recorded for that.}
}

@inproceedings{tardieuWhitePaperPlant2009,
  title = {White Paper on Plant Phenotyping},
  booktitle = {{{EPSO Workshop}}},
  author = {Tardieu, F and Schurr, U},
  year = {2009}
}

@article{tengLeafSegmentationClassification2011,
  title = {Leaf Segmentation, Classification, and Three-Dimensional Recovery from a Few Images with Close Viewpoints},
  author = {Teng, Chin-Hung and Kuo, Yi-Ting and Chen, Yung-Sheng},
  year = {2011},
  month = mar,
  journal = {Optical Engineering},
  volume = {50},
  number = {3},
  pages = {037003},
  publisher = {SPIE},
  issn = {0091-3286, 1560-2303},
  doi = {10.1117/1.3549927},
  urldate = {2023-01-13},
  abstract = {In this paper, we incorporate a set of sophisticated algorithms to implement a leaf segmentation and classification system. This system inherits the advantages of these algorithms while eliminating the difficulties each algorithm faced. Our system can segment leaves from images of live plants with arbitrary image conditions, and classify them against sketched leaf shapes or real leaves. This system can also estimate the three-dimensional (3-D) information of leaves which is not only useful for leaf segmentation but is also beneficial for further 3-D shape recovery. Although our system requires more than one image to reconstruct the 3-D structure of the scene, it has been designed so that only a few images with close viewpoints are sufficient to achieve the task, thus the system is still flexible and easy to use in image acquisition. For leaf classification, we adopt the normalized centroid-contour distance as our classification feature and employ a circular-shift comparing scheme to measure leaf similarity so that the system has the advantage of being invariant to leaf translation, rotation and scaling. We have conducted a series of experiments on many leaf images and the results are encouraging. The leaves can be well segmented and the classification results are also acceptable.}
}

@article{thelenUseOpticalRemote2004,
  title = {Use of {{Optical Remote Sensing}} for {{Detecting Herbicide Injury}} in {{Soybean}}},
  author = {Thelen, Kurt D. and Kravchenko, A. N. and Lee, Chad D.},
  year = {2004},
  journal = {Weed Technology},
  volume = {18},
  number = {2},
  eprint = {3989218},
  eprinttype = {jstor},
  pages = {292--297},
  publisher = {[Cambridge University Press, Weed Science Society of America]},
  issn = {0890-037X},
  urldate = {2023-01-10},
  abstract = {Experiments were conducted from 2000 to 2002 at two locations each year to determine if lactofen and imazethapyr injury to soybean could be detected using digital aerial imagery and ground-based optical remote sensing. Lactofen and imazethapyr were applied at base rates of 105 and 71 g/ha, respectively, and at 0, 2X, and 4X rates. Treated plots were evaluated between 7 and 21 d after treatment for crop injury using a ground-based radiometer and a system using computer analysis of digital aerial imagery. Both the ground-based radiometer and the digital aerial imagery were effective in detecting herbicide injury under most conditions. The digital aerial imagery system was found to be more sensitive in detecting herbicide injury than the ground-based radiometer system. Herbicide or herbicide rate had a significant effect on normalized differential vegetation indices (NDVI) derived from digital aerial imagery in four of four site-years. NDVI values derived from a multispectral ground-based radiometer were significant for herbicide or herbicide rate in four of six site-years. NDVI values from treated plots were subtracted from the NDVI value of the untreated check to generate a {$\Delta$}NDVI. The resulting {$\Delta$}NDVI values from the ground-based radiometer system were significant for herbicide or herbicide rate in six of six site-years. Neither optical remote-sensing system was effective at estimating actual application rates of lactofen and imazethapyr across a broad range of field and weather conditions due to temporal and spatial variability in crop response to the herbicides.}
}

@article{thelenUseOpticalRemote2004a,
  title = {Use of {{Optical Remote Sensing}} for {{Detecting Herbicide Injury}} in {{Soybean}}},
  author = {Thelen, Kurt D. and Kravchenko, A. N. and Lee, Chad D.},
  year = {2004},
  journal = {Weed Technology},
  volume = {18},
  number = {2},
  eprint = {3989218},
  eprinttype = {jstor},
  pages = {292--297},
  publisher = {[Cambridge University Press, Weed Science Society of America]},
  issn = {0890-037X},
  urldate = {2023-01-31},
  abstract = {Experiments were conducted from 2000 to 2002 at two locations each year to determine if lactofen and imazethapyr injury to soybean could be detected using digital aerial imagery and ground-based optical remote sensing. Lactofen and imazethapyr were applied at base rates of 105 and 71 g/ha, respectively, and at 0, 2X, and 4X rates. Treated plots were evaluated between 7 and 21 d after treatment for crop injury using a ground-based radiometer and a system using computer analysis of digital aerial imagery. Both the ground-based radiometer and the digital aerial imagery were effective in detecting herbicide injury under most conditions. The digital aerial imagery system was found to be more sensitive in detecting herbicide injury than the ground-based radiometer system. Herbicide or herbicide rate had a significant effect on normalized differential vegetation indices (NDVI) derived from digital aerial imagery in four of four site-years. NDVI values derived from a multispectral ground-based radiometer were significant for herbicide or herbicide rate in four of six site-years. NDVI values from treated plots were subtracted from the NDVI value of the untreated check to generate a {$\Delta$}NDVI. The resulting {$\Delta$}NDVI values from the ground-based radiometer system were significant for herbicide or herbicide rate in six of six site-years. Neither optical remote-sensing system was effective at estimating actual application rates of lactofen and imazethapyr across a broad range of field and weather conditions due to temporal and spatial variability in crop response to the herbicides.}
}

@article{thomasiRelationshipVegetationIndices2021,
  title = {Relationship of Vegetation Indices with Herbicide Phytotoxicity in Winter Cereals},
  author = {Thomasi, Rosana M. and L{\'u}cio, Alessandro D. and Amado, Telmo J. C. and Pott, Luan P. and Zanon, Alencar and Werle, Isabel S. and Macedo, Mariana and Ulguim, Andr{\'e} R.},
  year = {2021},
  month = nov,
  journal = {Advances in Weed Science},
  volume = {39},
  pages = {02100050},
  issn = {2675-9462},
  doi = {10.51694/AdvWeedSci/2021;39:00017},
  urldate = {2023-01-31},
  abstract = {Background: The evaluation of selective herbicides for weed control in winter cereals is extremely important. Simple methods to evaluate alterations caused by herbicides in the growth and development of winter cereals can be performed with vegetation indices.},
  langid = {english}
}

@article{thomasLeafReflectanceVs1977,
  title = {Leaf {{Reflectance}} vs. {{Leaf Chlorophyll}} and {{Carotenoid Concentrations}} for {{Eight Crops1}}},
  author = {Thomas, J. R. and Gausman, H. W.},
  year = {1977},
  journal = {Agronomy Journal},
  volume = {69},
  number = {5},
  pages = {799--802},
  issn = {1435-0645},
  doi = {10.2134/agronj1977.00021962006900050017x},
  urldate = {2023-03-24},
  abstract = {Leaf reflectance in the 0.40- to 0.75-{$\mu$}m wavelength interval is influenced primarily by the pigments chlorophyll and carotenoid. However, the literature contains very few references to the relation between reflectance from leaves and their carotenoid content. Our objectives in this study were to determine which of three wavelengths in the visible spectral region best related leaf reflectance to total chlorophyll and carotenoid concentrations, and the relative effect of these pigments on reflectance. Hemispherical reflectances of single leaves at each of the 0.45-, 0.55-, and 0.67-{$\mu$}m wavelengths for cantaloupe (Cucumis melo L. cv. reticulatus Naud.), corn (Zea mays L.), cotton (Gossypium hirsutum L.), cucumber (Cucumis sativus L.), head lettuce (Lactuca sativa L. cv. capitata L.), grain sorghum (Sorghum bicolor (L.) Moench), spinach (Spinacia oleracea L.), and tobacco (Nicotiana tabacum L.) were regressed on each crop's leaf total chlorophyll and carotenoid concentrations. The crops were grown in sand culture, and their leaf pigment concentrations were varied by supplying N at rates of 14, 28, 84, 140, and 196 ppm to a basic nutrient solution. Hemispherical reflectance of leaves was inversely related to each crop's leaf chlorophyll and carotenoid concentrations. However, of the three wavelengths tested, the 0.55-{$\mu$}m wavelength seemed superior for individually relating the two pigments to leaf reflectance. The independent effects of carotenoid on hemispherical reflectance were small and generally not statistically significant, whereas the independent effects of chlorophyll while small were generally significant. The combined effects of these variables were highly significant and accounted for 39 to 95\% of the reflectance variability. This study indicated that even though including carotenoid with total chlorophyll measurements improved the correlation of reflectance with pigment concentration, satisfactory results would be obtained by chlorophyll analysis alone.},
  langid = {english},
  keywords = {Absorptance,Carotene,Pigments,Remote sensing,Xanthophyll},
  file = {/home/samuelebumbaca/Zotero/storage/9KBN9C2P/agronj1977.html}
}

@article{thomasObservationPlantPathogen2016,
  title = {Observation of Plant--Pathogen Interaction by Simultaneous Hyperspectral Imaging Reflection and Transmission Measurements},
  author = {Thomas, Stefan and Wahabzada, Mirwaes and Kuska, Matheus Thomas and Rascher, Uwe and Mahlein, Anne-Katrin and Thomas, Stefan and Wahabzada, Mirwaes and Kuska, Matheus Thomas and Rascher, Uwe and Mahlein, Anne-Katrin},
  year = {2016},
  month = oct,
  journal = {Functional Plant Biology},
  volume = {44},
  number = {1},
  pages = {23--34},
  publisher = {CSIRO PUBLISHING},
  issn = {1445-4416, 1445-4416},
  doi = {10.1071/FP16127},
  urldate = {2023-01-13},
  abstract = {Hyperspectral imaging sensors are valuable tools for plant disease detection and plant phenotyping. Reflectance properties are influenced by plant pathogens and resistance responses, but changes of transmission characteristics of plants are less described. In this study we used simultaneously recorded reflectance and transmittance imaging data of resistant and susceptible barley genotypes that were inoculated with Blumeria graminis f. sp. hordei to evaluate the added value of imaging transmission, reflection and absorption for characterisation of disease development. These datasets were statistically analysed using principal component analysis, and compared with visual and molecular disease estimation. Reflection measurement performed significantly better for early detection of powdery mildew infection, colonies could be detected 2 days before symptoms became visible in RGB images. Transmission data could be used to detect powdery mildew 2 days after symptoms becoming visible in reflection based RGB images. Additionally distinct transmission changes occurred at 580--650 nm for pixels containing disease symptoms. It could be shown that the additional information of the transmission data allows for a clearer spatial differentiation and localisation between powdery mildew symptoms and necrotic tissue on the leaf then purely reflectance based data. Thus the information of both measurement approaches are complementary: reflectance based measurements facilitate an early detection, and transmission measurements provide additional information to better understand and quantify the complex spatio-temporal dynamics of plant-pathogen interactions.},
  langid = {english}
}

@article{thomasObservationPlantPathogen2017,
  title = {Observation of Plant--Pathogen Interaction by Simultaneous Hyperspectral Imaging Reflection and Transmission Measurements},
  author = {Thomas, Stefan and Wahabzada, Mirwaes and Kuska, Matheus Thomas and Rascher, Uwe and Mahlein, Anne-Katrin},
  year = {2017},
  journal = {Functional Plant Biology},
  volume = {44},
  number = {1},
  pages = {23},
  issn = {1445-4408},
  doi = {10.1071/FP16127},
  urldate = {2021-12-22},
  abstract = {Hyperspectral imaging sensors are valuable tools for plant disease detection and plant phenotyping. Reflectance properties are influenced by plant pathogens and resistance responses, but changes of transmission characteristics of plants are less described. In this study we used simultaneously recorded reflectance and transmittance imaging data of resistant and susceptible barley genotypes that were inoculated with Blumeria graminis f. sp. hordei to evaluate the added value of imaging transmission, reflection and absorption for characterisation of disease development. These datasets were statistically analysed using principal component analysis, and compared with visual and molecular disease estimation. Reflection measurement performed significantly better for early detection of powdery mildew infection, colonies could be detected 2 days before symptoms became visible in RGB images. Transmission data could be used to detect powdery mildew 2 days after symptoms becoming visible in reflection based RGB images. Additionally distinct transmission changes occurred at 580--650\,nm for pixels containing disease symptoms. It could be shown that the additional information of the transmission data allows for a clearer spatial differentiation and localisation between powdery mildew symptoms and necrotic tissue on the leaf then purely reflectance based data. Thus the information of both measurement approaches are complementary: reflectance based measurements facilitate an early detection, and transmission measurements provide additional information to better understand and quantify the complex spatio-temporal dynamics of plant-pathogen interactions.},
  langid = {english}
}

@article{thomasQuantitativeAssessmentDisease2018,
  title = {Quantitative Assessment of Disease Severity and Rating of Barley Cultivars Based on Hyperspectral Imaging in a Non-Invasive, Automated Phenotyping Platform},
  author = {Thomas, Stefan and Behmann, Jan and Steier, Angelina and Kraska, Thorsten and Muller, Onno and Rascher, Uwe and Mahlein, Anne-Katrin},
  year = {2018},
  month = jun,
  journal = {Plant Methods},
  volume = {14},
  number = {1},
  pages = {45},
  issn = {1746-4811},
  doi = {10.1186/s13007-018-0313-8},
  urldate = {2021-12-22},
  abstract = {Phenotyping is a bottleneck for the development of new plant cultivars. This study introduces a new hyperspectral phenotyping system, which combines the high throughput of canopy scale measurements with the advantages of high spatial resolution and a controlled measurement environment. Furthermore, the measured barley canopies were grown in large containers (called Mini-Plots), which allow plants to develop field-like phenotypes in greenhouse experiments, without being hindered by pot size.},
  keywords = {Disease rating,Greenhouse,High-throughput,Hyperspectral imaging,Phenotyping platform,Simplex Volume Maximization,Support Vector Machine}
}

@article{travisDevelopmentImplementationAdoption1991,
  title = {Development, {{Implementation}}, and {{Adoption}} of {{Expert Systems}} in {{Plant Pathology}}},
  author = {Travis, J W and Latin, R X},
  year = {1991},
  journal = {Annual Review of Phytopathology},
  volume = {29},
  number = {1},
  pages = {343--360},
  doi = {10.1146/annurev.py.29.090191.002015},
  urldate = {2023-01-13}
}

@article{travlosNovelSensorbasedMethod2021,
  title = {Novel Sensor-Based Method (Quick Test) for the in-Season Rapid Evaluation of Herbicide Efficacy under Real Field Conditions in Durum Wheat},
  author = {Travlos, Ilias and Tsekoura, Anastasia and Antonopoulos, Nikolaos and Kanatas, Panagiotis and Gazoulis, Ioannis},
  year = {2021},
  month = mar,
  journal = {Weed Science},
  volume = {69},
  number = {2},
  pages = {147--160},
  issn = {0043-1745, 1550-2759},
  doi = {10.1017/wsc.2021.8},
  urldate = {2022-09-20},
  abstract = {Abstract                            Optimum herbicide use is a key factor affecting the success of any integrated weed management strategy. The main objective of the current study was to implement a method based on spectrometer measurements for the in situ evaluation of herbicide efficacy and the detection of potentially herbicide-resistant weeds. Field trials were conducted in Greece between 2018 and 2020 in several durum wheat fields (               Triticum durum               Desf.). In all trials, the overall effect of herbicide application on the recorded Normalized Difference Vegetation Index (NDVI) values (at 1 and 2 wk after treatment [WAT]) was significant (P {$\leq$} 0.001). For the majority of the surveyed fields, low NDVI values were recorded after 2,4-D application and a mixture of clopyralid + florasulam from 1 WAT, suggesting their increased efficacy. In several cases, the application of pyroxsulam + florasulam resulted in significant NDVI reductions at 2 WAT. As observed at the end of the growing seasons, the herbicides that reduced NDVI resulted in lower weed biomass. Strong correlations were observed between weed aboveground biomass and NDVI (2 WAT). In particular, R               2               values were 0.8234 to 0.8649, 0.8453, 0.8595, 0.8149, and 0.8925 for the Aliartos, Thiva, Domokos, Larissa, and Orestiada fields, respectively. The overall effects of herbicide application on wheat grain yield were also significant (P {$\leq$} 0.001). Pot experiments confirmed that the high NDVI values in some cases could be attributed to the presence of herbicide-resistant weeds. For instance, the resistance indices of two accessions of catchweed bedstraw (               Galium aparine               L.) to mesosulfuron-methyl + iodosulfuron-methyl-sodium ranged between 9.7 and 13.2, whereas one sterile oat [               Avena sterilis               L. ssp.               ludoviciana               (Durieu) Gillet \& Magne] accession was 8.8 times more resistant to fenoxaprop-               p               -ethyl than a susceptible one. The present study is targeted at making a significant contribution toward establishing cause--effect relationships and presenting a useful tool for developing more effective weed management practices in more arable crops and under different soil and climatic conditions.},
  langid = {english}
}

@incollection{triggsBundleAdjustmentModern2000,
  title = {Bundle {{Adjustment}} --- {{A Modern Synthesis}}},
  booktitle = {Vision {{Algorithms}}: {{Theory}} and {{Practice}}},
  author = {Triggs, Bill and McLauchlan, Philip F. and Hartley, Richard I. and Fitzgibbon, Andrew W.},
  editor = {Goos, Gerhard and Hartmanis, Juris and {van Leeuwen}, Jan and Triggs, Bill and Zisserman, Andrew and Szeliski, Richard},
  year = {2000},
  volume = {1883},
  pages = {298--372},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/3-540-44480-7_21},
  urldate = {2022-12-06},
  abstract = {This paper is a survey of the theory and methods of photogrammetric bundle adjustment, aimed at potential implementors in the computer vision community. Bundle adjustment is the problem of refining a visual reconstruction to produce jointly optimal structure and viewing parameter estimates. Topics covered include: the choice of cost function and robustness; numerical optimization including sparse Newton methods, linearly convergent approximations, updating and recursive methods; gauge (datum) invariance; and quality control. The theory is developed for general robust cost functions rather than restricting attention to traditional nonlinear least squares.},
  isbn = {978-3-540-67973-8 978-3-540-44480-0},
  langid = {english}
}

@article{tschierschEstablishmentIntegratedProtocols2017,
  title = {Establishment of Integrated Protocols for Automated High Throughput Kinetic Chlorophyll Fluorescence Analyses},
  author = {Tschiersch, Henning and Junker, Astrid and Meyer, Rhonda C. and Altmann, Thomas},
  year = {2017},
  month = jul,
  journal = {Plant Methods},
  volume = {13},
  number = {1},
  pages = {54},
  issn = {1746-4811},
  doi = {10.1186/s13007-017-0204-4},
  urldate = {2021-12-18},
  abstract = {Automated plant phenotyping has been established as a powerful new tool in studying plant growth, development and response to various types of biotic or abiotic stressors. Respective facilities mainly apply non-invasive imaging based methods, which enable the continuous quantification of the dynamics of plant growth and physiology during developmental progression. However, especially for plants of larger size, integrative, automated and high throughput measurements of complex physiological parameters such as photosystem II efficiency determined through kinetic chlorophyll fluorescence analysis remain a challenge.},
  keywords = {Chlorophyll fluorescence imaging (CFI),High throughput screening,Photosynthesis,Plant phenotyping,PSII operating efficiency}
}

@article{tuckerRedPhotographicInfrared1979,
  title = {Red and Photographic Infrared Linear Combinations for Monitoring Vegetation},
  author = {Tucker, Compton J.},
  year = {1979},
  month = may,
  journal = {Remote Sensing of Environment},
  volume = {8},
  number = {2},
  pages = {127--150},
  issn = {0034-4257},
  doi = {10.1016/0034-4257(79)90013-0},
  urldate = {2023-03-24},
  abstract = {In situ collected spectrometer data were used to evaluate and quantify the relationships between various linear combinations of red and photographic infrared radiances and experimental plot biomass, leaf water content, and chlorophyll content. The radiance variables evaluated included the red and photographic infrared (IR) radiance and the linear combinations of the IR/red ratio, the square root of the IR/red ratio, the IR-red difference, the vegetation index, and the transformed vegetation index. In addition, the corresponding green and red linear combinations were evaluated for comparative purposes. Three data sets were used from June, September, and October sampling periods. Regression analysis showed the increased utility of the IR and red linear combinations vis-{\`a}-vis the same green and red linear combinations. The red and IR linear combinations had 7\% and 14\% greater regression significance than the green and red linear combinations for the June and September sampling periods, respectively. The vegetation index, transformed vegetation index, and square root of the IR/red ratio were the most significant, followed closely by the IR/red ratio. Less than a 6\% difference separated the highest and lowest of these four ER and red linear combinations. The use of these linear combinations was shown to be sensitive primarily to the green leaf area or green leaf biomass. As such, these linear combinations of the red and photographic IR radiances can be employed to monitor the photosynthetically active biomass of plant canopies.},
  langid = {english}
}

@article{uddlingEvaluatingRelationshipLeaf2007,
  title = {Evaluating the Relationship between Leaf Chlorophyll Concentration and {{SPAD-502}} Chlorophyll Meter Readings},
  author = {Uddling, J. and {Gelang-Alfredsson}, J. and Piikki, K. and Pleijel, H.},
  year = {2007},
  month = mar,
  journal = {Photosynthesis Research},
  volume = {91},
  number = {1},
  pages = {37--46},
  issn = {0166-8595, 1573-5079},
  doi = {10.1007/s11120-006-9077-5},
  urldate = {2022-09-19},
  langid = {english}
}

@article{uddlingEvaluatingRelationshipLeaf2007a,
  title = {Evaluating the Relationship between Leaf Chlorophyll Concentration and {{SPAD-502}} Chlorophyll Meter Readings},
  author = {Uddling, J. and {Gelang-Alfredsson}, J. and Piikki, K. and Pleijel, H.},
  year = {2007},
  month = jan,
  journal = {Photosynthesis Research},
  volume = {91},
  number = {1},
  pages = {37--46},
  issn = {1573-5079},
  doi = {10.1007/s11120-006-9077-5},
  urldate = {2022-09-19},
  abstract = {Relationships between chlorophyll concentration ([chl]) and SPAD values were determined for birch, wheat, and potato. For all three species, the relationships were non-linear with an increasing slope with increasing SPAD. The relationships for birch and wheat were strong (r2~{$\sim~$}0.9), while the potato relationship was comparatively weak (r2~{$\sim~$}0.5). Birch and wheat had very similar relationships when the chlorophyll concentration was expressed per unit leaf area, but diverged when it was expressed per unit fresh weight. Furthermore, wheat showed similar SPAD--[chl] relationships for two different cultivars and during two different growing seasons. The curvilinear shape of the SPAD--[chl] relationships agreed well with the simulated effects of non-uniform chlorophyll distribution across the leaf surface and multiple scattering, causing deviations from linearity in the high and low SPAD range, respectively. The effect of non-uniformly distributed chlorophyll is likely to be more important in explaining the non-linearity in the empirical relationships, since the effect of scattering was predicted to be comparatively weak. The simulations were based on the algorithm for the calculation of SPAD-502 output values. We suggest that SPAD calibration curves should generally be parameterised as non-linear equations, and we hope that the relationships between [chl] and SPAD and the simulations of the present study can facilitate the interpretation of chlorophyll meter calibrations in relation to optical properties of leaves in future studies.},
  langid = {english},
  keywords = {Absorbance,Chlorophyll,Non-uniform chlorophyll distribution,Reflectance,Scattering,SPAD}
}

@book{vanrossumPython3Reference2009,
  title = {Python 3 {{Reference Manual}}},
  author = {Van Rossum, Guido and Drake, Fred L.},
  year = {2009},
  publisher = {CreateSpace},
  address = {Scotts Valley, CA},
  isbn = {1-4414-1269-7}
}

@article{verreetRegionalMonitoringDisease2000,
  title = {Regional {{Monitoring}} for {{Disease Prediction}} and {{Optimization}} of {{Plant Protection Measuares}}: {{The IPM Wheat Model}}},
  shorttitle = {Regional {{Monitoring}} for {{Disease Prediction}} and {{Optimization}} of {{Plant Protection Measuares}}},
  author = {Verreet, J. A. and Klink, H. and Hoffmann, G. M.},
  year = {2000},
  month = aug,
  journal = {Plant Disease},
  volume = {84},
  number = {8},
  pages = {816--826},
  issn = {0191-2917, 1943-7692},
  doi = {10.1094/PDIS.2000.84.8.816},
  urldate = {2023-01-13},
  langid = {english}
}

@article{vianiSnowMetricsProxy2023,
  title = {Snow {{Metrics}} as {{Proxy}} to {{Assess Sarcoptic Mange}} in {{Wild Boar}}: {{Preliminary Results}} in {{Aosta Valley}} ({{Italy}})},
  author = {Viani, Annalisa and Orusa, Tommaso and {Borgogno-Mondino}, Enrico and Orusa, Riccardo},
  year = {2023},
  journal = {Life},
  volume = {13},
  number = {4},
  pages = {987}
}

@article{virletFieldScanalyzerAutomated2016,
  title = {Field {{Scanalyzer}}: {{An}} Automated Robotic Field Phenotyping Platform for Detailed Crop Monitoring},
  shorttitle = {Field {{Scanalyzer}}},
  author = {Virlet, Nicolas and Sabermanesh, Kasra and {Sadeghi-Tehran}, Pouria and Hawkesford, Malcolm J. and Virlet, Nicolas and Sabermanesh, Kasra and {Sadeghi-Tehran}, Pouria and Hawkesford, Malcolm J.},
  year = {2016},
  month = nov,
  journal = {Functional Plant Biology},
  volume = {44},
  number = {1},
  pages = {143--153},
  publisher = {CSIRO PUBLISHING},
  issn = {1445-4416, 1445-4416},
  doi = {10.1071/FP16163},
  urldate = {2023-01-13},
  abstract = {Current approaches to field phenotyping are laborious or permit the use of only a few sensors at a time. In an effort to overcome this, a fully automated robotic field phenotyping platform with a dedicated sensor array that may be accurately positioned in three dimensions and mounted on fixed rails has been established, to facilitate continual and high-throughput monitoring of crop performance. Employed sensors comprise of high-resolution visible, chlorophyll fluorescence and thermal infrared cameras, two hyperspectral imagers and dual 3D laser scanners. The sensor array facilitates specific growth measurements and identification of key growth stages with dense temporal and spectral resolution. Together, this platform produces a detailed description of canopy development across the crops entire lifecycle, with a high-degree of accuracy and reproducibility.},
  langid = {english}
}

@article{wahabzadaMetroMapsPlant2015,
  title = {Metro {{Maps}} of {{Plant Disease Dynamics}}---{{Automated Mining}} of {{Differences Using Hyperspectral Images}}},
  author = {Wahabzada, Mirwaes and Mahlein, Anne-Katrin and Bauckhage, Christian and Steiner, Ulrike and Oerke, Erich-Christian and Kersting, Kristian},
  year = {2015},
  month = jan,
  journal = {PLOS ONE},
  volume = {10},
  number = {1},
  pages = {e0116902},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0116902},
  urldate = {2023-01-13},
  abstract = {Understanding the response dynamics of plants to biotic stress is essential to improve management practices and breeding strategies of crops and thus to proceed towards a more sustainable agriculture in the coming decades. In this context, hyperspectral imaging offers a particularly promising approach since it provides non-destructive measurements of plants correlated with internal structure and biochemical compounds. In this paper, we present a cascade of data mining techniques for fast and reliable data-driven sketching of complex hyperspectral dynamics in plant science and plant phenotyping. To achieve this, we build on top of a recent linear time matrix factorization technique, called Simplex Volume Maximization, in order to automatically discover archetypal hyperspectral signatures that are characteristic for particular diseases. The methods were applied on a data set of barley leaves (Hordeum vulgare) diseased with foliar plant pathogens Pyrenophora teres, Puccinia hordei and Blumeria graminis hordei. Towards more intuitive visualizations of plant disease dynamics, we use the archetypal signatures to create structured summaries that are inspired by metro maps, i.e. schematic diagrams of public transport networks. Metro maps of plant disease dynamics produced on several real-world data sets conform to plant physiological knowledge and explicitly illustrate the interaction between diseases and plants. Most importantly, they provide an abstract and interpretable view on plant disease progression.},
  langid = {english},
  keywords = {Barley,Disease dynamics,Leaves,Pathogenesis,Pathogens,Plant pathology,Plant physiology,Powdery mildew}
}

@article{wahabzadaPlantPhenotypingUsing2016,
  title = {Plant {{Phenotyping}} Using {{Probabilistic Topic Models}}: {{Uncovering}} the {{Hyperspectral Language}} of {{Plants}}},
  shorttitle = {Plant {{Phenotyping}} Using {{Probabilistic Topic Models}}},
  author = {Wahabzada, Mirwaes and Mahlein, Anne-Katrin and Bauckhage, Christian and Steiner, Ulrike and Oerke, Erich-Christian and Kersting, Kristian},
  year = {2016},
  month = mar,
  journal = {Scientific Reports},
  volume = {6},
  number = {1},
  pages = {22482},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/srep22482},
  urldate = {2023-01-13},
  abstract = {Modern phenotyping and plant disease detection methods, based on optical sensors and information technology, provide promising approaches to plant research and precision farming. In particular, hyperspectral imaging have been found to reveal physiological and structural characteristics in plants and to allow for tracking physiological dynamics due to environmental effects. In this work, we present an approach to plant phenotyping that integrates non-invasive sensors, computer vision, as well as data mining techniques and allows for monitoring how plants respond to stress. To uncover latent hyperspectral characteristics of diseased plants reliably and in an easy-to-understand way, we ``wordify'' the hyperspectral images, i.e., we turn the images into a corpus of text documents. Then, we apply probabilistic topic models, a well-established natural language processing technique that identifies content and topics of documents. Based on recent regularized topic models, we demonstrate that one can track automatically the development of three foliar diseases of barley. We also present a visualization of the topics that provides plant scientists an intuitive tool for hyperspectral imaging. In short, our analysis and visualization of characteristic topics found during symptom development and disease progress reveal the hyperspectral language of plant diseases.},
  copyright = {2016 The Author(s)},
  langid = {english},
  keywords = {Data mining,High-throughput screening,Image processing,Plant sciences}
}

@article{walczynaEnhancingAnomalyDetection2025,
  title = {Enhancing {{Anomaly Detection Through Latent Space Manipulation}} in {{Autoencoders}}: {{A Comparative Analysis}}},
  shorttitle = {Enhancing {{Anomaly Detection Through Latent Space Manipulation}} in {{Autoencoders}}},
  author = {Walczyna, Tomasz and Jankowski, Damian and Piotrowski, Zbigniew},
  year = {2025},
  month = jan,
  journal = {Applied Sciences},
  volume = {15},
  number = {1},
  pages = {286},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-3417},
  doi = {10.3390/app15010286},
  urldate = {2025-01-05},
  abstract = {This article explores the practical implementation of autoencoders for anomaly detection, emphasizing their latent space manipulation and applicability across various domains. This study highlights the impact of optimizing parameter configurations, lightweight architectures, and training methodologies to enhance anomaly detection performance. A comparative analysis of autoencoders, Variational Autoencoders, and their modified counterparts was conducted within a tailored experimental environment designed to simulate real-world scenarios. The results demonstrate that these models, when fine-tuned, achieve significant improvements in detection accuracy, specificity, and sensitivity while maintaining computational efficiency. The findings underscore the importance of lightweight, practical models and the integration of streamlined training processes in developing effective anomaly detection systems. This study provides valuable insights into advancing machine learning methods for real-world applications and sets the stage for further refinement of autoencoder-based approaches.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {anomalies,autoencoders,deep learning,detection of anomalies,machine learning,neural networks}
}

@article{wangAdaptiveThresholdingAlgorithm2013,
  title = {An {{Adaptive Thresholding}} Algorithm of Field Leaf Image},
  author = {Wang, Jianlun and He, Jianlei and Han, Yu and Ouyang, Changqi and Li, Daoliang},
  year = {2013},
  month = aug,
  journal = {Computers and Electronics in Agriculture},
  volume = {96},
  pages = {23--39},
  issn = {0168-1699},
  doi = {10.1016/j.compag.2013.04.014},
  urldate = {2023-01-13},
  abstract = {In this paper, we analyze the background and foreground images of jujube leaf, and propose a new Adaptive Thresholding algorithm that can segment single leaves in a leaf image extracted randomly from an online system. We use the OTSU and CANNY operators to segment the area of the target leaf by choosing the thresholds with the Mapping Function, the Shape Identification algorithm and pattern recognition. The optimization process of the algorithm, which includes Mapping Function, the Shape Identification algorithm, morphological methods and logical operations, is designed to precisely obtain the entire leaf edge. This algorithm has an advantage when segmenting complicated leaf images that contain overlapping laminas and have an uneven gray scale in the leaf region itself. Experiments show that this algorithm is both feasible and effective in segmenting jujube leaf images from real-time video systems, and we can obtain clear, smooth, accurate edge images. The algorithm can be used for other kinds of leaf or fruit image segmentation tasks after debugging and improvement.},
  langid = {english},
  keywords = {Adaptive Thresholding,Image processing,Jujube leaf,Mapping Function,Online image,Segmentation algorithms},
  file = {/home/samuelebumbaca/Zotero/storage/SXECZ44H/S0168169913000884.html}
}

@article{wangCurveskeletonExtractionUsing2008,
  title = {Curve-Skeleton Extraction Using Iterative Least Squares Optimization},
  author = {Wang, Yu-Shuen and Lee, Tong-Yee},
  year = {2008},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {14},
  number = {4},
  pages = {926--936},
  publisher = {IEEE},
  urldate = {2024-06-10},
  file = {/home/samuelebumbaca/Zotero/storage/72LXEEW2/OpenURL.html}
}

@article{wangNonDestructiveMeasurementThreeDimensional2020,
  title = {Non-{{Destructive Measurement}} of {{Three-Dimensional Plants Based}} on {{Point Cloud}}},
  author = {Wang, Yawei and Chen, Yifei},
  year = {2020},
  month = apr,
  journal = {Plants},
  volume = {9},
  number = {5},
  pages = {571},
  issn = {2223-7747},
  doi = {10.3390/plants9050571},
  urldate = {2021-12-18},
  abstract = {In agriculture, information about the spatial distribution of plant growth is valuable for applications. Quantitative study of the characteristics of plants plays an important role in the plants' growth and development research, and non-destructive measurement of the height of plants based on machine vision technology is one of the difficulties. We propose a methodology for three-dimensional reconstruction under growing plants by Kinect v2.0 and explored the measure growth parameters based on three-dimensional (3D) point cloud in this paper. The strategy includes three steps---firstly, preprocessing 3D point cloud data, completing the 3D plant registration through point cloud outlier filtering and surface smooth method; secondly, using the locally convex connected patches method to segment the leaves and stem from the plant model; extracting the feature boundary points from the leaf point cloud, and using the contour extraction algorithm to get the feature boundary lines; finally, calculating the length, width of the leaf by Euclidean distance, and the area of the leaf by surface integral method, measuring the height of plant using the vertical distance technology. The results show that the automatic extraction scheme of plant information is effective and the measurement accuracy meets the need of measurement standard. The established 3D plant model is the key to study the whole plant information, which reduces the inaccuracy of occlusion to the description of leaf shape and conducive to the study of the real plant growth status.},
  langid = {english}
}

@article{wangSimplifiedEmpiricalLine2015,
  title = {A {{Simplified Empirical Line Method}} of {{Radiometric Calibration}} for {{Small Unmanned Aircraft Systems-Based Remote Sensing}}},
  author = {Wang, Chuyuan and Myint, Soe W.},
  year = {2015},
  month = may,
  journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  volume = {8},
  number = {5},
  pages = {1876--1885},
  issn = {2151-1535},
  doi = {10.1109/JSTARS.2015.2422716},
  abstract = {The use of small unmanned aircraft systems (sUAS) to acquire very high-resolution multispectral imagery has attracted growing attention recently; however, no systematic, feasible, and convenient radiometric calibration method has been specifically developed for sUAS remote sensing. In this research, we used a modified color infrared (CIR) digital single-lens reflex (DSLR) camera as the sensor and the DJI S800 hexacopter sUAS as the platform to collect imagery. Results show that the relationship between the natural logarithm of measured surface reflectance and image raw, unprocessed digital numbers (DNs) is linear and the y-intercept of the linear equation can be theoretically interpreted as the minimal possible surface reflectance that can be detected by each sensor waveband. The empirical line calibration equation for every single band image can be built using the y-intercept as one data point, and the natural log-transformed measured reflectance and image DNs of a gray calibration target as another point in the coordinate system. Image raw DNs are therefore converted to reflectance using the calibration equation. The Mann-Whitney U test results suggest that the difference between the measured and the predicted reflectance values of 13 tallgrass sampling quadrats is not statistically significant. The method theory developed in this study can be employed for other sUAS-based remote sensing applications.},
  keywords = {Calibration,Cameras,Earth,Empirical line,radiometric calibration,Radiometry,Remote sensing,Satellites,small unmanned aircraft systems (sUAS),Surface waves,very high resolution},
  file = {/home/samuelebumbaca/Zotero/storage/6LT8QAQF/7098353.html}
}

@article{wanRGBDPointCloud2021,
  title = {{{RGB-D Point Cloud Registration Based}} on {{Salient Object Detection}}},
  author = {Wan, Teng and Du, Shaoyi and Cui, Wenting and Yao, Runzhao and Ge, Yuyan and Li, Ce and Gao, Yue and Zheng, Nanning},
  year = {2021},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  pages = {1--13},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2021.3053274},
  urldate = {2021-12-19}
}

@article{wen3DPhytomerbasedGeometric2021,
  title = {{{3D}} Phytomer-Based Geometric Modelling Method for Plants---the Case of Maize},
  author = {Wen, Weiliang and Wang, Yongjian and Wu, Sheng and Liu, Kai and Gu, Shenghao and Guo, Xinyu},
  editor = {Buckley, Tom},
  year = {2021},
  month = oct,
  journal = {AoB PLANTS},
  volume = {13},
  number = {5},
  pages = {plab055},
  issn = {2041-2851},
  doi = {10.1093/aobpla/plab055},
  urldate = {2021-12-18},
  abstract = {Abstract              Geometric plant modelling is crucial in in silico plants. Existing geometric modelling methods have focused on the topological structure and basic organ profiles, simplifying the morphological features. However, the models cannot effectively differentiate cultivars, limiting FSPM application in crop breeding and management. This study proposes a 3D phytomer-based geometric modelling method with maize (Zea Mays) as the representative plant. Specifically, conversion methods between skeleton and mesh models of 3D phytomer are specified. This study describes the geometric modelling of maize shoots and populations by assembling 3D phytomers. Results show that the method can quickly and efficiently construct 3D models of maize plants and populations, with the ability to show morphological, structural and functional differences among four representative cultivars. The method takes into account both the geometric modelling efficiency and 3D detail features to achieve automatic operation of geometric modelling through the standardized description of 3D phytomers. Therefore, this study provides a theoretical and technical basis for the research and application of in silico plants.},
  langid = {english}
}

@article{wendelIlluminationCompensationGround2017,
  title = {Illumination Compensation in Ground Based Hyperspectral Imaging},
  author = {Wendel, Alexander and Underwood, James},
  year = {2017},
  month = jul,
  journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
  volume = {129},
  pages = {162--178},
  issn = {0924-2716},
  doi = {10.1016/j.isprsjprs.2017.04.010},
  urldate = {2023-01-13},
  abstract = {Hyperspectral imaging has emerged as an important tool for analysing vegetation data in agricultural applications. Recently, low altitude and ground based hyperspectral imaging solutions have come to the fore, providing very high resolution data for mapping and studying large areas of crops in detail. However, these platforms introduce a unique set of challenges that need to be overcome to ensure consistent, accurate and timely acquisition of data. One particular problem is dealing with changes in environmental illumination while operating with natural light under cloud cover, which can have considerable effects on spectral shape. In the past this has been commonly achieved by imaging known reference targets at the time of data acquisition, direct measurement of irradiance, or atmospheric modelling. While capturing a reference panel continuously or very frequently allows accurate compensation for illumination changes, this is often not practical with ground based platforms, and impossible in aerial applications. This paper examines the use of an autonomous unmanned ground vehicle (UGV) to gather high resolution hyperspectral imaging data of crops under natural illumination. A process of illumination compensation is performed to extract the inherent reflectance properties of the crops, despite variable illumination. This work adapts a previously developed subspace model approach to reflectance and illumination recovery. Though tested on a ground vehicle in this paper, it is applicable to low altitude unmanned aerial hyperspectral imagery also. The method uses occasional observations of reference panel training data from within the same or other datasets, which enables a practical field protocol that minimises in-field manual labour. This paper tests the new approach, comparing it against traditional methods. Several illumination compensation protocols for high volume ground based data collection are presented based on the results. The findings in this paper are applicable not only to robotics or agricultural applications, but most very low altitude or ground based hyperspectral sensors operating with natural light.},
  langid = {english},
  keywords = {Atmospheric correction,Ground based,Hyperspectral,Illumination compensation,Reflectance retrieval,Robotics}
}

@article{westPotentialOpticalCanopy2003,
  title = {The {{Potential}} of {{Optical Canopy Measurement}} for {{Targeted Control}} of {{Field Crop Diseases}}},
  author = {West, Jon and Bravo, Cedric and Oberti, Roberto and Lemaire, Dimitri and Moshou, Dimitrios and McCartney, H},
  year = {2003},
  month = feb,
  journal = {Annual review of phytopathology},
  volume = {41},
  pages = {593--614},
  doi = {10.1146/annurev.phyto.41.121702.103726},
  abstract = {There is increasing pressure to reduce the use of pesticides in modern crop production to decrease the environmental impact of current practice and to lower production costs. It is therefore imperative that sprays are only applied when and where needed. Since diseases in fields are frequently patchy, sprays may be applied unnecessarily to disease-free areas. Disease control could be more efficient if disease patches within fields could be identified and spray applied only to the infected areas. Recent developments in optical sensor technology have the potential to enable direct detection of foliar disease under field conditions. This review assesses recent developments in the use of optical methods for detecting foliar disease, evaluates the likely benefits of spatially selective disease control in field crops, and discusses practicalities and limitations of using optical disease detection systems for crop protection in precision pest management.}
}

@article{wuDetectionSegmentationMultiple2009,
  title = {Detection and {{Segmentation}} of {{Multiple}}, {{Partially Occluded Objects}} by {{Grouping}}, {{Merging}}, {{Assigning Part Detection Responses}}},
  author = {Wu, Bo and Nevatia, Ram},
  year = {2009},
  month = apr,
  journal = {International Journal of Computer Vision},
  volume = {82},
  number = {2},
  pages = {185--204},
  issn = {1573-1405},
  doi = {10.1007/s11263-008-0194-9},
  urldate = {2023-01-13},
  abstract = {We propose a method that detects and segments multiple, partially occluded objects in images. A part hierarchy is defined for the object class. Both the segmentation and detection tasks are formulated as binary classification problem. A whole-object segmentor and several part detectors are learned by boosting local shape feature based weak classifiers. Given a new image, the part detectors are applied to obtain a number of part responses. All the edge pixels in the image that positively contribute to the part responses are extracted. A joint likelihood of multiple objects is defined based on the part detection responses and the object edges. Computation of the joint likelihood includes an inter-object occlusion reasoning that is based on the object silhouettes extracted with the whole-object segmentor. By maximizing the joint likelihood, part detection responses are grouped, merged, and assigned to multiple object hypotheses. The proposed approach is demonstrated with the class of pedestrians. The experimental results show that our method outperforms the previous ones.},
  langid = {english},
  keywords = {Object detection,Object segmentation}
}

@article{wuResearchMaizeMultispectral2015,
  title = {{[Research on maize multispectral image accurate segmentation and chlorophyll index estimation]}},
  author = {Wu, Qian and Sun, Hong and Li, Min-zan and Song, Yuan-yuan and Zhang, Yan-e},
  year = {2015},
  month = jan,
  journal = {Guang Pu Xue Yu Guang Pu Fen Xi = Guang Pu},
  volume = {35},
  number = {1},
  pages = {178--183},
  issn = {1000-0593},
  abstract = {In order to rapidly acquire maize growing information in the field, a non-destructive method of maize chlorophyll content index measurement was conducted based on multi-spectral imaging technique and imaging processing technology. The experiment was conducted at Yangling in Shaanxi province of China and the crop was Zheng-dan 958 planted in about 1 000 m X 600 m experiment field. Firstly, a 2-CCD multi-spectral image monitoring system was available to acquire the canopy images. The system was based on a dichroic prism, allowing precise separation of the visible (Blue (B), Green (G), Red (R): 400-700 nm) and near-infrared (NIR, 760-1 000 nm) band. The multispectral images were output as RGB and NIR images via the system vertically fixed to the ground with vertical distance of 2 m and angular field of 50{$^\circ$}. SPAD index of each sample was'measured synchronously to show the chlorophyll content index. Secondly, after the image smoothing using adaptive smooth filtering algorithm, the NIR maize image was selected to segment the maize leaves from background, because there was a big difference showed in gray histogram between plant and soil background. The NIR image segmentation algorithm was conducted following steps of preliminary and accuracy segmentation: (1) The results of OTSU image segmentation method and the variable threshold algorithm were discussed. It was revealed that the latter was better one in corn plant and weed segmentation. As a result, the variable threshold algorithm based on local statistics was selected for the preliminary image segmentation. The expansion and corrosion were used to optimize the segmented image. (2) The region labeling algorithm was used to segment corn plants from soil and weed background with an accuracy of 95. 59 \%. And then, the multi-spectral image of maize canopy was accurately segmented in R, G and B band separately. Thirdly, the image parameters were abstracted based on the segmented visible and NIR images. The average gray value of each channel was calculated including red (ARed), green (AGreen), blue (ABlue), and near-infrared (ANIR). Meanwhile, the vegetation indices (NDVI (normalized difference vegetation index), RVI (ratio vegetation index); and NDGI(normalized difference green index)) which are widely used in remote sensing were applied. The chlorophyll index detecting model based on partial least squares regression method (PLSR) was built with detecting R2=0. 5960 and predicting R2= 0. 568 5. It was feasible to diagnose chlorophyll index of maize based on multi-spectral images.},
  langid = {chi},
  pmid = {25993844},
  keywords = {Algorithms,Chlorophyll,Least-Squares Analysis,Models Theoretical,Plant Leaves,Regression Analysis,Soil,Spectrum Analysis,Zea mays}
}

@book{wyattRadiometricCalibrationTheory2012,
  title = {Radiometric {{Calibration}}: {{Theory}} and {{Methods}}},
  shorttitle = {Radiometric {{Calibration}}},
  author = {Wyatt, Clair},
  year = {2012},
  month = dec,
  publisher = {Elsevier},
  abstract = {Approx.214 pages},
  googlebooks = {MDvdvecbTLoC},
  isbn = {978-0-323-16009-4},
  langid = {english},
  keywords = {Technology & Engineering / Sensors}
}

@article{yangAutomaticSkeletonExtraction2020,
  title = {Towards Automatic Skeleton Extraction with Skeleton Grafting},
  author = {Yang, Cong and Indurkhya, Bipin and See, John and Grzegorzek, Marcin},
  year = {2020},
  journal = {IEEE transactions on visualization and computer graphics},
  volume = {27},
  number = {12},
  pages = {4520--4532},
  publisher = {IEEE},
  urldate = {2024-06-10},
  file = {/home/samuelebumbaca/Zotero/storage/588PTXZL/OpenURL.html}
}

@inproceedings{yangDeepSpectralClustering2019,
  title = {Deep {{Spectral Clustering Using Dual Autoencoder Network}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Yang, Xu and Deng, Cheng and Zheng, Feng and Yan, Junchi and Liu, Wei},
  year = {2019},
  pages = {4066--4075},
  urldate = {2025-01-13}
}

@article{yanikogluAutomaticPlantIdentification2014,
  title = {Automatic Plant Identification from Photographs},
  author = {Yanikoglu, B. and Aptoula, E. and Tirkaz, C.},
  year = {2014},
  month = aug,
  journal = {Machine Vision and Applications},
  volume = {25},
  number = {6},
  pages = {1369--1383},
  issn = {1432-1769},
  doi = {10.1007/s00138-014-0612-7},
  urldate = {2023-01-13},
  abstract = {We present a plant identification system for automatically identifying the plant in a given image. In addition to common difficulties faced in object recognition, such as light, pose and orientation variations, there are further difficulties particular to this problem, such as changing leaf shapes according to plant age and changes in the overall shape due to leaf composition. Our system uses a rich variety of shape, texture and color features, some being specific to the plant domain. The system has achieved the best overall score in the ImageCLEF'12 plant identification campaign in both the automatic and human-assisted categories. We report the results of this system on the publicly available ImageCLEF'12 plant dataset, as well as the effectiveness of individual features. The results show 61 and 81~\% accuracies in classifying the 126 different plant species in the top-1 and top-5 choices.},
  langid = {english},
  keywords = {Color image segmentation,Leaf shape,Mathematical morphology,Plant identification}
}

@article{yenNewCriterionAutomatic1995,
  title = {A New Criterion for Automatic Multilevel Thresholding},
  author = {Yen, Jui-Cheng and Chang, Fu-Juay and Chang, Shyang},
  year = {1995},
  month = mar,
  journal = {IEEE Transactions on Image Processing},
  volume = {4},
  number = {3},
  pages = {370--378},
  issn = {1941-0042},
  doi = {10.1109/83.366472},
  abstract = {A new criterion for multilevel thresholding is proposed. The criterion is based on the consideration of two factors. The first one is the discrepancy between the thresholded and original images and the second one is the number of bits required to represent the thresholded image. Based on a new maximum correlation criterion for bilevel thresholding, the discrepancy is defined and then a cost function that takes both factors into account is proposed for multilevel thresholding. By minimizing the cost function, the classification number that the gray-levels should be classified and the threshold values can be determined automatically. In addition, the cost function is proven to possess a unique minimum under very mild conditions. Computational analyses indicate that the number of required mathematical operations in the implementation of our algorithm is much less than that of maximum entropy criterion. Finally, simulation results are included to demonstrate their effectiveness.{$<>$}},
  keywords = {Algorithm design and analysis,Analytical models,Application software,Computational complexity,Computational modeling,Computer industry,Cost function,Entropy,Image processing,Target recognition},
  file = {/home/samuelebumbaca/Zotero/storage/3796G8FE/366472.html}
}

@article{yinMultileafTrackingFluorescence2014,
  title = {Multi-Leaf Tracking from Fluorescence Plant Videos},
  author = {Yin, Xi and Liu, Xiaoming and Chen, Jin and Kramer, David M.},
  year = {2014},
  month = jan,
  journal = {2014 IEEE International Conference on Image Processing, ICIP 2014},
  series = {2014 {{IEEE International Conference}} on {{Image Processing}}, {{ICIP}} 2014},
  pages = {408--412},
  doi = {10.1109/ICIP.2014.7025081},
  urldate = {2023-01-13},
  abstract = {Driven by the plant phenotyping application, this paper proposes a new leaf tracking framework to jointly segment, align and track multiple leaves from fluorescence plant videos. Our framework consists of two steps. First, leaf alignment is applied to one video frame to generate a collection of leaf candidates. Second, we define a set of transformation parameters operated on the leaf candidates in order to optimize the alignment in the subsequent video frame according to an objective function. Gradient descent is employed to solve this optimization problem. Experimental results show that the proposed multi-leaf tracking algorithm is superior to the image-based leaf alignment method in terms of three quantitative metrics.},
  keywords = {alignment,Leaf tracking,multi-leaf}
}

@inproceedings{yogenderRoleGroundControl2020,
  title = {Role of {{Ground Control Points}} ({{GCPs}}) in {{Integration}} of {{Terrestrial Laser Scanner}} ({{TLS}}) and {{Close-range Photogrammetry}} ({{CRP}})},
  booktitle = {Applications of {{Geomatics}} in {{Civil Engineering}}},
  author = {{Yogender} and Raghavendra, S. and Kushwaha, S. K. P.},
  editor = {Ghosh, Jayanta Kumar and {da Silva}, Irineu},
  year = {2020},
  series = {Lecture {{Notes}} in {{Civil Engineering}}},
  pages = {531--537},
  publisher = {Springer},
  address = {Singapore},
  doi = {10.1007/978-981-13-7067-0_42},
  abstract = {The need for GCPs is increasingly more important with the increase in higher accuracy requirements and increase in user expectations. GCPs (Ground control points) are necessary for orientation and placement of photographs and 3D models in the spatial coordinate system, and they play a key role in co-registration of two point clouds. This paper deals with the assessment of the role of Ground Control Points in Co-registration of CRP and TLS point clouds by point-pair selection methodology and Automatic co-registration algorithm. In this work, the point cloud is generated from multiple overlapping sequences of images using Close-range Photogrammetry (CRP) and Terrestrial Laser Scanning (TLS) for a building over the planar surface. GCPs were collected by the total station to register the TLS and CRP point cloud. Overlapping photographs are processed in Agisoft PhotoScan software. TLS point cloud was generated from Riegl VZ 400 and GCPs were used to geo-reference it in Cloud Compare software. Various subsets of both point clouds are co-registered by the point-pair co-registration method and by Automatic point detection fine co-registration. Two subsets for each of CRP and TLS point cloud are considered in such a way that one is having some common overlap and other is having no common feature. GCPs registered point clouds integrate precisely as compared to that of the non-registered point cloud. The RMS error achieved in case of geo-referenced point cloud co-registration was 0.0091645433 m and in non-geo-referenced co-registration was found to be 0.03327466 m. In this study, it was also found that error is significantly higher in Automatic point detection method as compared to that of conventional point-pair selection co-registration. From this study, it is observed that higher accuracy of co-registration is achieved in the case of geo-referenced models by point-pair selection method. So, GCPs are the prerequisite for the effective and precise co-registration of 3D point clouds.},
  isbn = {978-981-13-7067-0},
  langid = {english},
  keywords = {Close-range photogrammetry,Co-registration,Geo-referencing,Ground control points,Point cloud,Terrestrial laser scanning}
}

@article{yonghuailiuAutomaticRangeImage2010,
  title = {Automatic {{Range Image Registration}} in the {{Markov Chain}}},
  author = {{Yonghuai Liu}},
  year = {2010},
  month = jan,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {32},
  number = {1},
  pages = {12--29},
  issn = {0162-8828},
  doi = {10.1109/TPAMI.2008.280},
  urldate = {2021-12-19}
}

@article{yonghuailiuPenalizingClosestPoint2011,
  title = {Penalizing {{Closest Point Sharing}} for {{Automatic Free Form Shape Registration}}},
  author = {{Yonghuai Liu}},
  year = {2011},
  month = may,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {33},
  number = {5},
  pages = {1058--1064},
  issn = {0162-8828},
  doi = {10.1109/TPAMI.2010.207},
  urldate = {2021-12-19}
}

@article{yuImageAnalysisPipeline2017,
  title = {An Image Analysis Pipeline for Automated Classification of Imaging Light Conditions and for Quantification of Wheat Canopy Cover Time Series in Field Phenotyping},
  author = {Yu, Kang and Kirchgessner, Norbert and Grieder, Christoph and Walter, Achim and Hund, Andreas},
  year = {2017},
  month = mar,
  journal = {Plant Methods},
  volume = {13},
  number = {1},
  pages = {15},
  issn = {1746-4811},
  doi = {10.1186/s13007-017-0168-4},
  urldate = {2023-01-13},
  abstract = {Robust segmentation of canopy cover (CC) from large amounts of images taken under different illumination/light conditions in the field is essential for high throughput field phenotyping (HTFP). We attempted to address this challenge by evaluating different vegetation indices and segmentation methods for analyzing images taken at varying illuminations throughout the early growth phase of wheat in the field. 40,000 images taken on 350 wheat genotypes in two consecutive years were assessed for this purpose.},
  langid = {english},
  keywords = {Canopy cover,Color vegetation index,High throughput field phenotyping,Image analysis,Image segmentation,Light contrast,Machine learning}
}

@inproceedings{yusongSurfaceModellingPlants2007,
  title = {Surface {{Modelling}} of {{Plants}} from {{Stereo Images}}},
  booktitle = {Sixth {{International Conference}} on 3-{{D Digital Imaging}} and {{Modeling}} ({{3DIM}} 2007)},
  author = {{Yu Song} and Wilson, R. and Edmondson, R. and Parsons, N.},
  year = {2007},
  month = aug,
  pages = {312--319},
  publisher = {IEEE},
  address = {Montreal, QC},
  doi = {10.1109/3DIM.2007.55},
  urldate = {2023-01-13},
  abstract = {Plants are characterised by a range of complex and variable attributes, and measuring these attributes accurately and reliably is a major challenge for the industry. In this paper, we investigate creating a surface model of plant from images taken by a stereo pair of cameras. The proposed modelling architecture comprises a fast stereo algorithm to estimate depths in the scene and a model of the scene based on visual appearance and 3D geometry measurements. Our stereo algorithm employs a coarse-fine strategy for disparity estimation. We develop a weighting method and use Kalman filter to refine estimations across scales. A selforganising map is applied to reconstruct a surface from these sample points created by the stereo algorithm. We compare and evaluate our stereo results against other popular stereo algorithms, and also demonstrate that the proposed surface model can be used to extract useful plant features that can be of importance in plant management and assessing quality for marketing.},
  isbn = {978-0-7695-2939-4},
  langid = {english}
}

@article{zackAutomaticMeasurementSister1977,
  title = {Automatic Measurement of Sister Chromatid Exchange Frequency.},
  author = {Zack, G W and Rogers, W E and Latt, S A},
  year = {1977},
  month = jul,
  journal = {Journal of Histochemistry \& Cytochemistry},
  volume = {25},
  number = {7},
  pages = {741--753},
  publisher = {Journal of Histochemistry \& Cytochemistry},
  issn = {0022-1554},
  doi = {10.1177/25.7.70454},
  urldate = {2023-01-25},
  abstract = {An automatic system for detecting and counting sister chromatid exchanges in human chromosomes has been developed. Metaphase chromosomes from lymphocytes which had incorporated 5-bromodeoxyuridine for two replication cycles were treated with the dye 33258 Hoechst and photodegraded so that the sister chromatids exhibited differential Giemsa staining. A computer-controlled television-microscope system was used to acquire digitized metaphase spread images by direct scanning of microscope slides. Individual objects in the images were identified by a thresholding procedure. The probability that each object was a single, separate chromosome was estimated from size and shape measurements. An analysis of the spatial relationships of the dark-chromatid regions of each object yielded a set of possible exchange locations and estimated probabilities that such locations corresponded to sister chromatid exchanges. A normalized estimate of the sister chromatid exchange frequency was obtained by summing the joint probabilities that a location contained an exchange within a single, separate chromosome over the set of chromosomes from one or more cells and dividing by the expected value of the total chromosome area analyzed. Comparison with manual scoring of exchanges showed satisfactory agreement up to levels of approximately 30 sister chromatid exchanges/cell, or slightly more than twice control levels. The processing time for this automated sister chromatid exchange detection system was comparable to that of manual scoring.},
  langid = {english}
}

@article{zaka-ud-dinClassificationDiseaseTomato2018,
  title = {Classification of {{Disease}} in {{Tomato Plants}}' {{Leaf Using Image Segmentation}} and {{SVM}}},
  author = {{Zaka-Ud-Din}, Muhammad and Adnan, Syed and Ahmad, Wakeel and Aziz, Sumair and Rashid, Junaid and Ismail, Waqar and Iqbal, Javed},
  year = {2018},
  month = aug,
  abstract = {Plant Disease recognition and classification play vital role in agriculture field. Product quality, quantity or productivity of plants is harshly affected by slight negligence in this domain. Huge amount of human work load for crops intensive care in vast farms can be reduced by automatic system accomplished of perceiving and classifying plant illnesses at early phases. This paper presents image processing framework for plant disease identification and classification. Our proposed workflow consists of three stages that are images segmentation, feature extraction and classification. For segmentation we use multithresholding then that of other common segmentation techniques. We used GLCM for feature extraction and Support Vector Machines for classification. We use GLCM texture feature as it gives pixel level information and SVM due to its robustness and optimality. Experiments were conducted on Tomato leaf dataset comprising of 4 different classes. Proposed framework achieved 98.3\% overall accuracy with 10- fold cross validation.}
}

@article{zhangDetectingPowderyMildew2012,
  title = {Detecting Powdery Mildew of Winter Wheat Using Leaf Level Hyperspectral Measurements},
  author = {Zhang, Jing-Cheng and Pu, Rui-liang and Wang, Ji-hua and Huang, Wen-jiang and Yuan, Lin and Luo, Ju-hua},
  year = {2012},
  month = jul,
  journal = {Computers and Electronics in Agriculture},
  volume = {85},
  pages = {13--23},
  issn = {0168-1699},
  doi = {10.1016/j.compag.2012.03.006},
  urldate = {2023-01-13},
  abstract = {Powdery mildew (Blumeria graminis) is one of the most destructive diseases, which has a significant impact on the production of winter wheat. Detecting powdery mildew via spectral measurement and analysis is a possible alternative to traditional methods in obtaining the spatial distribution information of the disease. In this study, hyperspectral reflectances of normal and powdery mildew infected leaves were measured with a spectroradiometer in a laboratory. A total of 32 spectral features (SFs) were extracted from the lab spectra and examined through a correlation analysis and an independent t-test associated with the disease severity. Two regression models: multivariate linear regression (MLR) and partial least square regression (PLSR) were developed for estimating the disease severity of powdery mildew. In addition, the fisher linear discriminant analysis (FLDA) was also adopted for discriminating the three healthy levels (normal, slightly-damaged and heavily-damaged) of powdery mildew with the extracted SFs. The experimental results indicated that (1) most SFs showed a clear response to powdery mildew; (2) for estimating the disease severity with SFs, the PLSR model outperformed the MLR model, with a relative root mean square error (RMSE) of 0.23 and a coefficient of determination (R2) of 0.80 when using seven components; (3) for discrimination analysis, a higher accuracy was produced for the heavily-damaged leaves by FLDA with both producer's and user's accuracies over 90\%; (4) the selected broad-band SFs revealed a great potential in estimating the disease severity and discriminating severity levels. The results imply that multispectral remote sensing is a cost effective method in the detection and mapping of powdery mildew.},
  langid = {english},
  keywords = {Cross validation,Fisher linear discriminate analysis (FLDA),Partial least square regression (PLSR),Powdery mildew,Spectral feature}
}

@article{zhangHighThroughputPhenotypingSeed2018,
  title = {High-{{Throughput Phenotyping}} of {{Seed}}/{{Seedling Evaluation Using Digital Image Analysis}}},
  author = {Zhang, Chongyuan and Si, Yongsheng and Lamkey, Jacob and Boydston, Rick and {Garland-Campbell}, Kimberly and Sankaran, Sindhuja},
  year = {2018},
  month = may,
  journal = {Agronomy},
  volume = {8},
  number = {5},
  pages = {63},
  issn = {2073-4395},
  doi = {10.3390/agronomy8050063},
  urldate = {2022-01-28},
  langid = {english}
}

@article{zhangPlantDiseaseLeaf2019,
  title = {Plant Disease Leaf Image Segmentation Based on Superpixel Clustering and {{EM}} Algorithm},
  author = {Zhang, Shanwen and You, Zhuhong and Wu, Xiaowei},
  year = {2019},
  month = feb,
  journal = {Neural Computing and Applications},
  volume = {31},
  number = {2},
  pages = {1225--1232},
  issn = {1433-3058},
  doi = {10.1007/s00521-017-3067-8},
  urldate = {2023-09-11},
  abstract = {Plant disease leaf image segmentation plays an important role in the plant disease detection through leaf symptoms. A novel segmentation method of plant disease leaf image is proposed based on a hybrid clustering. The whole color leaf image is firstly divided into a number of compact and nearly uniform superpixels by superpixel clustering, which can provide useful clustering cues to guide image segmentation to accelerate the convergence speed of the expectation maximization (EM) algorithm, and then, the lesion pixels are quickly and accurately segmented from each superpixel by EM algorithm. The experimental results and the comparison results with similar approaches demonstrate that the proposed method is effective and has high practical value for plant disease detection.},
  langid = {english},
  keywords = {EM algorithm,Plant disease detection,Plant disease leaf image segmentation,Superpixel clustering}
}

@article{zhangRobust3DPoint2018,
  title = {Robust {{3D}} Point Cloud Registration Based on Bidirectional {{Maximum Correntropy Criterion}}},
  author = {Zhang, Xuetao and Jian, Libo and Xu, Meifeng},
  editor = {Yang, You},
  year = {2018},
  month = may,
  journal = {PLOS ONE},
  volume = {13},
  number = {5},
  pages = {e0197542},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0197542},
  urldate = {2021-12-19},
  langid = {english}
}

@misc{zhongJianZhongDevVariationalAutoencoderPytorch2024,
  title = {{{JianZhongDev}}/{{VariationalAutoencoderPytorch}}},
  author = {Zhong, Jian},
  year = {2024},
  month = dec,
  urldate = {2025-01-05},
  abstract = {Quick guide on building and training variational autoencoder using Pytorch.},
  copyright = {GPL-3.0}
}

@article{zhouAccurateRobustNonrigid2018,
  title = {Accurate and {{Robust Non-rigid Point Set Registration}} Using {{Student}}'s-t {{Mixture Model}} with {{Prior Probability Modeling}}},
  author = {Zhou, Zhiyong and Tu, Jianfei and Geng, Chen and Hu, Jisu and Tong, Baotong and Ji, Jiansong and Dai, Yakang},
  year = {2018},
  month = dec,
  journal = {Scientific Reports},
  volume = {8},
  number = {1},
  pages = {8742},
  issn = {2045-2322},
  doi = {10.1038/s41598-018-26288-6},
  urldate = {2021-12-19},
  langid = {english}
}

@incollection{zhouAutomaticSegmentationMultiple2020,
  title = {Automatic {{Segmentation}} of {{Multiple Organs}} on {{3D CT Images}} by {{Using Deep Learning Approaches}}},
  booktitle = {Deep {{Learning}} in {{Medical Image Analysis}}},
  author = {Zhou, Xiangrong},
  editor = {Lee, Gobert and Fujita, Hiroshi},
  year = {2020},
  volume = {1213},
  pages = {135--147},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-33128-3_9},
  urldate = {2021-12-18},
  isbn = {978-3-030-33127-6 978-3-030-33128-3},
  langid = {english}
}

@article{zhouComprehensiveSurveyDeep2024,
  title = {A {{Comprehensive Survey}} on {{Deep Clustering}}: {{Taxonomy}}, {{Challenges}}, and {{Future Directions}}},
  shorttitle = {A {{Comprehensive Survey}} on {{Deep Clustering}}},
  author = {Zhou, Sheng and Xu, Hongjia and Zheng, Zhuonan and Chen, Jiawei and Li, Zhao and Bu, Jiajun and Wu, Jia and Wang, Xin and Zhu, Wenwu and Ester, Martin},
  year = {2024},
  month = nov,
  journal = {ACM Comput. Surv.},
  volume = {57},
  number = {3},
  pages = {69:1--69:38},
  issn = {0360-0300},
  doi = {10.1145/3689036},
  urldate = {2025-01-13},
  abstract = {Clustering is a fundamental machine learning task, which aim at assigning instances into groups so that similar samples belong to the same cluster while dissimilar samples belong to different clusters. Shallow clustering methods usually assume that data are collected and expressed as feature vectors within which clustering is performed. However, clustering high-dimensional data, such as images, texts, videos, and graphs, poses significant challenges for clustering tasks, such as indiscriminate representation and intricate relationships among instances. Over the past decades, deep learning has achieved remarkable success in effective representation learning and modeling complex relationships. Motivated by these advancements, Deep Clustering seeks to improve clustering outcomes through deep learning techniques, garnering considerable interest from both academia and industry. Despite many contributions to this vibrant area of research, the lack of systematic analysis and a comprehensive taxonomy has hindered progress in this field. In this survey, we first explore how deep learning can be integrated into deep clustering and identify two fundamental components: the representation learning module and the clustering module. Then, we summarize and analyze the representative design of these two modules. Furthermore, we introduce a novel taxonomy of deep clustering based on how these two modules interact, specifically through multistage, generative, iterative, and simultaneous approaches. In addition, we present well-known benchmark datasets, evaluation metrics, and open-source tools to clearly demonstrate different experimental approaches. Finally, we examine the practical applications of deep clustering and propose challenging areas for future research.}
}

@article{zhouEvaluatingGeometricMeasurement2018,
  title = {Evaluating {{Geometric Measurement Accuracy Based}} on {{3D Reconstruction}} of {{Automated Imagery}} in a {{Greenhouse}}},
  author = {Zhou, Jing and Fu, Xiuqing and Schumacher, Leon and Zhou, Jianfeng},
  year = {2018},
  month = jul,
  journal = {Sensors},
  volume = {18},
  number = {7},
  pages = {2270},
  doi = {10.3390/s18072270},
  urldate = {2021-12-22},
  abstract = {Geometric dimensions of plants are significant parameters for showing plant dynamic responses to environmental variations. An image-based high-throughput phenotyping platform was developed to automatically measure geometric dimensions of plants in a greenhouse. The goal of this paper was to evaluate the accuracy in geometric measurement using the Structure from Motion (SfM) method from images acquired using the automated image-based platform. Images of nine artificial objects of different shapes were taken under 17 combinations of three different overlaps in x and y directions, respectively, and two different spatial resolutions (SRs) with three replicates. Dimensions in x, y and z of these objects were measured from 3D models reconstructed using the SfM method to evaluate the geometric accuracy. A metric power of unit (POU) was proposed to combine the effects of image overlap and SR. Results showed that measurement error of dimension in z is the least affected by overlap and SR among the three dimensions and measurement error of dimensions in x and y increased following a power function with the decrease of POU (R2 = 0.78 and 0.88 for x and y respectively). POUs from 150 to 300 are a preferred range to obtain reasonable accuracy and efficiency for the developed image-based high-throughput phenotyping system. As a study case, the developed system was used to measure the height of 44 plants using an optimal POU in greenhouse environment. The results showed a good agreement (R2 = 92\% and Root Mean Square Error = 9.4 mm) between the manual and automated method.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {3D model reconstruction,geometric accuracy,high-throughput phenotyping,processing efficiency,structure from motion}
}

@article{zhouHIDESComputerBasedHerbicide2005,
  title = {{{HIDES}}: {{A Computer-Based Herbicide Injury Diagnostic Expert System}}},
  shorttitle = {{{HIDES}}},
  author = {Zhou, Jingkai and Messersmith, Calvin G. and Harrington, Janet D.},
  year = {2005},
  journal = {Weed Technology},
  volume = {19},
  number = {2},
  eprint = {3989738},
  eprinttype = {jstor},
  pages = {486--491},
  publisher = {[Cambridge University Press, Weed Science Society of America]},
  issn = {0890-037X},
  urldate = {2023-08-18},
  abstract = {Diagnosis of herbicide injury can be complex because of the large number and interaction of factors leading to herbicide injury. Computer-based expert systems have great potential to assist users, particularly nonexperts, in accurate diagnosis of herbicide injury. Rule-based and case-based reasoning are the most widely used forms of expert systems, and each system has strengths and limitations. Approaches that integrate rule-based and case-based reasoning may augment the positive aspects of the two reasoning methods and simultaneously minimize their negative aspects. The Herbicide Injury Diagnostic Expert System (HIDES) integrates rule-based and case-based reasoning and uses field-specific information, injury symptoms, herbicide use history, and herbicide information to diagnose crop injury from herbicides. The HIDES program uses a set of rules to identify suspect herbicide(s) that is the candidate for causing the observed injury and possible sources of the suspect herbicide(s). Case-based reasoning is used to propose a probable cause of injury by making an analogy to previously solved cases. A four-step procedure is followed when using HIDES: information collection, suspect herbicide identification, suspect herbicide source determination, injury reason suggestion, and knowledge accumulation.}
}

@article{zhouRGBDSalientObject2021,
  title = {{{RGB-D}} Salient Object Detection: {{A}} Survey},
  shorttitle = {{{RGB-D}} Salient Object Detection},
  author = {Zhou, Tao and Fan, Deng-Ping and Cheng, Ming-Ming and Shen, Jianbing and Shao, Ling},
  year = {2021},
  month = mar,
  journal = {Computational Visual Media},
  volume = {7},
  number = {1},
  pages = {37--69},
  issn = {2096-0433, 2096-0662},
  doi = {10.1007/s41095-020-0199-z},
  urldate = {2021-12-19},
  abstract = {Abstract                              Salient object detection, which simulates human visual perception in locating the most significant object(s) in a scene, has been widely applied to various computer vision tasks. Now, the advent of depth sensors means that depth maps can easily be captured; this additional spatial information can boost the performance of salient object detection. Although various RGB-D based salient object detection models with promising performance have been proposed over the past several years, an in-depth understanding of these models and the challenges in this field remains lacking. In this paper, we provide a comprehensive survey of RGB-D based salient object detection models from various perspectives, and review related benchmark datasets in detail. Further, as light fields can also provide depth maps, we review salient object detection models and popular benchmark datasets from this domain too. Moreover, to investigate the ability of existing models to detect salient objects, we have carried out a comprehensive attribute-based evaluation of several representative RGB-D based salient object detection models. Finally, we discuss several challenges and open directions of RGB-D based salient object detection for future research. All collected models, benchmark datasets, datasets constructed for attribute-based evaluation, and related code are publicly available at                https://github.com/taozh2017/RGBD-SODsurvey                .},
  langid = {english}
}

@article{zhuRegistrationMultiViewPoint2020,
  title = {Registration of {{Multi-View Point Sets Under}} the {{Perspective}} of {{Expectation-Maximization}}},
  author = {Zhu, Jihua and Guo, Rui and Li, Zhongyu and Zhang, Jing and Pang, Shanmin},
  year = {2020},
  journal = {IEEE Transactions on Image Processing},
  volume = {29},
  pages = {9176--9189},
  issn = {1057-7149, 1941-0042},
  doi = {10.1109/TIP.2020.3024096},
  urldate = {2021-12-19}
}

@article{zhuReviewPointSet2019,
  title = {A {{Review}} of {{Point Set Registration}}: {{From Pairwise Registration}} to {{Groupwise Registration}}},
  shorttitle = {A {{Review}} of {{Point Set Registration}}},
  author = {Zhu, Hao and Guo, Bin and Zou, Ke and Li, Yongfu and Yuen, Ka-Veng and Mihaylova, Lyudmila and Leung, Henry},
  year = {2019},
  month = mar,
  journal = {Sensors},
  volume = {19},
  number = {5},
  pages = {1191},
  issn = {1424-8220},
  doi = {10.3390/s19051191},
  urldate = {2021-12-19},
  abstract = {This paper presents a comprehensive literature review on point set registration. The state-of-the-art modeling methods and algorithms for point set registration are discussed and summarized. Special attention is paid to methods for pairwise registration and groupwise registration. Some of the most prominent representative methods are selected to conduct qualitative and quantitative experiments. From the experiments we have conducted on 2D and 3D data, CPD-GL pairwise registration algorithm and JRMPC groupwise registration algorithm seem to outperform their rivals both in accuracy and computational complexity. Furthermore, future research directions and avenues in the area are identified.},
  langid = {english}
}

@article{ziamtsovMachineLearningApproaches2019,
  title = {Machine {{Learning Approaches}} to {{Improve Three Basic Plant Phenotyping Tasks Using Three-Dimensional Point Clouds}}},
  author = {Ziamtsov, Illia and Navlakha, Saket},
  year = {2019},
  month = dec,
  journal = {Plant Physiology},
  volume = {181},
  number = {4},
  pages = {1425--1440},
  issn = {0032-0889, 1532-2548},
  doi = {10.1104/pp.19.00524},
  urldate = {2021-12-18},
  langid = {english}
}

@article{ziamtsovPlant3DP3D2020,
  title = {Plant {{3D}} ({{P3D}}): A Plant Phenotyping Toolkit for {{3D}} Point Clouds},
  shorttitle = {Plant {{3D}} ({{P3D}})},
  author = {Ziamtsov, Illia and Navlakha, Saket},
  editor = {Xu, Jinbo},
  year = {2020},
  month = jun,
  journal = {Bioinformatics},
  volume = {36},
  number = {12},
  pages = {3949--3950},
  issn = {1367-4803, 1460-2059},
  doi = {10.1093/bioinformatics/btaa220},
  urldate = {2021-12-18},
  abstract = {Abstract                              Motivation                Developing methods to efficiently analyze 3D point cloud data of plant architectures remain challenging for many phenotyping applications. Here, we describe a tool that tackles four core phenotyping tasks: classification of cloud points into stem and lamina points, graph skeletonization of the stem points, segmentation of individual lamina and whole leaf labeling. These four tasks are critical for numerous downstream phenotyping goals, such as quantifying plant biomass, performing morphological analyses of plant shapes and uncovering genotype to phenotype relationships. The Plant 3D tool provides an intuitive graphical user interface, a fast 3D rendering engine for visualizing plants with millions of cloud points, and several graph-theoretic and machine-learning algorithms for 3D architecture analyses.                                            Availability and implementation                P3D is open-source and implemented in C++. Source code and Windows installer are freely available at https://github.com/iziamtso/P3D/.                                            Contact                iziamtso@ucsd.edu or navlakha@cshl.edu                                            Supplementary information                Supplementary data are available at Bioinformatics online.},
  langid = {english}
}

@article{zilvanConvolutionalVariationalAutoencoderbased2022,
  title = {Convolutional Variational Autoencoder-Based Feature Learning for Automatic Tea Clone Recognition},
  author = {Zilvan, Vicky and Ramdan, Ade and Heryana, Ana and Krisnandi, Dikdik and Suryawati, Endang and Yuwana, R. Sandra and Kusumo, R. Budiarianto S. and Pardede, Hilman F.},
  year = {2022},
  month = jun,
  journal = {Journal of King Saud University - Computer and Information Sciences},
  volume = {34},
  number = {6, Part B},
  pages = {3332--3342},
  issn = {1319-1578},
  doi = {10.1016/j.jksuci.2021.01.020},
  urldate = {2025-01-05},
  abstract = {It is common to have various clones from cross-seedlings or unintended planting by the farmers in a tea plantation. Since each tea clone has distinctive features such as quality, resistance to diseases, etc., visual inspections are usually conducted on the plantations to segment areas with different tea clones within the plantation to produce crops with consistent quality. However, this would be costly and time-consuming. In this work, we apply machine learning and develop an application to recognize tea clones automatically. We propose a convolutional variational autoencoder-based feature learning algorithm to produce robust features against data distortions. There are two main advantages of using this algorithm for feature learning. First, there is no need to design complex handcrafted features for classifications, usually conducted in machine learning. Second, the resulting features are more robust when tested with data taken from unideal conditions. The proposed method is evaluated using the original and the distorted image. Our proposed method achieves the best performance of 0.83 (83\%) for the original image test, 0.75 (75\%) for the gaussian blur image test, and 0.78 (78\%) for the median blur image test. This is a much more robust result than VGGNet16, a popular supervised deep convolutional neural network.},
  keywords = {Convolutional variational autoencoder,Deep learning,Feature learning,Tea clones recognition}
}

@misc{ZoteroYourPersonal,
  title = {Zotero {\textbar} {{Your}} Personal Research Assistant},
  urldate = {2022-09-06},
  howpublished = {https://www.zotero.org/},
  file = {/home/samuelebumbaca/Zotero/storage/ZW7HUUKG/www.zotero.org.html}
}

@article{zouDegreesFreedomLasso2007,
  title = {On the ``Degrees of Freedom'' of the Lasso},
  author = {Zou, Hui and Hastie, Trevor and Tibshirani, Robert},
  year = {2007},
  month = oct,
  journal = {The Annals of Statistics},
  volume = {35},
  number = {5},
  pages = {2173--2192},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/009053607000000127},
  urldate = {2025-03-16},
  abstract = {We study the effective degrees of freedom of the lasso in the framework of Stein's unbiased risk estimation (SURE). We show that the number of nonzero coefficients is an unbiased estimate for the degrees of freedom of the lasso---a conclusion that requires no special assumption on the predictors. In addition, the unbiased estimator is shown to be asymptotically consistent. With these results on hand, various model selection criteria---Cp, AIC and BIC---are available, which, along with the LARS algorithm, provide a principled and efficient approach to obtaining the optimal lasso fit with the computational effort of a single ordinary least-squares fit.},
  keywords = {62J05,62J07,90C46,Degrees of freedom,LARS algorithm,Lasso,Model selection,SURE,unbiased estimate},
  file = {/home/samuelebumbaca/Zotero/storage/XGIPBUA2/Zou et al. - 2007 - On the “degrees of freedom” of the lasso.pdf}
}

@misc{simonyanVeryDeepConvolutional2015,
	title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
	url = {http://arxiv.org/abs/1409.1556},
	doi = {10.48550/arXiv.1409.1556},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	urldate = {2025-03-23},
	publisher = {arXiv},
	author = {Simonyan, Karen and Zisserman, Andrew},
	month = apr,
	year = {2015},
	note = {arXiv:1409.1556 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{hughesOpenAccessRepository2016,
	title = {An open access repository of images on plant health to enable the development of mobile disease diagnostics},
	url = {http://arxiv.org/abs/1511.08060},
	doi = {10.48550/arXiv.1511.08060},
	abstract = {Human society needs to increase food production by an estimated 70\% by 2050 to feed an expected population size that is predicted to be over 9 billion people. Currently, infectious diseases reduce the potential yield by an average of 40\% with many farmers in the developing world experiencing yield losses as high as 100\%. The widespread distribution of smartphones among crop growers around the world with an expected 5 billion smartphones by 2020 offers the potential of turning the smartphone into a valuable tool for diverse communities growing food. One potential application is the development of mobile disease diagnostics through machine learning and crowdsourcing. Here we announce the release of over 50,000 expertly curated images on healthy and infected leaves of crops plants through the existing online platform PlantVillage. We describe both the data and the platform. These data are the beginning of an on-going, crowdsourcing effort to enable computer vision approaches to help solve the problem of yield losses in crop plants due to infectious diseases.},
	urldate = {2025-03-23},
	publisher = {arXiv},
	author = {Hughes, David P. and Salathe, Marcel},
	month = apr,
	year = {2016},
	note = {arXiv:1511.08060 [cs]},
	keywords = {Computer Science - Computers and Society},
}

@misc{thapaPlantPathology20202020,
	title = {The {Plant} {Pathology} 2020 challenge dataset to classify foliar disease of apples},
	url = {http://arxiv.org/abs/2004.11958},
	doi = {10.48550/arXiv.2004.11958},
	abstract = {Apple orchards in the U.S. are under constant threat from a large number of pathogens and insects. Appropriate and timely deployment of disease management depends on early disease detection. Incorrect and delayed diagnosis can result in either excessive or inadequate use of chemicals, with increased production costs, environmental, and health impacts. We have manually captured 3,651 high-quality, real-life symptom images of multiple apple foliar diseases, with variable illumination, angles, surfaces, and noise. A subset, expert-annotated to create a pilot dataset for apple scab, cedar apple rust, and healthy leaves, was made available to the Kaggle community for 'Plant Pathology Challenge'; part of the Fine-Grained Visual Categorization (FGVC) workshop at CVPR 2020 (Computer Vision and Pattern Recognition). We also trained an off-the-shelf convolutional neural network (CNN) on this data for disease classification and achieved 97\% accuracy on a held-out test set. This dataset will contribute towards development and deployment of machine learning-based automated plant disease classification algorithms to ultimately realize fast and accurate disease detection. We will continue to add images to the pilot dataset for a larger, more comprehensive expert-annotated dataset for future Kaggle competitions and to explore more advanced methods for disease classification and quantification.},
	urldate = {2025-03-23},
	publisher = {arXiv},
	author = {Thapa, Ranjita and Snavely, Noah and Belongie, Serge and Khan, Awais},
	month = apr,
	year = {2020},
	note = {arXiv:2004.11958 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Electrical Engineering and Systems Science - Image and Video Processing},
}

@misc{heDeepResidualLearning2015,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	url = {http://arxiv.org/abs/1512.03385},
	doi = {10.48550/arXiv.1512.03385},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
	urldate = {2025-03-23},
	publisher = {arXiv},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = dec,
	year = {2015},
	note = {arXiv:1512.03385 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{huangDenselyConnectedConvolutional2017,
	title = {Densely {Connected} {Convolutional} {Networks}},
	url = {https://openaccess.thecvf.com/content_cvpr_2017/html/Huang_Densely_Connected_Convolutional_CVPR_2017_paper.html},
	urldate = {2025-03-23},
	author = {Huang, Gao and Liu, Zhuang and van der Maaten, Laurens and Weinberger, Kilian Q.},
	year = {2017},
	pages = {4700--4708},
}

@misc{tanEfficientNetRethinkingModel2020,
	title = {{EfficientNet}: {Rethinking} {Model} {Scaling} for {Convolutional} {Neural} {Networks}},
	shorttitle = {{EfficientNet}},
	url = {http://arxiv.org/abs/1905.11946},
	doi = {10.48550/arXiv.1905.11946},
	abstract = {Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up MobileNets and ResNet. To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves state-of-the-art 84.3\% top-1 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet. Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7\%), Flowers (98.8\%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters. Source code is at https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet.},
	urldate = {2025-03-23},
	publisher = {arXiv},
	author = {Tan, Mingxing and Le, Quoc V.},
	month = sep,
	year = {2020},
	note = {arXiv:1905.11946 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{dosovitskiyImageWorth16x162021,
	title = {An {Image} is {Worth} 16x16 {Words}: {Transformers} for {Image} {Recognition} at {Scale}},
	shorttitle = {An {Image} is {Worth} 16x16 {Words}},
	url = {http://arxiv.org/abs/2010.11929},
	doi = {10.48550/arXiv.2010.11929},
	abstract = {While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.},
	urldate = {2025-03-23},
	publisher = {arXiv},
	author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
	month = jun,
	year = {2021},
	note = {arXiv:2010.11929 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@misc{liuSwinTransformerHierarchical2021,
	title = {Swin {Transformer}: {Hierarchical} {Vision} {Transformer} using {Shifted} {Windows}},
	shorttitle = {Swin {Transformer}},
	url = {http://arxiv.org/abs/2103.14030},
	doi = {10.48550/arXiv.2103.14030},
	abstract = {This paper presents a new vision Transformer, called Swin Transformer, that capably serves as a general-purpose backbone for computer vision. Challenges in adapting Transformer from language to vision arise from differences between the two domains, such as large variations in the scale of visual entities and the high resolution of pixels in images compared to words in text. To address these differences, we propose a hierarchical Transformer whose representation is computed with {\textbackslash}textbf\{S\}hifted {\textbackslash}textbf\{win\}dows. The shifted windowing scheme brings greater efficiency by limiting self-attention computation to non-overlapping local windows while also allowing for cross-window connection. This hierarchical architecture has the flexibility to model at various scales and has linear computational complexity with respect to image size. These qualities of Swin Transformer make it compatible with a broad range of vision tasks, including image classification (87.3 top-1 accuracy on ImageNet-1K) and dense prediction tasks such as object detection (58.7 box AP and 51.1 mask AP on COCO test-dev) and semantic segmentation (53.5 mIoU on ADE20K val). Its performance surpasses the previous state-of-the-art by a large margin of +2.7 box AP and +2.6 mask AP on COCO, and +3.2 mIoU on ADE20K, demonstrating the potential of Transformer-based models as vision backbones. The hierarchical design and the shifted window approach also prove beneficial for all-MLP architectures. The code and models are publicly available at{\textasciitilde}{\textbackslash}url\{https://github.com/microsoft/Swin-Transformer\}.},
	urldate = {2025-03-23},
	publisher = {arXiv},
	author = {Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
	month = aug,
	year = {2021},
	note = {arXiv:2103.14030 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@misc{oquabDINOv2LearningRobust2024,
	title = {{DINOv2}: {Learning} {Robust} {Visual} {Features} without {Supervision}},
	shorttitle = {{DINOv2}},
	url = {http://arxiv.org/abs/2304.07193},
	doi = {10.48550/arXiv.2304.07193},
	abstract = {The recent breakthroughs in natural language processing for model pretraining on large quantities of data have opened the way for similar foundation models in computer vision. These models could greatly simplify the use of images in any system by producing all-purpose visual features, i.e., features that work across image distributions and tasks without finetuning. This work shows that existing pretraining methods, especially self-supervised methods, can produce such features if trained on enough curated data from diverse sources. We revisit existing approaches and combine different techniques to scale our pretraining in terms of data and model size. Most of the technical contributions aim at accelerating and stabilizing the training at scale. In terms of data, we propose an automatic pipeline to build a dedicated, diverse, and curated image dataset instead of uncurated data, as typically done in the self-supervised literature. In terms of models, we train a ViT model (Dosovitskiy et al., 2020) with 1B parameters and distill it into a series of smaller models that surpass the best available all-purpose features, OpenCLIP (Ilharco et al., 2021) on most of the benchmarks at image and pixel levels.},
	urldate = {2025-03-23},
	publisher = {arXiv},
	author = {Oquab, Maxime and Darcet, Timothée and Moutakanni, Théo and Vo, Huy and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and Assran, Mahmoud and Ballas, Nicolas and Galuba, Wojciech and Howes, Russell and Huang, Po-Yao and Li, Shang-Wen and Misra, Ishan and Rabbat, Michael and Sharma, Vasu and Synnaeve, Gabriel and Xu, Hu and Jegou, Hervé and Mairal, Julien and Labatut, Patrick and Joulin, Armand and Bojanowski, Piotr},
	month = feb,
	year = {2024},
	note = {arXiv:2304.07193 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{FacebookresearchDinov22025,
	title = {facebookresearch/dinov2},
	copyright = {Apache-2.0},
	url = {https://github.com/facebookresearch/dinov2},
	abstract = {PyTorch code and models for the DINOv2 self-supervised learning method.},
	urldate = {2025-03-23},
	publisher = {Meta Research},
	month = mar,
	year = {2025},
	note = {original-date: 2023-03-29T16:00:37Z},
}

@misc{ModelsPretrainedWeights,
	title = {Models and pre-trained weights — {Torchvision} main documentation},
	url = {https://pytorch.org/vision/master/models.html},
	urldate = {2025-03-23},
}

@misc{RobustDeepLearningBasedDetector,
	title = {A {Robust} {Deep}-{Learning}-{Based} {Detector} for {Real}-{Time} {Tomato} {Plant} {Diseases} and {Pests} {Recognition}},
	url = {https://www.mdpi.com/1424-8220/17/9/2022},
	urldate = {2025-03-23},
}

@article{todaHowConvolutionalNeural2019,
	title = {How {Convolutional} {Neural} {Networks} {Diagnose} {Plant} {Disease}},
	volume = {2019},
	issn = {2643-6515},
	doi = {10.34133/2019/9237136},
	abstract = {Deep learning with convolutional neural networks (CNNs) has achieved great success in the classification of various plant diseases. However, a limited number of studies have elucidated the process of inference, leaving it as an untouchable black box. Revealing the CNN to extract the learned feature as an interpretable form not only ensures its reliability but also enables the validation of the model authenticity and the training dataset by human intervention. In this study, a variety of neuron-wise and layer-wise visualization methods were applied using a CNN, trained with a publicly available plant disease image dataset. We showed that neural networks can capture the colors and textures of lesions specific to respective diseases upon diagnosis, which resembles human decision-making. While several visualization methods were used as they are, others had to be optimized to target a specific layer that fully captures the features to generate consequential outputs. Moreover, by interpreting the generated attention maps, we identified several layers that were not contributing to inference and removed such layers inside the network, decreasing the number of parameters by 75\% without affecting the classification accuracy. The results provide an impetus for the CNN black box users in the field of plant science to better understand the diagnosis process and lead to further efficient use of deep learning for plant disease diagnosis.},
	language = {eng},
	journal = {Plant Phenomics (Washington, D.C.)},
	author = {Toda, Yosuke and Okura, Fumio},
	year = {2019},
	pmid = {33313540},
	pmcid = {PMC7706313},
	pages = {9237136},
}

@misc{zotero-1449,
	url = {https://openaccess.thecvf.com/content/CVPR2021/papers/Salehi_Multiresolution_Knowledge_Distillation_for_Anomaly_Detection_CVPR_2021_paper.pdf},
	urldate = {2025-03-23},
}

@misc{zotero-1450,
	url = {https://people.csail.mit.edu/wrvb/files/publications/liu2018deep.pdf},
	urldate = {2025-03-23},
}

@misc{chalapathyDeepLearningAnomaly2019,
	title = {Deep {Learning} for {Anomaly} {Detection}: {A} {Survey}},
	shorttitle = {Deep {Learning} for {Anomaly} {Detection}},
	url = {http://arxiv.org/abs/1901.03407},
	doi = {10.48550/arXiv.1901.03407},
	abstract = {Anomaly detection is an important problem that has been well-studied within diverse research areas and application domains. The aim of this survey is two-fold, firstly we present a structured and comprehensive overview of research methods in deep learning-based anomaly detection. Furthermore, we review the adoption of these methods for anomaly across various application domains and assess their effectiveness. We have grouped state-of-the-art research techniques into different categories based on the underlying assumptions and approach adopted. Within each category we outline the basic anomaly detection technique, along with its variants and present key assumptions, to differentiate between normal and anomalous behavior. For each category, we present we also present the advantages and limitations and discuss the computational complexity of the techniques in real application domains. Finally, we outline open issues in research and challenges faced while adopting these techniques.},
	urldate = {2025-03-23},
	publisher = {arXiv},
	author = {Chalapathy, Raghavendra and Chawla, Sanjay},
	month = jan,
	year = {2019},
	note = {arXiv:1901.03407 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{10.1145/342009.335388,
author = {Breunig, Markus M. and Kriegel, Hans-Peter and Ng, Raymond T. and Sander, J\"{o}rg},
title = {LOF: identifying density-based local outliers},
year = {2000},
isbn = {1581132174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/342009.335388},
doi = {10.1145/342009.335388},
abstract = {For many KDD applications, such as detecting criminal activities in E-commerce, finding the rare instances or the outliers, can be more interesting than finding the common patterns. Existing work in outlier detection regards being an outlier as a binary property. In this paper, we contend that for many scenarios, it is more meaningful to assign to each object a degree of being an outlier. This degree is called the local outlier factor (LOF) of an object. It is local in that the degree depends on how isolated the object is with respect to the surrounding neighborhood. We give a detailed formal analysis showing that LOF enjoys many desirable properties. Using real-world datasets, we demonstrate that LOF can be used to find outliers which appear to be meaningful, but can otherwise not be identified with existing approaches. Finally, a careful performance evaluation of our algorithm confirms we show that our approach of finding local outliers can be practical.},
booktitle = {Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data},
pages = {93–104},
numpages = {12},
keywords = {outlier detection, database mining},
location = {Dallas, Texas, USA},
series = {SIGMOD '00}
}

@article{breunig2000lof,
author = {Breunig, Markus M. and Kriegel, Hans-Peter and Ng, Raymond T. and Sander, J\"{o}rg},
title = {LOF: identifying density-based local outliers},
year = {2000},
issue_date = {June 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {2},
issn = {0163-5808},
url = {https://doi.org/10.1145/335191.335388},
doi = {10.1145/335191.335388},
abstract = {For many KDD applications, such as detecting criminal activities in E-commerce, finding the rare instances or the outliers, can be more interesting than finding the common patterns. Existing work in outlier detection regards being an outlier as a binary property. In this paper, we contend that for many scenarios, it is more meaningful to assign to each object a degree of being an outlier. This degree is called the local outlier factor (LOF) of an object. It is local in that the degree depends on how isolated the object is with respect to the surrounding neighborhood. We give a detailed formal analysis showing that LOF enjoys many desirable properties. Using real-world datasets, we demonstrate that LOF can be used to find outliers which appear to be meaningful, but can otherwise not be identified with existing approaches. Finally, a careful performance evaluation of our algorithm confirms we show that our approach of finding local outliers can be practical.},
journal = {SIGMOD Rec.},
month = may,
pages = {93–104},
numpages = {12},
keywords = {outlier detection, database mining}
}

@article{scholkopf2001estimating,
    author = {Schölkopf, Bernhard and Platt, John C. and Shawe-Taylor, John and Smola, Alex J. and Williamson, Robert C.},
    title = {Estimating the Support of a High-Dimensional Distribution},
    journal = {Neural Computation},
    volume = {13},
    number = {7},
    pages = {1443-1471},
    year = {2001},
    month = {07},
    abstract = {Suppose you are given some data set drawn from an underlying probability distribution P and you want to estimate a “simple” subset S of input space such that the probability that a test point drawn from P lies outside of S equals some a priori specified value between 0 and 1.We propose a method to approach this problem by trying to estimate a function f that is positive on S and negative on the complement. The functional form of f is given by a kernel expansion in terms of a potentially small subset of the training data; it is regularized by controlling the length of the weight vector in an associated feature space. The expansion coefficients are found by solving a quadratic programming problem, which we do by carrying out sequential optimization over pairs of input patterns. We also provide a theoretical analysis of the statistical performance of our algorithm.The algorithm is a natural extension of the support vector algorithm to the case of unlabeled data.},
    issn = {0899-7667},
    doi = {10.1162/089976601750264965},
    url = {https://doi.org/10.1162/089976601750264965},
    eprint = {https://direct.mit.edu/neco/article-pdf/13/7/1443/814849/089976601750264965.pdf},
}

@INPROCEEDINGS{liu2008isolation,
  author={Liu, Fei Tony and Ting, Kai Ming and Zhou, Zhi-Hua},
  booktitle={2008 Eighth IEEE International Conference on Data Mining}, 
  title={Isolation Forest}, 
  year={2008},
  volume={},
  number={},
  pages={413-422},
  keywords={Application software;Credit cards;Detectors;Constraint optimization;Data mining;Information technology;Laboratories;Isolation technology;Performance evaluation;Astronomy;anomaly detection;outlier detection;novelty detection;isolation forest;binary trees;model based},
  doi={10.1109/ICDM.2008.17}}


@article{ruffUnifyingReviewDeep2021,
	title = {A {Unifying} {Review} of {Deep} and {Shallow} {Anomaly} {Detection}},
	volume = {109},
	issn = {0018-9219, 1558-2256},
	url = {http://arxiv.org/abs/2009.11732},
	doi = {10.1109/JPROC.2021.3052449},
	abstract = {Deep learning approaches to anomaly detection have recently improved the state of the art in detection performance on complex datasets such as large collections of images or text. These results have sparked a renewed interest in the anomaly detection problem and led to the introduction of a great variety of new methods. With the emergence of numerous such methods, including approaches based on generative models, one-class classification, and reconstruction, there is a growing need to bring methods of this field into a systematic and unified perspective. In this review we aim to identify the common underlying principles as well as the assumptions that are often made implicitly by various methods. In particular, we draw connections between classic 'shallow' and novel deep approaches and show how this relation might cross-fertilize or extend both directions. We further provide an empirical assessment of major existing methods that is enriched by the use of recent explainability techniques, and present specific worked-through examples together with practical advice. Finally, we outline critical open challenges and identify specific paths for future research in anomaly detection.},
	number = {5},
	urldate = {2025-03-23},
	journal = {Proceedings of the IEEE},
	author = {Ruff, Lukas and Kauffmann, Jacob R. and Vandermeulen, Robert A. and Montavon, Grégoire and Samek, Wojciech and Kloft, Marius and Dietterich, Thomas G. and Müller, Klaus-Robert},
	month = may,
	year = {2021},
	note = {arXiv:2009.11732 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	pages = {756--795},
}

@article{sajithaDeepLearningApproach2024,
	title = {A deep learning approach to detect diseases in pomegranate fruits via hybrid optimal attention capsule network},
	volume = {84},
	issn = {1574-9541},
	url = {https://www.sciencedirect.com/science/article/pii/S1574954124004011},
	doi = {10.1016/j.ecoinf.2024.102859},
	abstract = {In 2022, the production rate of pomegranate is estimated at approximately 4.8 million metric tons. Unfortunately, these fruits are susceptible to many different kinds of diseases caused by bacterial, viral, and fungal infections. Such diseases can have a major negative impact on fruit quality, production, and the profitability of pomegranate cultivation. Nowadays, several machine learning and deep learning methods are used to identify pomegranate fruit diseases automatically and effectively. In post-harvest pomegranate fruit disease detection, deep learning has great potential to extract complex patterns and features from large datasets. This can improve disease identification accuracy, enabling more efficient disease control, lower crop losses, and better resource management. The proposed work introduces an intelligent deep learning-based approach for accurately detecting pomegranate diseases, begins with Improved Guided Image Filtering (Improved GIF) and resizing to pre-process fruit images, followed by feature extraction (shape, color, texture) using GLCM and GLRLM to streamline classification. Extracted features are then fed into a novel Hybrid Optimal Attention Capsule Network (Hybrid OACapsNet), which classifies the images as normal or diseased, conditions such as bacterial blight, heart rot, and scab. Our analysis indicates that the proposed classifier has a classification accuracy of 99.19 \%, precision of 98.45 \%, recall of 98.41 \%, F1-score of 98.43 \%, and specificity of 99.45 \% compared to other techniques. So this approach offers a framework, which is a feasible solution for automated detection of diseases in fruits, thereby benefiting farmers and supporting their farming operations.},
	urldate = {2025-03-23},
	journal = {Ecological Informatics},
	author = {Sajitha, P. and Diana Andrushia, A. and Anand, N. and Naser, M. Z. and Lubloy, Eva},
	month = dec,
	year = {2024},
	keywords = {Deep learning, Fruit disease detection, Hybrid OACapsNet, Pomegranate, Post-harvest technique},
	pages = {102859},
}

@article{mohantyUsingDeepLearning2016,
	title = {Using {Deep} {Learning} for {Image}-{Based} {Plant} {Disease} {Detection}},
	volume = {7},
	issn = {1664-462X},
	url = {https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2016.01419/full},
	doi = {10.3389/fpls.2016.01419},
	abstract = {{\textless}p{\textgreater}Crop diseases are a major threat to food security, but their rapid identification remains difficult in many parts of the world due to the lack of the necessary infrastructure. The combination of increasing global smartphone penetration and recent advances in computer vision made possible by deep learning has paved the way for smartphone-assisted disease diagnosis. Using a public dataset of 54,306 images of diseased and healthy plant leaves collected under controlled conditions, we train a deep convolutional neural network to identify 14 crop species and 26 diseases (or absence thereof). The trained model achieves an accuracy of 99.35\% on a held-out test set, demonstrating the feasibility of this approach. Overall, the approach of training deep learning models on increasingly large and publicly available image datasets presents a clear path toward smartphone-assisted crop disease diagnosis on a massive global scale.{\textless}/p{\textgreater}},
	language = {English},
	urldate = {2025-03-23},
	journal = {Frontiers in Plant Science},
	author = {Mohanty, Sharada P. and Hughes, David P. and Salathé, Marcel},
	month = sep,
	year = {2016},
	note = {Publisher: Frontiers},
	keywords = {machine learning, deep learning, Disease diagnosis, Crop diseases, digital epidemiology},
}

@article{ferentinosDeepLearningModels2018,
	title = {Deep learning models for plant disease detection and diagnosis},
	volume = {145},
	issn = {0168-1699},
	url = {https://www.sciencedirect.com/science/article/pii/S0168169917311742},
	doi = {10.1016/j.compag.2018.01.009},
	abstract = {In this paper, convolutional neural network models were developed to perform plant disease detection and diagnosis using simple leaves images of healthy and diseased plants, through deep learning methodologies. Training of the models was performed with the use of an open database of 87,848 images, containing 25 different plants in a set of 58 distinct classes of [plant, disease] combinations, including healthy plants. Several model architectures were trained, with the best performance reaching a 99.53\% success rate in identifying the corresponding [plant, disease] combination (or healthy plant). The significantly high success rate makes the model a very useful advisory or early warning tool, and an approach that could be further expanded to support an integrated plant disease identification system to operate in real cultivation conditions.},
	urldate = {2025-03-23},
	journal = {Computers and Electronics in Agriculture},
	author = {Ferentinos, Konstantinos P.},
	month = feb,
	year = {2018},
	keywords = {Machine learning, Artificial intelligence, Convolutional neural networks, Pattern recognition, Plant disease identification},
	pages = {311--318},
}

@article{barbedoFactorsInfluencingUse2018,
	title = {Factors influencing the use of deep learning for plant disease recognition},
	volume = {172},
	issn = {1537-5110},
	url = {https://www.sciencedirect.com/science/article/pii/S1537511018303027},
	doi = {10.1016/j.biosystemseng.2018.05.013},
	abstract = {Deep learning is quickly becoming one of the most important tools for image classification. This technology is now beginning to be applied to the tasks of plant disease classification and recognition. The positive results that are being obtained using this approach hide some issues that are seldom taken into account in the respective experiments. This article presents an investigation into the main factors that affect the design and effectiveness of deep neural nets applied to plant pathology. An in-depth analysis of the subject, in which advantages and shortcomings are highlighted, should lead to more realistic conclusions on the subject. The arguments used throughout the text are built upon both studies found in the literature and experiments carried out using an image database carefully built to reflect and reproduce many of the conditions expected to be found in practice. This database, which contains almost 50,000 images, is being made freely available for academic purposes.},
	urldate = {2025-03-23},
	journal = {Biosystems Engineering},
	author = {Barbedo, Jayme G. A.},
	month = aug,
	year = {2018},
	keywords = {Image processing, Deep neural nets, Disease classification, Image database, Transfer learning},
	pages = {84--91},
}

@article{martinelliAdvancedMethodsPlant2015,
	title = {Advanced methods of plant disease detection. {A} review},
	volume = {35},
	url = {https://hal.science/hal-01284270},
	doi = {10.1007/s13593-014-0246-1},
	abstract = {Plant diseases are responsible for major economic losses in the agricultural industry worldwide. Monitoring plant health and detecting pathogen early are essential to reduce disease spread and facilitate effective management practices. DNA-based and serological methods now provide essential tools for accurate plant disease diagnosis, in addition to the traditional visual scouting for symptoms. Although DNA-based and serological methods have revolutionized plant disease detection, they are not very reliable at asymptomatic stage, especially in case of pathogen with systemic diffusion. They need at least 1–2 days for sample harvest, processing, and analysis. Here, we describe modern methods based on nucleic acid and protein analysis. Then, we review innovative approaches currently under development. Our main findings are the following: (1) novel sensors based on the analysis of host responses, e.g., differential mobility spectrometer and lateral flow devices, deliver instantaneous results and can effectively detect early infections directly in the field; (2) biosensors based on phage display and biophotonics can also detect instantaneously infections although they can be integrated with other systems; and (3) remote sensing techniques coupled with spectroscopy-based methods allow high spatialization of results, these techniques may be very useful as a rapid preliminary identification of primary infections. We explain how these tools will help plant disease management and complement serological and DNA-based methods. While serological and PCR-based methods are the most available and effective to confirm disease diagnosis, volatile and biophotonic sensors provide instantaneous results and may be used to identify infections at asymptomatic stages. Remote sensing technologies will be extremely helpful to greatly spatialize diagnostic results. These innovative techniques represent unprecedented tools to render agriculture more sustainable and safe, avoiding expensive use of pesticides in crop protection.},
	number = {1},
	urldate = {2025-03-23},
	journal = {Agronomy for Sustainable Development},
	author = {Martinelli, Federico and Scalenghe, Riccardo and Davino, Salvatore and Panno, Stefano and Scuderi, Giuseppe and Ruisi, Paolo and Villa, Paolo and Stroppiana, Daniela and Boschetti, Mirco and Goulart, Luiz R. and Davis, Cristina E. and Dandekar, Abhaya M.},
	year = {2015},
	note = {Publisher: Springer Verlag/EDP Sciences/INRA},
	keywords = {Remote sensing, Spectroscopy, Plant disease, Biophotonics, Commercial kits, DNA-based methods, Immunological assays, Volatile organic compounds},
	pages = {1--25},
}

@article{savaryGlobalBurdenPathogens2019,
	title = {The global burden of pathogens and pests on major food crops},
	volume = {3},
	issn = {2397-334X},
	doi = {10.1038/s41559-018-0793-y},
	abstract = {Crop pathogens and pests reduce the yield and quality of agricultural production. They cause substantial economic losses and reduce food security at household, national and global levels. Quantitative, standardized information on crop losses is difficult to compile and compare across crops, agroecosystems and regions. Here, we report on an expert-based assessment of crop health, and provide numerical estimates of yield losses on an individual pathogen and pest basis for five major crops globally and in food security hotspots. Our results document losses associated with 137 pathogens and pests associated with wheat, rice, maize, potato and soybean worldwide. Our yield loss (range) estimates at a global level and per hotspot for wheat (21.5\% (10.1-28.1\%)), rice (30.0\% (24.6-40.9\%)), maize (22.5\% (19.5-41.1\%)), potato (17.2\% (8.1-21.0\%)) and soybean (21.4\% (11.0-32.4\%)) suggest that the highest losses are associated with food-deficit regions with fast-growing populations, and frequently with emerging or re-emerging pests and diseases. Our assessment highlights differences in impacts among crop pathogens and pests and among food security hotspots. This analysis contributes critical information to prioritize crop health management to improve the sustainability of agroecosystems in delivering services to societies.},
	language = {eng},
	number = {3},
	journal = {Nature Ecology \& Evolution},
	author = {Savary, Serge and Willocquet, Laetitia and Pethybridge, Sarah Jane and Esker, Paul and McRoberts, Neil and Nelson, Andy},
	month = mar,
	year = {2019},
	pmid = {30718852},
	keywords = {Agriculture, Crops, Agricultural, Animals, Climate Change, Food Supply, Host-Pathogen Interactions, Insecta, Mites, Plant Weeds},
	pages = {430--439},
}

@article{sajithaDeepLearningApproach2024a,
	title = {A deep learning approach to detect diseases in pomegranate fruits via hybrid optimal attention capsule network},
	volume = {84},
	issn = {1574-9541},
	url = {https://www.sciencedirect.com/science/article/pii/S1574954124004011},
	doi = {10.1016/j.ecoinf.2024.102859},
	abstract = {In 2022, the production rate of pomegranate is estimated at approximately 4.8 million metric tons. Unfortunately, these fruits are susceptible to many different kinds of diseases caused by bacterial, viral, and fungal infections. Such diseases can have a major negative impact on fruit quality, production, and the profitability of pomegranate cultivation. Nowadays, several machine learning and deep learning methods are used to identify pomegranate fruit diseases automatically and effectively. In post-harvest pomegranate fruit disease detection, deep learning has great potential to extract complex patterns and features from large datasets. This can improve disease identification accuracy, enabling more efficient disease control, lower crop losses, and better resource management. The proposed work introduces an intelligent deep learning-based approach for accurately detecting pomegranate diseases, begins with Improved Guided Image Filtering (Improved GIF) and resizing to pre-process fruit images, followed by feature extraction (shape, color, texture) using GLCM and GLRLM to streamline classification. Extracted features are then fed into a novel Hybrid Optimal Attention Capsule Network (Hybrid OACapsNet), which classifies the images as normal or diseased, conditions such as bacterial blight, heart rot, and scab. Our analysis indicates that the proposed classifier has a classification accuracy of 99.19 \%, precision of 98.45 \%, recall of 98.41 \%, F1-score of 98.43 \%, and specificity of 99.45 \% compared to other techniques. So this approach offers a framework, which is a feasible solution for automated detection of diseases in fruits, thereby benefiting farmers and supporting their farming operations.},
	urldate = {2025-03-23},
	journal = {Ecological Informatics},
	author = {Sajitha, P. and Diana Andrushia, A. and Anand, N. and Naser, M. Z. and Lubloy, Eva},
	month = dec,
	year = {2024},
	keywords = {Deep learning, Fruit disease detection, Hybrid OACapsNet, Pomegranate, Post-harvest technique},
	pages = {102859},
}

@misc{zotero-1464,
	url = {https://pdf.sciencedirectassets.com/273474/1-s2.0-S1574954124X00059/1-s2.0-S1574954124004011/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEIX%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQD%2ByF0jnLEk0ShVLoli4s9AldcT06iPuHBM8qFj0cfjtwIgLW%2F%2FNp9t397jt6H8hS5kBxtbODHHdeYA8yYZy2ZwolMqvAUI3f%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAFGgwwNTkwMDM1NDY4NjUiDNUjJMeWp%2FPXgAOLyCqQBWcMZqqOlvNO9PsQWrdcK8lsqoG31Jot1jl3Ze7ddmb9NvvaklQeeDbaMrwkCF9%2BZmYPyr3XWVbd5edLuNjde5EeaxDMRUOUcEZX2xSUQAXtUAfp8WKYZlzWiDkRto0GC612yI5f9FXt57fmLe6LLK%2FiKZWNdhfK1lTqAbxas2uLr22sj5M9bfvZ5FaYMmZ0IwtaL1jLokfQG0hpIPTuLRzHmBhoURaOPfI9RdtzELeBENPOrC06P2IndVSq7KqbF1DxgjdimuNgNUisTBR5a5CtXkfw1dnRqNb8LceojxmKp9bjNKIDzIxu6ZVFSl1x6eF%2Fsnbq4e3%2BPMjRHC2lEp3xy%2B5vZN9n0rCA5%2Biiuc%2F60iGHKlv4qGPMZ84pi4ngD4alImmp%2F8xYb5WSS%2FGnbaG1GcgcFawPR5LXGJdfrWRc6WO9LQuP84WN1OGlvcFwUWKK%2FIS8xQPIwkESDEMYEQJqsIRDjqdAOBe1hI9s9RihqzwLHdU0QhWf0E6QbGtSHE5miN95sVp7OEHYAnfwp%2BIf%2B%2BcuxTAotvXIRjLV7iwEKx6n8F%2BQ4%2BfnddzXFEzaDCrGxfy7NLXWdUV69CYvxCtN2wUI%2F7yNH7vwPcI90aAtiISFFrxn%2BwlDpHpjE41ZalORoJWx6AhEYNdtTj%2FlA0ORklOF4HmDvTJStmXKJSrrytxVzJkbKjE8jcWG6R9tF5KZA2i253cGqN%2BKMDYCSbv8aYMcH3G03Xs37DpqCFswzRo6d8xi%2FncvVIoERrqxK%2FFHbXlpDI6oV5wsCmp0%2BYJWEp1pns5hM57GeoHifG%2Ftehry4w5IKETUfNxS9so2pI5ox%2BfB5WNDf30l2os2XGfBmN%2FUxj54Zi3Ab7YJKYTcMNPVgb8GOrEBdNlrJaodVDo2iSMhiUGufqOnXYqV2XMBUOzZPybMiSZtt8iKWkpQ%2Fx8v3ugBXkO21XSuSxgyNYC03nC6T09UddwBD62lpJWU%2BtOiMQus7bzrJMY4gWRixjM8KZUpRxrFqHmAGcjWDjVDRX%2B7swxL3URJqjWbBGdm3HILY8qt2hNjjxaXUfhBkKgbxUdP010F1W2fWHtq3Ul%2F8FXDSvwPn1GPVxF0wZwtRy9xlVKzdjtr&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250323T211138Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY3T3Y7MGC%2F20250323%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=14c743ad138e9da44a7d502dab6e56386653ec2b43218faa05df686323637671&hash=df35effb639e24a37a09e14a32f5724aa94d054b70eae3791e1070efde6d7f31&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1574954124004011&tid=spdf-5b9f07a9-b7b7-464a-a50d-1cbf2f221732&sid=b0c16a9e643f20470e4954013ab4a852191agxrqb&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=13115c5155550b065052&rr=9250ec2368e10e0f&cc=it},
	urldate = {2025-03-23},
}

@article{singhEffectivePlantDisease2024,
	title = {Effective plant disease diagnosis using {Vision} {Transformer} trained with leafy-generative adversarial network-generated images},
	volume = {254},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417424012533},
	doi = {10.1016/j.eswa.2024.124387},
	abstract = {Agriculture, as the foundation of human civilization, is critical to the global economy, providing food for billions. Plant diseases, caused by factors such as bacteria, fungi, viruses, and others, loom large over crop yields, jeopardizing farmers’ livelihoods worldwide. Rapid and accurate identification of these diseases is critical for agricultural productivity protection and to date, several automated plant disease diagnosis methods have been developed by researchers worldwide. However, the issue of having limited labeled datasets for certain plant leaf diseases poses a significant challenge in training classification models effectively. This scarcity often results in class imbalance which adversely affects a model’s ability to accurately predict all the disease classes. It appears there is a need to explore synthetic data generation techniques to train the model for making a better prediction. Further, the disease prediction model should be lightweight so that it can be conveniently integrated with low-end devices with less computational power that farmers can afford to purchase. In this work, we aim to develop an effective neural augmentation model that can render synthetic disease patterns on uninfected leaf images thereby enhancing the leaf disease dataset by adding artificial samples corresponding to those disease classes for which only minor ground truth information is available. Our work extends the state-of-the-art by introducing a new model for leaf disease augmentation, termed “LeafyGAN”, that comprises two key elements: a segmentation model and a disease translation model, both of which are GAN-based. The segmentation model is a pix2pix GAN that is trained to separate foreground leaf images from the background and is trained using a combination of L1 loss and standard GAN loss. The disease translation model is a CycleGAN which is trained using a combination of adversarial loss and cycle consistency loss, which uses the generated segmented mask to render synthetic disease patterns to the extracted leaf regions. A lightweight MobileViT model trained using this augmented data has been seen to perform disease diagnosis with a remarkable accuracy of 99.92\% on the PlantVillage dataset and 75.72\% on the PlantDoc dataset. Notably, our model achieves an accuracy that is comparable with the recent CNN and Transformer-based models with a significantly lesser number of parameters.},
	urldate = {2025-03-23},
	journal = {Expert Systems with Applications},
	author = {Singh, Aadarsh Kumar and Rao, Akhil and Chattopadhyay, Pratik and Maurya, Rahul and Singh, Lokesh},
	month = nov,
	year = {2024},
	keywords = {Disease pattern generation, Generative adversarial networks, Lightweight Vision Transformers, Plant disease diagnosis},
	pages = {124387},
}

@article{vallabhajosyulaNovelHierarchicalFramework2024,
	title = {A novel hierarchical framework for plant leaf disease detection using residual vision transformer},
	volume = {10},
	issn = {2405-8440},
	url = {https://www.sciencedirect.com/science/article/pii/S2405844024059437},
	doi = {10.1016/j.heliyon.2024.e29912},
	abstract = {Early detection of plant leaf diseases accurately and promptly is very crucial for safeguarding agricultural crop productivity and ensuring food security. During their life cycle, plant leaves get diseased because of multiple factors like bacteria, fungi, weather conditions, etc. In this work, the authors propose a model that aids in the early detection of leaf diseases using a novel hierarchical residual vision transformer using improved Vision Transformer and ResNet9 models. The proposed model can extract more meaningful and discriminating details by reducing the number of trainable parameters with a smaller number of computations. The proposed method is evaluated on the Local Crop dataset, Plant Village dataset, and Extended Plant Village Dataset with 13, 38, and 51 different leaf disease classes. The proposed model is trained using the best trail parameters of Improved Vision Transformer and classified the features using ResNet 9. Performance evaluation is carried out on a wide aspects over the aforementioned datasets and results revealed that the proposed model outperforms other models such as InceptionV3, MobileNetV2, and ResNet50.},
	number = {9},
	urldate = {2025-03-23},
	journal = {Heliyon},
	author = {Vallabhajosyula, Sasikala and Sistla, Venkatramaphanikumar and Kolli, Venkata Krishna Kishore},
	month = may,
	year = {2024},
	keywords = {Deep leaning, Inception V3, MobileNetV2, Plant leaf disease detection, Vision transformer},
	pages = {e29912},
}

@misc{katafuchiImagebasedPlantDisease2021,
	title = {Image-based {Plant} {Disease} {Diagnosis} with {Unsupervised} {Anomaly} {Detection} {Based} on {Reconstructability} of {Colors}},
	url = {http://arxiv.org/abs/2011.14306},
	doi = {10.48550/arXiv.2011.14306},
	abstract = {This paper proposes an unsupervised anomaly detection technique for image-based plant disease diagnosis. The construction of large and publicly available datasets containing labeled images of healthy and diseased crop plants led to growing interest in computer vision techniques for automatic plant disease diagnosis. Although supervised image classifiers based on deep learning can be a powerful tool for plant disease diagnosis, they require a huge amount of labeled data. The data mining technique of anomaly detection includes unsupervised approaches that do not require rare samples for training classifiers. We propose an unsupervised anomaly detection technique for image-based plant disease diagnosis that is based on the reconstructability of colors; a deep encoder-decoder network trained to reconstruct the colors of {\textbackslash}textit\{healthy\} plant images should fail to reconstruct colors of symptomatic regions. Our proposed method includes a new image-based framework for plant disease detection that utilizes a conditional adversarial network called pix2pix and a new anomaly score based on CIEDE2000 color difference. Experiments with PlantVillage dataset demonstrated the superiority of our proposed method compared to an existing anomaly detector at identifying diseased crop images in terms of accuracy, interpretability and computational efficiency.},
	urldate = {2025-03-23},
	publisher = {arXiv},
	author = {Katafuchi, Ryoya and Tokunaga, Terumasa},
	month = sep,
	year = {2021},
	note = {arXiv:2011.14306 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{bumbacaSupportingScreeningNew2024,
	title = {Supporting {Screening} of {New} {Plant} {Protection} {Products} through a {Multispectral} {Photogrammetric} {Approach} {Integrated} with {AI}},
	volume = {14},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2073-4395},
	url = {https://www.mdpi.com/2073-4395/14/2/306},
	doi = {10.3390/agronomy14020306},
	abstract = {This work was aimed at developing a prototype system based on multispectral digital photogrammetry to support tests required by international regulations for new Plant Protection Products (PPPs). In particular, the goal was to provide a system addressing the challenges of a new PPP evaluation with a higher degree of objectivity with respect to the current one, which relies on expert evaluations. The system uses Digital Photogrammetry, which is applied to multispectral acquisitions and Artificial Intelligence (AI). The goal of this paper is also to simplify the present screening process, moving it towards more objective and quantitative scores about phytotoxicity. The implementation of an opportunely trained AI model for phytotoxicity prediction aims to convert ordinary human visual observations, which are presently provided with a discrete scale (forbidding a variance analysis), into a continuous variable. The technical design addresses the need for a reduced dataset for training the AI model and relating discrete observations, as usually performed, to some proxy variables derived from the photogrammetric multispectral 3D model. To achieve this task, an appropriate photogrammetric multispectral system was designed. The system operates in multi-nadiral-view mode over a bench within a greenhouse exploiting an active system for lighting providing uniform and diffuse illumination. The whole system is intended to reduce the environmental variability of acquisitions tending to a standard situation. The methodology combines advanced image processing, image radiometric calibration, and machine learning techniques to predict the General Phytotoxicity percentage index (PHYGEN), a crucial measure of phytotoxicity. Results show that the system can generate reliable estimates of PHYGEN, compliant with existing accuracy standards (even from previous PPPs symptom severity models), using limited training datasets. The proposed solution addressing this challenge is the adoption of the Logistic Function with LASSO model regularization that has been shown to overcome the limitations of a small sample size (typical of new PPP trials). Additionally, it provides the estimate of a numerical continuous index (a percentage), which makes it possible to tackle the objectivity problem related to human visual evaluation that is presently based on an ordinal discrete scale. In our opinion, the proposed prototype system could have significant potential in improving the screening process for new PPPs. In fact, it works specifically for new PPPs screening and, despite this, it has an accuracy consistent with the one ordinarily accepted for human visual approaches. Additionally, it provides a higher degree of objectivity and repeatability.},
	language = {en},
	number = {2},
	urldate = {2025-03-23},
	journal = {Agronomy},
	author = {Bumbaca, Samuele and Borgogno-Mondino, Enrico},
	month = feb,
	year = {2024},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {machine learning, computer vision, diagnostic, digitalization, plant protection product},
	pages = {306},
}
